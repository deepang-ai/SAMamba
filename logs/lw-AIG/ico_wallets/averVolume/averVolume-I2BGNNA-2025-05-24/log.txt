Namespace(seed=15, model='I2BGNNA', dataset='ico_wallets/averVolume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/ico_wallets/averVolume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 342], edge_attr=[342, 2], x=[99, 14887], y=[1, 1], num_nodes=99)
Data(edge_index=[2, 342], edge_attr=[342, 2], x=[99, 14887], y=[1, 1], num_nodes=99)
Data(edge_index=[2, 306], edge_attr=[306, 2], x=[90, 14887], y=[1, 1], num_nodes=99)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e436a5960>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6944;  Loss pred: 0.6944; Loss self: 0.0000; time: 0.29s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.06s
Epoch 2/1000, LR 0.000000
Train loss: 0.6955;  Loss pred: 0.6955; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6947;  Loss pred: 0.6947; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6942;  Loss pred: 0.6942; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6881;  Loss pred: 0.6881; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6859;  Loss pred: 0.6859; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6801;  Loss pred: 0.6801; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6777;  Loss pred: 0.6777; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6753;  Loss pred: 0.6753; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6695;  Loss pred: 0.6695; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6641;  Loss pred: 0.6641; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6594;  Loss pred: 0.6594; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6548;  Loss pred: 0.6548; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6471;  Loss pred: 0.6471; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6384;  Loss pred: 0.6384; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6313;  Loss pred: 0.6313; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6260;  Loss pred: 0.6260; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4898 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6155;  Loss pred: 0.6155; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6103;  Loss pred: 0.6103; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6017;  Loss pred: 0.6017; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4898 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5948;  Loss pred: 0.5948; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5849;  Loss pred: 0.5849; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5710;  Loss pred: 0.5710; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5668;  Loss pred: 0.5668; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4898 time: 0.06s
Epoch 27/1000, LR 0.000270
Train loss: 0.5547;  Loss pred: 0.5547; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.4898 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5440;  Loss pred: 0.5440; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.4898 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5324;  Loss pred: 0.5324; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.4898 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5199;  Loss pred: 0.5199; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.4898 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5107;  Loss pred: 0.5107; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.4898 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4926;  Loss pred: 0.4926; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6872 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.4898 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4838;  Loss pred: 0.4838; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6862 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.4898 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4699;  Loss pred: 0.4699; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6852 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6881 score: 0.4898 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4597;  Loss pred: 0.4597; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6840 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.4898 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4435;  Loss pred: 0.4435; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6826 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6861 score: 0.4898 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4326;  Loss pred: 0.4326; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6811 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6849 score: 0.4898 time: 0.06s
Epoch 38/1000, LR 0.000270
Train loss: 0.4193;  Loss pred: 0.4193; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6793 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6835 score: 0.4898 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3952;  Loss pred: 0.3952; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6774 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6820 score: 0.4898 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3868;  Loss pred: 0.3868; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6753 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6804 score: 0.4898 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3800;  Loss pred: 0.3800; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6730 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6786 score: 0.4898 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3548;  Loss pred: 0.3548; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6705 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6767 score: 0.4898 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3453;  Loss pred: 0.3453; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6678 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6746 score: 0.4898 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3267;  Loss pred: 0.3267; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6648 score: 0.5102 time: 0.07s
Test loss: 0.6723 score: 0.5102 time: 0.06s
Epoch 45/1000, LR 0.000269
Train loss: 0.3243;  Loss pred: 0.3243; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6614 score: 0.5102 time: 0.08s
Test loss: 0.6697 score: 0.5102 time: 0.20s
Epoch 46/1000, LR 0.000269
Train loss: 0.2914;  Loss pred: 0.2914; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6576 score: 0.5102 time: 0.07s
Test loss: 0.6668 score: 0.5102 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2900;  Loss pred: 0.2900; Loss self: 0.0000; time: 0.11s
Val loss: 0.6534 score: 0.5306 time: 0.07s
Test loss: 0.6636 score: 0.5510 time: 0.06s
Epoch 48/1000, LR 0.000269
Train loss: 0.2799;  Loss pred: 0.2799; Loss self: 0.0000; time: 0.11s
Val loss: 0.6489 score: 0.5918 time: 0.07s
Test loss: 0.6602 score: 0.5918 time: 0.06s
Epoch 49/1000, LR 0.000269
Train loss: 0.2621;  Loss pred: 0.2621; Loss self: 0.0000; time: 0.12s
Val loss: 0.6442 score: 0.5918 time: 0.08s
Test loss: 0.6567 score: 0.6327 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2391;  Loss pred: 0.2391; Loss self: 0.0000; time: 0.12s
Val loss: 0.6392 score: 0.6122 time: 0.08s
Test loss: 0.6528 score: 0.6327 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2268;  Loss pred: 0.2268; Loss self: 0.0000; time: 0.12s
Val loss: 0.6340 score: 0.7347 time: 0.08s
Test loss: 0.6487 score: 0.6327 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2179;  Loss pred: 0.2179; Loss self: 0.0000; time: 0.12s
Val loss: 0.6284 score: 0.7347 time: 0.08s
Test loss: 0.6443 score: 0.6327 time: 0.17s
Epoch 53/1000, LR 0.000269
Train loss: 0.2009;  Loss pred: 0.2009; Loss self: 0.0000; time: 0.12s
Val loss: 0.6223 score: 0.7959 time: 0.08s
Test loss: 0.6395 score: 0.6735 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1943;  Loss pred: 0.1943; Loss self: 0.0000; time: 0.13s
Val loss: 0.6159 score: 0.8163 time: 0.08s
Test loss: 0.6344 score: 0.6939 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1765;  Loss pred: 0.1765; Loss self: 0.0000; time: 0.12s
Val loss: 0.6089 score: 0.8367 time: 0.08s
Test loss: 0.6289 score: 0.7143 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1648;  Loss pred: 0.1648; Loss self: 0.0000; time: 0.12s
Val loss: 0.6016 score: 0.8367 time: 0.08s
Test loss: 0.6232 score: 0.7347 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1573;  Loss pred: 0.1573; Loss self: 0.0000; time: 0.12s
Val loss: 0.5938 score: 0.8776 time: 0.08s
Test loss: 0.6170 score: 0.7551 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1454;  Loss pred: 0.1454; Loss self: 0.0000; time: 0.12s
Val loss: 0.5854 score: 0.8980 time: 0.08s
Test loss: 0.6102 score: 0.7959 time: 0.20s
Epoch 59/1000, LR 0.000268
Train loss: 0.1401;  Loss pred: 0.1401; Loss self: 0.0000; time: 0.12s
Val loss: 0.5765 score: 0.9184 time: 0.09s
Test loss: 0.6030 score: 0.8367 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1314;  Loss pred: 0.1314; Loss self: 0.0000; time: 0.12s
Val loss: 0.5671 score: 0.9184 time: 0.09s
Test loss: 0.5953 score: 0.8367 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.1156;  Loss pred: 0.1156; Loss self: 0.0000; time: 0.12s
Val loss: 0.5570 score: 0.9184 time: 0.08s
Test loss: 0.5873 score: 0.8367 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1075;  Loss pred: 0.1075; Loss self: 0.0000; time: 0.12s
Val loss: 0.5462 score: 0.9184 time: 0.07s
Test loss: 0.5786 score: 0.8571 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1005;  Loss pred: 0.1005; Loss self: 0.0000; time: 0.12s
Val loss: 0.5344 score: 0.9184 time: 0.07s
Test loss: 0.5692 score: 0.8571 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0935;  Loss pred: 0.0935; Loss self: 0.0000; time: 0.12s
Val loss: 0.5220 score: 0.9184 time: 0.07s
Test loss: 0.5594 score: 0.8571 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0827;  Loss pred: 0.0827; Loss self: 0.0000; time: 0.24s
Val loss: 0.5086 score: 0.9184 time: 0.07s
Test loss: 0.5489 score: 0.8571 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0747;  Loss pred: 0.0747; Loss self: 0.0000; time: 0.12s
Val loss: 0.4946 score: 0.9184 time: 0.08s
Test loss: 0.5380 score: 0.8367 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0691;  Loss pred: 0.0691; Loss self: 0.0000; time: 0.12s
Val loss: 0.4796 score: 0.9184 time: 0.08s
Test loss: 0.5264 score: 0.8571 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0638;  Loss pred: 0.0638; Loss self: 0.0000; time: 0.12s
Val loss: 0.4640 score: 0.9184 time: 0.08s
Test loss: 0.5145 score: 0.8571 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0589;  Loss pred: 0.0589; Loss self: 0.0000; time: 0.12s
Val loss: 0.4477 score: 0.9388 time: 0.08s
Test loss: 0.5022 score: 0.8776 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0539;  Loss pred: 0.0539; Loss self: 0.0000; time: 0.12s
Val loss: 0.4307 score: 0.9592 time: 0.08s
Test loss: 0.4895 score: 0.8776 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0472;  Loss pred: 0.0472; Loss self: 0.0000; time: 0.12s
Val loss: 0.4135 score: 0.9592 time: 0.10s
Test loss: 0.4767 score: 0.8776 time: 0.11s
Epoch 72/1000, LR 0.000267
Train loss: 0.0441;  Loss pred: 0.0441; Loss self: 0.0000; time: 0.12s
Val loss: 0.3961 score: 0.9592 time: 0.08s
Test loss: 0.4639 score: 0.8776 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0398;  Loss pred: 0.0398; Loss self: 0.0000; time: 0.12s
Val loss: 0.3784 score: 0.9592 time: 0.08s
Test loss: 0.4510 score: 0.8776 time: 0.06s
Epoch 74/1000, LR 0.000267
Train loss: 0.0373;  Loss pred: 0.0373; Loss self: 0.0000; time: 0.12s
Val loss: 0.3606 score: 0.9592 time: 0.07s
Test loss: 0.4383 score: 0.8776 time: 0.06s
Epoch 75/1000, LR 0.000267
Train loss: 0.0327;  Loss pred: 0.0327; Loss self: 0.0000; time: 0.11s
Val loss: 0.3427 score: 0.9592 time: 0.07s
Test loss: 0.4257 score: 0.8776 time: 0.06s
Epoch 76/1000, LR 0.000267
Train loss: 0.0309;  Loss pred: 0.0309; Loss self: 0.0000; time: 0.12s
Val loss: 0.3248 score: 0.9592 time: 0.07s
Test loss: 0.4134 score: 0.8776 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0278;  Loss pred: 0.0278; Loss self: 0.0000; time: 0.12s
Val loss: 0.3070 score: 0.9592 time: 0.07s
Test loss: 0.4014 score: 0.8776 time: 0.06s
Epoch 78/1000, LR 0.000267
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.11s
Val loss: 0.2900 score: 0.9592 time: 0.07s
Test loss: 0.3902 score: 0.8776 time: 0.06s
Epoch 79/1000, LR 0.000267
Train loss: 0.0227;  Loss pred: 0.0227; Loss self: 0.0000; time: 0.16s
Val loss: 0.2734 score: 0.9592 time: 0.07s
Test loss: 0.3796 score: 0.8776 time: 0.06s
Epoch 80/1000, LR 0.000267
Train loss: 0.0207;  Loss pred: 0.0207; Loss self: 0.0000; time: 0.11s
Val loss: 0.2574 score: 0.9592 time: 0.07s
Test loss: 0.3698 score: 0.8776 time: 0.06s
Epoch 81/1000, LR 0.000267
Train loss: 0.0190;  Loss pred: 0.0190; Loss self: 0.0000; time: 0.11s
Val loss: 0.2422 score: 0.9592 time: 0.07s
Test loss: 0.3607 score: 0.8776 time: 0.06s
Epoch 82/1000, LR 0.000267
Train loss: 0.0178;  Loss pred: 0.0178; Loss self: 0.0000; time: 0.11s
Val loss: 0.2280 score: 0.9592 time: 0.07s
Test loss: 0.3527 score: 0.8776 time: 0.06s
Epoch 83/1000, LR 0.000266
Train loss: 0.0158;  Loss pred: 0.0158; Loss self: 0.0000; time: 0.12s
Val loss: 0.2145 score: 0.9592 time: 0.07s
Test loss: 0.3455 score: 0.8776 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.12s
Val loss: 0.2018 score: 0.9592 time: 0.07s
Test loss: 0.3393 score: 0.8776 time: 0.06s
Epoch 85/1000, LR 0.000266
Train loss: 0.0157;  Loss pred: 0.0157; Loss self: 0.0000; time: 0.12s
Val loss: 0.1900 score: 0.9592 time: 0.07s
Test loss: 0.3337 score: 0.8776 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0128;  Loss pred: 0.0128; Loss self: 0.0000; time: 0.16s
Val loss: 0.1792 score: 0.9592 time: 0.07s
Test loss: 0.3292 score: 0.8776 time: 0.06s
Epoch 87/1000, LR 0.000266
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.11s
Val loss: 0.1692 score: 0.9592 time: 0.07s
Test loss: 0.3255 score: 0.8776 time: 0.06s
Epoch 88/1000, LR 0.000266
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.11s
Val loss: 0.1599 score: 0.9592 time: 0.07s
Test loss: 0.3226 score: 0.8776 time: 0.06s
Epoch 89/1000, LR 0.000266
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.11s
Val loss: 0.1517 score: 0.9592 time: 0.07s
Test loss: 0.3207 score: 0.8776 time: 0.06s
Epoch 90/1000, LR 0.000266
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.12s
Val loss: 0.1443 score: 0.9592 time: 0.08s
Test loss: 0.3197 score: 0.8776 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.12s
Val loss: 0.1379 score: 0.9592 time: 0.07s
Test loss: 0.3195 score: 0.8776 time: 0.06s
Epoch 92/1000, LR 0.000266
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.11s
Val loss: 0.1321 score: 0.9592 time: 0.07s
Test loss: 0.3201 score: 0.8776 time: 0.06s
Epoch 93/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.13s
Val loss: 0.1268 score: 0.9592 time: 0.14s
Test loss: 0.3210 score: 0.8776 time: 0.06s
Epoch 94/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.12s
Val loss: 0.1220 score: 0.9592 time: 0.07s
Test loss: 0.3226 score: 0.8776 time: 0.06s
Epoch 95/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.1178 score: 0.9388 time: 0.07s
Test loss: 0.3247 score: 0.8776 time: 0.06s
Epoch 96/1000, LR 0.000265
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.11s
Val loss: 0.1141 score: 0.9388 time: 0.07s
Test loss: 0.3275 score: 0.8776 time: 0.06s
Epoch 97/1000, LR 0.000265
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.11s
Val loss: 0.1110 score: 0.9388 time: 0.08s
Test loss: 0.3308 score: 0.8776 time: 0.06s
Epoch 98/1000, LR 0.000265
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.12s
Val loss: 0.1080 score: 0.9388 time: 0.07s
Test loss: 0.3342 score: 0.8776 time: 0.06s
Epoch 99/1000, LR 0.000265
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.11s
Val loss: 0.1056 score: 0.9388 time: 0.07s
Test loss: 0.3382 score: 0.8776 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.14s
Val loss: 0.1035 score: 0.9388 time: 0.08s
Test loss: 0.3422 score: 0.8776 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.12s
Val loss: 0.1017 score: 0.9388 time: 0.07s
Test loss: 0.3465 score: 0.8776 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.1003 score: 0.9388 time: 0.08s
Test loss: 0.3512 score: 0.8776 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.12s
Val loss: 0.0989 score: 0.9388 time: 0.07s
Test loss: 0.3558 score: 0.8776 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.12s
Val loss: 0.0978 score: 0.9388 time: 0.08s
Test loss: 0.3605 score: 0.8776 time: 0.07s
Epoch 105/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.0969 score: 0.9388 time: 0.07s
Test loss: 0.3652 score: 0.8776 time: 0.06s
Epoch 106/1000, LR 0.000264
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.11s
Val loss: 0.0960 score: 0.9388 time: 0.07s
Test loss: 0.3697 score: 0.8776 time: 0.06s
Epoch 107/1000, LR 0.000264
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.13s
Val loss: 0.0951 score: 0.9388 time: 0.15s
Test loss: 0.3741 score: 0.8776 time: 0.06s
Epoch 108/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.0945 score: 0.9388 time: 0.07s
Test loss: 0.3786 score: 0.8776 time: 0.07s
Epoch 109/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.11s
Val loss: 0.0939 score: 0.9388 time: 0.07s
Test loss: 0.3829 score: 0.8776 time: 0.06s
Epoch 110/1000, LR 0.000263
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.11s
Val loss: 0.0932 score: 0.9388 time: 0.07s
Test loss: 0.3870 score: 0.8571 time: 0.06s
Epoch 111/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.0925 score: 0.9388 time: 0.08s
Test loss: 0.3912 score: 0.8571 time: 0.07s
Epoch 112/1000, LR 0.000263
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.12s
Val loss: 0.0920 score: 0.9388 time: 0.08s
Test loss: 0.3952 score: 0.8571 time: 0.07s
Epoch 113/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.12s
Val loss: 0.0914 score: 0.9388 time: 0.07s
Test loss: 0.3988 score: 0.8571 time: 0.07s
Epoch 114/1000, LR 0.000263
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.13s
Val loss: 0.0908 score: 0.9388 time: 0.09s
Test loss: 0.4023 score: 0.8571 time: 0.06s
Epoch 115/1000, LR 0.000263
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.12s
Val loss: 0.0906 score: 0.9388 time: 0.07s
Test loss: 0.4059 score: 0.8571 time: 0.06s
Epoch 116/1000, LR 0.000263
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.11s
Val loss: 0.0902 score: 0.9388 time: 0.07s
Test loss: 0.4091 score: 0.8571 time: 0.06s
Epoch 117/1000, LR 0.000262
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.0899 score: 0.9388 time: 0.07s
Test loss: 0.4122 score: 0.8571 time: 0.06s
Epoch 118/1000, LR 0.000262
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.0897 score: 0.9388 time: 0.07s
Test loss: 0.4155 score: 0.8571 time: 0.07s
Epoch 119/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.12s
Val loss: 0.0894 score: 0.9388 time: 0.08s
Test loss: 0.4185 score: 0.8571 time: 0.07s
Epoch 120/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.11s
Val loss: 0.0893 score: 0.9388 time: 0.07s
Test loss: 0.4213 score: 0.8571 time: 0.07s
Epoch 121/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.12s
Val loss: 0.0890 score: 0.9388 time: 0.07s
Test loss: 0.4240 score: 0.8571 time: 0.20s
Epoch 122/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.12s
Val loss: 0.0890 score: 0.9388 time: 0.07s
Test loss: 0.4266 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.12s
Val loss: 0.0890 score: 0.9388 time: 0.07s
Test loss: 0.4289 score: 0.8571 time: 0.07s
Epoch 124/1000, LR 0.000261
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.12s
Val loss: 0.0890 score: 0.9388 time: 0.07s
Test loss: 0.4315 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 125/1000, LR 0.000261
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.12s
Val loss: 0.0892 score: 0.9388 time: 0.08s
Test loss: 0.4340 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 126/1000, LR 0.000261
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.0893 score: 0.9388 time: 0.08s
Test loss: 0.4363 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 127/1000, LR 0.000261
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.12s
Val loss: 0.0893 score: 0.9388 time: 0.08s
Test loss: 0.4385 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 128/1000, LR 0.000261
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.0893 score: 0.9388 time: 0.17s
Test loss: 0.4404 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 129/1000, LR 0.000261
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.12s
Val loss: 0.0895 score: 0.9388 time: 0.08s
Test loss: 0.4426 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 130/1000, LR 0.000260
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.12s
Val loss: 0.0895 score: 0.9388 time: 0.07s
Test loss: 0.4443 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 7 of 20
Epoch 131/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.12s
Val loss: 0.0895 score: 0.9388 time: 0.07s
Test loss: 0.4458 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 132/1000, LR 0.000260
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.12s
Val loss: 0.0897 score: 0.9388 time: 0.07s
Test loss: 0.4474 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 133/1000, LR 0.000260
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.12s
Val loss: 0.0901 score: 0.9388 time: 0.07s
Test loss: 0.4494 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 134/1000, LR 0.000260
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.12s
Val loss: 0.0899 score: 0.9388 time: 0.07s
Test loss: 0.4510 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 11 of 20
Epoch 135/1000, LR 0.000260
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.12s
Val loss: 0.0898 score: 0.9388 time: 0.07s
Test loss: 0.4523 score: 0.8571 time: 0.10s
     INFO: Early stopping counter 12 of 20
Epoch 136/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.15s
Val loss: 0.0899 score: 0.9388 time: 0.07s
Test loss: 0.4537 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 13 of 20
Epoch 137/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.12s
Val loss: 0.0899 score: 0.9388 time: 0.07s
Test loss: 0.4550 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 14 of 20
Epoch 138/1000, LR 0.000259
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.12s
Val loss: 0.0901 score: 0.9388 time: 0.07s
Test loss: 0.4562 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 15 of 20
Epoch 139/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.12s
Val loss: 0.0903 score: 0.9388 time: 0.07s
Test loss: 0.4577 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 16 of 20
Epoch 140/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.12s
Val loss: 0.0901 score: 0.9388 time: 0.07s
Test loss: 0.4585 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 141/1000, LR 0.000259
Train loss: 0.0016;  Loss pred: 0.0016; Loss self: 0.0000; time: 0.12s
Val loss: 0.0899 score: 0.9388 time: 0.08s
Test loss: 0.4594 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 18 of 20
Epoch 142/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.12s
Val loss: 0.0899 score: 0.9388 time: 0.07s
Test loss: 0.4604 score: 0.8571 time: 0.06s
     INFO: Early stopping counter 19 of 20
Epoch 143/1000, LR 0.000258
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.11s
Val loss: 0.0898 score: 0.9388 time: 0.17s
Test loss: 0.4614 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 122,   Train_Loss: 0.0026,   Val_Loss: 0.0890,   Val_Precision: 0.9565,   Val_Recall: 0.9167,   Val_accuracy: 0.9362,   Val_Score: 0.9388,   Val_Loss: 0.0890,   Test_Precision: 0.9091,   Test_Recall: 0.8000,   Test_accuracy: 0.8511,   Test_Score: 0.8571,   Test_loss: 0.4289


[0.06820148101542145, 0.07054007903207093, 0.07046255201566964, 0.07266960002016276, 0.07209534605499357, 0.07170149800367653, 0.07169011002406478, 0.07288669503759593, 0.07160780590493232, 0.07222241989802569, 0.07214544899761677, 0.07146997097879648, 0.07103432400617748, 0.07177042402327061, 0.0717611969448626, 0.07062257395591587, 0.0708327810280025, 0.07042577606625855, 0.07087301404681057, 0.07058697706088424, 0.07208934891968966, 0.07011432503350079, 0.07026386505458504, 0.07010347594041377, 0.07050372299272567, 0.06977482896763831, 0.07121941691730171, 0.07119734899606556, 0.07026722200680524, 0.0700958879897371, 0.07019805791787803, 0.07420337910298258, 0.07079684396740049, 0.07042647700291127, 0.07387233292683959, 0.07046048296615481, 0.0699759719427675, 0.0704453750513494, 0.0711399350548163, 0.07079007802531123, 0.0708161280490458, 0.07142506504897028, 0.07125964399892837, 0.0685480599058792, 0.2085472169565037, 0.07159148703794926, 0.06857560796197504, 0.06972219899762422, 0.07158694905228913, 0.07968426507432014, 0.07600058510433882, 0.1773902300046757, 0.07373767299577594, 0.07454095699358732, 0.07656385097652674, 0.07573397399391979, 0.07575756090227515, 0.2070517399115488, 0.08570832293480635, 0.08323100302368402, 0.07250858109910041, 0.07170012698043138, 0.07113833900075406, 0.07134313008282334, 0.07252505701035261, 0.07311598095111549, 0.07411441102158278, 0.0741470989305526, 0.07278633897658437, 0.07233011408243328, 0.1108005850110203, 0.07045415393076837, 0.06753928295802325, 0.06693291699048132, 0.06758643500506878, 0.07073295000009239, 0.06778313301037997, 0.07017476600594819, 0.06911636108998209, 0.06877440703101456, 0.06904147402383387, 0.06860998703632504, 0.07044190797023475, 0.06900080700870603, 0.07072270999196917, 0.06849582202266902, 0.06750739202834666, 0.06839234905783087, 0.06951158202718943, 0.07145558693446219, 0.06753922998905182, 0.06683529005385935, 0.06873603409621865, 0.06868523196317255, 0.06818902201484889, 0.06907923298422247, 0.06976252293679863, 0.06841126305516809, 0.07093714107759297, 0.07031746907159686, 0.07014903798699379, 0.07063400198239833, 0.07065761799458414, 0.07197518495377153, 0.06943469599355012, 0.06890112196560949, 0.06947511108592153, 0.07004226895514876, 0.06972356210462749, 0.06945207901299, 0.07177192298695445, 0.06998531997669488, 0.0705314779188484, 0.06819406594149768, 0.07170714600943029, 0.06848222389817238, 0.06879002403002232, 0.07138611597474664, 0.07105582696385682, 0.07396040193270892, 0.20393796893768013, 0.07224884198512882, 0.0739267299650237, 0.07388043403625488, 0.07554030499886721, 0.07324156002141535, 0.07308615406509489, 0.07161813706625253, 0.07159566297195852, 0.06939418206457049, 0.07025386590976268, 0.07078105490654707, 0.0701173460111022, 0.06945740303490311, 0.10454746300820261, 0.06808268604800105, 0.06849769095424563, 0.06949065206572413, 0.06923470203764737, 0.07088353391736746, 0.06961730890907347, 0.0695736410561949, 0.07714406796731055]
[0.001391866959498397, 0.0014395934496341006, 0.0014380112656259111, 0.0014830530616359748, 0.0014713335929590525, 0.0014632958776260518, 0.0014630634698788731, 0.0014874835721958354, 0.0014613837939782106, 0.001473926936694402, 0.001472356101992179, 0.001458570836301969, 0.0014496800817587242, 0.0014647025310871552, 0.0014645142233645429, 0.0014412770195084872, 0.001445566959755153, 0.0014372607360460929, 0.0014463880417716441, 0.0014405505522629436, 0.001471211202442646, 0.0014309045925204242, 0.001433956429685409, 0.001430683182457424, 0.0014388514896474627, 0.0014239761013803737, 0.0014534574881081982, 0.001453007122368685, 0.0014340249389143927, 0.001430528326321165, 0.00143261342689547, 0.0015143546755710731, 0.0014448335503551121, 0.0014372750408757403, 0.0015075986311599916, 0.0014379690401256084, 0.0014280810600564796, 0.0014376607153336613, 0.0014518354092819654, 0.001444695469904311, 0.001445227103041751, 0.0014576543887544955, 0.0014542784489577217, 0.0013989399980791674, 0.004256065652173545, 0.0014610507558765157, 0.001399502203305613, 0.001422902020359678, 0.001460958143924268, 0.001626209491312656, 0.0015510323490681393, 0.0036202087756056264, 0.0015048504693015497, 0.0015212440202772922, 0.0015625275709495253, 0.001545591305998363, 0.0015460726714750029, 0.004225545712480587, 0.0017491494476491092, 0.001698591898442531, 0.0014797669612061307, 0.001463267897559824, 0.0014518028367500827, 0.0014559822465882314, 0.0014801032042929105, 0.0014921628765533774, 0.001512539000440465, 0.0015132061006235225, 0.0014854354893180485, 0.001476124777192516, 0.002261236428796333, 0.00143783987613813, 0.0013783527134290459, 0.0013659778977649249, 0.0013793150001034445, 0.0014435295918386202, 0.0013833292451097953, 0.0014321380817540446, 0.001410537981428206, 0.0014035593271635625, 0.0014090096739557932, 0.0014002038170678579, 0.0014375899585762195, 0.0014081797348715517, 0.0014433206120810034, 0.00139787391882998, 0.0013777018781295236, 0.0013957622256700177, 0.0014186037148406006, 0.0014582772843767793, 0.001378351632429629, 0.0013639855113032522, 0.0014027762060452784, 0.001401739427819848, 0.0013916126941805895, 0.001409780264984132, 0.0014237249578938497, 0.0013961482256156753, 0.0014476967566855708, 0.0014350503892162625, 0.0014316130201427303, 0.0014415102445387415, 0.001441992203971105, 0.0014688813255871742, 0.0014170346121132678, 0.0014061453462369284, 0.001417859409916766, 0.0014294340603091583, 0.0014229298388699488, 0.0014173893676120409, 0.001464733122182744, 0.0014282718362590792, 0.0014394179167111917, 0.0013917156314591365, 0.0014634111430495977, 0.0013975964060851506, 0.001403878041429027, 0.001456859509688707, 0.001450118917629731, 0.001509395957810386, 0.004161999366075105, 0.0014744661629618127, 0.001508708774796402, 0.001507763959923569, 0.0015416388775279022, 0.0014947257147227622, 0.0014915541645937733, 0.0014615946340051536, 0.0014611359790195615, 0.0014162077972361324, 0.0014337523655053607, 0.0014445113246234096, 0.0014309662451245347, 0.0014174980211204716, 0.0021336216940449513, 0.0013894425724081847, 0.0013979120602907271, 0.0014181765727698803, 0.00141295310280913, 0.001446602733007499, 0.0014207614063076219, 0.0014198702256366306, 0.0015743687340267459]
[718.4594714141224, 694.6405599818257, 695.4048441092973, 674.2847075861786, 679.6555212124694, 683.3887905310918, 683.4973468941781, 672.2763321169268, 684.2829406762329, 678.4596814837478, 679.183519969758, 685.6026290333486, 689.8073668687088, 682.7324857954358, 682.8202717639859, 693.829143505685, 691.7700997879599, 695.7679806595162, 691.3773974341804, 694.1790403877961, 679.7120619661569, 698.8586137937958, 697.3712584972939, 698.9667679481228, 694.9987592152495, 702.2589768400046, 688.0146190595415, 688.2278721179323, 697.3379422236793, 699.0424318067588, 698.0250088588375, 660.3472859638337, 692.1212479833538, 695.7610558593532, 663.3065189443492, 695.4252644498165, 700.2403630788652, 695.5744073231589, 688.7833108400147, 692.1873992352415, 691.9327750602745, 686.0336769228664, 687.6262250304939, 714.826941379232, 234.95878158959005, 684.4389190299406, 714.5397825298223, 702.7890787218239, 684.4823064635569, 614.9269238324348, 644.7318784813226, 276.22716312340566, 664.5178510421256, 657.356733482982, 639.9887071383416, 647.0015689911361, 646.8001268310162, 236.65582342332644, 571.706437859852, 588.7229303971823, 675.7820834065104, 683.4018580381766, 688.7987643270756, 686.8215614189502, 675.6285623188891, 670.1681268936383, 661.1399770245865, 660.8485120354366, 673.2032506232175, 677.4495052524819, 442.2359321940983, 695.4877358707586, 725.5037047173611, 732.0762668533989, 724.9975530788855, 692.7464498502608, 722.8937026634102, 698.2566923820827, 708.949360574803, 712.4743362440468, 709.7183351427964, 714.1817411225762, 695.6086428082692, 710.1366219357047, 692.8467532644626, 715.3720993929121, 725.8464373712538, 716.4544086439671, 704.9184980545208, 685.7406411753631, 725.5042737079317, 733.1456175399741, 712.8720858612298, 713.3993523713027, 718.5907430866177, 709.3304005154702, 702.3828545362609, 716.2563269806246, 690.7523936776994, 696.8396423669411, 698.5127865771303, 693.7168874023388, 693.4850252630341, 680.7901922234988, 705.6990644065278, 711.1640362613731, 705.2885448344305, 699.5775655322777, 702.7753390807885, 705.5224364246211, 682.7182268601948, 700.1468310256637, 694.725269423364, 718.5375930221863, 683.3349634854517, 715.5141467493681, 712.3125873399132, 686.4079846749767, 689.5986169427638, 662.5166808122739, 240.2691379895695, 678.2115623401384, 662.8184423033853, 663.2337863087612, 648.6603410025257, 669.0190649362564, 670.4416264174699, 684.1842305206999, 684.3989980118148, 706.111067847245, 697.4705144758564, 692.2756387948044, 698.8285037520026, 705.4683569925147, 468.68664805530045, 719.7130848429366, 715.3525807567806, 705.1308131870153, 707.7375731805063, 691.2747896728991, 703.8479476993064, 704.2897174293711, 635.1752155559586]
Elapsed: 0.07518005450305014~0.02174521448280343
Time per graph: 0.00153428682659286~0.0004437798874041517
Speed: 674.5591059740404~81.20436884340876
Total Time: 0.0778
best val loss: 0.08896785974502563 test_score: 0.8571

Testing...
Test loss: 0.4895 score: 0.8776 time: 0.07s
test Score 0.8776
Epoch Time List: [0.4269473261665553, 0.25333308102563024, 0.25412796705495566, 0.2652982190484181, 0.27468802395742387, 0.25961347692646086, 0.2598321158438921, 0.26051825110334903, 0.26061901706270874, 0.25790083687752485, 0.25916229700669646, 0.2570972350658849, 0.25671734602656215, 0.26042358204722404, 0.26060515211429447, 0.2569717770675197, 0.25592819205485284, 0.2540595130994916, 0.25543231202755123, 0.2540585189126432, 0.2558621239149943, 0.25361194706056267, 0.25279555399902165, 0.2528341980651021, 0.25384680391289294, 0.2577593169407919, 0.2643336448818445, 0.25804819411132485, 0.2561864301096648, 0.25485508795827627, 0.2555139501346275, 0.25611838104669005, 0.2622958570718765, 0.25739872292615473, 0.2547132800100371, 0.25745510088745505, 0.253775681136176, 0.2599600012181327, 0.26379065902438015, 0.2579970830120146, 0.2611393529223278, 0.2671316539635882, 0.2598690538434312, 0.25199053389951587, 0.3944010949926451, 0.26697098196018487, 0.24389594595413655, 0.253520202008076, 0.2614180539967492, 0.2760192189598456, 0.27443650108762085, 0.37849338992964476, 0.267537759966217, 0.27805766102392226, 0.2755730369826779, 0.27738830901216716, 0.278378228074871, 0.4076352168340236, 0.28930948802735656, 0.2872702139429748, 0.26830877701286227, 0.25945253507234156, 0.2592718470841646, 0.25474974990356714, 0.38510407297872007, 0.2640180920716375, 0.266318507026881, 0.2692316179163754, 0.26876663602888584, 0.26289435708895326, 0.32215014402754605, 0.25775652192533016, 0.25698840094264597, 0.24485864606685936, 0.24731450621038675, 0.2538160680560395, 0.24832697492092848, 0.24497426091693342, 0.2948160788509995, 0.251008473103866, 0.2501027488615364, 0.2473090939456597, 0.2510957169579342, 0.2555118229938671, 0.251986016985029, 0.2941983670461923, 0.24519625713583082, 0.24981700698845088, 0.25327611388638616, 0.2571590510196984, 0.25120398099534214, 0.242032230948098, 0.33210902696009725, 0.2522523469524458, 0.24606381205376238, 0.25235421187244356, 0.2559921918436885, 0.24971599702257663, 0.25422659900505096, 0.2876001059776172, 0.25414309999905527, 0.2576894700760022, 0.25479288294445723, 0.26316244795452803, 0.2567206711973995, 0.25121319096069783, 0.34250901301857084, 0.2535397399915382, 0.2509522819891572, 0.2472211830317974, 0.2574277420062572, 0.2588816311908886, 0.25127073004841805, 0.2832103440305218, 0.24849731102585793, 0.25234804197680205, 0.250898061087355, 0.25085386692080647, 0.26244621409568936, 0.25428973499219865, 0.3897179609630257, 0.26067970297299325, 0.26574036106467247, 0.2630431829020381, 0.26981714193243533, 0.2748801599955186, 0.26611010206397623, 0.36772790108807385, 0.2658948239404708, 0.24963799898978323, 0.25276345503516495, 0.25572041515260935, 0.2595332800410688, 0.2532952941255644, 0.28413942200131714, 0.2837724540149793, 0.24879095412325114, 0.2539830489549786, 0.250952021102421, 0.255826850887388, 0.25999324407894164, 0.25449883099645376, 0.36166168085765094]
Total Epoch List: [143]
Total Time List: [0.07781030703336]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e4381c5e0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6924;  Loss pred: 0.6924; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6915;  Loss pred: 0.6915; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.11s
Epoch 4/1000, LR 0.000060
Train loss: 0.6912;  Loss pred: 0.6912; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6887;  Loss pred: 0.6887; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6825;  Loss pred: 0.6825; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6831;  Loss pred: 0.6831; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.08s
Epoch 9/1000, LR 0.000210
Train loss: 0.6786;  Loss pred: 0.6786; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6745;  Loss pred: 0.6745; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.08s
Epoch 11/1000, LR 0.000270
Train loss: 0.6696;  Loss pred: 0.6696; Loss self: 0.0000; time: 0.26s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6622;  Loss pred: 0.6622; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6574;  Loss pred: 0.6574; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.08s
Epoch 14/1000, LR 0.000270
Train loss: 0.6476;  Loss pred: 0.6476; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.08s
Epoch 15/1000, LR 0.000270
Train loss: 0.6417;  Loss pred: 0.6417; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.08s
Epoch 16/1000, LR 0.000270
Train loss: 0.6335;  Loss pred: 0.6335; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.08s
Epoch 17/1000, LR 0.000270
Train loss: 0.6286;  Loss pred: 0.6286; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4898 time: 0.08s
Epoch 18/1000, LR 0.000270
Train loss: 0.6248;  Loss pred: 0.6248; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 19/1000, LR 0.000270
Train loss: 0.6112;  Loss pred: 0.6112; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6022;  Loss pred: 0.6022; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.5946;  Loss pred: 0.5946; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4898 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.5807;  Loss pred: 0.5807; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4898 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.5721;  Loss pred: 0.5721; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4898 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.5597;  Loss pred: 0.5597; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4898 time: 0.08s
Epoch 25/1000, LR 0.000270
Train loss: 0.5465;  Loss pred: 0.5465; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.5373;  Loss pred: 0.5373; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4898 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5247;  Loss pred: 0.5247; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.4898 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5059;  Loss pred: 0.5059; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.4898 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.4974;  Loss pred: 0.4974; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.4898 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.4814;  Loss pred: 0.4814; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.4898 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.4668;  Loss pred: 0.4668; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.4898 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.4557;  Loss pred: 0.4557; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.4898 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.4407;  Loss pred: 0.4407; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.4898 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4227;  Loss pred: 0.4227; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6860 score: 0.4898 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4092;  Loss pred: 0.4092; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6849 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6846 score: 0.4898 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.3973;  Loss pred: 0.3973; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6836 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6830 score: 0.4898 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.3821;  Loss pred: 0.3821; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6821 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6812 score: 0.4898 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3721;  Loss pred: 0.3721; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6804 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6791 score: 0.4898 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3538;  Loss pred: 0.3538; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6785 score: 0.5102 time: 0.06s
Test loss: 0.6768 score: 0.5306 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3408;  Loss pred: 0.3408; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6764 score: 0.5102 time: 0.06s
Test loss: 0.6742 score: 0.5306 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3264;  Loss pred: 0.3264; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6740 score: 0.5102 time: 0.06s
Test loss: 0.6712 score: 0.5306 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3108;  Loss pred: 0.3108; Loss self: 0.0000; time: 0.12s
Val loss: 0.6713 score: 0.5306 time: 0.06s
Test loss: 0.6679 score: 0.5306 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.2976;  Loss pred: 0.2976; Loss self: 0.0000; time: 0.12s
Val loss: 0.6686 score: 0.5510 time: 0.06s
Test loss: 0.6645 score: 0.5306 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.2832;  Loss pred: 0.2832; Loss self: 0.0000; time: 0.12s
Val loss: 0.6654 score: 0.5714 time: 0.06s
Test loss: 0.6606 score: 0.5306 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2692;  Loss pred: 0.2692; Loss self: 0.0000; time: 0.12s
Val loss: 0.6619 score: 0.5918 time: 0.06s
Test loss: 0.6563 score: 0.5714 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2591;  Loss pred: 0.2591; Loss self: 0.0000; time: 0.12s
Val loss: 0.6581 score: 0.5918 time: 0.06s
Test loss: 0.6514 score: 0.5714 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2473;  Loss pred: 0.2473; Loss self: 0.0000; time: 0.12s
Val loss: 0.6538 score: 0.5918 time: 0.06s
Test loss: 0.6459 score: 0.5918 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2322;  Loss pred: 0.2322; Loss self: 0.0000; time: 0.12s
Val loss: 0.6489 score: 0.6122 time: 0.06s
Test loss: 0.6398 score: 0.6122 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2192;  Loss pred: 0.2192; Loss self: 0.0000; time: 0.12s
Val loss: 0.6437 score: 0.6122 time: 0.08s
Test loss: 0.6331 score: 0.6122 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2089;  Loss pred: 0.2089; Loss self: 0.0000; time: 0.12s
Val loss: 0.6380 score: 0.6122 time: 0.06s
Test loss: 0.6258 score: 0.6122 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.1995;  Loss pred: 0.1995; Loss self: 0.0000; time: 0.12s
Val loss: 0.6316 score: 0.6122 time: 0.06s
Test loss: 0.6177 score: 0.6327 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1820;  Loss pred: 0.1820; Loss self: 0.0000; time: 0.12s
Val loss: 0.6248 score: 0.6122 time: 0.06s
Test loss: 0.6089 score: 0.6531 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1719;  Loss pred: 0.1719; Loss self: 0.0000; time: 0.12s
Val loss: 0.6176 score: 0.6327 time: 0.06s
Test loss: 0.5996 score: 0.6735 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1596;  Loss pred: 0.1596; Loss self: 0.0000; time: 0.12s
Val loss: 0.6097 score: 0.6531 time: 0.06s
Test loss: 0.5894 score: 0.6939 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1523;  Loss pred: 0.1523; Loss self: 0.0000; time: 0.12s
Val loss: 0.6013 score: 0.7143 time: 0.06s
Test loss: 0.5788 score: 0.7143 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1426;  Loss pred: 0.1426; Loss self: 0.0000; time: 0.12s
Val loss: 0.5922 score: 0.7755 time: 0.06s
Test loss: 0.5673 score: 0.7347 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1307;  Loss pred: 0.1307; Loss self: 0.0000; time: 0.12s
Val loss: 0.5828 score: 0.7755 time: 0.06s
Test loss: 0.5554 score: 0.7347 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1254;  Loss pred: 0.1254; Loss self: 0.0000; time: 0.12s
Val loss: 0.5727 score: 0.7551 time: 0.06s
Test loss: 0.5427 score: 0.7551 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1149;  Loss pred: 0.1149; Loss self: 0.0000; time: 0.12s
Val loss: 0.5621 score: 0.7959 time: 0.06s
Test loss: 0.5294 score: 0.7551 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1070;  Loss pred: 0.1070; Loss self: 0.0000; time: 0.12s
Val loss: 0.5514 score: 0.8163 time: 0.06s
Test loss: 0.5159 score: 0.7755 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.0972;  Loss pred: 0.0972; Loss self: 0.0000; time: 0.12s
Val loss: 0.5402 score: 0.8163 time: 0.06s
Test loss: 0.5017 score: 0.8367 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0893;  Loss pred: 0.0893; Loss self: 0.0000; time: 0.12s
Val loss: 0.5286 score: 0.7959 time: 0.06s
Test loss: 0.4870 score: 0.8571 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0834;  Loss pred: 0.0834; Loss self: 0.0000; time: 0.12s
Val loss: 0.5169 score: 0.7959 time: 0.06s
Test loss: 0.4721 score: 0.9184 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.0772;  Loss pred: 0.0772; Loss self: 0.0000; time: 0.12s
Val loss: 0.5047 score: 0.8163 time: 0.07s
Test loss: 0.4563 score: 0.9184 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0709;  Loss pred: 0.0709; Loss self: 0.0000; time: 0.12s
Val loss: 0.4926 score: 0.8367 time: 0.06s
Test loss: 0.4403 score: 0.9184 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0656;  Loss pred: 0.0656; Loss self: 0.0000; time: 0.12s
Val loss: 0.4804 score: 0.8367 time: 0.06s
Test loss: 0.4241 score: 0.9184 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0621;  Loss pred: 0.0621; Loss self: 0.0000; time: 0.12s
Val loss: 0.4682 score: 0.8367 time: 0.06s
Test loss: 0.4076 score: 0.9184 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0564;  Loss pred: 0.0564; Loss self: 0.0000; time: 0.12s
Val loss: 0.4565 score: 0.8571 time: 0.06s
Test loss: 0.3916 score: 0.9184 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0489;  Loss pred: 0.0489; Loss self: 0.0000; time: 0.12s
Val loss: 0.4447 score: 0.8571 time: 0.06s
Test loss: 0.3752 score: 0.9388 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0435;  Loss pred: 0.0435; Loss self: 0.0000; time: 0.12s
Val loss: 0.4331 score: 0.8571 time: 0.07s
Test loss: 0.3584 score: 0.9184 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0427;  Loss pred: 0.0427; Loss self: 0.0000; time: 0.12s
Val loss: 0.4217 score: 0.8776 time: 0.06s
Test loss: 0.3415 score: 0.9388 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0389;  Loss pred: 0.0389; Loss self: 0.0000; time: 0.12s
Val loss: 0.4109 score: 0.8776 time: 0.06s
Test loss: 0.3249 score: 0.9388 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0356;  Loss pred: 0.0356; Loss self: 0.0000; time: 0.12s
Val loss: 0.4004 score: 0.8776 time: 0.06s
Test loss: 0.3080 score: 0.9796 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0315;  Loss pred: 0.0315; Loss self: 0.0000; time: 0.12s
Val loss: 0.3906 score: 0.8776 time: 0.07s
Test loss: 0.2914 score: 0.9796 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0297;  Loss pred: 0.0297; Loss self: 0.0000; time: 0.12s
Val loss: 0.3817 score: 0.8776 time: 0.06s
Test loss: 0.2751 score: 0.9796 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0262;  Loss pred: 0.0262; Loss self: 0.0000; time: 0.12s
Val loss: 0.3736 score: 0.8776 time: 0.06s
Test loss: 0.2592 score: 0.9796 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0250;  Loss pred: 0.0250; Loss self: 0.0000; time: 0.12s
Val loss: 0.3663 score: 0.8571 time: 0.06s
Test loss: 0.2441 score: 0.9796 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0226;  Loss pred: 0.0226; Loss self: 0.0000; time: 0.12s
Val loss: 0.3600 score: 0.8367 time: 0.06s
Test loss: 0.2294 score: 0.9796 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0215;  Loss pred: 0.0215; Loss self: 0.0000; time: 0.12s
Val loss: 0.3544 score: 0.8367 time: 0.06s
Test loss: 0.2156 score: 0.9796 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.12s
Val loss: 0.3499 score: 0.8367 time: 0.06s
Test loss: 0.2024 score: 0.9796 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.12s
Val loss: 0.3463 score: 0.8571 time: 0.06s
Test loss: 0.1900 score: 0.9592 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.12s
Val loss: 0.3434 score: 0.8571 time: 0.06s
Test loss: 0.1784 score: 0.9592 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.12s
Val loss: 0.3414 score: 0.8571 time: 0.06s
Test loss: 0.1677 score: 0.9592 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0137;  Loss pred: 0.0137; Loss self: 0.0000; time: 0.12s
Val loss: 0.3406 score: 0.8571 time: 0.06s
Test loss: 0.1580 score: 0.9592 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0131;  Loss pred: 0.0131; Loss self: 0.0000; time: 0.12s
Val loss: 0.3406 score: 0.8776 time: 0.06s
Test loss: 0.1491 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 86/1000, LR 0.000266
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.12s
Val loss: 0.3415 score: 0.8776 time: 0.06s
Test loss: 0.1411 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 87/1000, LR 0.000266
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.12s
Val loss: 0.3436 score: 0.8776 time: 0.06s
Test loss: 0.1340 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0110;  Loss pred: 0.0110; Loss self: 0.0000; time: 0.12s
Val loss: 0.3462 score: 0.8776 time: 0.06s
Test loss: 0.1277 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.12s
Val loss: 0.3496 score: 0.8776 time: 0.06s
Test loss: 0.1220 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.12s
Val loss: 0.3539 score: 0.8776 time: 0.06s
Test loss: 0.1171 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.12s
Val loss: 0.3584 score: 0.8776 time: 0.06s
Test loss: 0.1129 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.12s
Val loss: 0.3642 score: 0.8776 time: 0.06s
Test loss: 0.1096 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.12s
Val loss: 0.3704 score: 0.8776 time: 0.06s
Test loss: 0.1067 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.3770 score: 0.8776 time: 0.06s
Test loss: 0.1044 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.12s
Val loss: 0.3832 score: 0.8776 time: 0.07s
Test loss: 0.1024 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.12s
Val loss: 0.3899 score: 0.8776 time: 0.06s
Test loss: 0.1009 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.3968 score: 0.8776 time: 0.06s
Test loss: 0.0999 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.12s
Val loss: 0.4041 score: 0.8776 time: 0.06s
Test loss: 0.0992 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.4115 score: 0.8776 time: 0.06s
Test loss: 0.0988 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.12s
Val loss: 0.4185 score: 0.8776 time: 0.06s
Test loss: 0.0985 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.12s
Val loss: 0.4256 score: 0.8776 time: 0.06s
Test loss: 0.0986 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.12s
Val loss: 0.4322 score: 0.8776 time: 0.06s
Test loss: 0.0987 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.12s
Val loss: 0.4391 score: 0.8776 time: 0.06s
Test loss: 0.0991 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.4454 score: 0.8776 time: 0.06s
Test loss: 0.0994 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 083,   Train_Loss: 0.0137,   Val_Loss: 0.3406,   Val_Precision: 0.9500,   Val_Recall: 0.7600,   Val_accuracy: 0.8444,   Val_Score: 0.8571,   Val_Loss: 0.3406,   Test_Precision: 1.0000,   Test_Recall: 0.9167,   Test_accuracy: 0.9565,   Test_Score: 0.9592,   Test_loss: 0.1580


[0.06820148101542145, 0.07054007903207093, 0.07046255201566964, 0.07266960002016276, 0.07209534605499357, 0.07170149800367653, 0.07169011002406478, 0.07288669503759593, 0.07160780590493232, 0.07222241989802569, 0.07214544899761677, 0.07146997097879648, 0.07103432400617748, 0.07177042402327061, 0.0717611969448626, 0.07062257395591587, 0.0708327810280025, 0.07042577606625855, 0.07087301404681057, 0.07058697706088424, 0.07208934891968966, 0.07011432503350079, 0.07026386505458504, 0.07010347594041377, 0.07050372299272567, 0.06977482896763831, 0.07121941691730171, 0.07119734899606556, 0.07026722200680524, 0.0700958879897371, 0.07019805791787803, 0.07420337910298258, 0.07079684396740049, 0.07042647700291127, 0.07387233292683959, 0.07046048296615481, 0.0699759719427675, 0.0704453750513494, 0.0711399350548163, 0.07079007802531123, 0.0708161280490458, 0.07142506504897028, 0.07125964399892837, 0.0685480599058792, 0.2085472169565037, 0.07159148703794926, 0.06857560796197504, 0.06972219899762422, 0.07158694905228913, 0.07968426507432014, 0.07600058510433882, 0.1773902300046757, 0.07373767299577594, 0.07454095699358732, 0.07656385097652674, 0.07573397399391979, 0.07575756090227515, 0.2070517399115488, 0.08570832293480635, 0.08323100302368402, 0.07250858109910041, 0.07170012698043138, 0.07113833900075406, 0.07134313008282334, 0.07252505701035261, 0.07311598095111549, 0.07411441102158278, 0.0741470989305526, 0.07278633897658437, 0.07233011408243328, 0.1108005850110203, 0.07045415393076837, 0.06753928295802325, 0.06693291699048132, 0.06758643500506878, 0.07073295000009239, 0.06778313301037997, 0.07017476600594819, 0.06911636108998209, 0.06877440703101456, 0.06904147402383387, 0.06860998703632504, 0.07044190797023475, 0.06900080700870603, 0.07072270999196917, 0.06849582202266902, 0.06750739202834666, 0.06839234905783087, 0.06951158202718943, 0.07145558693446219, 0.06753922998905182, 0.06683529005385935, 0.06873603409621865, 0.06868523196317255, 0.06818902201484889, 0.06907923298422247, 0.06976252293679863, 0.06841126305516809, 0.07093714107759297, 0.07031746907159686, 0.07014903798699379, 0.07063400198239833, 0.07065761799458414, 0.07197518495377153, 0.06943469599355012, 0.06890112196560949, 0.06947511108592153, 0.07004226895514876, 0.06972356210462749, 0.06945207901299, 0.07177192298695445, 0.06998531997669488, 0.0705314779188484, 0.06819406594149768, 0.07170714600943029, 0.06848222389817238, 0.06879002403002232, 0.07138611597474664, 0.07105582696385682, 0.07396040193270892, 0.20393796893768013, 0.07224884198512882, 0.0739267299650237, 0.07388043403625488, 0.07554030499886721, 0.07324156002141535, 0.07308615406509489, 0.07161813706625253, 0.07159566297195852, 0.06939418206457049, 0.07025386590976268, 0.07078105490654707, 0.0701173460111022, 0.06945740303490311, 0.10454746300820261, 0.06808268604800105, 0.06849769095424563, 0.06949065206572413, 0.06923470203764737, 0.07088353391736746, 0.06961730890907347, 0.0695736410561949, 0.07714406796731055, 0.074946673004888, 0.0744456930551678, 0.11381597793661058, 0.07887719699647278, 0.07853365002665669, 0.07890251104254276, 0.07909044995903969, 0.0814684999641031, 0.08044380601495504, 0.08168846508488059, 0.07980251999106258, 0.07975824701134115, 0.08103598095476627, 0.08166299597360194, 0.08127703506033868, 0.0814616500865668, 0.08097175497096032, 0.08141770504880697, 0.08120053296443075, 0.08103081001900136, 0.08114317897707224, 0.08572705101687461, 0.08130373794119805, 0.0817723450018093, 0.08106593508273363, 0.08144824497867376, 0.08146279398351908, 0.08140941301826388, 0.08132803591433913, 0.08150628802832216, 0.08136423910036683, 0.08141808991786093, 0.08407220791559666, 0.07845612592063844, 0.07671848102472723, 0.07708825694862753, 0.07697077002376318, 0.07669433299452066, 0.07625316991470754, 0.0765102009754628, 0.07656628196127713, 0.07642722502350807, 0.0764007680118084, 0.0767303619068116, 0.07680252101272345, 0.07675274205394089, 0.07696050102822483, 0.0827050240477547, 0.08161178801674396, 0.07680369599256665, 0.07667698501609266, 0.07701226405333728, 0.07675203797407448, 0.07661862205713987, 0.07684350502677262, 0.07649230398237705, 0.07692075800150633, 0.07665077899582684, 0.07672012702096254, 0.07703201507683843, 0.07695236394647509, 0.07677257107570767, 0.07994983100797981, 0.07636370102409273, 0.07659332908224314, 0.07651249400805682, 0.07741934095975012, 0.07695224194321781, 0.07681501400656998, 0.0768012551125139, 0.07724435592535883, 0.07695166300982237, 0.07760962191969156, 0.07719051989261061, 0.07710915000643581, 0.07718483998905867, 0.07734475401230156, 0.07717752095777541, 0.07690449501387775, 0.07686076406389475, 0.0769343669526279, 0.07650904194451869, 0.07667795708402991, 0.07678341295104474, 0.07663557201158255, 0.07664970098994672, 0.07638797501567751, 0.07662352500483394, 0.0763514389982447, 0.0770113590406254, 0.07690805289894342, 0.07684870401863009, 0.0768856629729271, 0.07687703298870474, 0.08022893802262843, 0.07679120800457895, 0.07688187505118549, 0.0768654280109331, 0.0765127680497244, 0.0768288109684363, 0.07667416904587299, 0.07684912602417171, 0.07741478399839252, 0.07689079700503498]
[0.001391866959498397, 0.0014395934496341006, 0.0014380112656259111, 0.0014830530616359748, 0.0014713335929590525, 0.0014632958776260518, 0.0014630634698788731, 0.0014874835721958354, 0.0014613837939782106, 0.001473926936694402, 0.001472356101992179, 0.001458570836301969, 0.0014496800817587242, 0.0014647025310871552, 0.0014645142233645429, 0.0014412770195084872, 0.001445566959755153, 0.0014372607360460929, 0.0014463880417716441, 0.0014405505522629436, 0.001471211202442646, 0.0014309045925204242, 0.001433956429685409, 0.001430683182457424, 0.0014388514896474627, 0.0014239761013803737, 0.0014534574881081982, 0.001453007122368685, 0.0014340249389143927, 0.001430528326321165, 0.00143261342689547, 0.0015143546755710731, 0.0014448335503551121, 0.0014372750408757403, 0.0015075986311599916, 0.0014379690401256084, 0.0014280810600564796, 0.0014376607153336613, 0.0014518354092819654, 0.001444695469904311, 0.001445227103041751, 0.0014576543887544955, 0.0014542784489577217, 0.0013989399980791674, 0.004256065652173545, 0.0014610507558765157, 0.001399502203305613, 0.001422902020359678, 0.001460958143924268, 0.001626209491312656, 0.0015510323490681393, 0.0036202087756056264, 0.0015048504693015497, 0.0015212440202772922, 0.0015625275709495253, 0.001545591305998363, 0.0015460726714750029, 0.004225545712480587, 0.0017491494476491092, 0.001698591898442531, 0.0014797669612061307, 0.001463267897559824, 0.0014518028367500827, 0.0014559822465882314, 0.0014801032042929105, 0.0014921628765533774, 0.001512539000440465, 0.0015132061006235225, 0.0014854354893180485, 0.001476124777192516, 0.002261236428796333, 0.00143783987613813, 0.0013783527134290459, 0.0013659778977649249, 0.0013793150001034445, 0.0014435295918386202, 0.0013833292451097953, 0.0014321380817540446, 0.001410537981428206, 0.0014035593271635625, 0.0014090096739557932, 0.0014002038170678579, 0.0014375899585762195, 0.0014081797348715517, 0.0014433206120810034, 0.00139787391882998, 0.0013777018781295236, 0.0013957622256700177, 0.0014186037148406006, 0.0014582772843767793, 0.001378351632429629, 0.0013639855113032522, 0.0014027762060452784, 0.001401739427819848, 0.0013916126941805895, 0.001409780264984132, 0.0014237249578938497, 0.0013961482256156753, 0.0014476967566855708, 0.0014350503892162625, 0.0014316130201427303, 0.0014415102445387415, 0.001441992203971105, 0.0014688813255871742, 0.0014170346121132678, 0.0014061453462369284, 0.001417859409916766, 0.0014294340603091583, 0.0014229298388699488, 0.0014173893676120409, 0.001464733122182744, 0.0014282718362590792, 0.0014394179167111917, 0.0013917156314591365, 0.0014634111430495977, 0.0013975964060851506, 0.001403878041429027, 0.001456859509688707, 0.001450118917629731, 0.001509395957810386, 0.004161999366075105, 0.0014744661629618127, 0.001508708774796402, 0.001507763959923569, 0.0015416388775279022, 0.0014947257147227622, 0.0014915541645937733, 0.0014615946340051536, 0.0014611359790195615, 0.0014162077972361324, 0.0014337523655053607, 0.0014445113246234096, 0.0014309662451245347, 0.0014174980211204716, 0.0021336216940449513, 0.0013894425724081847, 0.0013979120602907271, 0.0014181765727698803, 0.00141295310280913, 0.001446602733007499, 0.0014207614063076219, 0.0014198702256366306, 0.0015743687340267459, 0.0015295239388752654, 0.0015192998582687304, 0.002322775059930828, 0.0016097387142137301, 0.0016027275515644221, 0.0016102553273988317, 0.001614090815490606, 0.0016626224482470021, 0.0016417103268358173, 0.0016671115323445018, 0.0016286228569604609, 0.0016277193267620644, 0.0016537955296891077, 0.0016665917545633049, 0.0016587150012314015, 0.001662482654827894, 0.0016524847953257207, 0.001661585817322591, 0.0016571537339679745, 0.0016536900003877829, 0.0016559832444300456, 0.0017495316534056043, 0.0016592599579836338, 0.0016688233673838632, 0.0016544068384231354, 0.0016622090811974236, 0.0016625059996636547, 0.0016614165922094668, 0.0016597558349865128, 0.0016633936332310646, 0.0016604946755176904, 0.0016615936717930802, 0.0017157593452162584, 0.0016011454269518049, 0.001565683286218923, 0.00157322973364546, 0.0015708320413012893, 0.0015651904692759319, 0.0015561871411164804, 0.0015614326729686285, 0.0015625771828832067, 0.0015597392861940423, 0.001559199347179763, 0.0015659257532002367, 0.0015673983880147642, 0.001566382490896753, 0.001570622469963772, 0.001687857633627647, 0.0016655466942192645, 0.0015674223671952377, 0.00156483642889985, 0.001571678858231373, 0.0015663681219198874, 0.0015636453481048954, 0.0015682347964647474, 0.0015610674282117766, 0.0015698113877858435, 0.0015643016121597315, 0.0015657168779788272, 0.0015720819403436414, 0.0015704564070709202, 0.0015667871648103607, 0.001631629204244486, 0.0015584428780427088, 0.0015631291649437376, 0.00156147946955218, 0.0015799865501989819, 0.0015704539172085269, 0.0015676533470728568, 0.0015673725533166102, 0.0015764154270481393, 0.0015704421022412728, 0.0015838698350957461, 0.0015753167325022574, 0.0015736561225803227, 0.0015752008161032383, 0.001578464367597991, 0.0015750514481178656, 0.0015694794900791378, 0.0015685870217121377, 0.001570089121482202, 0.0015614090192758916, 0.0015648562670210187, 0.0015670084275723416, 0.001563991265542501, 0.001564279612039729, 0.0015589382656260716, 0.0015637454082619172, 0.0015581926326172389, 0.0015716603885841916, 0.0015695520999784373, 0.0015683408983393895, 0.0015690951627127978, 0.001568919040585811, 0.001637325265767927, 0.0015671675102975294, 0.001569017858187459, 0.0015686822043047572, 0.0015614850622392735, 0.0015679349177231898, 0.0015647789601198568, 0.0015683495106973819, 0.0015798935509876025, 0.001569199938878265]
[718.4594714141224, 694.6405599818257, 695.4048441092973, 674.2847075861786, 679.6555212124694, 683.3887905310918, 683.4973468941781, 672.2763321169268, 684.2829406762329, 678.4596814837478, 679.183519969758, 685.6026290333486, 689.8073668687088, 682.7324857954358, 682.8202717639859, 693.829143505685, 691.7700997879599, 695.7679806595162, 691.3773974341804, 694.1790403877961, 679.7120619661569, 698.8586137937958, 697.3712584972939, 698.9667679481228, 694.9987592152495, 702.2589768400046, 688.0146190595415, 688.2278721179323, 697.3379422236793, 699.0424318067588, 698.0250088588375, 660.3472859638337, 692.1212479833538, 695.7610558593532, 663.3065189443492, 695.4252644498165, 700.2403630788652, 695.5744073231589, 688.7833108400147, 692.1873992352415, 691.9327750602745, 686.0336769228664, 687.6262250304939, 714.826941379232, 234.95878158959005, 684.4389190299406, 714.5397825298223, 702.7890787218239, 684.4823064635569, 614.9269238324348, 644.7318784813226, 276.22716312340566, 664.5178510421256, 657.356733482982, 639.9887071383416, 647.0015689911361, 646.8001268310162, 236.65582342332644, 571.706437859852, 588.7229303971823, 675.7820834065104, 683.4018580381766, 688.7987643270756, 686.8215614189502, 675.6285623188891, 670.1681268936383, 661.1399770245865, 660.8485120354366, 673.2032506232175, 677.4495052524819, 442.2359321940983, 695.4877358707586, 725.5037047173611, 732.0762668533989, 724.9975530788855, 692.7464498502608, 722.8937026634102, 698.2566923820827, 708.949360574803, 712.4743362440468, 709.7183351427964, 714.1817411225762, 695.6086428082692, 710.1366219357047, 692.8467532644626, 715.3720993929121, 725.8464373712538, 716.4544086439671, 704.9184980545208, 685.7406411753631, 725.5042737079317, 733.1456175399741, 712.8720858612298, 713.3993523713027, 718.5907430866177, 709.3304005154702, 702.3828545362609, 716.2563269806246, 690.7523936776994, 696.8396423669411, 698.5127865771303, 693.7168874023388, 693.4850252630341, 680.7901922234988, 705.6990644065278, 711.1640362613731, 705.2885448344305, 699.5775655322777, 702.7753390807885, 705.5224364246211, 682.7182268601948, 700.1468310256637, 694.725269423364, 718.5375930221863, 683.3349634854517, 715.5141467493681, 712.3125873399132, 686.4079846749767, 689.5986169427638, 662.5166808122739, 240.2691379895695, 678.2115623401384, 662.8184423033853, 663.2337863087612, 648.6603410025257, 669.0190649362564, 670.4416264174699, 684.1842305206999, 684.3989980118148, 706.111067847245, 697.4705144758564, 692.2756387948044, 698.8285037520026, 705.4683569925147, 468.68664805530045, 719.7130848429366, 715.3525807567806, 705.1308131870153, 707.7375731805063, 691.2747896728991, 703.8479476993064, 704.2897174293711, 635.1752155559586, 653.7982012464281, 658.1979156764471, 430.5195183341515, 621.2188295964825, 623.9363633724897, 621.0195259005144, 619.543826408583, 601.4594600562245, 609.1208562520098, 599.8398910921541, 614.0156978186618, 614.3565315951903, 604.6696717023943, 600.0269695694186, 602.8763224891661, 601.5100350647108, 605.1492896204775, 601.8346988609698, 603.4443150941394, 604.7082583588849, 603.8708443237774, 571.5815418677447, 602.6783176369905, 599.2245911367202, 604.4462442824099, 601.6090342134452, 601.5015886873865, 601.8959992870487, 602.4982584309613, 601.1806105434868, 602.2301755880254, 601.8318539458971, 582.832320154991, 624.5528876810141, 638.6987769505857, 635.6350751665606, 636.6052981524316, 638.8998780848742, 642.596236390023, 640.4374759872157, 639.9683874526049, 641.1327898524146, 641.3548093184957, 638.5998812244637, 637.9998905489371, 638.4136734237247, 636.6902416868301, 592.467030439492, 600.4034612003215, 637.9901301200714, 639.0444276038771, 636.2622966916477, 638.4195298703515, 639.5312090506831, 637.659617204189, 640.5873198863122, 637.0192035684365, 639.2629095480914, 638.6850739521266, 636.0991589162394, 636.7575664612772, 638.2487822594826, 612.8843473741589, 641.6661233396808, 639.7423977665936, 640.4182824682237, 632.916780129591, 636.7585760029779, 637.896127908133, 638.0104065775353, 634.3505543285087, 636.7633665531761, 631.3650136152439, 634.7929780518389, 635.4628470928584, 634.839691407613, 633.527129612522, 634.8998956160873, 637.1539139702788, 637.5164311307918, 636.9065209852392, 640.4471779366006, 639.0363262586905, 638.1586610540642, 639.3897600528672, 639.2719001790598, 641.4622195436319, 639.4902870483803, 641.7691747908838, 636.2697738414315, 637.1244382481717, 637.6164780621564, 637.3099756875847, 637.3815181863143, 610.7521950020034, 638.093881751127, 637.3413755501849, 637.4777486834574, 640.4159887164936, 637.7815741562205, 639.0678974386282, 637.6129766861344, 632.9540362861112, 637.2674222220817]
Elapsed: 0.07660123355486827~0.01684259311458114
Time per graph: 0.0015632904807115972~0.0003437263900934926
Speed: 653.7326595243007~68.51129496143045
Total Time: 0.0777
best val loss: 0.3405928313732147 test_score: 0.9592

Testing...
Test loss: 0.3415 score: 0.9388 time: 0.07s
test Score 0.9388
Epoch Time List: [0.4269473261665553, 0.25333308102563024, 0.25412796705495566, 0.2652982190484181, 0.27468802395742387, 0.25961347692646086, 0.2598321158438921, 0.26051825110334903, 0.26061901706270874, 0.25790083687752485, 0.25916229700669646, 0.2570972350658849, 0.25671734602656215, 0.26042358204722404, 0.26060515211429447, 0.2569717770675197, 0.25592819205485284, 0.2540595130994916, 0.25543231202755123, 0.2540585189126432, 0.2558621239149943, 0.25361194706056267, 0.25279555399902165, 0.2528341980651021, 0.25384680391289294, 0.2577593169407919, 0.2643336448818445, 0.25804819411132485, 0.2561864301096648, 0.25485508795827627, 0.2555139501346275, 0.25611838104669005, 0.2622958570718765, 0.25739872292615473, 0.2547132800100371, 0.25745510088745505, 0.253775681136176, 0.2599600012181327, 0.26379065902438015, 0.2579970830120146, 0.2611393529223278, 0.2671316539635882, 0.2598690538434312, 0.25199053389951587, 0.3944010949926451, 0.26697098196018487, 0.24389594595413655, 0.253520202008076, 0.2614180539967492, 0.2760192189598456, 0.27443650108762085, 0.37849338992964476, 0.267537759966217, 0.27805766102392226, 0.2755730369826779, 0.27738830901216716, 0.278378228074871, 0.4076352168340236, 0.28930948802735656, 0.2872702139429748, 0.26830877701286227, 0.25945253507234156, 0.2592718470841646, 0.25474974990356714, 0.38510407297872007, 0.2640180920716375, 0.266318507026881, 0.2692316179163754, 0.26876663602888584, 0.26289435708895326, 0.32215014402754605, 0.25775652192533016, 0.25698840094264597, 0.24485864606685936, 0.24731450621038675, 0.2538160680560395, 0.24832697492092848, 0.24497426091693342, 0.2948160788509995, 0.251008473103866, 0.2501027488615364, 0.2473090939456597, 0.2510957169579342, 0.2555118229938671, 0.251986016985029, 0.2941983670461923, 0.24519625713583082, 0.24981700698845088, 0.25327611388638616, 0.2571590510196984, 0.25120398099534214, 0.242032230948098, 0.33210902696009725, 0.2522523469524458, 0.24606381205376238, 0.25235421187244356, 0.2559921918436885, 0.24971599702257663, 0.25422659900505096, 0.2876001059776172, 0.25414309999905527, 0.2576894700760022, 0.25479288294445723, 0.26316244795452803, 0.2567206711973995, 0.25121319096069783, 0.34250901301857084, 0.2535397399915382, 0.2509522819891572, 0.2472211830317974, 0.2574277420062572, 0.2588816311908886, 0.25127073004841805, 0.2832103440305218, 0.24849731102585793, 0.25234804197680205, 0.250898061087355, 0.25085386692080647, 0.26244621409568936, 0.25428973499219865, 0.3897179609630257, 0.26067970297299325, 0.26574036106467247, 0.2630431829020381, 0.26981714193243533, 0.2748801599955186, 0.26611010206397623, 0.36772790108807385, 0.2658948239404708, 0.24963799898978323, 0.25276345503516495, 0.25572041515260935, 0.2595332800410688, 0.2532952941255644, 0.28413942200131714, 0.2837724540149793, 0.24879095412325114, 0.2539830489549786, 0.250952021102421, 0.255826850887388, 0.25999324407894164, 0.25449883099645376, 0.36166168085765094, 0.24800026998855174, 0.24578555906191468, 0.2853663720889017, 0.2865409019868821, 0.2548926039598882, 0.2573663740186021, 0.25789332296699286, 0.26453079108614475, 0.26381403987761587, 0.26295149500947446, 0.406110450043343, 0.26101477397605777, 0.26293472305405885, 0.2627391149289906, 0.2669031519908458, 0.2655713160056621, 0.26583897206000984, 0.2657190361060202, 0.2650711789028719, 0.2650118318852037, 0.2640689619584009, 0.26947103487327695, 0.26663888001348823, 0.2655013280455023, 0.26527521607931703, 0.2665644639637321, 0.2660468809772283, 0.26469696406275034, 0.2653566200751811, 0.2651624669088051, 0.26424240798223764, 0.2659758380614221, 0.2709018839523196, 0.2593253750819713, 0.25242652697488666, 0.2527960939332843, 0.25196898786816746, 0.2523226961493492, 0.25181631394661963, 0.25220634206198156, 0.2519868150120601, 0.2508389069698751, 0.2533758000936359, 0.2518783899722621, 0.25212549802381545, 0.258863509981893, 0.2525559790665284, 0.2571795219555497, 0.2691539528314024, 0.25185743486508727, 0.25163634109776467, 0.2514843010576442, 0.25319400313310325, 0.25212034094147384, 0.252313019009307, 0.25180569489020854, 0.252437048824504, 0.25309809495229274, 0.2521410209592432, 0.2517535201041028, 0.2527617869200185, 0.25152806495316327, 0.2560047891456634, 0.2534430930390954, 0.25406823598314077, 0.25109090097248554, 0.25252344517502934, 0.25180625391658396, 0.25305248191580176, 0.25359113805461675, 0.25304218102246523, 0.2526121649425477, 0.2551262929337099, 0.255416558124125, 0.25302111206110567, 0.2527242790674791, 0.2530090530635789, 0.2547827899688855, 0.25323887716513127, 0.25343781884294003, 0.25315195694565773, 0.2520240410231054, 0.25217268196865916, 0.25177488406188786, 0.2510944770183414, 0.2514843950048089, 0.2525127559201792, 0.2515659899218008, 0.2525814949767664, 0.25187365210149437, 0.2518126758513972, 0.2521513960091397, 0.25155572418589145, 0.25195092090871185, 0.2642731729429215, 0.25232086004689336, 0.2528223459376022, 0.25260345393326133, 0.25196052179671824, 0.25280780193861574, 0.25240326311904937, 0.25220954685937613, 0.2540801140712574, 0.25289274496026337]
Total Epoch List: [143, 104]
Total Time List: [0.07781030703336, 0.07772996998392045]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e436a4520>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6951;  Loss pred: 0.6951; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6957;  Loss pred: 0.6957; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6958;  Loss pred: 0.6958; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6945;  Loss pred: 0.6945; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6943;  Loss pred: 0.6943; Loss self: 0.0000; time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6912;  Loss pred: 0.6912; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6879;  Loss pred: 0.6879; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6904;  Loss pred: 0.6904; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6839;  Loss pred: 0.6839; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.09s
Epoch 10/1000, LR 0.000240
Train loss: 0.6821;  Loss pred: 0.6821; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6783;  Loss pred: 0.6783; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6763;  Loss pred: 0.6763; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6717;  Loss pred: 0.6717; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6669;  Loss pred: 0.6669; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6650;  Loss pred: 0.6650; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6611;  Loss pred: 0.6611; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6560;  Loss pred: 0.6560; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6518;  Loss pred: 0.6518; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6453;  Loss pred: 0.6453; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.16s
Epoch 20/1000, LR 0.000270
Train loss: 0.6416;  Loss pred: 0.6416; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6351;  Loss pred: 0.6351; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6260;  Loss pred: 0.6260; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6208;  Loss pred: 0.6208; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.6152;  Loss pred: 0.6152; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.6059;  Loss pred: 0.6059; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5970;  Loss pred: 0.5970; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5877;  Loss pred: 0.5877; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5000 time: 0.18s
Epoch 28/1000, LR 0.000270
Train loss: 0.5815;  Loss pred: 0.5815; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5674;  Loss pred: 0.5674; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5578;  Loss pred: 0.5578; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5493;  Loss pred: 0.5493; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5000 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5354;  Loss pred: 0.5354; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.5240;  Loss pred: 0.5240; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6887 score: 0.5000 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.5106;  Loss pred: 0.5106; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6879 score: 0.5000 time: 0.20s
Epoch 35/1000, LR 0.000270
Train loss: 0.4947;  Loss pred: 0.4947; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.5000 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4822;  Loss pred: 0.4822; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6861 score: 0.5000 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4741;  Loss pred: 0.4741; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6875 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6850 score: 0.5000 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4547;  Loss pred: 0.4547; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6866 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6837 score: 0.5000 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4434;  Loss pred: 0.4434; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6855 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6824 score: 0.5000 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.4274;  Loss pred: 0.4274; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6844 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6809 score: 0.5000 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.4141;  Loss pred: 0.4141; Loss self: 0.0000; time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6832 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6793 score: 0.5000 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.4010;  Loss pred: 0.4010; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6818 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6775 score: 0.5000 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3839;  Loss pred: 0.3839; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6803 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6755 score: 0.5000 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3715;  Loss pred: 0.3715; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6787 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6734 score: 0.5000 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3500;  Loss pred: 0.3500; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6769 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6710 score: 0.5000 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3339;  Loss pred: 0.3339; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6750 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6683 score: 0.5000 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.3272;  Loss pred: 0.3272; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6729 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6655 score: 0.5000 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.3119;  Loss pred: 0.3119; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6707 score: 0.4898 time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6626 score: 0.5000 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2980;  Loss pred: 0.2980; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6685 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6595 score: 0.5000 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2880;  Loss pred: 0.2880; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6660 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6561 score: 0.5000 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2723;  Loss pred: 0.2723; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6634 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6525 score: 0.5000 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2541;  Loss pred: 0.2541; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6606 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6486 score: 0.5000 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.2407;  Loss pred: 0.2407; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6580 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6448 score: 0.5000 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.2296;  Loss pred: 0.2296; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6551 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6408 score: 0.5000 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.2143;  Loss pred: 0.2143; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6521 score: 0.4898 time: 0.21s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6365 score: 0.5000 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.2054;  Loss pred: 0.2054; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6486 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6316 score: 0.5000 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1937;  Loss pred: 0.1937; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6450 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6265 score: 0.5000 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1794;  Loss pred: 0.1794; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6413 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6212 score: 0.5000 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1699;  Loss pred: 0.1699; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6372 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6154 score: 0.5000 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1586;  Loss pred: 0.1586; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6326 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6091 score: 0.5000 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1475;  Loss pred: 0.1475; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6277 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6024 score: 0.5000 time: 0.11s
Epoch 62/1000, LR 0.000268
Train loss: 0.1362;  Loss pred: 0.1362; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6223 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.5952 score: 0.5000 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1268;  Loss pred: 0.1268; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6169 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.5878 score: 0.5000 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.1210;  Loss pred: 0.1210; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6115 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.5805 score: 0.5000 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.1117;  Loss pred: 0.1117; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6060 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.5730 score: 0.5000 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.1019;  Loss pred: 0.1019; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6008 score: 0.4898 time: 0.07s
Test loss: 0.5658 score: 0.5208 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0929;  Loss pred: 0.0929; Loss self: 0.0000; time: 0.12s
Val loss: 0.5955 score: 0.5306 time: 0.07s
Test loss: 0.5583 score: 0.5208 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0880;  Loss pred: 0.0880; Loss self: 0.0000; time: 0.12s
Val loss: 0.5901 score: 0.5510 time: 0.07s
Test loss: 0.5507 score: 0.5417 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0812;  Loss pred: 0.0812; Loss self: 0.0000; time: 0.16s
Val loss: 0.5848 score: 0.5918 time: 0.07s
Test loss: 0.5429 score: 0.5625 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0740;  Loss pred: 0.0740; Loss self: 0.0000; time: 0.12s
Val loss: 0.5795 score: 0.6327 time: 0.07s
Test loss: 0.5352 score: 0.5833 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0673;  Loss pred: 0.0673; Loss self: 0.0000; time: 0.12s
Val loss: 0.5738 score: 0.6327 time: 0.07s
Test loss: 0.5271 score: 0.6042 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0617;  Loss pred: 0.0617; Loss self: 0.0000; time: 0.12s
Val loss: 0.5680 score: 0.6327 time: 0.07s
Test loss: 0.5185 score: 0.6458 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0555;  Loss pred: 0.0555; Loss self: 0.0000; time: 0.12s
Val loss: 0.5626 score: 0.6531 time: 0.07s
Test loss: 0.5102 score: 0.6458 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0522;  Loss pred: 0.0522; Loss self: 0.0000; time: 0.12s
Val loss: 0.5574 score: 0.6531 time: 0.07s
Test loss: 0.5019 score: 0.6458 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0477;  Loss pred: 0.0477; Loss self: 0.0000; time: 0.12s
Val loss: 0.5519 score: 0.6531 time: 0.07s
Test loss: 0.4931 score: 0.6458 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0434;  Loss pred: 0.0434; Loss self: 0.0000; time: 0.13s
Val loss: 0.5472 score: 0.6735 time: 0.14s
Test loss: 0.4851 score: 0.6667 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0399;  Loss pred: 0.0399; Loss self: 0.0000; time: 0.12s
Val loss: 0.5420 score: 0.6939 time: 0.07s
Test loss: 0.4765 score: 0.6875 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0366;  Loss pred: 0.0366; Loss self: 0.0000; time: 0.12s
Val loss: 0.5370 score: 0.7143 time: 0.07s
Test loss: 0.4676 score: 0.7292 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0316;  Loss pred: 0.0316; Loss self: 0.0000; time: 0.12s
Val loss: 0.5314 score: 0.7347 time: 0.07s
Test loss: 0.4582 score: 0.7292 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0297;  Loss pred: 0.0297; Loss self: 0.0000; time: 0.12s
Val loss: 0.5265 score: 0.7551 time: 0.07s
Test loss: 0.4491 score: 0.7708 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0278;  Loss pred: 0.0278; Loss self: 0.0000; time: 0.12s
Val loss: 0.5221 score: 0.7755 time: 0.07s
Test loss: 0.4404 score: 0.7917 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0257;  Loss pred: 0.0257; Loss self: 0.0000; time: 0.12s
Val loss: 0.5177 score: 0.7755 time: 0.07s
Test loss: 0.4313 score: 0.7917 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.13s
Val loss: 0.5128 score: 0.7755 time: 0.15s
Test loss: 0.4219 score: 0.8125 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0206;  Loss pred: 0.0206; Loss self: 0.0000; time: 0.12s
Val loss: 0.5083 score: 0.7755 time: 0.07s
Test loss: 0.4126 score: 0.8125 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0190;  Loss pred: 0.0190; Loss self: 0.0000; time: 0.12s
Val loss: 0.5040 score: 0.7755 time: 0.07s
Test loss: 0.4036 score: 0.8333 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0178;  Loss pred: 0.0178; Loss self: 0.0000; time: 0.12s
Val loss: 0.5002 score: 0.7959 time: 0.07s
Test loss: 0.3950 score: 0.8542 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0161;  Loss pred: 0.0161; Loss self: 0.0000; time: 0.13s
Val loss: 0.4967 score: 0.7959 time: 0.07s
Test loss: 0.3866 score: 0.8750 time: 0.08s
Epoch 88/1000, LR 0.000266
Train loss: 0.0147;  Loss pred: 0.0147; Loss self: 0.0000; time: 0.13s
Val loss: 0.4934 score: 0.7959 time: 0.07s
Test loss: 0.3785 score: 0.8750 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.12s
Val loss: 0.4905 score: 0.7959 time: 0.07s
Test loss: 0.3706 score: 0.8750 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.14s
Val loss: 0.4889 score: 0.7959 time: 0.11s
Test loss: 0.3641 score: 0.8958 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.12s
Val loss: 0.4872 score: 0.8163 time: 0.07s
Test loss: 0.3576 score: 0.8958 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.12s
Val loss: 0.4859 score: 0.8367 time: 0.07s
Test loss: 0.3516 score: 0.8958 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.4851 score: 0.8367 time: 0.07s
Test loss: 0.3463 score: 0.8958 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.12s
Val loss: 0.4846 score: 0.8367 time: 0.07s
Test loss: 0.3413 score: 0.8958 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.12s
Val loss: 0.4846 score: 0.8367 time: 0.07s
Test loss: 0.3370 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.12s
Val loss: 0.4856 score: 0.8367 time: 0.07s
Test loss: 0.3336 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.11s
Val loss: 0.4866 score: 0.8571 time: 0.07s
Test loss: 0.3305 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.4879 score: 0.8571 time: 0.16s
Test loss: 0.3279 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.12s
Val loss: 0.4887 score: 0.8571 time: 0.07s
Test loss: 0.3250 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.12s
Val loss: 0.4904 score: 0.8571 time: 0.07s
Test loss: 0.3229 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.12s
Val loss: 0.4917 score: 0.8571 time: 0.07s
Test loss: 0.3207 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.12s
Val loss: 0.4936 score: 0.8776 time: 0.07s
Test loss: 0.3192 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.4958 score: 0.8776 time: 0.07s
Test loss: 0.3182 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.12s
Val loss: 0.4984 score: 0.8776 time: 0.07s
Test loss: 0.3178 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.13s
Val loss: 0.5009 score: 0.8776 time: 0.13s
Test loss: 0.3174 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.12s
Val loss: 0.5035 score: 0.8776 time: 0.07s
Test loss: 0.3171 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.12s
Val loss: 0.5062 score: 0.8980 time: 0.07s
Test loss: 0.3172 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.12s
Val loss: 0.5089 score: 0.8980 time: 0.07s
Test loss: 0.3173 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.5117 score: 0.8980 time: 0.07s
Test loss: 0.3178 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.5144 score: 0.8980 time: 0.07s
Test loss: 0.3183 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.12s
Val loss: 0.5166 score: 0.8980 time: 0.07s
Test loss: 0.3185 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.13s
Val loss: 0.5198 score: 0.8980 time: 0.13s
Test loss: 0.3197 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.5230 score: 0.8980 time: 0.07s
Test loss: 0.3208 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.12s
Val loss: 0.5253 score: 0.8980 time: 0.07s
Test loss: 0.3214 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 093,   Train_Loss: 0.0095,   Val_Loss: 0.4846,   Val_Precision: 1.0000,   Val_Recall: 0.6800,   Val_accuracy: 0.8095,   Val_Score: 0.8367,   Val_Loss: 0.4846,   Test_Precision: 1.0000,   Test_Recall: 0.7917,   Test_accuracy: 0.8837,   Test_Score: 0.8958,   Test_loss: 0.3413


[0.06820148101542145, 0.07054007903207093, 0.07046255201566964, 0.07266960002016276, 0.07209534605499357, 0.07170149800367653, 0.07169011002406478, 0.07288669503759593, 0.07160780590493232, 0.07222241989802569, 0.07214544899761677, 0.07146997097879648, 0.07103432400617748, 0.07177042402327061, 0.0717611969448626, 0.07062257395591587, 0.0708327810280025, 0.07042577606625855, 0.07087301404681057, 0.07058697706088424, 0.07208934891968966, 0.07011432503350079, 0.07026386505458504, 0.07010347594041377, 0.07050372299272567, 0.06977482896763831, 0.07121941691730171, 0.07119734899606556, 0.07026722200680524, 0.0700958879897371, 0.07019805791787803, 0.07420337910298258, 0.07079684396740049, 0.07042647700291127, 0.07387233292683959, 0.07046048296615481, 0.0699759719427675, 0.0704453750513494, 0.0711399350548163, 0.07079007802531123, 0.0708161280490458, 0.07142506504897028, 0.07125964399892837, 0.0685480599058792, 0.2085472169565037, 0.07159148703794926, 0.06857560796197504, 0.06972219899762422, 0.07158694905228913, 0.07968426507432014, 0.07600058510433882, 0.1773902300046757, 0.07373767299577594, 0.07454095699358732, 0.07656385097652674, 0.07573397399391979, 0.07575756090227515, 0.2070517399115488, 0.08570832293480635, 0.08323100302368402, 0.07250858109910041, 0.07170012698043138, 0.07113833900075406, 0.07134313008282334, 0.07252505701035261, 0.07311598095111549, 0.07411441102158278, 0.0741470989305526, 0.07278633897658437, 0.07233011408243328, 0.1108005850110203, 0.07045415393076837, 0.06753928295802325, 0.06693291699048132, 0.06758643500506878, 0.07073295000009239, 0.06778313301037997, 0.07017476600594819, 0.06911636108998209, 0.06877440703101456, 0.06904147402383387, 0.06860998703632504, 0.07044190797023475, 0.06900080700870603, 0.07072270999196917, 0.06849582202266902, 0.06750739202834666, 0.06839234905783087, 0.06951158202718943, 0.07145558693446219, 0.06753922998905182, 0.06683529005385935, 0.06873603409621865, 0.06868523196317255, 0.06818902201484889, 0.06907923298422247, 0.06976252293679863, 0.06841126305516809, 0.07093714107759297, 0.07031746907159686, 0.07014903798699379, 0.07063400198239833, 0.07065761799458414, 0.07197518495377153, 0.06943469599355012, 0.06890112196560949, 0.06947511108592153, 0.07004226895514876, 0.06972356210462749, 0.06945207901299, 0.07177192298695445, 0.06998531997669488, 0.0705314779188484, 0.06819406594149768, 0.07170714600943029, 0.06848222389817238, 0.06879002403002232, 0.07138611597474664, 0.07105582696385682, 0.07396040193270892, 0.20393796893768013, 0.07224884198512882, 0.0739267299650237, 0.07388043403625488, 0.07554030499886721, 0.07324156002141535, 0.07308615406509489, 0.07161813706625253, 0.07159566297195852, 0.06939418206457049, 0.07025386590976268, 0.07078105490654707, 0.0701173460111022, 0.06945740303490311, 0.10454746300820261, 0.06808268604800105, 0.06849769095424563, 0.06949065206572413, 0.06923470203764737, 0.07088353391736746, 0.06961730890907347, 0.0695736410561949, 0.07714406796731055, 0.074946673004888, 0.0744456930551678, 0.11381597793661058, 0.07887719699647278, 0.07853365002665669, 0.07890251104254276, 0.07909044995903969, 0.0814684999641031, 0.08044380601495504, 0.08168846508488059, 0.07980251999106258, 0.07975824701134115, 0.08103598095476627, 0.08166299597360194, 0.08127703506033868, 0.0814616500865668, 0.08097175497096032, 0.08141770504880697, 0.08120053296443075, 0.08103081001900136, 0.08114317897707224, 0.08572705101687461, 0.08130373794119805, 0.0817723450018093, 0.08106593508273363, 0.08144824497867376, 0.08146279398351908, 0.08140941301826388, 0.08132803591433913, 0.08150628802832216, 0.08136423910036683, 0.08141808991786093, 0.08407220791559666, 0.07845612592063844, 0.07671848102472723, 0.07708825694862753, 0.07697077002376318, 0.07669433299452066, 0.07625316991470754, 0.0765102009754628, 0.07656628196127713, 0.07642722502350807, 0.0764007680118084, 0.0767303619068116, 0.07680252101272345, 0.07675274205394089, 0.07696050102822483, 0.0827050240477547, 0.08161178801674396, 0.07680369599256665, 0.07667698501609266, 0.07701226405333728, 0.07675203797407448, 0.07661862205713987, 0.07684350502677262, 0.07649230398237705, 0.07692075800150633, 0.07665077899582684, 0.07672012702096254, 0.07703201507683843, 0.07695236394647509, 0.07677257107570767, 0.07994983100797981, 0.07636370102409273, 0.07659332908224314, 0.07651249400805682, 0.07741934095975012, 0.07695224194321781, 0.07681501400656998, 0.0768012551125139, 0.07724435592535883, 0.07695166300982237, 0.07760962191969156, 0.07719051989261061, 0.07710915000643581, 0.07718483998905867, 0.07734475401230156, 0.07717752095777541, 0.07690449501387775, 0.07686076406389475, 0.0769343669526279, 0.07650904194451869, 0.07667795708402991, 0.07678341295104474, 0.07663557201158255, 0.07664970098994672, 0.07638797501567751, 0.07662352500483394, 0.0763514389982447, 0.0770113590406254, 0.07690805289894342, 0.07684870401863009, 0.0768856629729271, 0.07687703298870474, 0.08022893802262843, 0.07679120800457895, 0.07688187505118549, 0.0768654280109331, 0.0765127680497244, 0.0768288109684363, 0.07667416904587299, 0.07684912602417171, 0.07741478399839252, 0.07689079700503498, 0.07136190193705261, 0.07661031791940331, 0.07058857299853116, 0.07201708201318979, 0.07058212603442371, 0.0713268299587071, 0.07067805901169777, 0.07204778701998293, 0.09286728594452143, 0.07234199100639671, 0.07420325605198741, 0.07127499196212739, 0.07269468705635518, 0.07263168599456549, 0.07362568797543645, 0.07076890591997653, 0.07302106101997197, 0.07134168106131256, 0.16604854993056506, 0.07109127403236926, 0.07184374798089266, 0.0711295900400728, 0.07213233201764524, 0.07293438096530735, 0.0772580939810723, 0.07696720794774592, 0.18519995000679046, 0.07779016601853073, 0.07734326203353703, 0.07734399707987905, 0.07789410895202309, 0.07676145294681191, 0.07656930200755596, 0.2020494039170444, 0.07761317398399115, 0.07798267202451825, 0.07859878905583173, 0.07953122409526259, 0.07758171891327947, 0.07903846295084804, 0.0876177450409159, 0.07205641397740692, 0.07223803701344877, 0.0725627449573949, 0.07435042900033295, 0.07372479990590364, 0.07283497008029372, 0.07300641399342567, 0.07294974499382079, 0.0728947960305959, 0.07312416902277619, 0.07534165901597589, 0.07449936191551387, 0.07369086099788547, 0.07788543892093003, 0.07912921195384115, 0.07857281505130231, 0.07906110002659261, 0.07995587796904147, 0.07777789293322712, 0.12209530908148736, 0.07803538499865681, 0.07788362307474017, 0.07815634703729302, 0.07856060494668782, 0.07463072694372386, 0.0732208500849083, 0.07443386502563953, 0.07193444995209575, 0.07183002098463476, 0.07139629207085818, 0.07253974198829383, 0.07480374001897871, 0.07304992701392621, 0.07318182592280209, 0.0739528980338946, 0.07353941607289016, 0.07384737802203745, 0.07455426000524312, 0.0764509110013023, 0.07482848688960075, 0.07409203995484859, 0.07331081305164844, 0.0738030259963125, 0.07379278307780623, 0.08449005894362926, 0.07979041303042322, 0.07788280001841486, 0.07689014205243438, 0.07172435708343983, 0.07236642600037158, 0.07236080500297248, 0.07209932699333876, 0.07188462105114013, 0.07275909499730915, 0.07165763608645648, 0.07124905299860984, 0.07236650097183883, 0.07249235000927001, 0.07234465691726655, 0.0729433650849387, 0.07655456103384495, 0.07309435505885631, 0.07261691801249981, 0.07254239602480084, 0.07256711693480611, 0.07274893298745155, 0.07360874605365098, 0.07455172506161034, 0.07377995597198606, 0.07358275109436363, 0.07365816202946007, 0.07396197295747697, 0.07383170805405825]
[0.001391866959498397, 0.0014395934496341006, 0.0014380112656259111, 0.0014830530616359748, 0.0014713335929590525, 0.0014632958776260518, 0.0014630634698788731, 0.0014874835721958354, 0.0014613837939782106, 0.001473926936694402, 0.001472356101992179, 0.001458570836301969, 0.0014496800817587242, 0.0014647025310871552, 0.0014645142233645429, 0.0014412770195084872, 0.001445566959755153, 0.0014372607360460929, 0.0014463880417716441, 0.0014405505522629436, 0.001471211202442646, 0.0014309045925204242, 0.001433956429685409, 0.001430683182457424, 0.0014388514896474627, 0.0014239761013803737, 0.0014534574881081982, 0.001453007122368685, 0.0014340249389143927, 0.001430528326321165, 0.00143261342689547, 0.0015143546755710731, 0.0014448335503551121, 0.0014372750408757403, 0.0015075986311599916, 0.0014379690401256084, 0.0014280810600564796, 0.0014376607153336613, 0.0014518354092819654, 0.001444695469904311, 0.001445227103041751, 0.0014576543887544955, 0.0014542784489577217, 0.0013989399980791674, 0.004256065652173545, 0.0014610507558765157, 0.001399502203305613, 0.001422902020359678, 0.001460958143924268, 0.001626209491312656, 0.0015510323490681393, 0.0036202087756056264, 0.0015048504693015497, 0.0015212440202772922, 0.0015625275709495253, 0.001545591305998363, 0.0015460726714750029, 0.004225545712480587, 0.0017491494476491092, 0.001698591898442531, 0.0014797669612061307, 0.001463267897559824, 0.0014518028367500827, 0.0014559822465882314, 0.0014801032042929105, 0.0014921628765533774, 0.001512539000440465, 0.0015132061006235225, 0.0014854354893180485, 0.001476124777192516, 0.002261236428796333, 0.00143783987613813, 0.0013783527134290459, 0.0013659778977649249, 0.0013793150001034445, 0.0014435295918386202, 0.0013833292451097953, 0.0014321380817540446, 0.001410537981428206, 0.0014035593271635625, 0.0014090096739557932, 0.0014002038170678579, 0.0014375899585762195, 0.0014081797348715517, 0.0014433206120810034, 0.00139787391882998, 0.0013777018781295236, 0.0013957622256700177, 0.0014186037148406006, 0.0014582772843767793, 0.001378351632429629, 0.0013639855113032522, 0.0014027762060452784, 0.001401739427819848, 0.0013916126941805895, 0.001409780264984132, 0.0014237249578938497, 0.0013961482256156753, 0.0014476967566855708, 0.0014350503892162625, 0.0014316130201427303, 0.0014415102445387415, 0.001441992203971105, 0.0014688813255871742, 0.0014170346121132678, 0.0014061453462369284, 0.001417859409916766, 0.0014294340603091583, 0.0014229298388699488, 0.0014173893676120409, 0.001464733122182744, 0.0014282718362590792, 0.0014394179167111917, 0.0013917156314591365, 0.0014634111430495977, 0.0013975964060851506, 0.001403878041429027, 0.001456859509688707, 0.001450118917629731, 0.001509395957810386, 0.004161999366075105, 0.0014744661629618127, 0.001508708774796402, 0.001507763959923569, 0.0015416388775279022, 0.0014947257147227622, 0.0014915541645937733, 0.0014615946340051536, 0.0014611359790195615, 0.0014162077972361324, 0.0014337523655053607, 0.0014445113246234096, 0.0014309662451245347, 0.0014174980211204716, 0.0021336216940449513, 0.0013894425724081847, 0.0013979120602907271, 0.0014181765727698803, 0.00141295310280913, 0.001446602733007499, 0.0014207614063076219, 0.0014198702256366306, 0.0015743687340267459, 0.0015295239388752654, 0.0015192998582687304, 0.002322775059930828, 0.0016097387142137301, 0.0016027275515644221, 0.0016102553273988317, 0.001614090815490606, 0.0016626224482470021, 0.0016417103268358173, 0.0016671115323445018, 0.0016286228569604609, 0.0016277193267620644, 0.0016537955296891077, 0.0016665917545633049, 0.0016587150012314015, 0.001662482654827894, 0.0016524847953257207, 0.001661585817322591, 0.0016571537339679745, 0.0016536900003877829, 0.0016559832444300456, 0.0017495316534056043, 0.0016592599579836338, 0.0016688233673838632, 0.0016544068384231354, 0.0016622090811974236, 0.0016625059996636547, 0.0016614165922094668, 0.0016597558349865128, 0.0016633936332310646, 0.0016604946755176904, 0.0016615936717930802, 0.0017157593452162584, 0.0016011454269518049, 0.001565683286218923, 0.00157322973364546, 0.0015708320413012893, 0.0015651904692759319, 0.0015561871411164804, 0.0015614326729686285, 0.0015625771828832067, 0.0015597392861940423, 0.001559199347179763, 0.0015659257532002367, 0.0015673983880147642, 0.001566382490896753, 0.001570622469963772, 0.001687857633627647, 0.0016655466942192645, 0.0015674223671952377, 0.00156483642889985, 0.001571678858231373, 0.0015663681219198874, 0.0015636453481048954, 0.0015682347964647474, 0.0015610674282117766, 0.0015698113877858435, 0.0015643016121597315, 0.0015657168779788272, 0.0015720819403436414, 0.0015704564070709202, 0.0015667871648103607, 0.001631629204244486, 0.0015584428780427088, 0.0015631291649437376, 0.00156147946955218, 0.0015799865501989819, 0.0015704539172085269, 0.0015676533470728568, 0.0015673725533166102, 0.0015764154270481393, 0.0015704421022412728, 0.0015838698350957461, 0.0015753167325022574, 0.0015736561225803227, 0.0015752008161032383, 0.001578464367597991, 0.0015750514481178656, 0.0015694794900791378, 0.0015685870217121377, 0.001570089121482202, 0.0015614090192758916, 0.0015648562670210187, 0.0015670084275723416, 0.001563991265542501, 0.001564279612039729, 0.0015589382656260716, 0.0015637454082619172, 0.0015581926326172389, 0.0015716603885841916, 0.0015695520999784373, 0.0015683408983393895, 0.0015690951627127978, 0.001568919040585811, 0.001637325265767927, 0.0015671675102975294, 0.001569017858187459, 0.0015686822043047572, 0.0015614850622392735, 0.0015679349177231898, 0.0015647789601198568, 0.0015683495106973819, 0.0015798935509876025, 0.001569199938878265, 0.0014867062903552626, 0.001596048289987569, 0.0014705952708027326, 0.0015003558752747874, 0.001470460959050494, 0.001485975624139731, 0.0014724595627437036, 0.0015009955629163112, 0.0019347351238441963, 0.0015071248126332648, 0.0015459011677497376, 0.001484895665877654, 0.0015144726470073995, 0.001513160124886781, 0.0015338684994882594, 0.0014743522066661778, 0.0015212721045827493, 0.0014862850221106783, 0.0034593447902201055, 0.0014810682090076928, 0.0014967447496019304, 0.0014818664591681834, 0.0015027569170342758, 0.00151946627011057, 0.0016095436246056731, 0.0016034834989113733, 0.0038583322918081344, 0.0016206284587193902, 0.0016113179590320215, 0.00161133327249748, 0.001622793936500481, 0.001599196936391915, 0.0015951937918240826, 0.004209362581605092, 0.0016169411246664822, 0.001624639000510797, 0.0016374747719964944, 0.0016569005019846372, 0.0016162858106933224, 0.0016466346448093343, 0.0018253696883524146, 0.0015011752911959775, 0.0015049591044468495, 0.0015117238532790604, 0.0015489672708402698, 0.0015359333313729924, 0.001517395210006119, 0.001520966958196368, 0.001519786354037933, 0.0015186415839707479, 0.001523420187974504, 0.0015696178961661644, 0.001552070039906539, 0.0015352262707892805, 0.001622613310852709, 0.0016485252490383573, 0.0016369336469021316, 0.0016471062505540128, 0.001665747457688364, 0.0016203727694422316, 0.0025436522725309865, 0.0016257371874720168, 0.0016225754807237536, 0.0016282572299436044, 0.0016366792697226629, 0.0015548068113275804, 0.0015254343767689231, 0.0015507055213674903, 0.0014986343740019947, 0.0014964587705132242, 0.0014874227514762122, 0.0015112446247561213, 0.00155841125039539, 0.001521873479456796, 0.0015246213733917102, 0.0015406853757061374, 0.0015320711681852117, 0.0015384870421257801, 0.0015532137501092318, 0.0015927273125271313, 0.0015589268102000158, 0.0015435841657260123, 0.0015273086052426759, 0.0015375630415898438, 0.0015373496474542965, 0.0017602095613256097, 0.0016623002714671504, 0.0016225583337169762, 0.0016018779594257164, 0.0014942574392383297, 0.0015076338750077412, 0.0015075167708952601, 0.0015020693123612243, 0.0014975962718987528, 0.0015158144791106072, 0.0014928674184678432, 0.0014843552708043717, 0.001507635436913309, 0.0015102572918597919, 0.0015071803524430531, 0.0015196534392695564, 0.0015948866882051032, 0.001522799063726173, 0.001512852458593746, 0.0015112999171833508, 0.0015118149361417939, 0.0015156027705719073, 0.0015335155427843954, 0.0015531609387835488, 0.0015370824160830427, 0.0015329739811325755, 0.001534545042280418, 0.0015408744366141036, 0.001538160584459547]
[718.4594714141224, 694.6405599818257, 695.4048441092973, 674.2847075861786, 679.6555212124694, 683.3887905310918, 683.4973468941781, 672.2763321169268, 684.2829406762329, 678.4596814837478, 679.183519969758, 685.6026290333486, 689.8073668687088, 682.7324857954358, 682.8202717639859, 693.829143505685, 691.7700997879599, 695.7679806595162, 691.3773974341804, 694.1790403877961, 679.7120619661569, 698.8586137937958, 697.3712584972939, 698.9667679481228, 694.9987592152495, 702.2589768400046, 688.0146190595415, 688.2278721179323, 697.3379422236793, 699.0424318067588, 698.0250088588375, 660.3472859638337, 692.1212479833538, 695.7610558593532, 663.3065189443492, 695.4252644498165, 700.2403630788652, 695.5744073231589, 688.7833108400147, 692.1873992352415, 691.9327750602745, 686.0336769228664, 687.6262250304939, 714.826941379232, 234.95878158959005, 684.4389190299406, 714.5397825298223, 702.7890787218239, 684.4823064635569, 614.9269238324348, 644.7318784813226, 276.22716312340566, 664.5178510421256, 657.356733482982, 639.9887071383416, 647.0015689911361, 646.8001268310162, 236.65582342332644, 571.706437859852, 588.7229303971823, 675.7820834065104, 683.4018580381766, 688.7987643270756, 686.8215614189502, 675.6285623188891, 670.1681268936383, 661.1399770245865, 660.8485120354366, 673.2032506232175, 677.4495052524819, 442.2359321940983, 695.4877358707586, 725.5037047173611, 732.0762668533989, 724.9975530788855, 692.7464498502608, 722.8937026634102, 698.2566923820827, 708.949360574803, 712.4743362440468, 709.7183351427964, 714.1817411225762, 695.6086428082692, 710.1366219357047, 692.8467532644626, 715.3720993929121, 725.8464373712538, 716.4544086439671, 704.9184980545208, 685.7406411753631, 725.5042737079317, 733.1456175399741, 712.8720858612298, 713.3993523713027, 718.5907430866177, 709.3304005154702, 702.3828545362609, 716.2563269806246, 690.7523936776994, 696.8396423669411, 698.5127865771303, 693.7168874023388, 693.4850252630341, 680.7901922234988, 705.6990644065278, 711.1640362613731, 705.2885448344305, 699.5775655322777, 702.7753390807885, 705.5224364246211, 682.7182268601948, 700.1468310256637, 694.725269423364, 718.5375930221863, 683.3349634854517, 715.5141467493681, 712.3125873399132, 686.4079846749767, 689.5986169427638, 662.5166808122739, 240.2691379895695, 678.2115623401384, 662.8184423033853, 663.2337863087612, 648.6603410025257, 669.0190649362564, 670.4416264174699, 684.1842305206999, 684.3989980118148, 706.111067847245, 697.4705144758564, 692.2756387948044, 698.8285037520026, 705.4683569925147, 468.68664805530045, 719.7130848429366, 715.3525807567806, 705.1308131870153, 707.7375731805063, 691.2747896728991, 703.8479476993064, 704.2897174293711, 635.1752155559586, 653.7982012464281, 658.1979156764471, 430.5195183341515, 621.2188295964825, 623.9363633724897, 621.0195259005144, 619.543826408583, 601.4594600562245, 609.1208562520098, 599.8398910921541, 614.0156978186618, 614.3565315951903, 604.6696717023943, 600.0269695694186, 602.8763224891661, 601.5100350647108, 605.1492896204775, 601.8346988609698, 603.4443150941394, 604.7082583588849, 603.8708443237774, 571.5815418677447, 602.6783176369905, 599.2245911367202, 604.4462442824099, 601.6090342134452, 601.5015886873865, 601.8959992870487, 602.4982584309613, 601.1806105434868, 602.2301755880254, 601.8318539458971, 582.832320154991, 624.5528876810141, 638.6987769505857, 635.6350751665606, 636.6052981524316, 638.8998780848742, 642.596236390023, 640.4374759872157, 639.9683874526049, 641.1327898524146, 641.3548093184957, 638.5998812244637, 637.9998905489371, 638.4136734237247, 636.6902416868301, 592.467030439492, 600.4034612003215, 637.9901301200714, 639.0444276038771, 636.2622966916477, 638.4195298703515, 639.5312090506831, 637.659617204189, 640.5873198863122, 637.0192035684365, 639.2629095480914, 638.6850739521266, 636.0991589162394, 636.7575664612772, 638.2487822594826, 612.8843473741589, 641.6661233396808, 639.7423977665936, 640.4182824682237, 632.916780129591, 636.7585760029779, 637.896127908133, 638.0104065775353, 634.3505543285087, 636.7633665531761, 631.3650136152439, 634.7929780518389, 635.4628470928584, 634.839691407613, 633.527129612522, 634.8998956160873, 637.1539139702788, 637.5164311307918, 636.9065209852392, 640.4471779366006, 639.0363262586905, 638.1586610540642, 639.3897600528672, 639.2719001790598, 641.4622195436319, 639.4902870483803, 641.7691747908838, 636.2697738414315, 637.1244382481717, 637.6164780621564, 637.3099756875847, 637.3815181863143, 610.7521950020034, 638.093881751127, 637.3413755501849, 637.4777486834574, 640.4159887164936, 637.7815741562205, 639.0678974386282, 637.6129766861344, 632.9540362861112, 637.2674222220817, 672.6278125594265, 626.5474586660462, 679.9967467963803, 666.5085373940711, 680.0588576290526, 672.9585490871866, 679.1357978868042, 666.2244877373802, 516.8666179032627, 663.5150530451351, 646.871883443643, 673.447988959511, 660.2958475189378, 660.8685912040029, 651.9463698052522, 678.2639829740626, 657.344597976624, 672.8184602034788, 289.0720817500165, 675.1883498127303, 668.1165911996397, 674.8246401105066, 665.4436181026018, 658.1258298858, 621.2941263055191, 623.6422143906773, 259.17933562206713, 617.0445758987803, 620.6099760724675, 620.6040780440496, 616.2211834217705, 625.3138542499872, 626.8830816201419, 237.5656600289076, 618.4517078234772, 615.521355627677, 610.6964315430325, 603.5365423585779, 618.7024555830504, 607.2992592207917, 547.834231268847, 666.1447239804393, 664.4698829657248, 661.4964749222638, 645.5914329665138, 651.0699257409083, 659.0240916840428, 657.4764787696937, 657.9872212584958, 658.4832198426499, 656.4177158040497, 637.0977308824829, 644.3008203806428, 651.3697811371392, 616.2897797716723, 606.6027806267057, 610.8983109318344, 607.1253749802994, 600.3310978410539, 617.1419434209711, 393.13549685978865, 615.1055703874108, 616.304148484943, 614.1535757434564, 610.993258422251, 643.166721881122, 655.5509795958156, 644.8677625898627, 667.2741646313452, 668.2442708776006, 672.3038214976455, 661.7062410801799, 641.679145826422, 657.0848454215334, 655.9005517385443, 649.0617849485806, 652.7111930345459, 649.9892248804812, 643.8263889497977, 627.8538655894152, 641.4669331857193, 647.8428725845721, 654.7465237656464, 650.3798367616834, 650.4701137154478, 568.114173432226, 601.5760312169097, 616.3106615151321, 624.2672821083739, 669.2287244089155, 663.2910128759646, 663.3425374141184, 665.7482392926456, 667.7367049880093, 659.7113392047439, 669.851848616482, 673.6931647489622, 663.2903257085627, 662.1388324955939, 663.4906024213076, 658.0447713662035, 627.0037911755394, 656.6854576027098, 661.0029909522956, 661.6820318919399, 661.4566215042404, 659.8034916646751, 652.0964229578695, 643.8482806445094, 650.5832020044224, 652.326792435962, 651.6589428446787, 648.98214691483, 650.1271779444038]
Elapsed: 0.077021583303012~0.017403137525130282
Time per graph: 0.0015823325729254134~0.00035870570493970585
Speed: 646.9298266092723~69.90752609032323
Total Time: 0.0748
best val loss: 0.48456352949142456 test_score: 0.8958

Testing...
Test loss: 0.3172 score: 0.8958 time: 0.07s
test Score 0.8958
Epoch Time List: [0.4269473261665553, 0.25333308102563024, 0.25412796705495566, 0.2652982190484181, 0.27468802395742387, 0.25961347692646086, 0.2598321158438921, 0.26051825110334903, 0.26061901706270874, 0.25790083687752485, 0.25916229700669646, 0.2570972350658849, 0.25671734602656215, 0.26042358204722404, 0.26060515211429447, 0.2569717770675197, 0.25592819205485284, 0.2540595130994916, 0.25543231202755123, 0.2540585189126432, 0.2558621239149943, 0.25361194706056267, 0.25279555399902165, 0.2528341980651021, 0.25384680391289294, 0.2577593169407919, 0.2643336448818445, 0.25804819411132485, 0.2561864301096648, 0.25485508795827627, 0.2555139501346275, 0.25611838104669005, 0.2622958570718765, 0.25739872292615473, 0.2547132800100371, 0.25745510088745505, 0.253775681136176, 0.2599600012181327, 0.26379065902438015, 0.2579970830120146, 0.2611393529223278, 0.2671316539635882, 0.2598690538434312, 0.25199053389951587, 0.3944010949926451, 0.26697098196018487, 0.24389594595413655, 0.253520202008076, 0.2614180539967492, 0.2760192189598456, 0.27443650108762085, 0.37849338992964476, 0.267537759966217, 0.27805766102392226, 0.2755730369826779, 0.27738830901216716, 0.278378228074871, 0.4076352168340236, 0.28930948802735656, 0.2872702139429748, 0.26830877701286227, 0.25945253507234156, 0.2592718470841646, 0.25474974990356714, 0.38510407297872007, 0.2640180920716375, 0.266318507026881, 0.2692316179163754, 0.26876663602888584, 0.26289435708895326, 0.32215014402754605, 0.25775652192533016, 0.25698840094264597, 0.24485864606685936, 0.24731450621038675, 0.2538160680560395, 0.24832697492092848, 0.24497426091693342, 0.2948160788509995, 0.251008473103866, 0.2501027488615364, 0.2473090939456597, 0.2510957169579342, 0.2555118229938671, 0.251986016985029, 0.2941983670461923, 0.24519625713583082, 0.24981700698845088, 0.25327611388638616, 0.2571590510196984, 0.25120398099534214, 0.242032230948098, 0.33210902696009725, 0.2522523469524458, 0.24606381205376238, 0.25235421187244356, 0.2559921918436885, 0.24971599702257663, 0.25422659900505096, 0.2876001059776172, 0.25414309999905527, 0.2576894700760022, 0.25479288294445723, 0.26316244795452803, 0.2567206711973995, 0.25121319096069783, 0.34250901301857084, 0.2535397399915382, 0.2509522819891572, 0.2472211830317974, 0.2574277420062572, 0.2588816311908886, 0.25127073004841805, 0.2832103440305218, 0.24849731102585793, 0.25234804197680205, 0.250898061087355, 0.25085386692080647, 0.26244621409568936, 0.25428973499219865, 0.3897179609630257, 0.26067970297299325, 0.26574036106467247, 0.2630431829020381, 0.26981714193243533, 0.2748801599955186, 0.26611010206397623, 0.36772790108807385, 0.2658948239404708, 0.24963799898978323, 0.25276345503516495, 0.25572041515260935, 0.2595332800410688, 0.2532952941255644, 0.28413942200131714, 0.2837724540149793, 0.24879095412325114, 0.2539830489549786, 0.250952021102421, 0.255826850887388, 0.25999324407894164, 0.25449883099645376, 0.36166168085765094, 0.24800026998855174, 0.24578555906191468, 0.2853663720889017, 0.2865409019868821, 0.2548926039598882, 0.2573663740186021, 0.25789332296699286, 0.26453079108614475, 0.26381403987761587, 0.26295149500947446, 0.406110450043343, 0.26101477397605777, 0.26293472305405885, 0.2627391149289906, 0.2669031519908458, 0.2655713160056621, 0.26583897206000984, 0.2657190361060202, 0.2650711789028719, 0.2650118318852037, 0.2640689619584009, 0.26947103487327695, 0.26663888001348823, 0.2655013280455023, 0.26527521607931703, 0.2665644639637321, 0.2660468809772283, 0.26469696406275034, 0.2653566200751811, 0.2651624669088051, 0.26424240798223764, 0.2659758380614221, 0.2709018839523196, 0.2593253750819713, 0.25242652697488666, 0.2527960939332843, 0.25196898786816746, 0.2523226961493492, 0.25181631394661963, 0.25220634206198156, 0.2519868150120601, 0.2508389069698751, 0.2533758000936359, 0.2518783899722621, 0.25212549802381545, 0.258863509981893, 0.2525559790665284, 0.2571795219555497, 0.2691539528314024, 0.25185743486508727, 0.25163634109776467, 0.2514843010576442, 0.25319400313310325, 0.25212034094147384, 0.252313019009307, 0.25180569489020854, 0.252437048824504, 0.25309809495229274, 0.2521410209592432, 0.2517535201041028, 0.2527617869200185, 0.25152806495316327, 0.2560047891456634, 0.2534430930390954, 0.25406823598314077, 0.25109090097248554, 0.25252344517502934, 0.25180625391658396, 0.25305248191580176, 0.25359113805461675, 0.25304218102246523, 0.2526121649425477, 0.2551262929337099, 0.255416558124125, 0.25302111206110567, 0.2527242790674791, 0.2530090530635789, 0.2547827899688855, 0.25323887716513127, 0.25343781884294003, 0.25315195694565773, 0.2520240410231054, 0.25217268196865916, 0.25177488406188786, 0.2510944770183414, 0.2514843950048089, 0.2525127559201792, 0.2515659899218008, 0.2525814949767664, 0.25187365210149437, 0.2518126758513972, 0.2521513960091397, 0.25155572418589145, 0.25195092090871185, 0.2642731729429215, 0.25232086004689336, 0.2528223459376022, 0.25260345393326133, 0.25196052179671824, 0.25280780193861574, 0.25240326311904937, 0.25220954685937613, 0.2540801140712574, 0.25289274496026337, 0.24315834697335958, 0.2527287791017443, 0.24178069096524268, 0.24211037787608802, 0.28884243115317076, 0.24169408390298486, 0.24133976502344012, 0.249935002066195, 0.28274437924847007, 0.25460590689908713, 0.2619225470116362, 0.3347450679866597, 0.24571571790147573, 0.2502729530679062, 0.25209593400359154, 0.24396616697777063, 0.24961803085170686, 0.24675214802846313, 0.3407588499831036, 0.24430802604183555, 0.2435630359686911, 0.2478760980302468, 0.24790753901470453, 0.2501940580550581, 0.26656168699264526, 0.26547883497551084, 0.3741534221917391, 0.26365640200674534, 0.266737851081416, 0.26494550495408475, 0.26815261191222817, 0.27038924617227167, 0.26290007890202105, 0.38907184987328947, 0.26747603190597147, 0.26617294107563794, 0.2733875149860978, 0.2717773588374257, 0.2689706919481978, 0.2647984439972788, 0.32938517595175654, 0.25149412103928626, 0.25144426606129855, 0.2517198050627485, 0.2544742450118065, 0.2604969987878576, 0.2541975111234933, 0.3835748250130564, 0.2537269728491083, 0.25323639099951833, 0.2539786529960111, 0.2574750640196726, 0.2585209119133651, 0.2557202619500458, 0.4006793861044571, 0.2728618629043922, 0.26988752314355224, 0.2703951069852337, 0.2768415198661387, 0.27058267791289836, 0.30773324705660343, 0.29173028306104243, 0.2676715370034799, 0.2680195448920131, 0.2691300531150773, 0.2629809968639165, 0.2576115259435028, 0.2548702780622989, 0.2901037890696898, 0.2520185619359836, 0.2499849508749321, 0.2516501630889252, 0.2580826240591705, 0.2590055549517274, 0.25614150904584676, 0.338890005950816, 0.25790879293344915, 0.2581352851120755, 0.2598863741150126, 0.2632030139211565, 0.2634791140444577, 0.2593070239527151, 0.3491403170628473, 0.2581834960728884, 0.2557200021110475, 0.268477096920833, 0.27455133688636124, 0.2731344449566677, 0.2660870780237019, 0.3159903531195596, 0.252321889041923, 0.25256272102706134, 0.2509619559859857, 0.2499109829077497, 0.2565752068767324, 0.25199305010028183, 0.24755878292489797, 0.3418866239953786, 0.25116029602941126, 0.25247209111694247, 0.2537825672188774, 0.25661713199224323, 0.25855171494185925, 0.25291596492752433, 0.3296556930290535, 0.25349315488711, 0.2528529589762911, 0.2540204001124948, 0.25416374090127647, 0.25987996393814683, 0.25776351906824857, 0.3344834119779989, 0.26045674993656576, 0.25901833607349545]
Total Epoch List: [143, 104, 114]
Total Time List: [0.07781030703336, 0.07772996998392045, 0.0748419500887394]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e437754b0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6916;  Loss pred: 0.6916; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6895;  Loss pred: 0.6895; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6874;  Loss pred: 0.6874; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6854;  Loss pred: 0.6854; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6817;  Loss pred: 0.6817; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6788;  Loss pred: 0.6788; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6762;  Loss pred: 0.6762; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6723;  Loss pred: 0.6723; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6658;  Loss pred: 0.6658; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6604;  Loss pred: 0.6604; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6555;  Loss pred: 0.6555; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6532;  Loss pred: 0.6532; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6452;  Loss pred: 0.6452; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5102 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6388;  Loss pred: 0.6388; Loss self: 0.0000; time: 0.12s
Val loss: 0.6929 score: 0.5510 time: 0.07s
Test loss: 0.6928 score: 0.5714 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6322;  Loss pred: 0.6322; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
Test loss: 0.6927 score: 0.5306 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6248;  Loss pred: 0.6248; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4898 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6176;  Loss pred: 0.6176; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6072;  Loss pred: 0.6072; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4898 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.5979;  Loss pred: 0.5979; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4898 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5910;  Loss pred: 0.5910; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4898 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5804;  Loss pred: 0.5804; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5655;  Loss pred: 0.5655; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5575;  Loss pred: 0.5575; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4898 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5503;  Loss pred: 0.5503; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.4898 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5385;  Loss pred: 0.5385; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.4898 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5212;  Loss pred: 0.5212; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.4898 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5133;  Loss pred: 0.5133; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.4898 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.4969;  Loss pred: 0.4969; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6894 score: 0.4898 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4852;  Loss pred: 0.4852; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.4898 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4729;  Loss pred: 0.4729; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.4898 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4577;  Loss pred: 0.4577; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6874 score: 0.4898 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4413;  Loss pred: 0.4413; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6876 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.4898 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4225;  Loss pred: 0.4225; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6868 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6855 score: 0.4898 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4107;  Loss pred: 0.4107; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6859 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6843 score: 0.4898 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3944;  Loss pred: 0.3944; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6849 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6829 score: 0.4898 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3824;  Loss pred: 0.3824; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6837 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6813 score: 0.4898 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3639;  Loss pred: 0.3639; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6795 score: 0.4898 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3401;  Loss pred: 0.3401; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6808 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6775 score: 0.4898 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3251;  Loss pred: 0.3251; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6751 score: 0.4898 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3162;  Loss pred: 0.3162; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6771 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6724 score: 0.4898 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.2948;  Loss pred: 0.2948; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6750 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6695 score: 0.4898 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2777;  Loss pred: 0.2777; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6726 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6662 score: 0.4898 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2631;  Loss pred: 0.2631; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6700 score: 0.5102 time: 0.08s
Test loss: 0.6626 score: 0.5102 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2439;  Loss pred: 0.2439; Loss self: 0.0000; time: 0.12s
Val loss: 0.6670 score: 0.5306 time: 0.07s
Test loss: 0.6586 score: 0.5102 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2302;  Loss pred: 0.2302; Loss self: 0.0000; time: 0.12s
Val loss: 0.6638 score: 0.5306 time: 0.07s
Test loss: 0.6543 score: 0.5306 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2120;  Loss pred: 0.2120; Loss self: 0.0000; time: 0.12s
Val loss: 0.6603 score: 0.5510 time: 0.07s
Test loss: 0.6494 score: 0.5510 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.1962;  Loss pred: 0.1962; Loss self: 0.0000; time: 0.12s
Val loss: 0.6564 score: 0.5510 time: 0.07s
Test loss: 0.6442 score: 0.5714 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.1855;  Loss pred: 0.1855; Loss self: 0.0000; time: 0.12s
Val loss: 0.6523 score: 0.5918 time: 0.07s
Test loss: 0.6385 score: 0.5714 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1715;  Loss pred: 0.1715; Loss self: 0.0000; time: 0.12s
Val loss: 0.6478 score: 0.5918 time: 0.07s
Test loss: 0.6324 score: 0.5714 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1599;  Loss pred: 0.1599; Loss self: 0.0000; time: 0.12s
Val loss: 0.6428 score: 0.6122 time: 0.07s
Test loss: 0.6259 score: 0.6122 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1453;  Loss pred: 0.1453; Loss self: 0.0000; time: 0.12s
Val loss: 0.6376 score: 0.6327 time: 0.07s
Test loss: 0.6189 score: 0.6122 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1360;  Loss pred: 0.1360; Loss self: 0.0000; time: 0.12s
Val loss: 0.6320 score: 0.6327 time: 0.07s
Test loss: 0.6116 score: 0.6327 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1246;  Loss pred: 0.1246; Loss self: 0.0000; time: 0.12s
Val loss: 0.6262 score: 0.6327 time: 0.07s
Test loss: 0.6040 score: 0.6531 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1157;  Loss pred: 0.1157; Loss self: 0.0000; time: 0.12s
Val loss: 0.6202 score: 0.6327 time: 0.07s
Test loss: 0.5961 score: 0.6531 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1062;  Loss pred: 0.1062; Loss self: 0.0000; time: 0.12s
Val loss: 0.6140 score: 0.6531 time: 0.07s
Test loss: 0.5879 score: 0.6531 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.0963;  Loss pred: 0.0963; Loss self: 0.0000; time: 0.12s
Val loss: 0.6078 score: 0.6735 time: 0.07s
Test loss: 0.5794 score: 0.6531 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.0882;  Loss pred: 0.0882; Loss self: 0.0000; time: 0.12s
Val loss: 0.6016 score: 0.6735 time: 0.07s
Test loss: 0.5710 score: 0.6735 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.0804;  Loss pred: 0.0804; Loss self: 0.0000; time: 0.12s
Val loss: 0.5951 score: 0.6735 time: 0.08s
Test loss: 0.5623 score: 0.6735 time: 0.08s
Epoch 62/1000, LR 0.000268
Train loss: 0.0714;  Loss pred: 0.0714; Loss self: 0.0000; time: 0.13s
Val loss: 0.5886 score: 0.6735 time: 0.08s
Test loss: 0.5535 score: 0.6735 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0665;  Loss pred: 0.0665; Loss self: 0.0000; time: 0.12s
Val loss: 0.5818 score: 0.6939 time: 0.07s
Test loss: 0.5443 score: 0.6735 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0597;  Loss pred: 0.0597; Loss self: 0.0000; time: 0.12s
Val loss: 0.5750 score: 0.6939 time: 0.07s
Test loss: 0.5350 score: 0.6735 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0534;  Loss pred: 0.0534; Loss self: 0.0000; time: 0.12s
Val loss: 0.5682 score: 0.7143 time: 0.08s
Test loss: 0.5256 score: 0.6939 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0495;  Loss pred: 0.0495; Loss self: 0.0000; time: 0.12s
Val loss: 0.5612 score: 0.7143 time: 0.07s
Test loss: 0.5160 score: 0.7143 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0448;  Loss pred: 0.0448; Loss self: 0.0000; time: 0.12s
Val loss: 0.5540 score: 0.7143 time: 0.07s
Test loss: 0.5061 score: 0.7347 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0400;  Loss pred: 0.0400; Loss self: 0.0000; time: 0.12s
Val loss: 0.5468 score: 0.7143 time: 0.07s
Test loss: 0.4960 score: 0.7755 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0358;  Loss pred: 0.0358; Loss self: 0.0000; time: 0.12s
Val loss: 0.5394 score: 0.7143 time: 0.07s
Test loss: 0.4855 score: 0.7959 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0334;  Loss pred: 0.0334; Loss self: 0.0000; time: 0.12s
Val loss: 0.5317 score: 0.7143 time: 0.07s
Test loss: 0.4745 score: 0.7959 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0297;  Loss pred: 0.0297; Loss self: 0.0000; time: 0.12s
Val loss: 0.5236 score: 0.7347 time: 0.07s
Test loss: 0.4627 score: 0.8163 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0282;  Loss pred: 0.0282; Loss self: 0.0000; time: 0.12s
Val loss: 0.5152 score: 0.7347 time: 0.08s
Test loss: 0.4506 score: 0.8163 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0259;  Loss pred: 0.0259; Loss self: 0.0000; time: 0.12s
Val loss: 0.5068 score: 0.7347 time: 0.07s
Test loss: 0.4384 score: 0.8367 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0236;  Loss pred: 0.0236; Loss self: 0.0000; time: 0.12s
Val loss: 0.4985 score: 0.7551 time: 0.07s
Test loss: 0.4264 score: 0.8571 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0209;  Loss pred: 0.0209; Loss self: 0.0000; time: 0.12s
Val loss: 0.4898 score: 0.7551 time: 0.07s
Test loss: 0.4140 score: 0.8571 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.12s
Val loss: 0.4811 score: 0.7551 time: 0.07s
Test loss: 0.4017 score: 0.8571 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.12s
Val loss: 0.4722 score: 0.7755 time: 0.07s
Test loss: 0.3893 score: 0.8571 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.12s
Val loss: 0.4637 score: 0.7959 time: 0.07s
Test loss: 0.3773 score: 0.8571 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.12s
Val loss: 0.4551 score: 0.7959 time: 0.07s
Test loss: 0.3656 score: 0.8571 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.12s
Val loss: 0.4465 score: 0.7959 time: 0.07s
Test loss: 0.3538 score: 0.8571 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.12s
Val loss: 0.4384 score: 0.8163 time: 0.07s
Test loss: 0.3426 score: 0.8571 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0118;  Loss pred: 0.0118; Loss self: 0.0000; time: 0.12s
Val loss: 0.4303 score: 0.8163 time: 0.07s
Test loss: 0.3317 score: 0.8571 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.12s
Val loss: 0.4225 score: 0.8163 time: 0.07s
Test loss: 0.3211 score: 0.8571 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.12s
Val loss: 0.4157 score: 0.8367 time: 0.07s
Test loss: 0.3116 score: 0.8571 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.12s
Val loss: 0.4093 score: 0.8367 time: 0.07s
Test loss: 0.3027 score: 0.8571 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.12s
Val loss: 0.4036 score: 0.8163 time: 0.07s
Test loss: 0.2946 score: 0.8571 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.12s
Val loss: 0.3986 score: 0.8367 time: 0.07s
Test loss: 0.2872 score: 0.8571 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.12s
Val loss: 0.3946 score: 0.8367 time: 0.07s
Test loss: 0.2808 score: 0.8367 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.12s
Val loss: 0.3909 score: 0.8367 time: 0.07s
Test loss: 0.2750 score: 0.8367 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.3875 score: 0.8367 time: 0.07s
Test loss: 0.2696 score: 0.8367 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.12s
Val loss: 0.3853 score: 0.8367 time: 0.07s
Test loss: 0.2654 score: 0.8571 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.3837 score: 0.8367 time: 0.19s
Test loss: 0.2619 score: 0.8571 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.12s
Val loss: 0.3827 score: 0.8367 time: 0.07s
Test loss: 0.2589 score: 0.8571 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.12s
Val loss: 0.3819 score: 0.8367 time: 0.07s
Test loss: 0.2562 score: 0.8776 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.12s
Val loss: 0.3817 score: 0.8367 time: 0.07s
Test loss: 0.2541 score: 0.8776 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.12s
Val loss: 0.3816 score: 0.8367 time: 0.07s
Test loss: 0.2521 score: 0.8776 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.3821 score: 0.8367 time: 0.07s
Test loss: 0.2507 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.12s
Val loss: 0.3829 score: 0.8367 time: 0.07s
Test loss: 0.2497 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.13s
Val loss: 0.3843 score: 0.8367 time: 0.12s
Test loss: 0.2492 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.3857 score: 0.8367 time: 0.07s
Test loss: 0.2488 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.12s
Val loss: 0.3874 score: 0.8367 time: 0.07s
Test loss: 0.2486 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.3894 score: 0.8571 time: 0.07s
Test loss: 0.2486 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.12s
Val loss: 0.3914 score: 0.8571 time: 0.07s
Test loss: 0.2487 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.12s
Val loss: 0.3934 score: 0.8571 time: 0.07s
Test loss: 0.2489 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.3959 score: 0.8571 time: 0.07s
Test loss: 0.2494 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.13s
Val loss: 0.3983 score: 0.8571 time: 0.13s
Test loss: 0.2499 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.12s
Val loss: 0.4005 score: 0.8571 time: 0.07s
Test loss: 0.2505 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.12s
Val loss: 0.4028 score: 0.8571 time: 0.07s
Test loss: 0.2511 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.12s
Val loss: 0.4050 score: 0.8776 time: 0.07s
Test loss: 0.2516 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.12s
Val loss: 0.4071 score: 0.8776 time: 0.07s
Test loss: 0.2523 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.12s
Val loss: 0.4095 score: 0.8776 time: 0.07s
Test loss: 0.2531 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.4116 score: 0.8776 time: 0.07s
Test loss: 0.2537 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.13s
Val loss: 0.4137 score: 0.8776 time: 0.11s
Test loss: 0.2544 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.12s
Val loss: 0.4158 score: 0.8776 time: 0.07s
Test loss: 0.2551 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0025;  Loss pred: 0.0025; Loss self: 0.0000; time: 0.12s
Val loss: 0.4181 score: 0.8776 time: 0.07s
Test loss: 0.2560 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.12s
Val loss: 0.4202 score: 0.8776 time: 0.07s
Test loss: 0.2569 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 095,   Train_Loss: 0.0055,   Val_Loss: 0.3816,   Val_Precision: 0.9444,   Val_Recall: 0.7083,   Val_accuracy: 0.8095,   Val_Score: 0.8367,   Val_Loss: 0.3816,   Test_Precision: 0.9524,   Test_Recall: 0.8000,   Test_accuracy: 0.8696,   Test_Score: 0.8776,   Test_loss: 0.2521


[0.07428603991866112, 0.07368665502872318, 0.07369477499742061, 0.07374373695347458, 0.07380805595312268, 0.07418648502789438, 0.07388828811235726, 0.07400949799921364, 0.07364533701911569, 0.07329934102017432, 0.07351951801683754, 0.07323871506378055, 0.07333967601880431, 0.07359892001841217, 0.07331554393749684, 0.07364430406596512, 0.07308613008353859, 0.07324132206849754, 0.0735149149550125, 0.07394484092947096, 0.07376707100775093, 0.07367894297931343, 0.07371359190437943, 0.07356877694837749, 0.07355665497016162, 0.07319004891905934, 0.07340334309265018, 0.07347590907011181, 0.0734468400478363, 0.073728768969886, 0.07369029801338911, 0.07379617891274393, 0.0738879480632022, 0.07414013298694044, 0.0743026080308482, 0.0739616829669103, 0.07424623798578978, 0.07402401801664382, 0.07418964593671262, 0.07410295808222145, 0.07418317603878677, 0.07362364290747792, 0.07686437398660928, 0.07348728796932846, 0.07359017198905349, 0.08234513096977025, 0.0728802380617708, 0.07267327699810266, 0.07309860805980861, 0.0730595689965412, 0.07276798598468304, 0.07280478999018669, 0.07253558305092156, 0.07256661111023277, 0.07246251590549946, 0.07279512996319681, 0.07265368802472949, 0.07246784400194883, 0.07362675899639726, 0.07691313803661615, 0.08181193796917796, 0.07464776106644422, 0.07361069309990853, 0.07469659601338208, 0.08008829702157527, 0.07456428196746856, 0.07354245299939066, 0.07381768699269742, 0.07417470903601497, 0.07365290098823607, 0.07403540308587253, 0.07368809904437512, 0.07372190000023693, 0.07365433895029128, 0.07386644405778497, 0.07360471202991903, 0.07402470905799419, 0.0742970600258559, 0.07350145594682544, 0.07358346204273403, 0.07366716396063566, 0.07360699202399701, 0.07374014100059867, 0.07374450203496963, 0.07427561702206731, 0.07351024798117578, 0.07427464995998889, 0.0735362300183624, 0.07397153903730214, 0.07498381403274834, 0.0732289069565013, 0.07379264093469828, 0.07399367401376367, 0.07395968504715711, 0.07454889104701579, 0.07511695509310812, 0.07412585197016597, 0.07350716891232878, 0.07468835706822574, 0.07574352703522891, 0.07588431297335774, 0.07642976101487875, 0.07748996489681304, 0.07632595708128065, 0.07614559202920645, 0.07311372295953333, 0.07282393495552242, 0.07271667406894267, 0.07332176202908158, 0.0746127360034734, 0.07305571099277586, 0.07353160402271897, 0.07263262697961181, 0.07310205302201211, 0.07274960202630609, 0.0730654610088095]
[0.001516041630993084, 0.001503809286300473, 0.0015039749999473594, 0.0015049742235402977, 0.001506286856186177, 0.0015140098985284567, 0.0015079242471909644, 0.0015103979183512988, 0.0015029660616146059, 0.0014959049187790677, 0.0015003983268742354, 0.0014946676543628682, 0.0014967280820164146, 0.0015020187758859626, 0.00149623559056116, 0.0015029449809380636, 0.001491553675174257, 0.001494720858540766, 0.0015003043868369898, 0.0015090783863157338, 0.0015054504287296108, 0.0015036518975370089, 0.001504359018456723, 0.0015014036111913774, 0.0015011562238808494, 0.0014936744677359049, 0.0014980274100540852, 0.0014995083483696288, 0.0014989151030170675, 0.0015046687544874695, 0.0015038836329263083, 0.0015060444676070189, 0.0015079173074122897, 0.0015130639385089887, 0.001516379755731596, 0.0015094221013655163, 0.001515229346648771, 0.001510694245237629, 0.001514074406871686, 0.0015123052669841113, 0.0015139423681385055, 0.0015025233246424065, 0.001568660693604271, 0.0014997405708026216, 0.001501840244674561, 0.0016805128769340869, 0.0014873517971789958, 0.0014831281020020951, 0.0014918083277511963, 0.0014910116121743101, 0.0014850609384629192, 0.001485812040616055, 0.0014803180214473788, 0.0014809512471476076, 0.0014788268552142748, 0.0014856148972080983, 0.0014827283270352958, 0.0014789355918765068, 0.0015025869182938216, 0.0015696558782982888, 0.0016696313871260807, 0.0015234236952335555, 0.0015022590428552761, 0.0015244203268037159, 0.0016344550412566382, 0.0015217200401524196, 0.0015008663877426665, 0.001506483408014233, 0.001513769572163571, 0.0015031204283313484, 0.0015109265935892354, 0.0015038387560076555, 0.0015045285714334067, 0.0015031497744957404, 0.001507478450158877, 0.001502136980202429, 0.0015107083481223304, 0.0015162665311399164, 0.0015000297132005192, 0.001501703306994572, 0.0015034115094007278, 0.0015021835106938165, 0.0015049008367469115, 0.0015049898374483598, 0.0015158289188177002, 0.001500209142472975, 0.0015158091828569161, 0.001500739388129845, 0.0015096232456592272, 0.0015302819190356805, 0.00149446748890819, 0.0015059722639734344, 0.0015100749798727278, 0.0015093813274930023, 0.0015214059397350161, 0.0015329990835328186, 0.0015127724891870606, 0.0015001463043332404, 0.0015242521850658314, 0.0015457862660250797, 0.0015486594484358722, 0.0015597910411199744, 0.0015814278550370007, 0.0015576725934955235, 0.0015539916740654378, 0.001492116795092517, 0.001486202754194335, 0.001484013756509034, 0.00149636249038942, 0.0015227088980300694, 0.001490932877403589, 0.001500644980055489, 0.0014822985097879963, 0.0014918786331022881, 0.0014846857556388999, 0.001491131857322643]
[659.6124931905395, 664.9779390976523, 664.9046693163125, 664.4632076472396, 663.8841704640089, 660.4976631737685, 663.1632867916603, 662.0771836679751, 665.3510185890161, 668.4916851641767, 666.4896794995032, 669.0450529795334, 668.1240313556387, 665.7706388591262, 668.3439468412539, 665.3603509663072, 670.4418464076869, 669.021238504866, 666.5314110746857, 662.6561012787423, 664.2530241556076, 665.0475430104575, 664.7349387554243, 666.0434226653358, 666.1531851859894, 669.4899200598835, 667.544527749259, 666.8852501470035, 667.1491920971147, 664.5981030825797, 664.9450649676702, 663.9910185314236, 663.1663388200526, 660.9106030148503, 659.465411761276, 662.5052058634482, 659.9660983412825, 661.9473153832674, 660.4695221459796, 661.2421591271932, 660.5271251042188, 665.5470724476077, 637.4864902761897, 666.781988477398, 665.849782322682, 595.0564340955193, 672.3358938326913, 674.250591469534, 670.327401582102, 670.6855881167294, 673.3730408632449, 673.0326398387342, 675.5305181127576, 675.2416745156562, 676.211685278805, 673.1219523170441, 674.4323837121885, 676.1619677643821, 665.5189046471229, 637.0823145542768, 598.9345958099707, 656.4162045849565, 665.6641574274335, 655.9870545000676, 611.8247212423522, 657.1511011314784, 666.2818277275303, 663.7975530830089, 660.6025239169919, 665.2826886998835, 661.8455219750158, 664.964907976417, 664.6600263943621, 665.2697003101163, 663.3593998604805, 665.7182488545347, 661.9411359200516, 659.5146562050727, 666.6534610613564, 665.9104999917367, 665.1538808550217, 665.6976280735022, 664.4956103298227, 664.4563140010656, 659.7050548289903, 666.5737274148188, 659.7136442433034, 666.3382116239088, 662.4169327515334, 653.4743615282066, 669.1346632977396, 664.0228534897109, 662.2187727951641, 662.5231025356223, 657.2867726375318, 652.3161107803701, 661.0379334286968, 666.601648860151, 656.059417068712, 646.9199668667359, 645.7197552437938, 641.1115166310813, 632.3399431816654, 641.9834336020074, 643.5040912309871, 670.1888238835862, 672.8557036903732, 673.8482009441618, 668.2872675722816, 656.7243425803194, 670.7210063953164, 666.3801320702936, 674.627946663067, 670.2958121469635, 673.54320347047, 670.6315039070522]
Elapsed: 0.07403074317021649~0.0015127296355315933
Time per graph: 0.001510831493269724~3.087203337819578e-05
Speed: 662.1462085031078~12.687112027862238
Total Time: 0.0737
best val loss: 0.38164418935775757 test_score: 0.8776

Testing...
Test loss: 0.2516 score: 0.8980 time: 0.07s
test Score 0.8980
Epoch Time List: [0.2622560451272875, 0.25796876777894795, 0.25848431303165853, 0.2580867059295997, 0.2589477440342307, 0.2590590459294617, 0.258798627066426, 0.2577539780177176, 0.2575912610627711, 0.2565029120305553, 0.25680349208414555, 0.2559241330018267, 0.2561759949894622, 0.25614570803008974, 0.25670704699587077, 0.25666141498368233, 0.25629607297014445, 0.2560281759360805, 0.2562161289388314, 0.25621885794680566, 0.257247079978697, 0.25707807403523475, 0.2561769678723067, 0.2565242189448327, 0.2563294470310211, 0.25570802798029035, 0.25612286606337875, 0.25597506610210985, 0.2561398730613291, 0.2568738410482183, 0.257267851033248, 0.2572026080451906, 0.25746925093699247, 0.2573914119275287, 0.2581857340410352, 0.25748086790554225, 0.2586088831303641, 0.2584591649938375, 0.25796948990318924, 0.25819071801379323, 0.2597210290841758, 0.25927206804044545, 0.2668680880451575, 0.2582940779393539, 0.25576693704351783, 0.27290072303730994, 0.2557453179033473, 0.2534283968852833, 0.253620722098276, 0.2538745510391891, 0.2536341028753668, 0.2538859529886395, 0.25295148009900004, 0.25274586700834334, 0.25267262605484575, 0.2530542069580406, 0.2531494329450652, 0.25320833700243384, 0.2556638140231371, 0.26098171109333634, 0.27434650517534465, 0.280140882008709, 0.2601546950172633, 0.26138650986831635, 0.27935940597672015, 0.25942207395564765, 0.2563966140151024, 0.25637420709244907, 0.25734971603378654, 0.2577879340387881, 0.2583124057855457, 0.2642977449577302, 0.25666330894455314, 0.25722130585927516, 0.2574169710278511, 0.25657316006254405, 0.257989858975634, 0.25800983898807317, 0.2561765128048137, 0.2562936310423538, 0.25647680298425257, 0.25583676900714636, 0.25739237491507083, 0.25782336690463126, 0.2574705280130729, 0.2581893909955397, 0.2580223650438711, 0.2567282388918102, 0.2575419490458444, 0.2604817310348153, 0.25743252609390765, 0.38285427913069725, 0.256247624871321, 0.25625686696730554, 0.2575836241012439, 0.25958501000422984, 0.25774747296236455, 0.2531495519215241, 0.3243314999854192, 0.260102909989655, 0.262544349883683, 0.26232013397384435, 0.2656427500769496, 0.2687826860928908, 0.26323216187302023, 0.32721925305668265, 0.25414251384790987, 0.25383645005058497, 0.2547208690084517, 0.25836250407155603, 0.2568845801288262, 0.252450012951158, 0.3053483059629798, 0.2542786691337824, 0.25339521607384086, 0.25346772593911737]
Total Epoch List: [116]
Total Time List: [0.0736960619688034]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e43776230>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7023;  Loss pred: 0.7023; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7018 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.7040;  Loss pred: 0.7040; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6973 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7020 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.7057;  Loss pred: 0.7057; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7022 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.7006;  Loss pred: 0.7006; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7023 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6979;  Loss pred: 0.6979; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6976 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7023 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6962;  Loss pred: 0.6962; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7023 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6946;  Loss pred: 0.6946; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7022 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6973 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7020 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6846;  Loss pred: 0.6846; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6971 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7017 score: 0.4898 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6808;  Loss pred: 0.6808; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7013 score: 0.4898 time: 0.21s
Epoch 11/1000, LR 0.000270
Train loss: 0.6749;  Loss pred: 0.6749; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6965 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7009 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6706;  Loss pred: 0.6706; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7005 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6628;  Loss pred: 0.6628; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7001 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6578;  Loss pred: 0.6578; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6998 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6480;  Loss pred: 0.6480; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6994 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6400;  Loss pred: 0.6400; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6991 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6331;  Loss pred: 0.6331; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6987 score: 0.4898 time: 0.20s
Epoch 18/1000, LR 0.000270
Train loss: 0.6284;  Loss pred: 0.6284; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6984 score: 0.4898 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6134;  Loss pred: 0.6134; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6981 score: 0.4898 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6083;  Loss pred: 0.6083; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.5954;  Loss pred: 0.5954; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.4898 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.5844;  Loss pred: 0.5844; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.4898 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5723;  Loss pred: 0.5723; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.4898 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5648;  Loss pred: 0.5648; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4898 time: 0.12s
Epoch 25/1000, LR 0.000270
Train loss: 0.5511;  Loss pred: 0.5511; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5402;  Loss pred: 0.5402; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.4898 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5222;  Loss pred: 0.5222; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5080;  Loss pred: 0.5080; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5039;  Loss pred: 0.5039; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.4902;  Loss pred: 0.4902; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4898 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.4726;  Loss pred: 0.4726; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4598;  Loss pred: 0.4598; Loss self: 0.0000; time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4492;  Loss pred: 0.4492; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4898 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4371;  Loss pred: 0.4371; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6877 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4167;  Loss pred: 0.4167; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6869 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4898 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4056;  Loss pred: 0.4056; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.4898 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.3936;  Loss pred: 0.3936; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6849 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.4898 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3747;  Loss pred: 0.3747; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6838 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.4898 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3651;  Loss pred: 0.3651; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5102 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6878 score: 0.4898 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3476;  Loss pred: 0.3476; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.4898 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3349;  Loss pred: 0.3349; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6849 score: 0.4898 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3222;  Loss pred: 0.3222; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6771 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6830 score: 0.4898 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3090;  Loss pred: 0.3090; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6746 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6808 score: 0.4898 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.2899;  Loss pred: 0.2899; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6714 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6778 score: 0.4898 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2856;  Loss pred: 0.2856; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6680 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6746 score: 0.4898 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2618;  Loss pred: 0.2618; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6642 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6712 score: 0.4898 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2433;  Loss pred: 0.2433; Loss self: 0.0000; time: 0.11s
Val loss: 0.6602 score: 0.5306 time: 0.08s
Test loss: 0.6674 score: 0.5102 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2424;  Loss pred: 0.2424; Loss self: 0.0000; time: 0.10s
Val loss: 0.6559 score: 0.5306 time: 0.07s
Test loss: 0.6633 score: 0.5306 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2281;  Loss pred: 0.2281; Loss self: 0.0000; time: 0.10s
Val loss: 0.6513 score: 0.5306 time: 0.08s
Test loss: 0.6589 score: 0.5306 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2162;  Loss pred: 0.2162; Loss self: 0.0000; time: 0.11s
Val loss: 0.6464 score: 0.5510 time: 0.08s
Test loss: 0.6543 score: 0.5510 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2033;  Loss pred: 0.2033; Loss self: 0.0000; time: 0.11s
Val loss: 0.6409 score: 0.5510 time: 0.07s
Test loss: 0.6491 score: 0.5510 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1909;  Loss pred: 0.1909; Loss self: 0.0000; time: 0.10s
Val loss: 0.6349 score: 0.5918 time: 0.07s
Test loss: 0.6434 score: 0.5714 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1855;  Loss pred: 0.1855; Loss self: 0.0000; time: 0.11s
Val loss: 0.6284 score: 0.5918 time: 0.17s
Test loss: 0.6372 score: 0.5714 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1746;  Loss pred: 0.1746; Loss self: 0.0000; time: 0.10s
Val loss: 0.6215 score: 0.5918 time: 0.07s
Test loss: 0.6306 score: 0.5714 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1586;  Loss pred: 0.1586; Loss self: 0.0000; time: 0.10s
Val loss: 0.6137 score: 0.5918 time: 0.07s
Test loss: 0.6231 score: 0.5918 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1563;  Loss pred: 0.1563; Loss self: 0.0000; time: 0.10s
Val loss: 0.6053 score: 0.6327 time: 0.07s
Test loss: 0.6150 score: 0.6122 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1445;  Loss pred: 0.1445; Loss self: 0.0000; time: 0.10s
Val loss: 0.5965 score: 0.6531 time: 0.07s
Test loss: 0.6066 score: 0.6122 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1304;  Loss pred: 0.1304; Loss self: 0.0000; time: 0.11s
Val loss: 0.5871 score: 0.6531 time: 0.07s
Test loss: 0.5976 score: 0.6531 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1267;  Loss pred: 0.1267; Loss self: 0.0000; time: 0.11s
Val loss: 0.5773 score: 0.6735 time: 0.07s
Test loss: 0.5882 score: 0.6735 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1148;  Loss pred: 0.1148; Loss self: 0.0000; time: 0.15s
Val loss: 0.5671 score: 0.6735 time: 0.08s
Test loss: 0.5785 score: 0.6939 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1034;  Loss pred: 0.1034; Loss self: 0.0000; time: 0.11s
Val loss: 0.5560 score: 0.7347 time: 0.08s
Test loss: 0.5680 score: 0.6939 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1126;  Loss pred: 0.1126; Loss self: 0.0000; time: 0.11s
Val loss: 0.5446 score: 0.7347 time: 0.08s
Test loss: 0.5572 score: 0.7143 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0932;  Loss pred: 0.0932; Loss self: 0.0000; time: 0.11s
Val loss: 0.5326 score: 0.7755 time: 0.09s
Test loss: 0.5459 score: 0.7551 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.0869;  Loss pred: 0.0869; Loss self: 0.0000; time: 0.11s
Val loss: 0.5197 score: 0.8163 time: 0.08s
Test loss: 0.5339 score: 0.7347 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0838;  Loss pred: 0.0838; Loss self: 0.0000; time: 0.11s
Val loss: 0.5068 score: 0.8163 time: 0.08s
Test loss: 0.5218 score: 0.7551 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0727;  Loss pred: 0.0727; Loss self: 0.0000; time: 0.11s
Val loss: 0.4934 score: 0.8163 time: 0.08s
Test loss: 0.5094 score: 0.7551 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0671;  Loss pred: 0.0671; Loss self: 0.0000; time: 0.11s
Val loss: 0.4799 score: 0.8163 time: 0.10s
Test loss: 0.4969 score: 0.7551 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0646;  Loss pred: 0.0646; Loss self: 0.0000; time: 0.10s
Val loss: 0.4663 score: 0.8163 time: 0.08s
Test loss: 0.4843 score: 0.7755 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0574;  Loss pred: 0.0574; Loss self: 0.0000; time: 0.11s
Val loss: 0.4526 score: 0.8163 time: 0.08s
Test loss: 0.4717 score: 0.7959 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0586;  Loss pred: 0.0586; Loss self: 0.0000; time: 0.11s
Val loss: 0.4387 score: 0.8367 time: 0.08s
Test loss: 0.4589 score: 0.7959 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0525;  Loss pred: 0.0525; Loss self: 0.0000; time: 0.11s
Val loss: 0.4243 score: 0.8367 time: 0.08s
Test loss: 0.4456 score: 0.7959 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0469;  Loss pred: 0.0469; Loss self: 0.0000; time: 0.11s
Val loss: 0.4096 score: 0.8367 time: 0.08s
Test loss: 0.4320 score: 0.8367 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0463;  Loss pred: 0.0463; Loss self: 0.0000; time: 0.11s
Val loss: 0.3946 score: 0.8776 time: 0.07s
Test loss: 0.4181 score: 0.8367 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0428;  Loss pred: 0.0428; Loss self: 0.0000; time: 0.12s
Val loss: 0.3797 score: 0.9184 time: 0.15s
Test loss: 0.4045 score: 0.8571 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0369;  Loss pred: 0.0369; Loss self: 0.0000; time: 0.10s
Val loss: 0.3637 score: 0.9388 time: 0.07s
Test loss: 0.3900 score: 0.8776 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0378;  Loss pred: 0.0378; Loss self: 0.0000; time: 0.10s
Val loss: 0.3481 score: 0.9388 time: 0.07s
Test loss: 0.3760 score: 0.8776 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0371;  Loss pred: 0.0371; Loss self: 0.0000; time: 0.10s
Val loss: 0.3330 score: 0.9388 time: 0.07s
Test loss: 0.3625 score: 0.8980 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0330;  Loss pred: 0.0330; Loss self: 0.0000; time: 0.10s
Val loss: 0.3182 score: 0.9388 time: 0.07s
Test loss: 0.3494 score: 0.8980 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0281;  Loss pred: 0.0281; Loss self: 0.0000; time: 0.10s
Val loss: 0.3035 score: 0.9388 time: 0.07s
Test loss: 0.3367 score: 0.8980 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0266;  Loss pred: 0.0266; Loss self: 0.0000; time: 0.10s
Val loss: 0.2882 score: 0.9388 time: 0.07s
Test loss: 0.3238 score: 0.9184 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0276;  Loss pred: 0.0276; Loss self: 0.0000; time: 0.10s
Val loss: 0.2742 score: 0.9388 time: 0.07s
Test loss: 0.3121 score: 0.9184 time: 0.20s
Epoch 82/1000, LR 0.000267
Train loss: 0.0277;  Loss pred: 0.0277; Loss self: 0.0000; time: 0.10s
Val loss: 0.2610 score: 0.9388 time: 0.08s
Test loss: 0.3010 score: 0.9184 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0211;  Loss pred: 0.0211; Loss self: 0.0000; time: 0.11s
Val loss: 0.2478 score: 0.9388 time: 0.08s
Test loss: 0.2904 score: 0.9184 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0210;  Loss pred: 0.0210; Loss self: 0.0000; time: 0.11s
Val loss: 0.2352 score: 0.9388 time: 0.08s
Test loss: 0.2803 score: 0.9184 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0191;  Loss pred: 0.0191; Loss self: 0.0000; time: 0.11s
Val loss: 0.2232 score: 0.9388 time: 0.08s
Test loss: 0.2710 score: 0.9184 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0194;  Loss pred: 0.0194; Loss self: 0.0000; time: 0.11s
Val loss: 0.2121 score: 0.9388 time: 0.08s
Test loss: 0.2624 score: 0.9184 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.10s
Val loss: 0.2018 score: 0.9388 time: 0.08s
Test loss: 0.2546 score: 0.9184 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.11s
Val loss: 0.1918 score: 0.9388 time: 0.22s
Test loss: 0.2475 score: 0.9184 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.10s
Val loss: 0.1828 score: 0.9388 time: 0.08s
Test loss: 0.2415 score: 0.9184 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0161;  Loss pred: 0.0161; Loss self: 0.0000; time: 0.10s
Val loss: 0.1750 score: 0.9388 time: 0.08s
Test loss: 0.2365 score: 0.9184 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.10s
Val loss: 0.1676 score: 0.9388 time: 0.07s
Test loss: 0.2323 score: 0.9184 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0127;  Loss pred: 0.0127; Loss self: 0.0000; time: 0.10s
Val loss: 0.1609 score: 0.9388 time: 0.08s
Test loss: 0.2291 score: 0.9184 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.11s
Val loss: 0.1543 score: 0.9388 time: 0.08s
Test loss: 0.2267 score: 0.9184 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.11s
Val loss: 0.1483 score: 0.9388 time: 0.07s
Test loss: 0.2248 score: 0.8980 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.11s
Val loss: 0.1433 score: 0.9388 time: 0.07s
Test loss: 0.2235 score: 0.8980 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.11s
Val loss: 0.1395 score: 0.9388 time: 0.07s
Test loss: 0.2221 score: 0.8980 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.11s
Val loss: 0.1364 score: 0.9388 time: 0.07s
Test loss: 0.2208 score: 0.8980 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.10s
Val loss: 0.1332 score: 0.9388 time: 0.07s
Test loss: 0.2201 score: 0.8980 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.10s
Val loss: 0.1302 score: 0.9388 time: 0.07s
Test loss: 0.2203 score: 0.8980 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.1277 score: 0.9388 time: 0.07s
Test loss: 0.2210 score: 0.8980 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.11s
Val loss: 0.1253 score: 0.9388 time: 0.07s
Test loss: 0.2221 score: 0.8980 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.10s
Val loss: 0.1232 score: 0.9388 time: 0.07s
Test loss: 0.2233 score: 0.8980 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.11s
Val loss: 0.1213 score: 0.9388 time: 0.07s
Test loss: 0.2248 score: 0.8980 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.11s
Val loss: 0.1195 score: 0.9388 time: 0.07s
Test loss: 0.2272 score: 0.8980 time: 0.07s
Epoch 105/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.11s
Val loss: 0.1181 score: 0.9388 time: 0.07s
Test loss: 0.2295 score: 0.8980 time: 0.07s
Epoch 106/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.11s
Val loss: 0.1166 score: 0.9388 time: 0.08s
Test loss: 0.2324 score: 0.8980 time: 0.07s
Epoch 107/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.1155 score: 0.9388 time: 0.07s
Test loss: 0.2354 score: 0.8980 time: 0.07s
Epoch 108/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.11s
Val loss: 0.1152 score: 0.9388 time: 0.07s
Test loss: 0.2377 score: 0.8980 time: 0.07s
Epoch 109/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.11s
Val loss: 0.1151 score: 0.9388 time: 0.07s
Test loss: 0.2398 score: 0.8980 time: 0.07s
Epoch 110/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.1153 score: 0.9388 time: 0.07s
Test loss: 0.2425 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.1153 score: 0.9388 time: 0.07s
Test loss: 0.2450 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.1156 score: 0.9388 time: 0.07s
Test loss: 0.2469 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.1161 score: 0.9388 time: 0.07s
Test loss: 0.2490 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.11s
Val loss: 0.1169 score: 0.9388 time: 0.07s
Test loss: 0.2509 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.1178 score: 0.9388 time: 0.07s
Test loss: 0.2528 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.11s
Val loss: 0.1187 score: 0.9388 time: 0.07s
Test loss: 0.2541 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.11s
Val loss: 0.1199 score: 0.9388 time: 0.07s
Test loss: 0.2548 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.1215 score: 0.9388 time: 0.07s
Test loss: 0.2556 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.11s
Val loss: 0.1228 score: 0.9388 time: 0.07s
Test loss: 0.2565 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.11s
Val loss: 0.1238 score: 0.9388 time: 0.07s
Test loss: 0.2576 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.1248 score: 0.9388 time: 0.07s
Test loss: 0.2589 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 122/1000, LR 0.000262
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.11s
Val loss: 0.1267 score: 0.9388 time: 0.07s
Test loss: 0.2595 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.11s
Val loss: 0.1304 score: 0.9388 time: 0.07s
Test loss: 0.2587 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 124/1000, LR 0.000261
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.10s
Val loss: 0.1340 score: 0.9388 time: 0.07s
Test loss: 0.2575 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 125/1000, LR 0.000261
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.11s
Val loss: 0.1374 score: 0.9388 time: 0.07s
Test loss: 0.2571 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 126/1000, LR 0.000261
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.1408 score: 0.9388 time: 0.07s
Test loss: 0.2565 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 127/1000, LR 0.000261
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.10s
Val loss: 0.1442 score: 0.9388 time: 0.07s
Test loss: 0.2557 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 128/1000, LR 0.000261
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.10s
Val loss: 0.1467 score: 0.9388 time: 0.07s
Test loss: 0.2550 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 129/1000, LR 0.000261
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.10s
Val loss: 0.1505 score: 0.9388 time: 0.07s
Test loss: 0.2541 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 108,   Train_Loss: 0.0045,   Val_Loss: 0.1151,   Val_Precision: 0.8929,   Val_Recall: 1.0000,   Val_accuracy: 0.9434,   Val_Score: 0.9388,   Val_Loss: 0.1151,   Test_Precision: 0.9130,   Test_Recall: 0.8750,   Test_accuracy: 0.8936,   Test_Score: 0.8980,   Test_loss: 0.2398


[0.07428603991866112, 0.07368665502872318, 0.07369477499742061, 0.07374373695347458, 0.07380805595312268, 0.07418648502789438, 0.07388828811235726, 0.07400949799921364, 0.07364533701911569, 0.07329934102017432, 0.07351951801683754, 0.07323871506378055, 0.07333967601880431, 0.07359892001841217, 0.07331554393749684, 0.07364430406596512, 0.07308613008353859, 0.07324132206849754, 0.0735149149550125, 0.07394484092947096, 0.07376707100775093, 0.07367894297931343, 0.07371359190437943, 0.07356877694837749, 0.07355665497016162, 0.07319004891905934, 0.07340334309265018, 0.07347590907011181, 0.0734468400478363, 0.073728768969886, 0.07369029801338911, 0.07379617891274393, 0.0738879480632022, 0.07414013298694044, 0.0743026080308482, 0.0739616829669103, 0.07424623798578978, 0.07402401801664382, 0.07418964593671262, 0.07410295808222145, 0.07418317603878677, 0.07362364290747792, 0.07686437398660928, 0.07348728796932846, 0.07359017198905349, 0.08234513096977025, 0.0728802380617708, 0.07267327699810266, 0.07309860805980861, 0.0730595689965412, 0.07276798598468304, 0.07280478999018669, 0.07253558305092156, 0.07256661111023277, 0.07246251590549946, 0.07279512996319681, 0.07265368802472949, 0.07246784400194883, 0.07362675899639726, 0.07691313803661615, 0.08181193796917796, 0.07464776106644422, 0.07361069309990853, 0.07469659601338208, 0.08008829702157527, 0.07456428196746856, 0.07354245299939066, 0.07381768699269742, 0.07417470903601497, 0.07365290098823607, 0.07403540308587253, 0.07368809904437512, 0.07372190000023693, 0.07365433895029128, 0.07386644405778497, 0.07360471202991903, 0.07402470905799419, 0.0742970600258559, 0.07350145594682544, 0.07358346204273403, 0.07366716396063566, 0.07360699202399701, 0.07374014100059867, 0.07374450203496963, 0.07427561702206731, 0.07351024798117578, 0.07427464995998889, 0.0735362300183624, 0.07397153903730214, 0.07498381403274834, 0.0732289069565013, 0.07379264093469828, 0.07399367401376367, 0.07395968504715711, 0.07454889104701579, 0.07511695509310812, 0.07412585197016597, 0.07350716891232878, 0.07468835706822574, 0.07574352703522891, 0.07588431297335774, 0.07642976101487875, 0.07748996489681304, 0.07632595708128065, 0.07614559202920645, 0.07311372295953333, 0.07282393495552242, 0.07271667406894267, 0.07332176202908158, 0.0746127360034734, 0.07305571099277586, 0.07353160402271897, 0.07263262697961181, 0.07310205302201211, 0.07274960202630609, 0.0730654610088095, 0.07552606100216508, 0.07583262107800692, 0.07406364101916552, 0.07455114205367863, 0.07450683799106628, 0.07459830900188535, 0.07725368696264923, 0.07411818695254624, 0.0736725990427658, 0.21618004294577986, 0.07332140801008791, 0.07367570593487471, 0.07344492000993341, 0.07501758099533617, 0.07459385506808758, 0.07305610901676118, 0.20138117705937475, 0.07267551892437041, 0.0732358890818432, 0.07316016405820847, 0.07335241499822587, 0.07441921893041581, 0.07384620199445635, 0.13177755696233362, 0.07847432803828269, 0.07825024402700365, 0.07876858406234533, 0.07840227393899113, 0.07896690804045647, 0.07761529495473951, 0.0793004808947444, 0.0784780359826982, 0.07872049196157604, 0.07861785590648651, 0.07931864296551794, 0.07971617800649256, 0.0790110289817676, 0.07384553097654134, 0.07470265100710094, 0.0743353390134871, 0.07493970007635653, 0.07529615703970194, 0.07638838700950146, 0.07761771604418755, 0.07657768903300166, 0.08618880610447377, 0.07460852002259344, 0.07493161293677986, 0.0789056490175426, 0.0821980619803071, 0.07363282598089427, 0.07342154392972589, 0.07292757998220623, 0.07339807704556733, 0.0734377020271495, 0.07433494797442108, 0.07654820999596268, 0.07491336902603507, 0.0760114990407601, 0.07902835996355861, 0.07847887207753956, 0.07888170902151614, 0.08650525694247335, 0.07921771495603025, 0.07787248294334859, 0.0794960210332647, 0.07742235995829105, 0.07713137799873948, 0.0767420920310542, 0.07766081695444882, 0.08016849402338266, 0.07670234306715429, 0.07634738401975483, 0.07367645390331745, 0.07324766996316612, 0.07313985994551331, 0.07381953799631447, 0.07553839206229895, 0.07493582100141793, 0.07439126202370971, 0.20853927196003497, 0.07730065600480884, 0.07722417695913464, 0.07727749401237816, 0.08008301397785544, 0.07723255001474172, 0.07680061203427613, 0.07759480399545282, 0.07758290995843709, 0.0776352440007031, 0.0749026940902695, 0.07682832796126604, 0.07626405102200806, 0.0761678769486025, 0.07629861799068749, 0.07607644703239202, 0.07609484891872853, 0.07601839501876384, 0.0762181329773739, 0.07633580802939832, 0.0759819969534874, 0.07639802095945925, 0.07632585510145873, 0.0764810279943049, 0.07624755799770355, 0.07630937790963799, 0.07557458593510091, 0.07561126304790378, 0.07595626800321043, 0.0759173430269584, 0.0760705400025472, 0.07631805597338825, 0.07672882499173284, 0.07617975305765867, 0.07577509596012533, 0.07644259603694081, 0.0765635099960491, 0.0765751029830426, 0.07611685199663043, 0.07611627399455756, 0.07624806498643011, 0.07632257102522999, 0.07497555203735828, 0.07565402099862695, 0.0754615250043571, 0.0758845090167597, 0.07541850896086544, 0.07526238600257784, 0.07572478998918086]
[0.001516041630993084, 0.001503809286300473, 0.0015039749999473594, 0.0015049742235402977, 0.001506286856186177, 0.0015140098985284567, 0.0015079242471909644, 0.0015103979183512988, 0.0015029660616146059, 0.0014959049187790677, 0.0015003983268742354, 0.0014946676543628682, 0.0014967280820164146, 0.0015020187758859626, 0.00149623559056116, 0.0015029449809380636, 0.001491553675174257, 0.001494720858540766, 0.0015003043868369898, 0.0015090783863157338, 0.0015054504287296108, 0.0015036518975370089, 0.001504359018456723, 0.0015014036111913774, 0.0015011562238808494, 0.0014936744677359049, 0.0014980274100540852, 0.0014995083483696288, 0.0014989151030170675, 0.0015046687544874695, 0.0015038836329263083, 0.0015060444676070189, 0.0015079173074122897, 0.0015130639385089887, 0.001516379755731596, 0.0015094221013655163, 0.001515229346648771, 0.001510694245237629, 0.001514074406871686, 0.0015123052669841113, 0.0015139423681385055, 0.0015025233246424065, 0.001568660693604271, 0.0014997405708026216, 0.001501840244674561, 0.0016805128769340869, 0.0014873517971789958, 0.0014831281020020951, 0.0014918083277511963, 0.0014910116121743101, 0.0014850609384629192, 0.001485812040616055, 0.0014803180214473788, 0.0014809512471476076, 0.0014788268552142748, 0.0014856148972080983, 0.0014827283270352958, 0.0014789355918765068, 0.0015025869182938216, 0.0015696558782982888, 0.0016696313871260807, 0.0015234236952335555, 0.0015022590428552761, 0.0015244203268037159, 0.0016344550412566382, 0.0015217200401524196, 0.0015008663877426665, 0.001506483408014233, 0.001513769572163571, 0.0015031204283313484, 0.0015109265935892354, 0.0015038387560076555, 0.0015045285714334067, 0.0015031497744957404, 0.001507478450158877, 0.001502136980202429, 0.0015107083481223304, 0.0015162665311399164, 0.0015000297132005192, 0.001501703306994572, 0.0015034115094007278, 0.0015021835106938165, 0.0015049008367469115, 0.0015049898374483598, 0.0015158289188177002, 0.001500209142472975, 0.0015158091828569161, 0.001500739388129845, 0.0015096232456592272, 0.0015302819190356805, 0.00149446748890819, 0.0015059722639734344, 0.0015100749798727278, 0.0015093813274930023, 0.0015214059397350161, 0.0015329990835328186, 0.0015127724891870606, 0.0015001463043332404, 0.0015242521850658314, 0.0015457862660250797, 0.0015486594484358722, 0.0015597910411199744, 0.0015814278550370007, 0.0015576725934955235, 0.0015539916740654378, 0.001492116795092517, 0.001486202754194335, 0.001484013756509034, 0.00149636249038942, 0.0015227088980300694, 0.001490932877403589, 0.001500644980055489, 0.0014822985097879963, 0.0014918786331022881, 0.0014846857556388999, 0.001491131857322643, 0.0015413481837176547, 0.0015476045117960597, 0.0015115028779421533, 0.0015214518786465026, 0.0015205477141033933, 0.0015224144694262318, 0.0015766058563805964, 0.0015126160602560456, 0.0015035224294442, 0.004411837611138365, 0.001496355265511998, 0.0015035858354056064, 0.0014988759185700696, 0.0015309710407211464, 0.0015223235728181138, 0.0014909410003420649, 0.00410981993998724, 0.001483173855599396, 0.0014946099812621061, 0.0014930645726164992, 0.001496988061188283, 0.001518759570008486, 0.0015070653468256397, 0.002689337897190482, 0.001601516898740463, 0.0015969437556531355, 0.0016075221237213332, 0.0016000464069181864, 0.0016115695518460504, 0.0015839856113212146, 0.0016183771611172327, 0.0016015925710754736, 0.001606540652277062, 0.001604446038907888, 0.001618747815622815, 0.0016268607756427052, 0.0016124699792197468, 0.0015070516525824763, 0.0015245438981041008, 0.0015170477349691245, 0.0015293816342113577, 0.001536656266116366, 0.0015589466736632951, 0.0015840350213099498, 0.0015628099802653401, 0.0017589552266219137, 0.0015226228576039477, 0.0015292165905465276, 0.001610319367704951, 0.0016775114689858593, 0.0015027107343039646, 0.0014983988557086916, 0.0014883179588205352, 0.0014979199397054557, 0.0014987286127989693, 0.0015170397545800221, 0.0015622083672645446, 0.0015288442658374505, 0.001551255082464492, 0.001612823672725686, 0.0016016096342355013, 0.0016098307963574724, 0.0017654134069892522, 0.001616688060327148, 0.0015892343457826242, 0.0016223677761890755, 0.0015800481624141031, 0.001574109755076316, 0.001566165143490902, 0.0015849146317234452, 0.0016360917147629115, 0.001565353940146006, 0.00155810987795418, 0.001503601100067703, 0.0014948504074115533, 0.0014926502029696594, 0.0015065211835982545, 0.0015415998380061012, 0.0015293024694166925, 0.001518189020892035, 0.004255903509388469, 0.001577564408261405, 0.001576003611410911, 0.0015770917145383296, 0.0016343472240378661, 0.0015761744900967699, 0.0015673594292709414, 0.001583567428478629, 0.0015833246930293283, 0.0015843927347082266, 0.0015286264100055002, 0.0015679250604340009, 0.0015564092045307768, 0.0015544464683388264, 0.0015571146528711732, 0.0015525805516814698, 0.001552956100382215, 0.0015513958167094662, 0.0015554721015790592, 0.001557873633253027, 0.0015506529990507631, 0.0015591432848869233, 0.001557670512274668, 0.0015608373060062223, 0.0015560726121980318, 0.0015573342430538365, 0.0015423384884714472, 0.001543087000977628, 0.0015501279184328659, 0.0015493335311624165, 0.0015524600000519837, 0.0015575113463956788, 0.0015658943875863844, 0.0015546888379114015, 0.001546430529798476, 0.001560052980345731, 0.0015625206121642674, 0.0015627572037355633, 0.001553405142788376, 0.0015533933468277054, 0.0015560829589067369, 0.001557603490310816, 0.0015301133068848628, 0.0015439596122168765, 0.0015400311225379, 0.0015486634493216264, 0.0015391532440992947, 0.001535967061277099, 0.0015454038773302216]
[659.6124931905395, 664.9779390976523, 664.9046693163125, 664.4632076472396, 663.8841704640089, 660.4976631737685, 663.1632867916603, 662.0771836679751, 665.3510185890161, 668.4916851641767, 666.4896794995032, 669.0450529795334, 668.1240313556387, 665.7706388591262, 668.3439468412539, 665.3603509663072, 670.4418464076869, 669.021238504866, 666.5314110746857, 662.6561012787423, 664.2530241556076, 665.0475430104575, 664.7349387554243, 666.0434226653358, 666.1531851859894, 669.4899200598835, 667.544527749259, 666.8852501470035, 667.1491920971147, 664.5981030825797, 664.9450649676702, 663.9910185314236, 663.1663388200526, 660.9106030148503, 659.465411761276, 662.5052058634482, 659.9660983412825, 661.9473153832674, 660.4695221459796, 661.2421591271932, 660.5271251042188, 665.5470724476077, 637.4864902761897, 666.781988477398, 665.849782322682, 595.0564340955193, 672.3358938326913, 674.250591469534, 670.327401582102, 670.6855881167294, 673.3730408632449, 673.0326398387342, 675.5305181127576, 675.2416745156562, 676.211685278805, 673.1219523170441, 674.4323837121885, 676.1619677643821, 665.5189046471229, 637.0823145542768, 598.9345958099707, 656.4162045849565, 665.6641574274335, 655.9870545000676, 611.8247212423522, 657.1511011314784, 666.2818277275303, 663.7975530830089, 660.6025239169919, 665.2826886998835, 661.8455219750158, 664.964907976417, 664.6600263943621, 665.2697003101163, 663.3593998604805, 665.7182488545347, 661.9411359200516, 659.5146562050727, 666.6534610613564, 665.9104999917367, 665.1538808550217, 665.6976280735022, 664.4956103298227, 664.4563140010656, 659.7050548289903, 666.5737274148188, 659.7136442433034, 666.3382116239088, 662.4169327515334, 653.4743615282066, 669.1346632977396, 664.0228534897109, 662.2187727951641, 662.5231025356223, 657.2867726375318, 652.3161107803701, 661.0379334286968, 666.601648860151, 656.059417068712, 646.9199668667359, 645.7197552437938, 641.1115166310813, 632.3399431816654, 641.9834336020074, 643.5040912309871, 670.1888238835862, 672.8557036903732, 673.8482009441618, 668.2872675722816, 656.7243425803194, 670.7210063953164, 666.3801320702936, 674.627946663067, 670.2958121469635, 673.54320347047, 670.6315039070522, 648.7826764670718, 646.1599151319728, 661.5931829130602, 657.2669264371405, 657.6577576124669, 656.8513503270108, 634.2739347015324, 661.1062954274904, 665.1048101554862, 226.662921018522, 668.2904942749919, 665.076762797676, 667.1666330819444, 653.1802192214958, 656.8905703462291, 670.7173521759554, 243.31966232153343, 674.229791891706, 669.070869683047, 669.7633969357163, 668.0079994801143, 658.4320650532017, 663.5412340322991, 371.8387343757315, 624.408022660557, 626.1961302394203, 622.075419830024, 624.9818728233499, 620.5130885319231, 631.3188660633681, 617.9029363647586, 624.378520517548, 622.4554595507, 623.2680786701176, 617.7614513816341, 614.6807489441999, 620.1665847347354, 663.5472634839058, 655.9338837298056, 659.1750390902184, 653.8590353320549, 650.7636236224304, 641.4587598754404, 631.2991736590708, 639.8730572671516, 568.519303314222, 656.7614527826246, 653.9296043359099, 620.9948287619577, 596.1211106380994, 665.4640691464725, 667.3790467672468, 671.8994379349435, 667.5924216594883, 667.2322069920567, 659.1785066811518, 640.1194750678608, 654.0888580644497, 644.6393061360944, 620.0305817126253, 624.3718685404459, 621.1832959480446, 566.4395636970984, 618.5485156596277, 629.233821087315, 616.3830511654943, 632.8921002459401, 635.2797171703685, 638.5022704381296, 630.9488094715829, 611.21267895725, 638.833157379555, 641.8032605717216, 665.0700108924984, 668.963258826397, 669.949327719568, 663.7809085508824, 648.6767676969894, 653.8928825384168, 658.6795097572467, 234.96773312506093, 633.888540311375, 634.5163125005494, 634.0785325175177, 611.8650830692945, 634.4475223289553, 638.0157488605857, 631.4855824994606, 631.5823939350871, 631.1566432322443, 654.1820770952152, 637.7855837849804, 642.5045528444289, 643.3158171530083, 642.2134671689679, 644.0889646060449, 643.9332056803661, 644.5808279417789, 642.8916333406662, 641.9005872202099, 644.8896049678123, 641.37787058649, 641.9842913631966, 640.6817649423953, 642.6435322882838, 642.1229125733867, 648.3661060621406, 648.0516000500597, 645.1080508316829, 645.4388160370681, 644.1389794046321, 642.049897301971, 638.61267268565, 643.2155268725149, 646.6504513011105, 641.0038714059475, 639.9915573688894, 639.8946666888708, 643.7470640820662, 643.751952486581, 642.6392592221264, 642.0119152406703, 653.5463716970651, 647.6853358645577, 649.3375266027392, 645.7180870627753, 649.707885705166, 651.055628216752, 647.0800382147095]
Elapsed: 0.07706592254939355~0.01527161243225016
Time per graph: 0.0015727739295794602~0.0003116655598418399
Speed: 645.8957624132621~52.47637069660354
Total Time: 0.0766
best val loss: 0.11512555927038193 test_score: 0.8980

Testing...
Test loss: 0.3900 score: 0.8776 time: 0.07s
test Score 0.8776
Epoch Time List: [0.2622560451272875, 0.25796876777894795, 0.25848431303165853, 0.2580867059295997, 0.2589477440342307, 0.2590590459294617, 0.258798627066426, 0.2577539780177176, 0.2575912610627711, 0.2565029120305553, 0.25680349208414555, 0.2559241330018267, 0.2561759949894622, 0.25614570803008974, 0.25670704699587077, 0.25666141498368233, 0.25629607297014445, 0.2560281759360805, 0.2562161289388314, 0.25621885794680566, 0.257247079978697, 0.25707807403523475, 0.2561769678723067, 0.2565242189448327, 0.2563294470310211, 0.25570802798029035, 0.25612286606337875, 0.25597506610210985, 0.2561398730613291, 0.2568738410482183, 0.257267851033248, 0.2572026080451906, 0.25746925093699247, 0.2573914119275287, 0.2581857340410352, 0.25748086790554225, 0.2586088831303641, 0.2584591649938375, 0.25796948990318924, 0.25819071801379323, 0.2597210290841758, 0.25927206804044545, 0.2668680880451575, 0.2582940779393539, 0.25576693704351783, 0.27290072303730994, 0.2557453179033473, 0.2534283968852833, 0.253620722098276, 0.2538745510391891, 0.2536341028753668, 0.2538859529886395, 0.25295148009900004, 0.25274586700834334, 0.25267262605484575, 0.2530542069580406, 0.2531494329450652, 0.25320833700243384, 0.2556638140231371, 0.26098171109333634, 0.27434650517534465, 0.280140882008709, 0.2601546950172633, 0.26138650986831635, 0.27935940597672015, 0.25942207395564765, 0.2563966140151024, 0.25637420709244907, 0.25734971603378654, 0.2577879340387881, 0.2583124057855457, 0.2642977449577302, 0.25666330894455314, 0.25722130585927516, 0.2574169710278511, 0.25657316006254405, 0.257989858975634, 0.25800983898807317, 0.2561765128048137, 0.2562936310423538, 0.25647680298425257, 0.25583676900714636, 0.25739237491507083, 0.25782336690463126, 0.2574705280130729, 0.2581893909955397, 0.2580223650438711, 0.2567282388918102, 0.2575419490458444, 0.2604817310348153, 0.25743252609390765, 0.38285427913069725, 0.256247624871321, 0.25625686696730554, 0.2575836241012439, 0.25958501000422984, 0.25774747296236455, 0.2531495519215241, 0.3243314999854192, 0.260102909989655, 0.262544349883683, 0.26232013397384435, 0.2656427500769496, 0.2687826860928908, 0.26323216187302023, 0.32721925305668265, 0.25414251384790987, 0.25383645005058497, 0.2547208690084517, 0.25836250407155603, 0.2568845801288262, 0.252450012951158, 0.3053483059629798, 0.2542786691337824, 0.25339521607384086, 0.25346772593911737, 0.2512685100082308, 0.24512015096843243, 0.2800760760437697, 0.24472369987051934, 0.24517161305993795, 0.24590348999481648, 0.2491112700663507, 0.25078558491077274, 0.24006347986869514, 0.38776236993726343, 0.2518505500629544, 0.2403430569684133, 0.23536634410265833, 0.24149299005512148, 0.2493771279696375, 0.2423763358965516, 0.3686313870130107, 0.23838572192471474, 0.23923552210908383, 0.2386640440672636, 0.240260424092412, 0.24546912696678191, 0.24238990200683475, 0.3000442209886387, 0.25730835797730833, 0.2537645240081474, 0.25557601207401603, 0.25585346098523587, 0.25797624699771404, 0.25195339298807085, 0.2533895989181474, 0.3197972719790414, 0.2556264199083671, 0.25604077603202313, 0.2577331808861345, 0.2609655010746792, 0.25799800897948444, 0.25148984498810023, 0.3484755769604817, 0.2447374960174784, 0.2441845361609012, 0.2457620861241594, 0.25147463707253337, 0.2578202551230788, 0.24995518114883453, 0.3580026348354295, 0.25436761789023876, 0.24638205603696406, 0.25461980199906975, 0.266032071900554, 0.24816970294341445, 0.24319363094400615, 0.3494739399757236, 0.24345290416385978, 0.24167376896366477, 0.24285763199441135, 0.24850371805951, 0.24836836906615645, 0.24909945798572153, 0.303092057001777, 0.2591531239449978, 0.2572635820833966, 0.27991902199573815, 0.26097265898715705, 0.2584184849401936, 0.2562836459837854, 0.2853086721152067, 0.2526468450669199, 0.2532963758567348, 0.25527098891325295, 0.2603589609498158, 0.2572302609914914, 0.2519606848945841, 0.33599971886724234, 0.23933191609103233, 0.23983981797937304, 0.241252445965074, 0.24638072005473077, 0.24898029793985188, 0.24521054199431092, 0.3792204090859741, 0.25267452490516007, 0.2540244630072266, 0.25455375004094094, 0.2594911199994385, 0.258946951944381, 0.25220689608249813, 0.4005793969845399, 0.25135973712895066, 0.2523343189386651, 0.24819716694764793, 0.25224039307795465, 0.2545069269835949, 0.2519902141066268, 0.252617200021632, 0.2525799940340221, 0.25142005691304803, 0.2505140299908817, 0.25090250209905207, 0.25282912515103817, 0.2519808099605143, 0.25065611000172794, 0.25164602196309716, 0.25259707192890346, 0.25376535416580737, 0.25228274008259177, 0.2521903070155531, 0.2505409551085904, 0.2508796330075711, 0.25152718101162463, 0.2513720999704674, 0.2524374200729653, 0.2521249658893794, 0.25230627798009664, 0.2518264150712639, 0.2518649520352483, 0.2510951830772683, 0.25124750088434666, 0.2523913929471746, 0.2517643201863393, 0.2516442929627374, 0.2531879669986665, 0.2510451308917254, 0.24923960387241095, 0.2500725210411474, 0.25024773506447673, 0.2473089499399066, 0.24898321507498622, 0.24905419209972024]
Total Epoch List: [116, 129]
Total Time List: [0.0736960619688034, 0.07658716500736773]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e437758a0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7016;  Loss pred: 0.7016; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.7014;  Loss pred: 0.7014; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.7002;  Loss pred: 0.7002; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6999;  Loss pred: 0.6999; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6996;  Loss pred: 0.6996; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6979;  Loss pred: 0.6979; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6945;  Loss pred: 0.6945; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6895;  Loss pred: 0.6895; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6852;  Loss pred: 0.6852; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6833;  Loss pred: 0.6833; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5000 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6804;  Loss pred: 0.6804; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6745;  Loss pred: 0.6745; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5000 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6719;  Loss pred: 0.6719; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6637;  Loss pred: 0.6637; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6627;  Loss pred: 0.6627; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6561;  Loss pred: 0.6561; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6502;  Loss pred: 0.6502; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6461;  Loss pred: 0.6461; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6408;  Loss pred: 0.6408; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6354;  Loss pred: 0.6354; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6276;  Loss pred: 0.6276; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6251;  Loss pred: 0.6251; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.6080;  Loss pred: 0.6080; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.6022;  Loss pred: 0.6022; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5961;  Loss pred: 0.5961; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5873;  Loss pred: 0.5873; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6906 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5781;  Loss pred: 0.5781; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5706;  Loss pred: 0.5706; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5580;  Loss pred: 0.5580; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5451;  Loss pred: 0.5451; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5000 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5310;  Loss pred: 0.5310; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.5246;  Loss pred: 0.5246; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6874 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5000 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.5140;  Loss pred: 0.5140; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6866 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6894 score: 0.5000 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4941;  Loss pred: 0.4941; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6857 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5000 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4939;  Loss pred: 0.4939; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.5000 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4739;  Loss pred: 0.4739; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6834 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.5000 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4571;  Loss pred: 0.4571; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6822 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6863 score: 0.5000 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4471;  Loss pred: 0.4471; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6808 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6854 score: 0.5000 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.4357;  Loss pred: 0.4357; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6794 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6844 score: 0.5000 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.4246;  Loss pred: 0.4246; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6777 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6833 score: 0.5000 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.4054;  Loss pred: 0.4054; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6759 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6820 score: 0.5000 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3987;  Loss pred: 0.3987; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6738 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6805 score: 0.5000 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3750;  Loss pred: 0.3750; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6715 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6788 score: 0.5000 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3522;  Loss pred: 0.3522; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6690 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6769 score: 0.5000 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3407;  Loss pred: 0.3407; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6663 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6750 score: 0.5000 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.3392;  Loss pred: 0.3392; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6633 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6727 score: 0.5000 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.3173;  Loss pred: 0.3173; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6597 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6701 score: 0.5000 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.3086;  Loss pred: 0.3086; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6559 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6674 score: 0.5000 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2888;  Loss pred: 0.2888; Loss self: 0.0000; time: 0.12s
Val loss: 0.6519 score: 0.5510 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6645 score: 0.5000 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2659;  Loss pred: 0.2659; Loss self: 0.0000; time: 0.22s
Val loss: 0.6476 score: 0.5510 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6615 score: 0.5000 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2557;  Loss pred: 0.2557; Loss self: 0.0000; time: 0.12s
Val loss: 0.6429 score: 0.5918 time: 0.07s
Test loss: 0.6580 score: 0.5208 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.2383;  Loss pred: 0.2383; Loss self: 0.0000; time: 0.12s
Val loss: 0.6375 score: 0.5918 time: 0.07s
Test loss: 0.6540 score: 0.5208 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.2296;  Loss pred: 0.2296; Loss self: 0.0000; time: 0.12s
Val loss: 0.6317 score: 0.6122 time: 0.07s
Test loss: 0.6495 score: 0.5208 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.2106;  Loss pred: 0.2106; Loss self: 0.0000; time: 0.12s
Val loss: 0.6251 score: 0.6122 time: 0.07s
Test loss: 0.6445 score: 0.5208 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1990;  Loss pred: 0.1990; Loss self: 0.0000; time: 0.13s
Val loss: 0.6177 score: 0.6122 time: 0.07s
Test loss: 0.6388 score: 0.5208 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1890;  Loss pred: 0.1890; Loss self: 0.0000; time: 0.12s
Val loss: 0.6097 score: 0.6122 time: 0.07s
Test loss: 0.6325 score: 0.5208 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1767;  Loss pred: 0.1767; Loss self: 0.0000; time: 0.21s
Val loss: 0.6008 score: 0.6327 time: 0.07s
Test loss: 0.6255 score: 0.5208 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1606;  Loss pred: 0.1606; Loss self: 0.0000; time: 0.12s
Val loss: 0.5907 score: 0.6531 time: 0.07s
Test loss: 0.6174 score: 0.5208 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1537;  Loss pred: 0.1537; Loss self: 0.0000; time: 0.12s
Val loss: 0.5796 score: 0.6939 time: 0.07s
Test loss: 0.6085 score: 0.5208 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1389;  Loss pred: 0.1389; Loss self: 0.0000; time: 0.12s
Val loss: 0.5675 score: 0.6939 time: 0.07s
Test loss: 0.5986 score: 0.5833 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1297;  Loss pred: 0.1297; Loss self: 0.0000; time: 0.13s
Val loss: 0.5546 score: 0.7143 time: 0.07s
Test loss: 0.5881 score: 0.6667 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1204;  Loss pred: 0.1204; Loss self: 0.0000; time: 0.12s
Val loss: 0.5404 score: 0.7755 time: 0.07s
Test loss: 0.5762 score: 0.6667 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.1117;  Loss pred: 0.1117; Loss self: 0.0000; time: 0.12s
Val loss: 0.5254 score: 0.8163 time: 0.08s
Test loss: 0.5634 score: 0.7292 time: 0.14s
Epoch 65/1000, LR 0.000268
Train loss: 0.1014;  Loss pred: 0.1014; Loss self: 0.0000; time: 0.12s
Val loss: 0.5096 score: 0.7959 time: 0.07s
Test loss: 0.5498 score: 0.7500 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0894;  Loss pred: 0.0894; Loss self: 0.0000; time: 0.12s
Val loss: 0.4932 score: 0.8776 time: 0.07s
Test loss: 0.5356 score: 0.7500 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0839;  Loss pred: 0.0839; Loss self: 0.0000; time: 0.12s
Val loss: 0.4762 score: 0.8776 time: 0.07s
Test loss: 0.5207 score: 0.7917 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0754;  Loss pred: 0.0754; Loss self: 0.0000; time: 0.12s
Val loss: 0.4586 score: 0.8776 time: 0.07s
Test loss: 0.5053 score: 0.7917 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0739;  Loss pred: 0.0739; Loss self: 0.0000; time: 0.12s
Val loss: 0.4406 score: 0.8980 time: 0.07s
Test loss: 0.4892 score: 0.8125 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0655;  Loss pred: 0.0655; Loss self: 0.0000; time: 0.12s
Val loss: 0.4226 score: 0.8980 time: 0.07s
Test loss: 0.4729 score: 0.8333 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0574;  Loss pred: 0.0574; Loss self: 0.0000; time: 0.12s
Val loss: 0.4045 score: 0.8980 time: 0.07s
Test loss: 0.4563 score: 0.8333 time: 0.12s
Epoch 72/1000, LR 0.000267
Train loss: 0.0524;  Loss pred: 0.0524; Loss self: 0.0000; time: 0.13s
Val loss: 0.3868 score: 0.8980 time: 0.07s
Test loss: 0.4399 score: 0.8958 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0478;  Loss pred: 0.0478; Loss self: 0.0000; time: 0.12s
Val loss: 0.3692 score: 0.9184 time: 0.07s
Test loss: 0.4234 score: 0.9167 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0444;  Loss pred: 0.0444; Loss self: 0.0000; time: 0.12s
Val loss: 0.3519 score: 0.9184 time: 0.07s
Test loss: 0.4068 score: 0.8750 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0389;  Loss pred: 0.0389; Loss self: 0.0000; time: 0.12s
Val loss: 0.3351 score: 0.9184 time: 0.07s
Test loss: 0.3906 score: 0.8750 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0361;  Loss pred: 0.0361; Loss self: 0.0000; time: 0.12s
Val loss: 0.3193 score: 0.9184 time: 0.07s
Test loss: 0.3750 score: 0.8750 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0332;  Loss pred: 0.0332; Loss self: 0.0000; time: 0.12s
Val loss: 0.3041 score: 0.9184 time: 0.07s
Test loss: 0.3596 score: 0.8750 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0296;  Loss pred: 0.0296; Loss self: 0.0000; time: 0.12s
Val loss: 0.2897 score: 0.9184 time: 0.07s
Test loss: 0.3446 score: 0.8958 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0281;  Loss pred: 0.0281; Loss self: 0.0000; time: 0.13s
Val loss: 0.2761 score: 0.9184 time: 0.13s
Test loss: 0.3300 score: 0.8750 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.12s
Val loss: 0.2633 score: 0.9184 time: 0.07s
Test loss: 0.3160 score: 0.8958 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.12s
Val loss: 0.2514 score: 0.9184 time: 0.07s
Test loss: 0.3026 score: 0.8958 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0210;  Loss pred: 0.0210; Loss self: 0.0000; time: 0.12s
Val loss: 0.2404 score: 0.9184 time: 0.07s
Test loss: 0.2901 score: 0.9167 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0192;  Loss pred: 0.0192; Loss self: 0.0000; time: 0.12s
Val loss: 0.2303 score: 0.9184 time: 0.07s
Test loss: 0.2783 score: 0.9167 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.12s
Val loss: 0.2209 score: 0.9388 time: 0.07s
Test loss: 0.2673 score: 0.9167 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0162;  Loss pred: 0.0162; Loss self: 0.0000; time: 0.12s
Val loss: 0.2126 score: 0.9388 time: 0.07s
Test loss: 0.2572 score: 0.9167 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.12s
Val loss: 0.2048 score: 0.9388 time: 0.15s
Test loss: 0.2478 score: 0.9167 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0140;  Loss pred: 0.0140; Loss self: 0.0000; time: 0.12s
Val loss: 0.1981 score: 0.9388 time: 0.07s
Test loss: 0.2395 score: 0.9167 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.12s
Val loss: 0.1921 score: 0.9592 time: 0.07s
Test loss: 0.2320 score: 0.9167 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.12s
Val loss: 0.1869 score: 0.9388 time: 0.07s
Test loss: 0.2255 score: 0.9167 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.12s
Val loss: 0.1824 score: 0.9388 time: 0.07s
Test loss: 0.2198 score: 0.9167 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.12s
Val loss: 0.1786 score: 0.9388 time: 0.07s
Test loss: 0.2149 score: 0.9167 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.12s
Val loss: 0.1755 score: 0.9388 time: 0.07s
Test loss: 0.2109 score: 0.9167 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.13s
Val loss: 0.1731 score: 0.9388 time: 0.14s
Test loss: 0.2078 score: 0.9167 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.12s
Val loss: 0.1713 score: 0.9388 time: 0.07s
Test loss: 0.2054 score: 0.9167 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.12s
Val loss: 0.1700 score: 0.9388 time: 0.07s
Test loss: 0.2036 score: 0.9167 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.12s
Val loss: 0.1692 score: 0.9388 time: 0.07s
Test loss: 0.2024 score: 0.9167 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.12s
Val loss: 0.1687 score: 0.9388 time: 0.07s
Test loss: 0.2018 score: 0.9167 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.12s
Val loss: 0.1686 score: 0.9388 time: 0.07s
Test loss: 0.2016 score: 0.9167 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.12s
Val loss: 0.1689 score: 0.9388 time: 0.07s
Test loss: 0.2019 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.1694 score: 0.9388 time: 0.11s
Test loss: 0.2026 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.12s
Val loss: 0.1701 score: 0.9388 time: 0.07s
Test loss: 0.2036 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.1709 score: 0.9388 time: 0.07s
Test loss: 0.2046 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.12s
Val loss: 0.1718 score: 0.9388 time: 0.07s
Test loss: 0.2057 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.12s
Val loss: 0.1729 score: 0.9388 time: 0.07s
Test loss: 0.2070 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.13s
Val loss: 0.1742 score: 0.9388 time: 0.07s
Test loss: 0.2084 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.1755 score: 0.9388 time: 0.07s
Test loss: 0.2104 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.1768 score: 0.9388 time: 0.14s
Test loss: 0.2120 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.12s
Val loss: 0.1781 score: 0.9388 time: 0.07s
Test loss: 0.2137 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.12s
Val loss: 0.1794 score: 0.9388 time: 0.07s
Test loss: 0.2155 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.12s
Val loss: 0.1807 score: 0.9388 time: 0.07s
Test loss: 0.2172 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.12s
Val loss: 0.1821 score: 0.9388 time: 0.07s
Test loss: 0.2190 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.13s
Val loss: 0.1833 score: 0.9388 time: 0.07s
Test loss: 0.2204 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.1845 score: 0.9388 time: 0.07s
Test loss: 0.2221 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.12s
Val loss: 0.1857 score: 0.9388 time: 0.07s
Test loss: 0.2236 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.21s
Val loss: 0.1869 score: 0.9388 time: 0.07s
Test loss: 0.2251 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.12s
Val loss: 0.1880 score: 0.9388 time: 0.07s
Test loss: 0.2264 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.12s
Val loss: 0.1890 score: 0.9388 time: 0.07s
Test loss: 0.2277 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.12s
Val loss: 0.1900 score: 0.9388 time: 0.07s
Test loss: 0.2289 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 097,   Train_Loss: 0.0071,   Val_Loss: 0.1686,   Val_Precision: 0.9583,   Val_Recall: 0.9200,   Val_accuracy: 0.9388,   Val_Score: 0.9388,   Val_Loss: 0.1686,   Test_Precision: 0.9545,   Test_Recall: 0.8750,   Test_accuracy: 0.9130,   Test_Score: 0.9167,   Test_loss: 0.2016


[0.07428603991866112, 0.07368665502872318, 0.07369477499742061, 0.07374373695347458, 0.07380805595312268, 0.07418648502789438, 0.07388828811235726, 0.07400949799921364, 0.07364533701911569, 0.07329934102017432, 0.07351951801683754, 0.07323871506378055, 0.07333967601880431, 0.07359892001841217, 0.07331554393749684, 0.07364430406596512, 0.07308613008353859, 0.07324132206849754, 0.0735149149550125, 0.07394484092947096, 0.07376707100775093, 0.07367894297931343, 0.07371359190437943, 0.07356877694837749, 0.07355665497016162, 0.07319004891905934, 0.07340334309265018, 0.07347590907011181, 0.0734468400478363, 0.073728768969886, 0.07369029801338911, 0.07379617891274393, 0.0738879480632022, 0.07414013298694044, 0.0743026080308482, 0.0739616829669103, 0.07424623798578978, 0.07402401801664382, 0.07418964593671262, 0.07410295808222145, 0.07418317603878677, 0.07362364290747792, 0.07686437398660928, 0.07348728796932846, 0.07359017198905349, 0.08234513096977025, 0.0728802380617708, 0.07267327699810266, 0.07309860805980861, 0.0730595689965412, 0.07276798598468304, 0.07280478999018669, 0.07253558305092156, 0.07256661111023277, 0.07246251590549946, 0.07279512996319681, 0.07265368802472949, 0.07246784400194883, 0.07362675899639726, 0.07691313803661615, 0.08181193796917796, 0.07464776106644422, 0.07361069309990853, 0.07469659601338208, 0.08008829702157527, 0.07456428196746856, 0.07354245299939066, 0.07381768699269742, 0.07417470903601497, 0.07365290098823607, 0.07403540308587253, 0.07368809904437512, 0.07372190000023693, 0.07365433895029128, 0.07386644405778497, 0.07360471202991903, 0.07402470905799419, 0.0742970600258559, 0.07350145594682544, 0.07358346204273403, 0.07366716396063566, 0.07360699202399701, 0.07374014100059867, 0.07374450203496963, 0.07427561702206731, 0.07351024798117578, 0.07427464995998889, 0.0735362300183624, 0.07397153903730214, 0.07498381403274834, 0.0732289069565013, 0.07379264093469828, 0.07399367401376367, 0.07395968504715711, 0.07454889104701579, 0.07511695509310812, 0.07412585197016597, 0.07350716891232878, 0.07468835706822574, 0.07574352703522891, 0.07588431297335774, 0.07642976101487875, 0.07748996489681304, 0.07632595708128065, 0.07614559202920645, 0.07311372295953333, 0.07282393495552242, 0.07271667406894267, 0.07332176202908158, 0.0746127360034734, 0.07305571099277586, 0.07353160402271897, 0.07263262697961181, 0.07310205302201211, 0.07274960202630609, 0.0730654610088095, 0.07552606100216508, 0.07583262107800692, 0.07406364101916552, 0.07455114205367863, 0.07450683799106628, 0.07459830900188535, 0.07725368696264923, 0.07411818695254624, 0.0736725990427658, 0.21618004294577986, 0.07332140801008791, 0.07367570593487471, 0.07344492000993341, 0.07501758099533617, 0.07459385506808758, 0.07305610901676118, 0.20138117705937475, 0.07267551892437041, 0.0732358890818432, 0.07316016405820847, 0.07335241499822587, 0.07441921893041581, 0.07384620199445635, 0.13177755696233362, 0.07847432803828269, 0.07825024402700365, 0.07876858406234533, 0.07840227393899113, 0.07896690804045647, 0.07761529495473951, 0.0793004808947444, 0.0784780359826982, 0.07872049196157604, 0.07861785590648651, 0.07931864296551794, 0.07971617800649256, 0.0790110289817676, 0.07384553097654134, 0.07470265100710094, 0.0743353390134871, 0.07493970007635653, 0.07529615703970194, 0.07638838700950146, 0.07761771604418755, 0.07657768903300166, 0.08618880610447377, 0.07460852002259344, 0.07493161293677986, 0.0789056490175426, 0.0821980619803071, 0.07363282598089427, 0.07342154392972589, 0.07292757998220623, 0.07339807704556733, 0.0734377020271495, 0.07433494797442108, 0.07654820999596268, 0.07491336902603507, 0.0760114990407601, 0.07902835996355861, 0.07847887207753956, 0.07888170902151614, 0.08650525694247335, 0.07921771495603025, 0.07787248294334859, 0.0794960210332647, 0.07742235995829105, 0.07713137799873948, 0.0767420920310542, 0.07766081695444882, 0.08016849402338266, 0.07670234306715429, 0.07634738401975483, 0.07367645390331745, 0.07324766996316612, 0.07313985994551331, 0.07381953799631447, 0.07553839206229895, 0.07493582100141793, 0.07439126202370971, 0.20853927196003497, 0.07730065600480884, 0.07722417695913464, 0.07727749401237816, 0.08008301397785544, 0.07723255001474172, 0.07680061203427613, 0.07759480399545282, 0.07758290995843709, 0.0776352440007031, 0.0749026940902695, 0.07682832796126604, 0.07626405102200806, 0.0761678769486025, 0.07629861799068749, 0.07607644703239202, 0.07609484891872853, 0.07601839501876384, 0.0762181329773739, 0.07633580802939832, 0.0759819969534874, 0.07639802095945925, 0.07632585510145873, 0.0764810279943049, 0.07624755799770355, 0.07630937790963799, 0.07557458593510091, 0.07561126304790378, 0.07595626800321043, 0.0759173430269584, 0.0760705400025472, 0.07631805597338825, 0.07672882499173284, 0.07617975305765867, 0.07577509596012533, 0.07644259603694081, 0.0765635099960491, 0.0765751029830426, 0.07611685199663043, 0.07611627399455756, 0.07624806498643011, 0.07632257102522999, 0.07497555203735828, 0.07565402099862695, 0.0754615250043571, 0.0758845090167597, 0.07541850896086544, 0.07526238600257784, 0.07572478998918086, 0.07365368597675115, 0.07352588605135679, 0.07343815197236836, 0.07342699007131159, 0.07389887003228068, 0.07397479109931737, 0.0738080769078806, 0.07426001306157559, 0.07381361699663103, 0.07436325110029429, 0.07418784301262349, 0.0739551909500733, 0.07433331897482276, 0.07408591697458178, 0.07393830304499716, 0.07401990203652531, 0.07428648706991225, 0.07376573700457811, 0.07470186799764633, 0.07373360206838697, 0.07401082396972924, 0.07393709803000093, 0.07418543403036892, 0.07541728601790965, 0.07482078904286027, 0.07348905398976058, 0.0734312990680337, 0.07319816504605114, 0.07396346004679799, 0.07397532102186233, 0.07412682694848627, 0.07457332406193018, 0.07452649995684624, 0.0750127820065245, 0.07439037598669529, 0.07464202889241278, 0.07510268606711179, 0.07524359493982047, 0.07486738299485296, 0.07515172497369349, 0.07500487903598696, 0.07512369100004435, 0.07544864399824291, 0.07538368599489331, 0.07564948790241033, 0.07528530596755445, 0.07481457001995295, 0.07452413497958332, 0.0728559319395572, 0.07419328100513667, 0.07256813498679549, 0.07203439297154546, 0.07225397101137787, 0.07228720793500543, 0.07529461605008692, 0.07355182396713644, 0.07395858294330537, 0.07321952597703785, 0.07285330293234438, 0.07275407004635781, 0.0730548829305917, 0.07428457005880773, 0.07379715202841908, 0.14335175696760416, 0.07476878701709211, 0.07555579405743629, 0.07622638705652207, 0.07511904602870345, 0.07513278303667903, 0.07366933301091194, 0.12259119900409132, 0.07384991797152907, 0.07362716400530189, 0.07354905502870679, 0.07356338191311806, 0.07528677699156106, 0.0731021020328626, 0.07367184502072632, 0.07246190402656794, 0.07392303005326539, 0.07491087098605931, 0.07484735094476491, 0.07686319400090724, 0.07435865700244904, 0.07401527103502303, 0.0712833070429042, 0.073043717071414, 0.07315680896863341, 0.07336417096666992, 0.07522557000629604, 0.07304609101265669, 0.0725159189896658, 0.07141011906787753, 0.070906548993662, 0.07085879205260426, 0.0711286460282281, 0.07257922703865916, 0.07070237398147583, 0.06986802304163575, 0.0894184720236808, 0.07662189204711467, 0.07643063797149807, 0.07675348105840385, 0.07747981802094728, 0.07545277697499841, 0.07520299800671637, 0.08037137798964977, 0.074903829023242, 0.07496308500412852, 0.07556645106524229, 0.07570010609924793, 0.07604110601823777, 0.07456552796065807, 0.08381082292180508, 0.07714032602962106, 0.07604865694884211, 0.07615894405171275, 0.07668568601366132]
[0.001516041630993084, 0.001503809286300473, 0.0015039749999473594, 0.0015049742235402977, 0.001506286856186177, 0.0015140098985284567, 0.0015079242471909644, 0.0015103979183512988, 0.0015029660616146059, 0.0014959049187790677, 0.0015003983268742354, 0.0014946676543628682, 0.0014967280820164146, 0.0015020187758859626, 0.00149623559056116, 0.0015029449809380636, 0.001491553675174257, 0.001494720858540766, 0.0015003043868369898, 0.0015090783863157338, 0.0015054504287296108, 0.0015036518975370089, 0.001504359018456723, 0.0015014036111913774, 0.0015011562238808494, 0.0014936744677359049, 0.0014980274100540852, 0.0014995083483696288, 0.0014989151030170675, 0.0015046687544874695, 0.0015038836329263083, 0.0015060444676070189, 0.0015079173074122897, 0.0015130639385089887, 0.001516379755731596, 0.0015094221013655163, 0.001515229346648771, 0.001510694245237629, 0.001514074406871686, 0.0015123052669841113, 0.0015139423681385055, 0.0015025233246424065, 0.001568660693604271, 0.0014997405708026216, 0.001501840244674561, 0.0016805128769340869, 0.0014873517971789958, 0.0014831281020020951, 0.0014918083277511963, 0.0014910116121743101, 0.0014850609384629192, 0.001485812040616055, 0.0014803180214473788, 0.0014809512471476076, 0.0014788268552142748, 0.0014856148972080983, 0.0014827283270352958, 0.0014789355918765068, 0.0015025869182938216, 0.0015696558782982888, 0.0016696313871260807, 0.0015234236952335555, 0.0015022590428552761, 0.0015244203268037159, 0.0016344550412566382, 0.0015217200401524196, 0.0015008663877426665, 0.001506483408014233, 0.001513769572163571, 0.0015031204283313484, 0.0015109265935892354, 0.0015038387560076555, 0.0015045285714334067, 0.0015031497744957404, 0.001507478450158877, 0.001502136980202429, 0.0015107083481223304, 0.0015162665311399164, 0.0015000297132005192, 0.001501703306994572, 0.0015034115094007278, 0.0015021835106938165, 0.0015049008367469115, 0.0015049898374483598, 0.0015158289188177002, 0.001500209142472975, 0.0015158091828569161, 0.001500739388129845, 0.0015096232456592272, 0.0015302819190356805, 0.00149446748890819, 0.0015059722639734344, 0.0015100749798727278, 0.0015093813274930023, 0.0015214059397350161, 0.0015329990835328186, 0.0015127724891870606, 0.0015001463043332404, 0.0015242521850658314, 0.0015457862660250797, 0.0015486594484358722, 0.0015597910411199744, 0.0015814278550370007, 0.0015576725934955235, 0.0015539916740654378, 0.001492116795092517, 0.001486202754194335, 0.001484013756509034, 0.00149636249038942, 0.0015227088980300694, 0.001490932877403589, 0.001500644980055489, 0.0014822985097879963, 0.0014918786331022881, 0.0014846857556388999, 0.001491131857322643, 0.0015413481837176547, 0.0015476045117960597, 0.0015115028779421533, 0.0015214518786465026, 0.0015205477141033933, 0.0015224144694262318, 0.0015766058563805964, 0.0015126160602560456, 0.0015035224294442, 0.004411837611138365, 0.001496355265511998, 0.0015035858354056064, 0.0014988759185700696, 0.0015309710407211464, 0.0015223235728181138, 0.0014909410003420649, 0.00410981993998724, 0.001483173855599396, 0.0014946099812621061, 0.0014930645726164992, 0.001496988061188283, 0.001518759570008486, 0.0015070653468256397, 0.002689337897190482, 0.001601516898740463, 0.0015969437556531355, 0.0016075221237213332, 0.0016000464069181864, 0.0016115695518460504, 0.0015839856113212146, 0.0016183771611172327, 0.0016015925710754736, 0.001606540652277062, 0.001604446038907888, 0.001618747815622815, 0.0016268607756427052, 0.0016124699792197468, 0.0015070516525824763, 0.0015245438981041008, 0.0015170477349691245, 0.0015293816342113577, 0.001536656266116366, 0.0015589466736632951, 0.0015840350213099498, 0.0015628099802653401, 0.0017589552266219137, 0.0015226228576039477, 0.0015292165905465276, 0.001610319367704951, 0.0016775114689858593, 0.0015027107343039646, 0.0014983988557086916, 0.0014883179588205352, 0.0014979199397054557, 0.0014987286127989693, 0.0015170397545800221, 0.0015622083672645446, 0.0015288442658374505, 0.001551255082464492, 0.001612823672725686, 0.0016016096342355013, 0.0016098307963574724, 0.0017654134069892522, 0.001616688060327148, 0.0015892343457826242, 0.0016223677761890755, 0.0015800481624141031, 0.001574109755076316, 0.001566165143490902, 0.0015849146317234452, 0.0016360917147629115, 0.001565353940146006, 0.00155810987795418, 0.001503601100067703, 0.0014948504074115533, 0.0014926502029696594, 0.0015065211835982545, 0.0015415998380061012, 0.0015293024694166925, 0.001518189020892035, 0.004255903509388469, 0.001577564408261405, 0.001576003611410911, 0.0015770917145383296, 0.0016343472240378661, 0.0015761744900967699, 0.0015673594292709414, 0.001583567428478629, 0.0015833246930293283, 0.0015843927347082266, 0.0015286264100055002, 0.0015679250604340009, 0.0015564092045307768, 0.0015544464683388264, 0.0015571146528711732, 0.0015525805516814698, 0.001552956100382215, 0.0015513958167094662, 0.0015554721015790592, 0.001557873633253027, 0.0015506529990507631, 0.0015591432848869233, 0.001557670512274668, 0.0015608373060062223, 0.0015560726121980318, 0.0015573342430538365, 0.0015423384884714472, 0.001543087000977628, 0.0015501279184328659, 0.0015493335311624165, 0.0015524600000519837, 0.0015575113463956788, 0.0015658943875863844, 0.0015546888379114015, 0.001546430529798476, 0.001560052980345731, 0.0015625206121642674, 0.0015627572037355633, 0.001553405142788376, 0.0015533933468277054, 0.0015560829589067369, 0.001557603490310816, 0.0015301133068848628, 0.0015439596122168765, 0.0015400311225379, 0.0015486634493216264, 0.0015391532440992947, 0.001535967061277099, 0.0015454038773302216, 0.0015344517911823157, 0.0015317892927366, 0.001529961499424341, 0.0015297289598189916, 0.0015395597923391808, 0.0015411414812357787, 0.0015376682689141792, 0.0015470836054494914, 0.001537783687429813, 0.0015492343979227978, 0.0015455800627629894, 0.0015407331447931938, 0.0015486108119754742, 0.0015434566036371204, 0.0015403813134374407, 0.0015420812924276106, 0.0015476351472898386, 0.0015367861875953774, 0.001556288916617632, 0.001536116709758062, 0.0015418921660360259, 0.0015403562089583527, 0.0015455298756326858, 0.0015711934587064509, 0.0015587664383929223, 0.001531021958120012, 0.0015298187305840354, 0.0015249617717927322, 0.0015409054176416248, 0.0015411525212887984, 0.0015443088947601307, 0.0015536109179568787, 0.0015526354157676299, 0.0015627662918025937, 0.0015497994997228186, 0.001555042268591933, 0.001564639293064829, 0.001567574894579593, 0.0015597371457261033, 0.0015656609369519476, 0.0015626016465830617, 0.0015650768958342571, 0.0015718467499633941, 0.001570493458226944, 0.0015760309979668818, 0.001568443874324051, 0.0015586368754156865, 0.001552586145407986, 0.0015178319154074416, 0.0015456933542736806, 0.0015118361455582392, 0.0015007165202405304, 0.001505291062737039, 0.0015059834986459464, 0.0015686378343768108, 0.0015323296659820091, 0.001540803811318862, 0.0015254067911882885, 0.0015177771444238413, 0.0015157097926324543, 0.0015219767277206604, 0.0015475952095584944, 0.0015374406672587309, 0.002986494936825087, 0.0015576830628560856, 0.001574079042863256, 0.0015880497303442098, 0.0015649801255979885, 0.0015652663132641464, 0.0015347777710606654, 0.002553983312585236, 0.0015385399577401888, 0.001533899250110456, 0.0015322719797647248, 0.001532570456523293, 0.001568474520657522, 0.0015229604590179708, 0.0015348301045984651, 0.0015096230005534987, 0.0015400631261096958, 0.0015606431455429022, 0.001559319811349269, 0.0016013165416855675, 0.0015491386875510216, 0.0015419848132296465, 0.0014850688967271708, 0.0015217441056544583, 0.0015241001868465294, 0.0015284202284722899, 0.0015671993751311675, 0.001521793562763681, 0.0015107483122847043, 0.0014877108139141153, 0.0014772197707012917, 0.0014762248344292554, 0.0014818467922547522, 0.0015120672299720657, 0.0014729661246140797, 0.0014555838133674115, 0.0018628848338266835, 0.0015962894176482223, 0.0015923049577395432, 0.0015990308553834136, 0.0016141628754364017, 0.0015719328536458004, 0.0015667291251399245, 0.0016744037081177037, 0.0015604964379842083, 0.0015617309375860107, 0.0015743010638592143, 0.0015770855437343319, 0.0015841897087132868, 0.0015534484991803765, 0.0017460588108709392, 0.0016070901256171055, 0.001584347019767544, 0.0015866446677440156, 0.0015976184586179443]
[659.6124931905395, 664.9779390976523, 664.9046693163125, 664.4632076472396, 663.8841704640089, 660.4976631737685, 663.1632867916603, 662.0771836679751, 665.3510185890161, 668.4916851641767, 666.4896794995032, 669.0450529795334, 668.1240313556387, 665.7706388591262, 668.3439468412539, 665.3603509663072, 670.4418464076869, 669.021238504866, 666.5314110746857, 662.6561012787423, 664.2530241556076, 665.0475430104575, 664.7349387554243, 666.0434226653358, 666.1531851859894, 669.4899200598835, 667.544527749259, 666.8852501470035, 667.1491920971147, 664.5981030825797, 664.9450649676702, 663.9910185314236, 663.1663388200526, 660.9106030148503, 659.465411761276, 662.5052058634482, 659.9660983412825, 661.9473153832674, 660.4695221459796, 661.2421591271932, 660.5271251042188, 665.5470724476077, 637.4864902761897, 666.781988477398, 665.849782322682, 595.0564340955193, 672.3358938326913, 674.250591469534, 670.327401582102, 670.6855881167294, 673.3730408632449, 673.0326398387342, 675.5305181127576, 675.2416745156562, 676.211685278805, 673.1219523170441, 674.4323837121885, 676.1619677643821, 665.5189046471229, 637.0823145542768, 598.9345958099707, 656.4162045849565, 665.6641574274335, 655.9870545000676, 611.8247212423522, 657.1511011314784, 666.2818277275303, 663.7975530830089, 660.6025239169919, 665.2826886998835, 661.8455219750158, 664.964907976417, 664.6600263943621, 665.2697003101163, 663.3593998604805, 665.7182488545347, 661.9411359200516, 659.5146562050727, 666.6534610613564, 665.9104999917367, 665.1538808550217, 665.6976280735022, 664.4956103298227, 664.4563140010656, 659.7050548289903, 666.5737274148188, 659.7136442433034, 666.3382116239088, 662.4169327515334, 653.4743615282066, 669.1346632977396, 664.0228534897109, 662.2187727951641, 662.5231025356223, 657.2867726375318, 652.3161107803701, 661.0379334286968, 666.601648860151, 656.059417068712, 646.9199668667359, 645.7197552437938, 641.1115166310813, 632.3399431816654, 641.9834336020074, 643.5040912309871, 670.1888238835862, 672.8557036903732, 673.8482009441618, 668.2872675722816, 656.7243425803194, 670.7210063953164, 666.3801320702936, 674.627946663067, 670.2958121469635, 673.54320347047, 670.6315039070522, 648.7826764670718, 646.1599151319728, 661.5931829130602, 657.2669264371405, 657.6577576124669, 656.8513503270108, 634.2739347015324, 661.1062954274904, 665.1048101554862, 226.662921018522, 668.2904942749919, 665.076762797676, 667.1666330819444, 653.1802192214958, 656.8905703462291, 670.7173521759554, 243.31966232153343, 674.229791891706, 669.070869683047, 669.7633969357163, 668.0079994801143, 658.4320650532017, 663.5412340322991, 371.8387343757315, 624.408022660557, 626.1961302394203, 622.075419830024, 624.9818728233499, 620.5130885319231, 631.3188660633681, 617.9029363647586, 624.378520517548, 622.4554595507, 623.2680786701176, 617.7614513816341, 614.6807489441999, 620.1665847347354, 663.5472634839058, 655.9338837298056, 659.1750390902184, 653.8590353320549, 650.7636236224304, 641.4587598754404, 631.2991736590708, 639.8730572671516, 568.519303314222, 656.7614527826246, 653.9296043359099, 620.9948287619577, 596.1211106380994, 665.4640691464725, 667.3790467672468, 671.8994379349435, 667.5924216594883, 667.2322069920567, 659.1785066811518, 640.1194750678608, 654.0888580644497, 644.6393061360944, 620.0305817126253, 624.3718685404459, 621.1832959480446, 566.4395636970984, 618.5485156596277, 629.233821087315, 616.3830511654943, 632.8921002459401, 635.2797171703685, 638.5022704381296, 630.9488094715829, 611.21267895725, 638.833157379555, 641.8032605717216, 665.0700108924984, 668.963258826397, 669.949327719568, 663.7809085508824, 648.6767676969894, 653.8928825384168, 658.6795097572467, 234.96773312506093, 633.888540311375, 634.5163125005494, 634.0785325175177, 611.8650830692945, 634.4475223289553, 638.0157488605857, 631.4855824994606, 631.5823939350871, 631.1566432322443, 654.1820770952152, 637.7855837849804, 642.5045528444289, 643.3158171530083, 642.2134671689679, 644.0889646060449, 643.9332056803661, 644.5808279417789, 642.8916333406662, 641.9005872202099, 644.8896049678123, 641.37787058649, 641.9842913631966, 640.6817649423953, 642.6435322882838, 642.1229125733867, 648.3661060621406, 648.0516000500597, 645.1080508316829, 645.4388160370681, 644.1389794046321, 642.049897301971, 638.61267268565, 643.2155268725149, 646.6504513011105, 641.0038714059475, 639.9915573688894, 639.8946666888708, 643.7470640820662, 643.751952486581, 642.6392592221264, 642.0119152406703, 653.5463716970651, 647.6853358645577, 649.3375266027392, 645.7180870627753, 649.707885705166, 651.055628216752, 647.0800382147095, 651.6985452045298, 652.8313030661429, 653.6112185674327, 653.7105763614014, 649.5363187425264, 648.8696931304066, 650.3353292879924, 646.3774785522718, 650.2865183017761, 645.4801167213901, 647.006275567717, 649.0416613541638, 645.7400350475128, 647.8964148674622, 649.1899059515648, 648.4742438096483, 646.1471243730558, 650.7086073988658, 642.5542129885207, 650.9922023812239, 648.5537847765647, 649.2004863448033, 647.0272854419168, 636.4588615480176, 641.5329297383341, 653.1584963209347, 653.672216196642, 655.7541431510172, 648.96909865533, 648.8650449494406, 647.5388462716357, 643.6618000310393, 644.066205011558, 639.8909454634683, 645.2447559693044, 643.0693365688926, 639.1249436419249, 637.928052725155, 641.1336696956529, 638.7078941541552, 639.9583682678808, 638.9462413391225, 636.1943363901656, 636.742544046621, 634.5052865648101, 637.574615432744, 641.5862576928325, 644.086644053636, 658.8344795290218, 646.9588532777892, 661.4473419874176, 666.3483652726918, 664.3233489885479, 664.0178998635216, 637.4957801507322, 652.6010833048381, 649.0118940866605, 655.5628346331159, 658.8582544373515, 659.7569039012541, 657.0402699242437, 646.1637990500661, 650.4316044813671, 334.84068151914903, 641.979118760175, 635.2921122569525, 629.7032019162586, 638.9857504534723, 638.8689205957792, 651.5601273719991, 391.5452364439152, 649.9668695435134, 651.9333000051927, 652.6256521074977, 652.4985495730789, 637.562157898994, 656.6158655522914, 651.5379109413645, 662.4170403030115, 649.3240329219933, 640.7614725095461, 641.3052618979468, 624.4861487207186, 645.5199963928759, 648.5148176690057, 673.3694323568577, 657.1407086672623, 656.1248457485399, 654.2703252491858, 638.0809078081112, 657.1193521044547, 661.9236254434071, 672.1736446675648, 676.9473438100971, 677.4035883135813, 674.8335963115442, 661.346255099037, 678.9022390192457, 687.0095633219197, 536.8018365074288, 626.4528154758287, 628.0204022096452, 625.378801561788, 619.5161685462764, 636.1594884162447, 638.2724262630211, 597.227535481368, 640.8217126671325, 640.3151630880245, 635.2025180930877, 634.0810135334391, 631.2375307703657, 643.7290972488728, 572.718395150274, 622.2426384556439, 631.1748547024253, 630.2608393231855, 625.9316763685069]
Elapsed: 0.07653287946684004~0.01336921871694633
Time per graph: 0.0015723201121278676~0.00027305797896311765
Speed: 644.1790356567359~49.010256657219436
Total Time: 0.0778
best val loss: 0.16856345534324646 test_score: 0.9167

Testing...
Test loss: 0.2320 score: 0.9167 time: 0.07s
test Score 0.9167
Epoch Time List: [0.2622560451272875, 0.25796876777894795, 0.25848431303165853, 0.2580867059295997, 0.2589477440342307, 0.2590590459294617, 0.258798627066426, 0.2577539780177176, 0.2575912610627711, 0.2565029120305553, 0.25680349208414555, 0.2559241330018267, 0.2561759949894622, 0.25614570803008974, 0.25670704699587077, 0.25666141498368233, 0.25629607297014445, 0.2560281759360805, 0.2562161289388314, 0.25621885794680566, 0.257247079978697, 0.25707807403523475, 0.2561769678723067, 0.2565242189448327, 0.2563294470310211, 0.25570802798029035, 0.25612286606337875, 0.25597506610210985, 0.2561398730613291, 0.2568738410482183, 0.257267851033248, 0.2572026080451906, 0.25746925093699247, 0.2573914119275287, 0.2581857340410352, 0.25748086790554225, 0.2586088831303641, 0.2584591649938375, 0.25796948990318924, 0.25819071801379323, 0.2597210290841758, 0.25927206804044545, 0.2668680880451575, 0.2582940779393539, 0.25576693704351783, 0.27290072303730994, 0.2557453179033473, 0.2534283968852833, 0.253620722098276, 0.2538745510391891, 0.2536341028753668, 0.2538859529886395, 0.25295148009900004, 0.25274586700834334, 0.25267262605484575, 0.2530542069580406, 0.2531494329450652, 0.25320833700243384, 0.2556638140231371, 0.26098171109333634, 0.27434650517534465, 0.280140882008709, 0.2601546950172633, 0.26138650986831635, 0.27935940597672015, 0.25942207395564765, 0.2563966140151024, 0.25637420709244907, 0.25734971603378654, 0.2577879340387881, 0.2583124057855457, 0.2642977449577302, 0.25666330894455314, 0.25722130585927516, 0.2574169710278511, 0.25657316006254405, 0.257989858975634, 0.25800983898807317, 0.2561765128048137, 0.2562936310423538, 0.25647680298425257, 0.25583676900714636, 0.25739237491507083, 0.25782336690463126, 0.2574705280130729, 0.2581893909955397, 0.2580223650438711, 0.2567282388918102, 0.2575419490458444, 0.2604817310348153, 0.25743252609390765, 0.38285427913069725, 0.256247624871321, 0.25625686696730554, 0.2575836241012439, 0.25958501000422984, 0.25774747296236455, 0.2531495519215241, 0.3243314999854192, 0.260102909989655, 0.262544349883683, 0.26232013397384435, 0.2656427500769496, 0.2687826860928908, 0.26323216187302023, 0.32721925305668265, 0.25414251384790987, 0.25383645005058497, 0.2547208690084517, 0.25836250407155603, 0.2568845801288262, 0.252450012951158, 0.3053483059629798, 0.2542786691337824, 0.25339521607384086, 0.25346772593911737, 0.2512685100082308, 0.24512015096843243, 0.2800760760437697, 0.24472369987051934, 0.24517161305993795, 0.24590348999481648, 0.2491112700663507, 0.25078558491077274, 0.24006347986869514, 0.38776236993726343, 0.2518505500629544, 0.2403430569684133, 0.23536634410265833, 0.24149299005512148, 0.2493771279696375, 0.2423763358965516, 0.3686313870130107, 0.23838572192471474, 0.23923552210908383, 0.2386640440672636, 0.240260424092412, 0.24546912696678191, 0.24238990200683475, 0.3000442209886387, 0.25730835797730833, 0.2537645240081474, 0.25557601207401603, 0.25585346098523587, 0.25797624699771404, 0.25195339298807085, 0.2533895989181474, 0.3197972719790414, 0.2556264199083671, 0.25604077603202313, 0.2577331808861345, 0.2609655010746792, 0.25799800897948444, 0.25148984498810023, 0.3484755769604817, 0.2447374960174784, 0.2441845361609012, 0.2457620861241594, 0.25147463707253337, 0.2578202551230788, 0.24995518114883453, 0.3580026348354295, 0.25436761789023876, 0.24638205603696406, 0.25461980199906975, 0.266032071900554, 0.24816970294341445, 0.24319363094400615, 0.3494739399757236, 0.24345290416385978, 0.24167376896366477, 0.24285763199441135, 0.24850371805951, 0.24836836906615645, 0.24909945798572153, 0.303092057001777, 0.2591531239449978, 0.2572635820833966, 0.27991902199573815, 0.26097265898715705, 0.2584184849401936, 0.2562836459837854, 0.2853086721152067, 0.2526468450669199, 0.2532963758567348, 0.25527098891325295, 0.2603589609498158, 0.2572302609914914, 0.2519606848945841, 0.33599971886724234, 0.23933191609103233, 0.23983981797937304, 0.241252445965074, 0.24638072005473077, 0.24898029793985188, 0.24521054199431092, 0.3792204090859741, 0.25267452490516007, 0.2540244630072266, 0.25455375004094094, 0.2594911199994385, 0.258946951944381, 0.25220689608249813, 0.4005793969845399, 0.25135973712895066, 0.2523343189386651, 0.24819716694764793, 0.25224039307795465, 0.2545069269835949, 0.2519902141066268, 0.252617200021632, 0.2525799940340221, 0.25142005691304803, 0.2505140299908817, 0.25090250209905207, 0.25282912515103817, 0.2519808099605143, 0.25065611000172794, 0.25164602196309716, 0.25259707192890346, 0.25376535416580737, 0.25228274008259177, 0.2521903070155531, 0.2505409551085904, 0.2508796330075711, 0.25152718101162463, 0.2513720999704674, 0.2524374200729653, 0.2521249658893794, 0.25230627798009664, 0.2518264150712639, 0.2518649520352483, 0.2510951830772683, 0.25124750088434666, 0.2523913929471746, 0.2517643201863393, 0.2516442929627374, 0.2531879669986665, 0.2510451308917254, 0.24923960387241095, 0.2500725210411474, 0.25024773506447673, 0.2473089499399066, 0.24898321507498622, 0.24905419209972024, 0.2608615920180455, 0.25809068605303764, 0.25980921799782664, 0.26099730492569506, 0.26020690507721156, 0.26055413286667317, 0.2593975749332458, 0.2603199310833588, 0.25933436292689294, 0.26097372197546065, 0.2606671069515869, 0.2605308360652998, 0.2610106250504032, 0.26081637386232615, 0.26244818896520883, 0.2605393179692328, 0.2602398671442643, 0.2598107170779258, 0.25992681505158544, 0.25991146091837436, 0.259316912968643, 0.26083184499293566, 0.2624686621129513, 0.2627014050958678, 0.26186642108950764, 0.2599479709751904, 0.2611258600372821, 0.2619199859909713, 0.2605318049900234, 0.26135633094236255, 0.2622087070485577, 0.26278678397648036, 0.2620937238680199, 0.2676860790234059, 0.2640188279328868, 0.26428402098827064, 0.26476191100664437, 0.2658386880066246, 0.26410170004237443, 0.26486670307349414, 0.26374662201851606, 0.26376020803581923, 0.2640970019856468, 0.26550593704450876, 0.2646002140827477, 0.2656941609457135, 0.26364499202463776, 0.264355712919496, 0.25974042783491313, 0.2566025539999828, 0.35946425900328904, 0.25449288298841566, 0.254136425210163, 0.2545543670421466, 0.2609274670248851, 0.26352233614306897, 0.25712584401480854, 0.34162082301918417, 0.2566520798718557, 0.2559534090105444, 0.25648919108789414, 0.26521984802093357, 0.26087399991229177, 0.34340037091169506, 0.2646062570856884, 0.26178588008042425, 0.2618437489727512, 0.26205906900577247, 0.2655799560016021, 0.2612268350785598, 0.30406189104542136, 0.26716947299428284, 0.2555214390158653, 0.25592110806610435, 0.25618871208280325, 0.26160263596102595, 0.2593301428714767, 0.25774874293711036, 0.32650501909665763, 0.2608559090876952, 0.2626668540760875, 0.26086241903249174, 0.2662851690547541, 0.2631168990628794, 0.25787352095358074, 0.3363105618627742, 0.2525743590667844, 0.25487029494252056, 0.2578293739352375, 0.25930393498856574, 0.2600740959169343, 0.25595692987553775, 0.3389471599366516, 0.2502817700151354, 0.2521209199912846, 0.25109315710142255, 0.25379904091823846, 0.2551231780089438, 0.24611140904016793, 0.3111356709850952, 0.266990726813674, 0.26399944501463324, 0.2666898709721863, 0.2667552089551464, 0.264868873055093, 0.2613375000655651, 0.33378883404657245, 0.260546506033279, 0.26262682292144746, 0.2621707629878074, 0.26411371293943375, 0.2690671960590407, 0.26233436702750623, 0.26498402701690793, 0.35471213317941874, 0.26214566302951425, 0.2638204168761149, 0.2651986819691956]
Total Epoch List: [116, 129, 118]
Total Time List: [0.0736960619688034, 0.07658716500736773, 0.07777439395431429]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e43687460>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6964;  Loss pred: 0.6964; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5102 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.4898 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6933;  Loss pred: 0.6933; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6869;  Loss pred: 0.6869; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6858;  Loss pred: 0.6858; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6814;  Loss pred: 0.6814; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6782;  Loss pred: 0.6782; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.19s
Epoch 10/1000, LR 0.000240
Train loss: 0.6717;  Loss pred: 0.6717; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6664;  Loss pred: 0.6664; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6602;  Loss pred: 0.6602; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6526;  Loss pred: 0.6526; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6443;  Loss pred: 0.6443; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6417;  Loss pred: 0.6417; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6326;  Loss pred: 0.6326; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6259;  Loss pred: 0.6259; Loss self: 0.0000; time: 0.24s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5102 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6185;  Loss pred: 0.6185; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5102 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6088;  Loss pred: 0.6088; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5102 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6046;  Loss pred: 0.6046; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5102 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.5925;  Loss pred: 0.5925; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 22/1000, LR 0.000270
Train loss: 0.5869;  Loss pred: 0.5869; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.5719;  Loss pred: 0.5719; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.5589;  Loss pred: 0.5589; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.5102 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5479;  Loss pred: 0.5479; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.5420;  Loss pred: 0.5420; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5299;  Loss pred: 0.5299; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5216;  Loss pred: 0.5216; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5088;  Loss pred: 0.5088; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6900 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.4939;  Loss pred: 0.4939; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.4814;  Loss pred: 0.4814; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5102 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4712;  Loss pred: 0.4712; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.4898 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5102 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4525;  Loss pred: 0.4525; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.5102 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4517;  Loss pred: 0.4517; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.5102 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4297;  Loss pred: 0.4297; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5102 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4105;  Loss pred: 0.4105; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5102 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.3947;  Loss pred: 0.3947; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.5102 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3795;  Loss pred: 0.3795; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.5102 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3678;  Loss pred: 0.3678; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6879 score: 0.5102 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3478;  Loss pred: 0.3478; Loss self: 0.0000; time: 0.23s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6884 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.5102 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3385;  Loss pred: 0.3385; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6866 score: 0.5102 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3220;  Loss pred: 0.3220; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6862 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6857 score: 0.5102 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3032;  Loss pred: 0.3032; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6846 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6847 score: 0.5102 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.2891;  Loss pred: 0.2891; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6829 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6835 score: 0.5102 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2793;  Loss pred: 0.2793; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6807 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6818 score: 0.5102 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2600;  Loss pred: 0.2600; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6781 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6799 score: 0.5102 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2484;  Loss pred: 0.2484; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6750 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6776 score: 0.5102 time: 0.23s
Epoch 48/1000, LR 0.000269
Train loss: 0.2348;  Loss pred: 0.2348; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6715 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6749 score: 0.5102 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2156;  Loss pred: 0.2156; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6671 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6714 score: 0.5102 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2081;  Loss pred: 0.2081; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6623 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6677 score: 0.5102 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.1896;  Loss pred: 0.1896; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6570 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6636 score: 0.5102 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1818;  Loss pred: 0.1818; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6506 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6585 score: 0.5102 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1680;  Loss pred: 0.1680; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6432 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6527 score: 0.5102 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1581;  Loss pred: 0.1581; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6350 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6462 score: 0.5102 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1476;  Loss pred: 0.1476; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6267 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6397 score: 0.5102 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1332;  Loss pred: 0.1332; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6162 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6314 score: 0.5102 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1248;  Loss pred: 0.1248; Loss self: 0.0000; time: 0.10s
Val loss: 0.6051 score: 0.5102 time: 0.07s
Test loss: 0.6227 score: 0.5306 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1181;  Loss pred: 0.1181; Loss self: 0.0000; time: 0.10s
Val loss: 0.5926 score: 0.5306 time: 0.07s
Test loss: 0.6130 score: 0.5510 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1050;  Loss pred: 0.1050; Loss self: 0.0000; time: 0.10s
Val loss: 0.5795 score: 0.5714 time: 0.07s
Test loss: 0.6027 score: 0.5714 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.0971;  Loss pred: 0.0971; Loss self: 0.0000; time: 0.10s
Val loss: 0.5666 score: 0.6122 time: 0.07s
Test loss: 0.5926 score: 0.5714 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.0906;  Loss pred: 0.0906; Loss self: 0.0000; time: 0.10s
Val loss: 0.5528 score: 0.6122 time: 0.07s
Test loss: 0.5818 score: 0.5918 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0862;  Loss pred: 0.0862; Loss self: 0.0000; time: 0.10s
Val loss: 0.5385 score: 0.6531 time: 0.07s
Test loss: 0.5707 score: 0.6327 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0787;  Loss pred: 0.0787; Loss self: 0.0000; time: 0.10s
Val loss: 0.5249 score: 0.6531 time: 0.07s
Test loss: 0.5602 score: 0.6531 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0741;  Loss pred: 0.0741; Loss self: 0.0000; time: 0.10s
Val loss: 0.5117 score: 0.6531 time: 0.07s
Test loss: 0.5500 score: 0.6531 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0631;  Loss pred: 0.0631; Loss self: 0.0000; time: 0.10s
Val loss: 0.4972 score: 0.6939 time: 0.07s
Test loss: 0.5387 score: 0.6939 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0592;  Loss pred: 0.0592; Loss self: 0.0000; time: 0.10s
Val loss: 0.4835 score: 0.7143 time: 0.07s
Test loss: 0.5281 score: 0.7143 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0566;  Loss pred: 0.0566; Loss self: 0.0000; time: 0.10s
Val loss: 0.4675 score: 0.7755 time: 0.07s
Test loss: 0.5155 score: 0.7347 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0524;  Loss pred: 0.0524; Loss self: 0.0000; time: 0.10s
Val loss: 0.4521 score: 0.7755 time: 0.07s
Test loss: 0.5034 score: 0.7347 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0474;  Loss pred: 0.0474; Loss self: 0.0000; time: 0.10s
Val loss: 0.4369 score: 0.7755 time: 0.07s
Test loss: 0.4915 score: 0.7347 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0421;  Loss pred: 0.0421; Loss self: 0.0000; time: 0.10s
Val loss: 0.4218 score: 0.8367 time: 0.07s
Test loss: 0.4797 score: 0.7551 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0428;  Loss pred: 0.0428; Loss self: 0.0000; time: 0.10s
Val loss: 0.4069 score: 0.8367 time: 0.07s
Test loss: 0.4681 score: 0.7551 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0396;  Loss pred: 0.0396; Loss self: 0.0000; time: 0.10s
Val loss: 0.3930 score: 0.8367 time: 0.07s
Test loss: 0.4574 score: 0.7551 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0343;  Loss pred: 0.0343; Loss self: 0.0000; time: 0.10s
Val loss: 0.3772 score: 0.8571 time: 0.07s
Test loss: 0.4452 score: 0.7551 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0317;  Loss pred: 0.0317; Loss self: 0.0000; time: 0.10s
Val loss: 0.3612 score: 0.8776 time: 0.07s
Test loss: 0.4328 score: 0.7755 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0283;  Loss pred: 0.0283; Loss self: 0.0000; time: 0.10s
Val loss: 0.3451 score: 0.8776 time: 0.07s
Test loss: 0.4203 score: 0.7755 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0272;  Loss pred: 0.0272; Loss self: 0.0000; time: 0.10s
Val loss: 0.3286 score: 0.8776 time: 0.07s
Test loss: 0.4076 score: 0.8367 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0250;  Loss pred: 0.0250; Loss self: 0.0000; time: 0.10s
Val loss: 0.3116 score: 0.8776 time: 0.07s
Test loss: 0.3945 score: 0.8367 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0217;  Loss pred: 0.0217; Loss self: 0.0000; time: 0.10s
Val loss: 0.2944 score: 0.8776 time: 0.07s
Test loss: 0.3814 score: 0.8367 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0211;  Loss pred: 0.0211; Loss self: 0.0000; time: 0.10s
Val loss: 0.2757 score: 0.8776 time: 0.07s
Test loss: 0.3672 score: 0.8163 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0205;  Loss pred: 0.0205; Loss self: 0.0000; time: 0.10s
Val loss: 0.2578 score: 0.8776 time: 0.07s
Test loss: 0.3535 score: 0.8163 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.11s
Val loss: 0.2408 score: 0.8980 time: 0.07s
Test loss: 0.3408 score: 0.7959 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0178;  Loss pred: 0.0178; Loss self: 0.0000; time: 0.11s
Val loss: 0.2261 score: 0.8980 time: 0.07s
Test loss: 0.3300 score: 0.8163 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0147;  Loss pred: 0.0147; Loss self: 0.0000; time: 0.10s
Val loss: 0.2120 score: 0.8980 time: 0.07s
Test loss: 0.3199 score: 0.8571 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0137;  Loss pred: 0.0137; Loss self: 0.0000; time: 0.10s
Val loss: 0.1983 score: 0.9184 time: 0.07s
Test loss: 0.3104 score: 0.8571 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.10s
Val loss: 0.1862 score: 0.9388 time: 0.07s
Test loss: 0.3025 score: 0.8571 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0125;  Loss pred: 0.0125; Loss self: 0.0000; time: 0.10s
Val loss: 0.1744 score: 0.9388 time: 0.07s
Test loss: 0.2953 score: 0.8776 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.10s
Val loss: 0.1634 score: 0.9592 time: 0.07s
Test loss: 0.2890 score: 0.8776 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.10s
Val loss: 0.1533 score: 0.9592 time: 0.07s
Test loss: 0.2838 score: 0.8776 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.10s
Val loss: 0.1454 score: 0.9592 time: 0.07s
Test loss: 0.2800 score: 0.8776 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.11s
Val loss: 0.1387 score: 0.9592 time: 0.07s
Test loss: 0.2772 score: 0.8776 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.11s
Val loss: 0.1323 score: 0.9592 time: 0.07s
Test loss: 0.2748 score: 0.8776 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.10s
Val loss: 0.1275 score: 0.9592 time: 0.07s
Test loss: 0.2736 score: 0.8776 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.11s
Val loss: 0.1232 score: 0.9592 time: 0.07s
Test loss: 0.2729 score: 0.8776 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.11s
Val loss: 0.1196 score: 0.9592 time: 0.07s
Test loss: 0.2727 score: 0.8776 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.10s
Val loss: 0.1161 score: 0.9592 time: 0.07s
Test loss: 0.2729 score: 0.8776 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.10s
Val loss: 0.1132 score: 0.9592 time: 0.07s
Test loss: 0.2733 score: 0.8776 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.10s
Val loss: 0.1098 score: 0.9592 time: 0.07s
Test loss: 0.2737 score: 0.8776 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.11s
Val loss: 0.1065 score: 0.9592 time: 0.07s
Test loss: 0.2744 score: 0.8776 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.11s
Val loss: 0.1038 score: 0.9592 time: 0.07s
Test loss: 0.2751 score: 0.8776 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.11s
Val loss: 0.1018 score: 0.9592 time: 0.07s
Test loss: 0.2764 score: 0.8776 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.10s
Val loss: 0.0993 score: 0.9592 time: 0.07s
Test loss: 0.2776 score: 0.8776 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.10s
Val loss: 0.0968 score: 0.9592 time: 0.07s
Test loss: 0.2789 score: 0.8776 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.10s
Val loss: 0.0964 score: 0.9592 time: 0.07s
Test loss: 0.2810 score: 0.8776 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.10s
Val loss: 0.0971 score: 0.9592 time: 0.07s
Test loss: 0.2834 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.10s
Val loss: 0.0976 score: 0.9592 time: 0.07s
Test loss: 0.2859 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.10s
Val loss: 0.0974 score: 0.9592 time: 0.07s
Test loss: 0.2878 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.10s
Val loss: 0.0989 score: 0.9592 time: 0.07s
Test loss: 0.2905 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.10s
Val loss: 0.0996 score: 0.9592 time: 0.07s
Test loss: 0.2929 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.10s
Val loss: 0.0997 score: 0.9592 time: 0.07s
Test loss: 0.2949 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.10s
Val loss: 0.0992 score: 0.9592 time: 0.07s
Test loss: 0.2963 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.10s
Val loss: 0.0978 score: 0.9592 time: 0.07s
Test loss: 0.2972 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.0966 score: 0.9592 time: 0.07s
Test loss: 0.2983 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.0955 score: 0.9592 time: 0.07s
Test loss: 0.2993 score: 0.8776 time: 0.07s
Epoch 114/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.0944 score: 0.9796 time: 0.08s
Test loss: 0.3002 score: 0.8776 time: 0.07s
Epoch 115/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.10s
Val loss: 0.0926 score: 0.9796 time: 0.07s
Test loss: 0.3006 score: 0.8776 time: 0.07s
Epoch 116/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.0903 score: 0.9796 time: 0.07s
Test loss: 0.3010 score: 0.8776 time: 0.07s
Epoch 117/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.11s
Val loss: 0.0881 score: 0.9796 time: 0.07s
Test loss: 0.3015 score: 0.8776 time: 0.07s
Epoch 118/1000, LR 0.000262
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.11s
Val loss: 0.0860 score: 0.9796 time: 0.07s
Test loss: 0.3021 score: 0.8776 time: 0.07s
Epoch 119/1000, LR 0.000262
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.11s
Val loss: 0.0833 score: 0.9796 time: 0.07s
Test loss: 0.3027 score: 0.8776 time: 0.07s
Epoch 120/1000, LR 0.000262
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.10s
Val loss: 0.0808 score: 0.9796 time: 0.07s
Test loss: 0.3033 score: 0.8776 time: 0.07s
Epoch 121/1000, LR 0.000262
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.10s
Val loss: 0.0789 score: 0.9796 time: 0.07s
Test loss: 0.3039 score: 0.8776 time: 0.07s
Epoch 122/1000, LR 0.000262
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.10s
Val loss: 0.0771 score: 0.9796 time: 0.07s
Test loss: 0.3049 score: 0.8776 time: 0.07s
Epoch 123/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.11s
Val loss: 0.0756 score: 0.9796 time: 0.07s
Test loss: 0.3059 score: 0.8776 time: 0.07s
Epoch 124/1000, LR 0.000261
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.11s
Val loss: 0.0742 score: 0.9796 time: 0.07s
Test loss: 0.3069 score: 0.8980 time: 0.07s
Epoch 125/1000, LR 0.000261
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.11s
Val loss: 0.0724 score: 0.9796 time: 0.07s
Test loss: 0.3081 score: 0.8980 time: 0.07s
Epoch 126/1000, LR 0.000261
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.10s
Val loss: 0.0707 score: 0.9796 time: 0.07s
Test loss: 0.3094 score: 0.8980 time: 0.07s
Epoch 127/1000, LR 0.000261
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.11s
Val loss: 0.0695 score: 0.9796 time: 0.07s
Test loss: 0.3105 score: 0.8980 time: 0.07s
Epoch 128/1000, LR 0.000261
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.11s
Val loss: 0.0683 score: 0.9796 time: 0.07s
Test loss: 0.3117 score: 0.8980 time: 0.07s
Epoch 129/1000, LR 0.000261
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.11s
Val loss: 0.0673 score: 0.9796 time: 0.07s
Test loss: 0.3132 score: 0.8980 time: 0.07s
Epoch 130/1000, LR 0.000260
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.10s
Val loss: 0.0665 score: 0.9796 time: 0.07s
Test loss: 0.3144 score: 0.8980 time: 0.07s
Epoch 131/1000, LR 0.000260
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.10s
Val loss: 0.0657 score: 0.9796 time: 0.07s
Test loss: 0.3158 score: 0.8980 time: 0.07s
Epoch 132/1000, LR 0.000260
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.11s
Val loss: 0.0652 score: 0.9796 time: 0.07s
Test loss: 0.3169 score: 0.8980 time: 0.07s
Epoch 133/1000, LR 0.000260
Train loss: 0.0025;  Loss pred: 0.0025; Loss self: 0.0000; time: 0.10s
Val loss: 0.0650 score: 0.9796 time: 0.07s
Test loss: 0.3178 score: 0.8980 time: 0.07s
Epoch 134/1000, LR 0.000260
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.10s
Val loss: 0.0648 score: 0.9796 time: 0.07s
Test loss: 0.3186 score: 0.8980 time: 0.07s
Epoch 135/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.10s
Val loss: 0.0648 score: 0.9796 time: 0.07s
Test loss: 0.3194 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 136/1000, LR 0.000260
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.10s
Val loss: 0.0650 score: 0.9796 time: 0.07s
Test loss: 0.3199 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 137/1000, LR 0.000259
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.10s
Val loss: 0.0647 score: 0.9796 time: 0.07s
Test loss: 0.3211 score: 0.8980 time: 0.07s
Epoch 138/1000, LR 0.000259
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.10s
Val loss: 0.0645 score: 0.9796 time: 0.07s
Test loss: 0.3221 score: 0.8980 time: 0.07s
Epoch 139/1000, LR 0.000259
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.11s
Val loss: 0.0643 score: 0.9796 time: 0.07s
Test loss: 0.3231 score: 0.8980 time: 0.07s
Epoch 140/1000, LR 0.000259
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.10s
Val loss: 0.0641 score: 0.9796 time: 0.07s
Test loss: 0.3242 score: 0.8980 time: 0.07s
Epoch 141/1000, LR 0.000259
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.10s
Val loss: 0.0641 score: 0.9796 time: 0.07s
Test loss: 0.3250 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 142/1000, LR 0.000259
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.10s
Val loss: 0.0643 score: 0.9796 time: 0.07s
Test loss: 0.3255 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 143/1000, LR 0.000258
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.11s
Val loss: 0.0646 score: 0.9796 time: 0.07s
Test loss: 0.3262 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 144/1000, LR 0.000258
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.10s
Val loss: 0.0651 score: 0.9796 time: 0.07s
Test loss: 0.3265 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 145/1000, LR 0.000258
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.10s
Val loss: 0.0659 score: 0.9796 time: 0.07s
Test loss: 0.3269 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 146/1000, LR 0.000258
Train loss: 0.0025;  Loss pred: 0.0025; Loss self: 0.0000; time: 0.21s
Val loss: 0.0677 score: 0.9796 time: 0.07s
Test loss: 0.3275 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 147/1000, LR 0.000258
Train loss: 0.0016;  Loss pred: 0.0016; Loss self: 0.0000; time: 0.10s
Val loss: 0.0693 score: 0.9796 time: 0.07s
Test loss: 0.3282 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 148/1000, LR 0.000257
Train loss: 0.0018;  Loss pred: 0.0018; Loss self: 0.0000; time: 0.10s
Val loss: 0.0707 score: 0.9796 time: 0.07s
Test loss: 0.3289 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 149/1000, LR 0.000257
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.10s
Val loss: 0.0721 score: 0.9796 time: 0.07s
Test loss: 0.3292 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 150/1000, LR 0.000257
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.11s
Val loss: 0.0731 score: 0.9796 time: 0.07s
Test loss: 0.3298 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 151/1000, LR 0.000257
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.11s
Val loss: 0.0745 score: 0.9796 time: 0.07s
Test loss: 0.3305 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 152/1000, LR 0.000257
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.10s
Val loss: 0.0757 score: 0.9796 time: 0.07s
Test loss: 0.3312 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 153/1000, LR 0.000257
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.10s
Val loss: 0.0779 score: 0.9796 time: 0.08s
Test loss: 0.3317 score: 0.8776 time: 0.17s
     INFO: Early stopping counter 13 of 20
Epoch 154/1000, LR 0.000256
Train loss: 0.0016;  Loss pred: 0.0016; Loss self: 0.0000; time: 0.10s
Val loss: 0.0794 score: 0.9796 time: 0.07s
Test loss: 0.3325 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 155/1000, LR 0.000256
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.10s
Val loss: 0.0808 score: 0.9796 time: 0.07s
Test loss: 0.3333 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 156/1000, LR 0.000256
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.10s
Val loss: 0.0812 score: 0.9796 time: 0.07s
Test loss: 0.3339 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 157/1000, LR 0.000256
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.10s
Val loss: 0.0813 score: 0.9796 time: 0.07s
Test loss: 0.3347 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 158/1000, LR 0.000256
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.10s
Val loss: 0.0814 score: 0.9796 time: 0.07s
Test loss: 0.3352 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 159/1000, LR 0.000255
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.10s
Val loss: 0.0815 score: 0.9796 time: 0.07s
Test loss: 0.3356 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 160/1000, LR 0.000255
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.10s
Val loss: 0.0813 score: 0.9796 time: 0.07s
Test loss: 0.3362 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 139,   Train_Loss: 0.0020,   Val_Loss: 0.0641,   Val_Precision: 0.9600,   Val_Recall: 1.0000,   Val_accuracy: 0.9796,   Val_Score: 0.9796,   Val_Loss: 0.0641,   Test_Precision: 0.9167,   Test_Recall: 0.8800,   Test_accuracy: 0.8980,   Test_Score: 0.8980,   Test_loss: 0.3242


[0.07893816498108208, 0.07403193099889904, 0.07486623909790069, 0.07473262900020927, 0.0751354640815407, 0.07692626502830535, 0.07579160400200635, 0.07541519799269736, 0.1975945649901405, 0.0742039909819141, 0.07432586990762502, 0.07441400503739715, 0.07459088193718344, 0.07519129395950586, 0.07367003394756466, 0.0744550060480833, 0.07869485893752426, 0.07938422402366996, 0.07889562693890184, 0.07940660393796861, 0.07592196599580348, 0.07410074002109468, 0.07500873401295394, 0.07513771404046565, 0.07437845098320395, 0.07416161010041833, 0.07468028797302395, 0.07472636306192726, 0.07486346899531782, 0.0743516490329057, 0.07491507800295949, 0.0760219469666481, 0.07529263594187796, 0.0749096650397405, 0.07559530099388212, 0.07567189098335803, 0.07615141500718892, 0.07504054391756654, 0.0761786769144237, 0.07584341696929187, 0.0760900330496952, 0.07590217504184693, 0.07647302595432848, 0.07850468496326357, 0.07672111899591982, 0.07644483796320856, 0.23223313398193568, 0.08062189596239477, 0.07558678998611867, 0.07427726907189935, 0.07604201801586896, 0.07537905604112893, 0.0754797700792551, 0.07570098200812936, 0.07607632200233638, 0.07550338108558208, 0.07597431796602905, 0.07564383395947516, 0.07604937697760761, 0.07590700802393258, 0.07639593991916627, 0.07590653200168163, 0.07603675394784659, 0.07607007899787277, 0.07651669206097722, 0.07632295007351786, 0.07618582400027663, 0.07622368296142668, 0.07661276904400438, 0.07619526993948966, 0.07649798400234431, 0.07658538699615747, 0.07657614001072943, 0.07650889607612044, 0.07675281702540815, 0.07648700603749603, 0.0766114640282467, 0.07632816606201231, 0.07741219806484878, 0.07785992801655084, 0.0769164509838447, 0.07714935601688921, 0.0759194940328598, 0.07621081301476806, 0.07607218902558088, 0.07638385996688157, 0.07640665408689529, 0.07667597301770002, 0.07620792801026255, 0.07689316500909626, 0.07770808797795326, 0.0773852450074628, 0.07728121499530971, 0.0769625490065664, 0.07713165297172964, 0.07752628694288433, 0.07719632098451257, 0.07728804706130177, 0.07732867600861937, 0.07757244096137583, 0.0763980170013383, 0.07645734096877277, 0.07666735502425581, 0.0769381410209462, 0.0770021709613502, 0.07690287195146084, 0.07644702703692019, 0.07647775497753173, 0.07677635294385254, 0.07645727193448693, 0.0769813519436866, 0.0770897869952023, 0.07744388794526458, 0.07738953200168908, 0.07671818800736219, 0.0768815919291228, 0.07662901096045971, 0.07678938203025609, 0.07686558598652482, 0.0763223230605945, 0.07662521698512137, 0.07623722602147609, 0.07681450992822647, 0.07675787701737136, 0.07600306300446391, 0.07623052597045898, 0.07685029006097466, 0.07710484904237092, 0.0769933060510084, 0.07682748197112232, 0.07651922397781163, 0.07663239794783294, 0.07689537294209003, 0.07673545507714152, 0.07704090303741395, 0.07708561304025352, 0.07697418506722897, 0.0768077940447256, 0.076781713985838, 0.07651441101916134, 0.07675541599746794, 0.07668225490488112, 0.0770800719037652, 0.07495411403942853, 0.07602147001307458, 0.07581031403969973, 0.07631239807233214, 0.07582855294458568, 0.07665363396517932, 0.07727397396229208, 0.07596707798074931, 0.0751260599354282, 0.17492842103820294, 0.07599642197601497, 0.0763886549975723, 0.0763129839906469, 0.07674711395520717, 0.07729481800924987, 0.0752035640180111, 0.07669741590507329]
[0.0016109829587975936, 0.001510855734671409, 0.001527882430569402, 0.0015251556938818218, 0.0015333768179906265, 0.0015699237760878643, 0.0015467674286123744, 0.0015390856733203543, 0.004032542142655929, 0.0015143671628962063, 0.0015168544879107146, 0.0015186531640285132, 0.001522262896677213, 0.0015345162032552216, 0.001503470080562544, 0.0015194899193486388, 0.0016060175293372298, 0.001620086204564693, 0.0016101148354877926, 0.0016205429375095635, 0.001549427877465377, 0.0015122600004305036, 0.0015307904900602844, 0.0015334227355197072, 0.0015179275710857948, 0.0015135022469473128, 0.00152408750965355, 0.0015250278175903522, 0.001527825897863629, 0.0015173805925082795, 0.0015288791429175406, 0.001551468305441798, 0.0015365844069771012, 0.0015287686742804184, 0.0015427612447731045, 0.001544324305782817, 0.0015541105103507942, 0.0015314396717870723, 0.0015546668758045655, 0.0015478248361079972, 0.0015528578173407183, 0.0015490239804458556, 0.001560673999067928, 0.0016021364278217055, 0.0015657371223657107, 0.0015600987339430318, 0.004739451713917054, 0.001645344815559077, 0.0015425875507371158, 0.001515862634120395, 0.0015518779186912033, 0.001538348082472019, 0.0015404034710052063, 0.0015449180001659052, 0.0015525780000476812, 0.0015408853282771853, 0.0015504962850210009, 0.0015437517134586768, 0.0015520281015838288, 0.0015491226127333179, 0.0015591008146768625, 0.0015491128979935025, 0.001551770488731563, 0.0015524505917933217, 0.001561565144101576, 0.0015576112259901604, 0.001554812734699523, 0.001555585366559728, 0.0015635258988572322, 0.0015550055089691768, 0.0015611833469866185, 0.001562967081554234, 0.0015627783675659069, 0.001561406042369805, 0.0015663840209266969, 0.0015609593068876741, 0.0015634992658825858, 0.0015577176747349451, 0.0015798407768336485, 0.001588978122786752, 0.0015697234894662183, 0.0015744766534059023, 0.0015493774292420369, 0.0015553227145871033, 0.0015524936535832833, 0.0015588542850383995, 0.0015593194711611283, 0.001564815775871429, 0.0015552638369441337, 0.0015692482654917606, 0.0015858793464888418, 0.0015792907144380162, 0.0015771676529655043, 0.0015706642654401306, 0.0015741153667699925, 0.0015821691212833536, 0.0015754351221329095, 0.0015773070828837095, 0.0015781362450738646, 0.0015831110400280782, 0.001559143204108945, 0.0015603538973218932, 0.0015646398984542002, 0.0015701661432846164, 0.001571472876762249, 0.0015694463663563436, 0.0015601434089167385, 0.0015607705097455456, 0.0015668643457929091, 0.0015603524884589169, 0.001571047998850747, 0.0015732609590857613, 0.0015804875090870323, 0.0015793782041161036, 0.0015656773062726977, 0.0015690120801861798, 0.001563857366539994, 0.0015671302455154304, 0.0015686854282964248, 0.001557598429808051, 0.0015637799384718646, 0.0015558617555403284, 0.001567643059759724, 0.0015664872860688033, 0.0015510829184584472, 0.0015557250198052854, 0.0015683732665505033, 0.001573568347803488, 0.0015712919602246613, 0.001567907795329027, 0.0015616168158737067, 0.0015639264887312846, 0.0015692933253487762, 0.0015660296954518678, 0.0015722633272941624, 0.0015731757763317044, 0.0015709017360658975, 0.0015675060009127672, 0.0015669737548130204, 0.0015615185922277825, 0.001566437061172815, 0.001564943977650635, 0.0015730626919135756, 0.0015296757967230312, 0.0015514585716953995, 0.001547149266116321, 0.0015573958790271866, 0.0015475214886650139, 0.0015643598768403943, 0.001577019876781471, 0.0015503485302193736, 0.001533184896641392, 0.003569967776289856, 0.0015509473872656117, 0.001558952142807598, 0.0015574078365438143, 0.001566267631738922, 0.0015774452654948952, 0.0015347666126124713, 0.001565253385817822]
[620.7390305024584, 661.8765624353186, 654.5006212469674, 655.670764638332, 652.1554182033506, 636.9736003947447, 646.5096054531697, 649.7364099573774, 247.98252928892546, 660.3418408039922, 659.2590179018293, 658.4781987661435, 656.9167534614385, 651.671189837335, 665.1279682438617, 658.1155868600108, 622.6582099715184, 617.2511050229539, 621.0737134764955, 617.0771393054179, 645.399514584599, 661.2619521215428, 653.2572592351412, 652.1358897558541, 658.7929615671227, 660.7192040956458, 656.1303033231447, 655.7257437966398, 654.5248391183236, 659.0304403109358, 654.0739368657438, 644.5507114083383, 650.7940569091708, 654.1212001682946, 648.1884370559691, 647.5323843932514, 643.454885183345, 652.9803415847763, 643.2246133001861, 646.0679378388179, 643.9739613202374, 645.5677979318111, 640.7488050657754, 624.166570733067, 638.6768159964653, 640.9850724463929, 210.99487036940852, 607.775337147312, 648.2614225183888, 659.6903818928599, 644.3805842945193, 650.0479386908775, 649.1805678335948, 647.2835450765751, 644.0900231545784, 648.9775596202659, 644.9547861937995, 647.77256036825, 644.3182304363628, 645.5266947756771, 641.3953418446894, 645.530742978937, 644.4251951314094, 644.1428830561651, 640.3831462153541, 642.0087267696138, 643.1642716080893, 642.8448232394735, 639.5800675453419, 643.0845384354338, 640.5397559038729, 639.8087405689872, 639.8860009545322, 640.4483989842016, 638.4130498269412, 640.6316907734479, 639.5909622864492, 641.9648542346775, 632.9751799445396, 629.3352851493, 637.0548741294865, 635.1316787307094, 645.4205289986734, 642.9533823567112, 644.1250163515435, 641.4967772150474, 641.3054018079837, 639.0528619531017, 642.9777226511317, 637.2477969167146, 630.5649936194789, 633.1956433719967, 634.0480025187734, 636.6732993188589, 635.2774524093179, 632.0436839197471, 634.7452750997107, 633.9919542945, 633.6588511425989, 631.6676308329351, 641.3779038157711, 640.8802526890507, 639.1246963521503, 636.8752786301385, 636.3456950401389, 637.1673613298548, 640.9667177290673, 640.7091841855926, 638.2173432467453, 640.8808313483389, 636.5177898648036, 635.6224593414628, 632.7161677966374, 633.1605674903234, 638.7012163960098, 637.3437226062272, 639.444505231626, 638.1090549822801, 637.4764385272508, 642.0140010819309, 639.4761663058589, 642.7306259306531, 637.9003139613122, 638.3709647012597, 644.7108585231896, 642.7871167908323, 637.6033188830173, 635.498293668578, 636.4189630659228, 637.7926067968486, 640.3619568098153, 639.4162431581022, 637.2294993211352, 638.5574953682193, 636.0257742072904, 635.6568763929084, 636.5770544657742, 637.9560903867, 638.1727817255786, 640.4022372691209, 638.3914328809898, 639.0005101021222, 635.7025725297286, 653.7332957364322, 644.5547552760124, 646.3500464374818, 642.0974997215486, 646.1945810281838, 639.2391001613667, 634.107416604598, 645.0162531250314, 652.2370538547625, 280.1145732019087, 644.767197269692, 641.456509498135, 642.0925698044458, 638.4604902354823, 633.9364172399781, 651.5648645091422, 638.8741970217906]
Elapsed: 0.07866644386740518~0.0173279576964479
Time per graph: 0.0016054376299470443~0.00035363178972342655
Speed: 634.7589353062596~54.5658485043482
Total Time: 0.0774
best val loss: 0.06409522891044617 test_score: 0.8980

Testing...
Test loss: 0.3002 score: 0.8776 time: 0.07s
test Score 0.8776
Epoch Time List: [0.25548477401025593, 0.3494161950657144, 0.2411726809805259, 0.24112801009323448, 0.2429196499288082, 0.24673061398789287, 0.24831568519584835, 0.24407313391566277, 0.36780757002998143, 0.24130217300262302, 0.24199698015581816, 0.24269700306467712, 0.24280981009360403, 0.2488495911238715, 0.2417602970963344, 0.24031610798556358, 0.38509826303925365, 0.2527664400404319, 0.2537275879876688, 0.25494986993726343, 0.2520710799144581, 0.24313935299869627, 0.23940398183185607, 0.3289638600545004, 0.24097133905161172, 0.2385966150322929, 0.24002682301215827, 0.2467922680079937, 0.2462941890116781, 0.2425900740781799, 0.241078382008709, 0.30186566011980176, 0.24304277694318444, 0.2429790268652141, 0.24585287005174905, 0.24558660294860601, 0.24964161089155823, 0.24511994584463537, 0.24380555213429034, 0.3746585400076583, 0.24499999394174665, 0.2451915011042729, 0.24634094606153667, 0.24720933905337006, 0.25308188097551465, 0.24690508504863828, 0.4025066838366911, 0.2536544568138197, 0.24849699984770268, 0.2406896719476208, 0.24601358082145452, 0.2498727791244164, 0.24748146103229374, 0.24656253005377948, 0.24743031291291118, 0.24718802201095968, 0.2467696830863133, 0.24679096799809486, 0.24732032092288136, 0.24461416120175272, 0.24493671394884586, 0.24591115687508136, 0.24726638500578701, 0.24699281889479607, 0.24716904805973172, 0.2469851749483496, 0.24839956196956336, 0.2465850559528917, 0.2460406409809366, 0.24591257888823748, 0.24647960299625993, 0.24828217003960162, 0.2465324611403048, 0.2476383929606527, 0.24965017789509147, 0.2486682808957994, 0.249403360998258, 0.2493203921476379, 0.25065526901744306, 0.25056909408885986, 0.2509932171087712, 0.251838814932853, 0.2482374939136207, 0.2480910299345851, 0.24884032981935889, 0.24875075893942267, 0.2478486900217831, 0.24837085709441453, 0.24921688996255398, 0.25228985119611025, 0.2532021610531956, 0.2509544799104333, 0.25140457006637007, 0.25173505197744817, 0.24964242801070213, 0.25071428425144404, 0.2511280319886282, 0.25184072996489704, 0.25217435194645077, 0.25191262690350413, 0.24871931900270283, 0.2473246098961681, 0.24847193202003837, 0.2483171639032662, 0.24898426025174558, 0.24998478102497756, 0.248587831039913, 0.24976177199278027, 0.25038197496905923, 0.2492449899436906, 0.24947091890498996, 0.2527983139734715, 0.25260171794798225, 0.25391052407212555, 0.25103009096346796, 0.25215579802170396, 0.25194272911176085, 0.2510538150090724, 0.25199120305478573, 0.24846289888955653, 0.25039327901322395, 0.25028821488376707, 0.25116473506204784, 0.2510213280329481, 0.25025139399804175, 0.2499516699463129, 0.250913891941309, 0.25156735198106617, 0.251678912085481, 0.2510161300888285, 0.2501432579010725, 0.2505947971949354, 0.2500466980272904, 0.24941778101492673, 0.2503620338393375, 0.24994455510750413, 0.24986577103845775, 0.2501135270576924, 0.25169499695766717, 0.24886978894937783, 0.24969299288932234, 0.2491156451869756, 0.25127372390124947, 0.245438412996009, 0.24465963197872043, 0.35158834396861494, 0.24774616386275738, 0.24764447892084718, 0.24880983086768538, 0.25157734495587647, 0.24970852595288306, 0.24385594099294394, 0.351532629923895, 0.24686982296407223, 0.24614832003135234, 0.24759719078429043, 0.24928584997542202, 0.25133160897530615, 0.24816489312797785, 0.24477547802962363]
Total Epoch List: [160]
Total Time List: [0.0773575030034408]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e43653910>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6929;  Loss pred: 0.6929; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
Epoch 3/1000, LR 0.000030
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6886;  Loss pred: 0.6886; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.23s
     INFO: Early stopping counter 4 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6878;  Loss pred: 0.6878; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6821;  Loss pred: 0.6821; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6804;  Loss pred: 0.6804; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6772;  Loss pred: 0.6772; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6731;  Loss pred: 0.6731; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6674;  Loss pred: 0.6674; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6626;  Loss pred: 0.6626; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.4898 time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6583;  Loss pred: 0.6583; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6591;  Loss pred: 0.6591; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5102 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6493;  Loss pred: 0.6493; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5102 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6438;  Loss pred: 0.6438; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5102 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6378;  Loss pred: 0.6378; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5102 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6338;  Loss pred: 0.6338; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5102 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6285;  Loss pred: 0.6285; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5102 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6163;  Loss pred: 0.6163; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5102 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6104;  Loss pred: 0.6104; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5102 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6033;  Loss pred: 0.6033; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5102 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5965;  Loss pred: 0.5965; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5102 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5899;  Loss pred: 0.5899; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5102 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5783;  Loss pred: 0.5783; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5102 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5660;  Loss pred: 0.5660; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5102 time: 0.12s
Epoch 28/1000, LR 0.000270
Train loss: 0.5568;  Loss pred: 0.5568; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6900 score: 0.5102 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5470;  Loss pred: 0.5470; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5102 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5315;  Loss pred: 0.5315; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.5102 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5227;  Loss pred: 0.5227; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.5102 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5109;  Loss pred: 0.5109; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5102 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.4988;  Loss pred: 0.4988; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6890 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6869 score: 0.5102 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4812;  Loss pred: 0.4812; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6859 score: 0.5102 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4765;  Loss pred: 0.4765; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.4898 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6849 score: 0.5102 time: 0.11s
Epoch 36/1000, LR 0.000270
Train loss: 0.4564;  Loss pred: 0.4564; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6859 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6838 score: 0.5102 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4464;  Loss pred: 0.4464; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6825 score: 0.5102 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4329;  Loss pred: 0.4329; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6833 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6811 score: 0.5102 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4144;  Loss pred: 0.4144; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6818 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6796 score: 0.5102 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.4061;  Loss pred: 0.4061; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6801 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6779 score: 0.5102 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3943;  Loss pred: 0.3943; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6783 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6761 score: 0.5102 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3759;  Loss pred: 0.3759; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6765 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6742 score: 0.5102 time: 0.17s
Epoch 43/1000, LR 0.000269
Train loss: 0.3662;  Loss pred: 0.3662; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6744 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6720 score: 0.5102 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3427;  Loss pred: 0.3427; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6721 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6696 score: 0.5102 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3366;  Loss pred: 0.3366; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6697 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6670 score: 0.5102 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3207;  Loss pred: 0.3207; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6671 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6641 score: 0.5102 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.3095;  Loss pred: 0.3095; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6644 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6611 score: 0.5102 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2856;  Loss pred: 0.2856; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6614 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6578 score: 0.5102 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2704;  Loss pred: 0.2704; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6583 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6543 score: 0.5102 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2600;  Loss pred: 0.2600; Loss self: 0.0000; time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6548 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6504 score: 0.5102 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2350;  Loss pred: 0.2350; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6512 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6462 score: 0.5102 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2279;  Loss pred: 0.2279; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6475 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6418 score: 0.5102 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.2224;  Loss pred: 0.2224; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6435 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6371 score: 0.5102 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1995;  Loss pred: 0.1995; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6393 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6320 score: 0.5102 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1955;  Loss pred: 0.1955; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6351 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6267 score: 0.5102 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1794;  Loss pred: 0.1794; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6303 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6209 score: 0.5102 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1686;  Loss pred: 0.1686; Loss self: 0.0000; time: 0.12s
Val loss: 0.6254 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6147 score: 0.5102 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1545;  Loss pred: 0.1545; Loss self: 0.0000; time: 0.11s
Val loss: 0.6200 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6079 score: 0.5102 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1459;  Loss pred: 0.1459; Loss self: 0.0000; time: 0.11s
Val loss: 0.6144 score: 0.5102 time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6008 score: 0.5102 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1373;  Loss pred: 0.1373; Loss self: 0.0000; time: 0.11s
Val loss: 0.6083 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.5930 score: 0.5102 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1302;  Loss pred: 0.1302; Loss self: 0.0000; time: 0.11s
Val loss: 0.6017 score: 0.5306 time: 0.07s
Test loss: 0.5846 score: 0.5306 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1186;  Loss pred: 0.1186; Loss self: 0.0000; time: 0.12s
Val loss: 0.5946 score: 0.5306 time: 0.07s
Test loss: 0.5756 score: 0.5306 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1100;  Loss pred: 0.1100; Loss self: 0.0000; time: 0.11s
Val loss: 0.5872 score: 0.5306 time: 0.07s
Test loss: 0.5662 score: 0.5306 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.1024;  Loss pred: 0.1024; Loss self: 0.0000; time: 0.13s
Val loss: 0.5793 score: 0.5306 time: 0.13s
Test loss: 0.5561 score: 0.5510 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.0981;  Loss pred: 0.0981; Loss self: 0.0000; time: 0.12s
Val loss: 0.5712 score: 0.5510 time: 0.07s
Test loss: 0.5457 score: 0.5714 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0909;  Loss pred: 0.0909; Loss self: 0.0000; time: 0.11s
Val loss: 0.5626 score: 0.5714 time: 0.07s
Test loss: 0.5347 score: 0.5714 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0822;  Loss pred: 0.0822; Loss self: 0.0000; time: 0.12s
Val loss: 0.5535 score: 0.6122 time: 0.08s
Test loss: 0.5229 score: 0.5918 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0733;  Loss pred: 0.0733; Loss self: 0.0000; time: 0.11s
Val loss: 0.5440 score: 0.6735 time: 0.07s
Test loss: 0.5105 score: 0.6327 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0693;  Loss pred: 0.0693; Loss self: 0.0000; time: 0.12s
Val loss: 0.5340 score: 0.6939 time: 0.07s
Test loss: 0.4972 score: 0.6735 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0613;  Loss pred: 0.0613; Loss self: 0.0000; time: 0.11s
Val loss: 0.5233 score: 0.6939 time: 0.07s
Test loss: 0.4831 score: 0.7347 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0619;  Loss pred: 0.0619; Loss self: 0.0000; time: 0.12s
Val loss: 0.5124 score: 0.6939 time: 0.16s
Test loss: 0.4685 score: 0.7755 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0502;  Loss pred: 0.0502; Loss self: 0.0000; time: 0.11s
Val loss: 0.5007 score: 0.7143 time: 0.07s
Test loss: 0.4528 score: 0.7959 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0474;  Loss pred: 0.0474; Loss self: 0.0000; time: 0.11s
Val loss: 0.4892 score: 0.7755 time: 0.07s
Test loss: 0.4368 score: 0.8367 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0512;  Loss pred: 0.0512; Loss self: 0.0000; time: 0.11s
Val loss: 0.4776 score: 0.7959 time: 0.07s
Test loss: 0.4204 score: 0.8367 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0455;  Loss pred: 0.0455; Loss self: 0.0000; time: 0.11s
Val loss: 0.4649 score: 0.7959 time: 0.07s
Test loss: 0.4023 score: 0.8571 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0374;  Loss pred: 0.0374; Loss self: 0.0000; time: 0.12s
Val loss: 0.4527 score: 0.8163 time: 0.08s
Test loss: 0.3844 score: 0.8776 time: 0.08s
Epoch 77/1000, LR 0.000267
Train loss: 0.0347;  Loss pred: 0.0347; Loss self: 0.0000; time: 0.12s
Val loss: 0.4404 score: 0.8367 time: 0.07s
Test loss: 0.3659 score: 0.9388 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0343;  Loss pred: 0.0343; Loss self: 0.0000; time: 0.12s
Val loss: 0.4285 score: 0.8571 time: 0.16s
Test loss: 0.3473 score: 0.9388 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0311;  Loss pred: 0.0311; Loss self: 0.0000; time: 0.12s
Val loss: 0.4170 score: 0.8571 time: 0.07s
Test loss: 0.3286 score: 0.9388 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0280;  Loss pred: 0.0280; Loss self: 0.0000; time: 0.11s
Val loss: 0.4060 score: 0.8571 time: 0.07s
Test loss: 0.3099 score: 0.9388 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0258;  Loss pred: 0.0258; Loss self: 0.0000; time: 0.11s
Val loss: 0.3960 score: 0.8571 time: 0.07s
Test loss: 0.2919 score: 0.9592 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0231;  Loss pred: 0.0231; Loss self: 0.0000; time: 0.11s
Val loss: 0.3869 score: 0.8571 time: 0.07s
Test loss: 0.2746 score: 0.9592 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0200;  Loss pred: 0.0200; Loss self: 0.0000; time: 0.12s
Val loss: 0.3787 score: 0.8571 time: 0.07s
Test loss: 0.2579 score: 0.9592 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.12s
Val loss: 0.3705 score: 0.8571 time: 0.07s
Test loss: 0.2411 score: 0.9796 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0190;  Loss pred: 0.0190; Loss self: 0.0000; time: 0.12s
Val loss: 0.3624 score: 0.8571 time: 0.07s
Test loss: 0.2245 score: 0.9796 time: 0.18s
Epoch 86/1000, LR 0.000266
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.12s
Val loss: 0.3548 score: 0.8776 time: 0.07s
Test loss: 0.2085 score: 0.9796 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.12s
Val loss: 0.3477 score: 0.8776 time: 0.07s
Test loss: 0.1930 score: 0.9796 time: 0.08s
Epoch 88/1000, LR 0.000266
Train loss: 0.0140;  Loss pred: 0.0140; Loss self: 0.0000; time: 0.12s
Val loss: 0.3431 score: 0.8776 time: 0.07s
Test loss: 0.1797 score: 0.9796 time: 0.08s
Epoch 89/1000, LR 0.000266
Train loss: 0.0161;  Loss pred: 0.0161; Loss self: 0.0000; time: 0.12s
Val loss: 0.3385 score: 0.8776 time: 0.07s
Test loss: 0.1667 score: 0.9796 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.12s
Val loss: 0.3345 score: 0.8776 time: 0.07s
Test loss: 0.1545 score: 0.9796 time: 0.08s
Epoch 91/1000, LR 0.000266
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.12s
Val loss: 0.3295 score: 0.8776 time: 0.07s
Test loss: 0.1419 score: 0.9796 time: 0.08s
Epoch 92/1000, LR 0.000266
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.11s
Val loss: 0.3257 score: 0.9184 time: 0.07s
Test loss: 0.1306 score: 0.9796 time: 0.08s
Epoch 93/1000, LR 0.000265
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.24s
Val loss: 0.3233 score: 0.9184 time: 0.08s
Test loss: 0.1205 score: 0.9796 time: 0.08s
Epoch 94/1000, LR 0.000265
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.3213 score: 0.9184 time: 0.08s
Test loss: 0.1111 score: 0.9796 time: 0.08s
Epoch 95/1000, LR 0.000265
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.11s
Val loss: 0.3208 score: 0.9184 time: 0.08s
Test loss: 0.1032 score: 0.9796 time: 0.08s
Epoch 96/1000, LR 0.000265
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.12s
Val loss: 0.3214 score: 0.9184 time: 0.08s
Test loss: 0.0962 score: 0.9796 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.12s
Val loss: 0.3229 score: 0.9184 time: 0.07s
Test loss: 0.0901 score: 0.9796 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.11s
Val loss: 0.3249 score: 0.9184 time: 0.07s
Test loss: 0.0847 score: 0.9796 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.3276 score: 0.9184 time: 0.19s
Test loss: 0.0798 score: 0.9796 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.11s
Val loss: 0.3295 score: 0.9184 time: 0.07s
Test loss: 0.0750 score: 0.9796 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.11s
Val loss: 0.3312 score: 0.9184 time: 0.07s
Test loss: 0.0704 score: 0.9796 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.11s
Val loss: 0.3320 score: 0.9184 time: 0.07s
Test loss: 0.0656 score: 0.9796 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.11s
Val loss: 0.3301 score: 0.9184 time: 0.07s
Test loss: 0.0601 score: 0.9796 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.11s
Val loss: 0.3293 score: 0.9184 time: 0.07s
Test loss: 0.0556 score: 0.9796 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.12s
Val loss: 0.3290 score: 0.9184 time: 0.07s
Test loss: 0.0517 score: 0.9796 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.3295 score: 0.9184 time: 0.07s
Test loss: 0.0485 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.11s
Val loss: 0.3308 score: 0.9184 time: 0.07s
Test loss: 0.0458 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.12s
Val loss: 0.3328 score: 0.9184 time: 0.07s
Test loss: 0.0434 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.3350 score: 0.9184 time: 0.07s
Test loss: 0.0415 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.12s
Val loss: 0.3372 score: 0.9184 time: 0.07s
Test loss: 0.0398 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.12s
Val loss: 0.3398 score: 0.9184 time: 0.07s
Test loss: 0.0384 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.11s
Val loss: 0.3424 score: 0.9184 time: 0.07s
Test loss: 0.0373 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.3442 score: 0.9184 time: 0.07s
Test loss: 0.0360 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.11s
Val loss: 0.3445 score: 0.9184 time: 0.07s
Test loss: 0.0344 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.3456 score: 0.9184 time: 0.07s
Test loss: 0.0331 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 094,   Train_Loss: 0.0086,   Val_Loss: 0.3208,   Val_Precision: 1.0000,   Val_Recall: 0.8400,   Val_accuracy: 0.9130,   Val_Score: 0.9184,   Val_Loss: 0.3208,   Test_Precision: 1.0000,   Test_Recall: 0.9583,   Test_accuracy: 0.9787,   Test_Score: 0.9796,   Test_loss: 0.1032


[0.07893816498108208, 0.07403193099889904, 0.07486623909790069, 0.07473262900020927, 0.0751354640815407, 0.07692626502830535, 0.07579160400200635, 0.07541519799269736, 0.1975945649901405, 0.0742039909819141, 0.07432586990762502, 0.07441400503739715, 0.07459088193718344, 0.07519129395950586, 0.07367003394756466, 0.0744550060480833, 0.07869485893752426, 0.07938422402366996, 0.07889562693890184, 0.07940660393796861, 0.07592196599580348, 0.07410074002109468, 0.07500873401295394, 0.07513771404046565, 0.07437845098320395, 0.07416161010041833, 0.07468028797302395, 0.07472636306192726, 0.07486346899531782, 0.0743516490329057, 0.07491507800295949, 0.0760219469666481, 0.07529263594187796, 0.0749096650397405, 0.07559530099388212, 0.07567189098335803, 0.07615141500718892, 0.07504054391756654, 0.0761786769144237, 0.07584341696929187, 0.0760900330496952, 0.07590217504184693, 0.07647302595432848, 0.07850468496326357, 0.07672111899591982, 0.07644483796320856, 0.23223313398193568, 0.08062189596239477, 0.07558678998611867, 0.07427726907189935, 0.07604201801586896, 0.07537905604112893, 0.0754797700792551, 0.07570098200812936, 0.07607632200233638, 0.07550338108558208, 0.07597431796602905, 0.07564383395947516, 0.07604937697760761, 0.07590700802393258, 0.07639593991916627, 0.07590653200168163, 0.07603675394784659, 0.07607007899787277, 0.07651669206097722, 0.07632295007351786, 0.07618582400027663, 0.07622368296142668, 0.07661276904400438, 0.07619526993948966, 0.07649798400234431, 0.07658538699615747, 0.07657614001072943, 0.07650889607612044, 0.07675281702540815, 0.07648700603749603, 0.0766114640282467, 0.07632816606201231, 0.07741219806484878, 0.07785992801655084, 0.0769164509838447, 0.07714935601688921, 0.0759194940328598, 0.07621081301476806, 0.07607218902558088, 0.07638385996688157, 0.07640665408689529, 0.07667597301770002, 0.07620792801026255, 0.07689316500909626, 0.07770808797795326, 0.0773852450074628, 0.07728121499530971, 0.0769625490065664, 0.07713165297172964, 0.07752628694288433, 0.07719632098451257, 0.07728804706130177, 0.07732867600861937, 0.07757244096137583, 0.0763980170013383, 0.07645734096877277, 0.07666735502425581, 0.0769381410209462, 0.0770021709613502, 0.07690287195146084, 0.07644702703692019, 0.07647775497753173, 0.07677635294385254, 0.07645727193448693, 0.0769813519436866, 0.0770897869952023, 0.07744388794526458, 0.07738953200168908, 0.07671818800736219, 0.0768815919291228, 0.07662901096045971, 0.07678938203025609, 0.07686558598652482, 0.0763223230605945, 0.07662521698512137, 0.07623722602147609, 0.07681450992822647, 0.07675787701737136, 0.07600306300446391, 0.07623052597045898, 0.07685029006097466, 0.07710484904237092, 0.0769933060510084, 0.07682748197112232, 0.07651922397781163, 0.07663239794783294, 0.07689537294209003, 0.07673545507714152, 0.07704090303741395, 0.07708561304025352, 0.07697418506722897, 0.0768077940447256, 0.076781713985838, 0.07651441101916134, 0.07675541599746794, 0.07668225490488112, 0.0770800719037652, 0.07495411403942853, 0.07602147001307458, 0.07581031403969973, 0.07631239807233214, 0.07582855294458568, 0.07665363396517932, 0.07727397396229208, 0.07596707798074931, 0.0751260599354282, 0.17492842103820294, 0.07599642197601497, 0.0763886549975723, 0.0763129839906469, 0.07674711395520717, 0.07729481800924987, 0.0752035640180111, 0.07669741590507329, 0.08204839401878417, 0.08257865102495998, 0.08266659895889461, 0.0830600670306012, 0.08077708689961582, 0.23341552598867565, 0.0849187069106847, 0.07640909508336335, 0.07547529297880828, 0.08186447201296687, 0.07555372198112309, 0.07513943698722869, 0.07655897701624781, 0.07591266208328307, 0.07610401103738695, 0.07613781199324876, 0.07868057396262884, 0.07544138201046735, 0.07444567093625665, 0.07388777995947748, 0.07532382104545832, 0.07558518298901618, 0.07583800808060914, 0.07546541199553758, 0.07747730205301195, 0.0749916429631412, 0.127258519991301, 0.07987786596640944, 0.07972238992806524, 0.07954330602660775, 0.07968157809227705, 0.08231298497412354, 0.0809394660172984, 0.08043338602874428, 0.11543223995249718, 0.07635188696440309, 0.07671091996598989, 0.07688894507009536, 0.07667876791674644, 0.07799717993475497, 0.07580824405886233, 0.17499428102746606, 0.07601986196823418, 0.07585819403175265, 0.07429727294947952, 0.07497287099249661, 0.07736204599495977, 0.0755813290597871, 0.07707959797699004, 0.07615944801364094, 0.07562688295729458, 0.07528133597224951, 0.07583725498989224, 0.07646392600145191, 0.07447764498647302, 0.07436770503409207, 0.07495907600969076, 0.07480977394152433, 0.07547420205082744, 0.07564839499536902, 0.07694658997934312, 0.07555719709489495, 0.07556559005752206, 0.0813154170755297, 0.08061745902523398, 0.08045241795480251, 0.08095874695573002, 0.08353381603956223, 0.08135306206531823, 0.08061918499879539, 0.07837919006124139, 0.07837493706028908, 0.07871390494983643, 0.07891746901441365, 0.08074775303248316, 0.08112208289094269, 0.0818669319851324, 0.0799864890286699, 0.07820003805682063, 0.07828337501268834, 0.0785066430689767, 0.07974116306286305, 0.07951374305412173, 0.07983085606247187, 0.18390959699172527, 0.08112283900845796, 0.08089167007710785, 0.08152298699133098, 0.08130935905501246, 0.08206050796434283, 0.08096293697599322, 0.0817766230320558, 0.08313753094989806, 0.07991277298424393, 0.08387386391405016, 0.08894030493684113, 0.08112967608030885, 0.08020913903601468, 0.07718988205306232, 0.0785903240321204, 0.07971918198745698, 0.07912474300246686, 0.08088255499023944, 0.08008008496835828, 0.07974305097013712, 0.07981929404195398, 0.0797984020318836, 0.08043178694788367, 0.0803730629850179, 0.0801728890510276, 0.08002535300329328, 0.07408228097483516, 0.07414002204313874, 0.07399072009138763, 0.0741339250234887]
[0.0016109829587975936, 0.001510855734671409, 0.001527882430569402, 0.0015251556938818218, 0.0015333768179906265, 0.0015699237760878643, 0.0015467674286123744, 0.0015390856733203543, 0.004032542142655929, 0.0015143671628962063, 0.0015168544879107146, 0.0015186531640285132, 0.001522262896677213, 0.0015345162032552216, 0.001503470080562544, 0.0015194899193486388, 0.0016060175293372298, 0.001620086204564693, 0.0016101148354877926, 0.0016205429375095635, 0.001549427877465377, 0.0015122600004305036, 0.0015307904900602844, 0.0015334227355197072, 0.0015179275710857948, 0.0015135022469473128, 0.00152408750965355, 0.0015250278175903522, 0.001527825897863629, 0.0015173805925082795, 0.0015288791429175406, 0.001551468305441798, 0.0015365844069771012, 0.0015287686742804184, 0.0015427612447731045, 0.001544324305782817, 0.0015541105103507942, 0.0015314396717870723, 0.0015546668758045655, 0.0015478248361079972, 0.0015528578173407183, 0.0015490239804458556, 0.001560673999067928, 0.0016021364278217055, 0.0015657371223657107, 0.0015600987339430318, 0.004739451713917054, 0.001645344815559077, 0.0015425875507371158, 0.001515862634120395, 0.0015518779186912033, 0.001538348082472019, 0.0015404034710052063, 0.0015449180001659052, 0.0015525780000476812, 0.0015408853282771853, 0.0015504962850210009, 0.0015437517134586768, 0.0015520281015838288, 0.0015491226127333179, 0.0015591008146768625, 0.0015491128979935025, 0.001551770488731563, 0.0015524505917933217, 0.001561565144101576, 0.0015576112259901604, 0.001554812734699523, 0.001555585366559728, 0.0015635258988572322, 0.0015550055089691768, 0.0015611833469866185, 0.001562967081554234, 0.0015627783675659069, 0.001561406042369805, 0.0015663840209266969, 0.0015609593068876741, 0.0015634992658825858, 0.0015577176747349451, 0.0015798407768336485, 0.001588978122786752, 0.0015697234894662183, 0.0015744766534059023, 0.0015493774292420369, 0.0015553227145871033, 0.0015524936535832833, 0.0015588542850383995, 0.0015593194711611283, 0.001564815775871429, 0.0015552638369441337, 0.0015692482654917606, 0.0015858793464888418, 0.0015792907144380162, 0.0015771676529655043, 0.0015706642654401306, 0.0015741153667699925, 0.0015821691212833536, 0.0015754351221329095, 0.0015773070828837095, 0.0015781362450738646, 0.0015831110400280782, 0.001559143204108945, 0.0015603538973218932, 0.0015646398984542002, 0.0015701661432846164, 0.001571472876762249, 0.0015694463663563436, 0.0015601434089167385, 0.0015607705097455456, 0.0015668643457929091, 0.0015603524884589169, 0.001571047998850747, 0.0015732609590857613, 0.0015804875090870323, 0.0015793782041161036, 0.0015656773062726977, 0.0015690120801861798, 0.001563857366539994, 0.0015671302455154304, 0.0015686854282964248, 0.001557598429808051, 0.0015637799384718646, 0.0015558617555403284, 0.001567643059759724, 0.0015664872860688033, 0.0015510829184584472, 0.0015557250198052854, 0.0015683732665505033, 0.001573568347803488, 0.0015712919602246613, 0.001567907795329027, 0.0015616168158737067, 0.0015639264887312846, 0.0015692933253487762, 0.0015660296954518678, 0.0015722633272941624, 0.0015731757763317044, 0.0015709017360658975, 0.0015675060009127672, 0.0015669737548130204, 0.0015615185922277825, 0.001566437061172815, 0.001564943977650635, 0.0015730626919135756, 0.0015296757967230312, 0.0015514585716953995, 0.001547149266116321, 0.0015573958790271866, 0.0015475214886650139, 0.0015643598768403943, 0.001577019876781471, 0.0015503485302193736, 0.001533184896641392, 0.003569967776289856, 0.0015509473872656117, 0.001558952142807598, 0.0015574078365438143, 0.001566267631738922, 0.0015774452654948952, 0.0015347666126124713, 0.001565253385817822, 0.0016744570207915135, 0.0016852785923461221, 0.0016870734481407063, 0.0016951034087877796, 0.0016485119775431802, 0.004763582163034197, 0.0017330348349119328, 0.0015593692874155787, 0.0015403121016083323, 0.0016707035104687117, 0.001541912693492308, 0.0015334578976985446, 0.0015624281023724042, 0.0015492380016996544, 0.001553143082395652, 0.0015538328978214034, 0.0016057259992373232, 0.001539620041029946, 0.0015192994068623806, 0.0015079138767240302, 0.0015372208376624146, 0.0015425547548778811, 0.0015477144506246764, 0.001540110448888522, 0.0015811694296533052, 0.0015304416931253306, 0.0025971126528836937, 0.0016301605299267235, 0.0016269875495523519, 0.0016233327760532194, 0.0016261546549444295, 0.0016798568362066028, 0.0016518258370877225, 0.0016414976740560057, 0.0023557599990305547, 0.0015582017747837367, 0.0015655289788977528, 0.0015691621442876604, 0.0015648728146274782, 0.0015917791823419382, 0.0015471070216094352, 0.003571311857703389, 0.0015514257544537587, 0.0015481264088112786, 0.0015162708765199902, 0.0015300585916836042, 0.0015788172652032605, 0.001542476103260961, 0.0015730530199385723, 0.0015542744492579783, 0.001543405774638665, 0.0015363537953520308, 0.0015476990814263724, 0.0015604882857439164, 0.0015199519384994494, 0.001517708266001879, 0.0015297770614222605, 0.001526730080439272, 0.0015402898377719887, 0.0015438447958238575, 0.0015703385710070024, 0.0015419836141815294, 0.0015421548991331033, 0.0016594983076638713, 0.0016452542658211017, 0.0016418860807102553, 0.0016522193256271432, 0.0017047717559094332, 0.0016602665727615965, 0.0016452894897713345, 0.0015995753073722732, 0.0015994885114344712, 0.0016064062234660496, 0.001610560592130891, 0.001647913327193534, 0.001655552712060055, 0.0016707537139822937, 0.001632377327115712, 0.0015959191440167476, 0.0015976198982181294, 0.0016021763891627897, 0.0016273706747523071, 0.001622729450084117, 0.001629201144132079, 0.003753257081463781, 0.0016555681430297543, 0.0016508504097368947, 0.0016637344283945098, 0.001659374674592091, 0.0016747042441702619, 0.0016523048362447595, 0.0016689106741235877, 0.0016966843050999604, 0.0016308729180457946, 0.0017117115084500033, 0.001815108264017166, 0.001655707675108344, 0.001636921204816626, 0.0015753037153686188, 0.0016038841639208247, 0.001626922081376673, 0.0016147906735197318, 0.001650664387555907, 0.0016342874483338424, 0.0016274092034721862, 0.001628965184529673, 0.0016285388169772163, 0.001641465039752728, 0.0016402665915309774, 0.0016361814092046448, 0.001633170469454965, 0.0015118832852007175, 0.0015130616743497703, 0.0015100146957426046, 0.0015129372453773205]
[620.7390305024584, 661.8765624353186, 654.5006212469674, 655.670764638332, 652.1554182033506, 636.9736003947447, 646.5096054531697, 649.7364099573774, 247.98252928892546, 660.3418408039922, 659.2590179018293, 658.4781987661435, 656.9167534614385, 651.671189837335, 665.1279682438617, 658.1155868600108, 622.6582099715184, 617.2511050229539, 621.0737134764955, 617.0771393054179, 645.399514584599, 661.2619521215428, 653.2572592351412, 652.1358897558541, 658.7929615671227, 660.7192040956458, 656.1303033231447, 655.7257437966398, 654.5248391183236, 659.0304403109358, 654.0739368657438, 644.5507114083383, 650.7940569091708, 654.1212001682946, 648.1884370559691, 647.5323843932514, 643.454885183345, 652.9803415847763, 643.2246133001861, 646.0679378388179, 643.9739613202374, 645.5677979318111, 640.7488050657754, 624.166570733067, 638.6768159964653, 640.9850724463929, 210.99487036940852, 607.775337147312, 648.2614225183888, 659.6903818928599, 644.3805842945193, 650.0479386908775, 649.1805678335948, 647.2835450765751, 644.0900231545784, 648.9775596202659, 644.9547861937995, 647.77256036825, 644.3182304363628, 645.5266947756771, 641.3953418446894, 645.530742978937, 644.4251951314094, 644.1428830561651, 640.3831462153541, 642.0087267696138, 643.1642716080893, 642.8448232394735, 639.5800675453419, 643.0845384354338, 640.5397559038729, 639.8087405689872, 639.8860009545322, 640.4483989842016, 638.4130498269412, 640.6316907734479, 639.5909622864492, 641.9648542346775, 632.9751799445396, 629.3352851493, 637.0548741294865, 635.1316787307094, 645.4205289986734, 642.9533823567112, 644.1250163515435, 641.4967772150474, 641.3054018079837, 639.0528619531017, 642.9777226511317, 637.2477969167146, 630.5649936194789, 633.1956433719967, 634.0480025187734, 636.6732993188589, 635.2774524093179, 632.0436839197471, 634.7452750997107, 633.9919542945, 633.6588511425989, 631.6676308329351, 641.3779038157711, 640.8802526890507, 639.1246963521503, 636.8752786301385, 636.3456950401389, 637.1673613298548, 640.9667177290673, 640.7091841855926, 638.2173432467453, 640.8808313483389, 636.5177898648036, 635.6224593414628, 632.7161677966374, 633.1605674903234, 638.7012163960098, 637.3437226062272, 639.444505231626, 638.1090549822801, 637.4764385272508, 642.0140010819309, 639.4761663058589, 642.7306259306531, 637.9003139613122, 638.3709647012597, 644.7108585231896, 642.7871167908323, 637.6033188830173, 635.498293668578, 636.4189630659228, 637.7926067968486, 640.3619568098153, 639.4162431581022, 637.2294993211352, 638.5574953682193, 636.0257742072904, 635.6568763929084, 636.5770544657742, 637.9560903867, 638.1727817255786, 640.4022372691209, 638.3914328809898, 639.0005101021222, 635.7025725297286, 653.7332957364322, 644.5547552760124, 646.3500464374818, 642.0974997215486, 646.1945810281838, 639.2391001613667, 634.107416604598, 645.0162531250314, 652.2370538547625, 280.1145732019087, 644.767197269692, 641.456509498135, 642.0925698044458, 638.4604902354823, 633.9364172399781, 651.5648645091422, 638.8741970217906, 597.2085204834349, 593.3737036366628, 592.7424209669604, 589.9345106710219, 606.6076641374034, 209.92605265845629, 577.0224463207728, 641.2849144010977, 649.2190764169417, 598.550247685451, 648.5451505915556, 652.1209362844766, 640.0294506234184, 645.478615230784, 643.8556829275161, 643.5698467976056, 622.7712576585128, 649.5109009694619, 658.1981112367938, 663.1678476044784, 650.5246191696548, 648.2752050374812, 646.1140164430124, 649.3040812246207, 632.4432924429009, 653.4061405226681, 385.04298182431705, 613.4365184543823, 614.6328533830141, 616.0166385793568, 614.9476600884391, 595.288823694147, 605.3907001255445, 609.1997666552169, 424.4914594065275, 641.7654094501274, 638.7617306861182, 637.2827713441696, 639.029568826686, 628.2278415833591, 646.3676953386929, 280.0091506550963, 644.5683895147723, 645.942084773197, 659.5127661457898, 653.5697426460298, 633.3855234799814, 648.3082609097748, 635.706481170641, 643.387016030153, 647.9177520468429, 650.8917431813719, 646.1204325833105, 640.8250604222125, 657.9155397421549, 658.8881555177363, 653.690021388007, 654.9946272836121, 649.2284604347507, 647.7335044980088, 636.8053478803208, 648.5153219548255, 648.4432922802589, 602.591756425309, 607.8087872338244, 609.055653585549, 605.2465217476038, 586.5887891053994, 602.312915531784, 607.7957746748762, 625.1659396035346, 625.1998641135402, 622.5075484595409, 620.9018182153122, 606.828031243028, 604.0278830842356, 598.5322621946885, 612.6034608474529, 626.5981605328158, 625.9311123473915, 624.1510028259407, 614.4881528925205, 616.2456717280648, 613.7977521079682, 266.43525298032534, 604.0222531522992, 605.7484034300694, 601.0574662237361, 602.6366530185962, 597.1203592998914, 605.215198832637, 599.1932435360211, 589.3848354665395, 613.1685607964215, 584.2105956894129, 550.9313244967644, 603.9713501567016, 610.9029543129559, 634.7982235070152, 623.4864228320698, 614.6575865230236, 619.2753131403199, 605.816668451103, 611.8874626489367, 614.4736049583801, 613.8866622178468, 614.0473838112944, 609.2118782807834, 609.6569942734911, 611.1791726603865, 612.3059525646017, 661.4267184435736, 660.9115920074735, 662.2452104734077, 660.9659475668498]
Elapsed: 0.08020166731058535~0.018718348310696332
Time per graph: 0.001636768720624191~0.00038200710838155787
Speed: 625.0671474886435~62.307110468932635
Total Time: 0.0751
best val loss: 0.32075750827789307 test_score: 0.9796

Testing...
Test loss: 0.1306 score: 0.9796 time: 0.07s
test Score 0.9796
Epoch Time List: [0.25548477401025593, 0.3494161950657144, 0.2411726809805259, 0.24112801009323448, 0.2429196499288082, 0.24673061398789287, 0.24831568519584835, 0.24407313391566277, 0.36780757002998143, 0.24130217300262302, 0.24199698015581816, 0.24269700306467712, 0.24280981009360403, 0.2488495911238715, 0.2417602970963344, 0.24031610798556358, 0.38509826303925365, 0.2527664400404319, 0.2537275879876688, 0.25494986993726343, 0.2520710799144581, 0.24313935299869627, 0.23940398183185607, 0.3289638600545004, 0.24097133905161172, 0.2385966150322929, 0.24002682301215827, 0.2467922680079937, 0.2462941890116781, 0.2425900740781799, 0.241078382008709, 0.30186566011980176, 0.24304277694318444, 0.2429790268652141, 0.24585287005174905, 0.24558660294860601, 0.24964161089155823, 0.24511994584463537, 0.24380555213429034, 0.3746585400076583, 0.24499999394174665, 0.2451915011042729, 0.24634094606153667, 0.24720933905337006, 0.25308188097551465, 0.24690508504863828, 0.4025066838366911, 0.2536544568138197, 0.24849699984770268, 0.2406896719476208, 0.24601358082145452, 0.2498727791244164, 0.24748146103229374, 0.24656253005377948, 0.24743031291291118, 0.24718802201095968, 0.2467696830863133, 0.24679096799809486, 0.24732032092288136, 0.24461416120175272, 0.24493671394884586, 0.24591115687508136, 0.24726638500578701, 0.24699281889479607, 0.24716904805973172, 0.2469851749483496, 0.24839956196956336, 0.2465850559528917, 0.2460406409809366, 0.24591257888823748, 0.24647960299625993, 0.24828217003960162, 0.2465324611403048, 0.2476383929606527, 0.24965017789509147, 0.2486682808957994, 0.249403360998258, 0.2493203921476379, 0.25065526901744306, 0.25056909408885986, 0.2509932171087712, 0.251838814932853, 0.2482374939136207, 0.2480910299345851, 0.24884032981935889, 0.24875075893942267, 0.2478486900217831, 0.24837085709441453, 0.24921688996255398, 0.25228985119611025, 0.2532021610531956, 0.2509544799104333, 0.25140457006637007, 0.25173505197744817, 0.24964242801070213, 0.25071428425144404, 0.2511280319886282, 0.25184072996489704, 0.25217435194645077, 0.25191262690350413, 0.24871931900270283, 0.2473246098961681, 0.24847193202003837, 0.2483171639032662, 0.24898426025174558, 0.24998478102497756, 0.248587831039913, 0.24976177199278027, 0.25038197496905923, 0.2492449899436906, 0.24947091890498996, 0.2527983139734715, 0.25260171794798225, 0.25391052407212555, 0.25103009096346796, 0.25215579802170396, 0.25194272911176085, 0.2510538150090724, 0.25199120305478573, 0.24846289888955653, 0.25039327901322395, 0.25028821488376707, 0.25116473506204784, 0.2510213280329481, 0.25025139399804175, 0.2499516699463129, 0.250913891941309, 0.25156735198106617, 0.251678912085481, 0.2510161300888285, 0.2501432579010725, 0.2505947971949354, 0.2500466980272904, 0.24941778101492673, 0.2503620338393375, 0.24994455510750413, 0.24986577103845775, 0.2501135270576924, 0.25169499695766717, 0.24886978894937783, 0.24969299288932234, 0.2491156451869756, 0.25127372390124947, 0.245438412996009, 0.24465963197872043, 0.35158834396861494, 0.24774616386275738, 0.24764447892084718, 0.24880983086768538, 0.25157734495587647, 0.24970852595288306, 0.24385594099294394, 0.351532629923895, 0.24686982296407223, 0.24614832003135234, 0.24759719078429043, 0.24928584997542202, 0.25133160897530615, 0.24816489312797785, 0.24477547802962363, 0.26978611398953944, 0.27185937901958823, 0.2732125459006056, 0.2757919149007648, 0.26905846293084323, 0.4175381548702717, 0.28862210491206497, 0.2711036920081824, 0.24954102898482233, 0.25523453194182366, 0.2526243559550494, 0.24961129995062947, 0.38119901716709137, 0.25217569211963564, 0.25383290788158774, 0.2532345241634175, 0.257468338124454, 0.2560609879437834, 0.24937367404345423, 0.3270660890266299, 0.24964130390435457, 0.2523066479479894, 0.2516874320572242, 0.25297253392636776, 0.26051077409647405, 0.2541294420370832, 0.30454089085105807, 0.2786464629461989, 0.2640776069601998, 0.2641084201168269, 0.265237329993397, 0.26751545688603073, 0.2720414139330387, 0.267438237904571, 0.3279629598837346, 0.25660487706772983, 0.25718514481559396, 0.2567959448788315, 0.2578309749951586, 0.26248878391925246, 0.257028469000943, 0.3529351931065321, 0.25304819212760776, 0.25300738599617034, 0.2523679961450398, 0.2497326349839568, 0.2552434030221775, 0.2573341669049114, 0.2521084559848532, 0.308852621819824, 0.2533476040698588, 0.2509131159167737, 0.25423240603413433, 0.25458940805401653, 0.2536910299677402, 0.24773270904552191, 0.35501582198776305, 0.2500645039835945, 0.37803569284733385, 0.25319667800795287, 0.2563025200506672, 0.256185520789586, 0.253507170942612, 0.3326055780053139, 0.2666076871100813, 0.26453050202690065, 0.26650840998627245, 0.26724439195822924, 0.2697874139994383, 0.2649229180533439, 0.35369601706042886, 0.25829905993305147, 0.2584998479578644, 0.2600168319186196, 0.2619676520116627, 0.27741959097329527, 0.26564510993193835, 0.34975450194906443, 0.2604460100410506, 0.2576210378902033, 0.2581615939270705, 0.25996990397106856, 0.2675767819164321, 0.26276217692065984, 0.36889360088389367, 0.26522699801716954, 0.26479901815764606, 0.26626948500052094, 0.2668193830177188, 0.26956640905700624, 0.2662651940481737, 0.2621889179572463, 0.3985128211788833, 0.2678258978994563, 0.2714901629369706, 0.28604796587023884, 0.2658861849922687, 0.2633303049951792, 0.37416411796584725, 0.25612452800851315, 0.2596034179441631, 0.26077125302981585, 0.26380635204259306, 0.2623038109159097, 0.26270650199148804, 0.2632200779626146, 0.26172162499278784, 0.2650399530539289, 0.2650875170947984, 0.26481077598873526, 0.2641087560914457, 0.2498637258540839, 0.24638427002355456, 0.24614360206760466, 0.24546081596054137]
Total Epoch List: [160, 115]
Total Time List: [0.0773575030034408, 0.0750872140051797]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x752e437edfc0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6956 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.06s
Epoch 2/1000, LR 0.000000
Train loss: 0.6951;  Loss pred: 0.6951; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6944;  Loss pred: 0.6944; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6905;  Loss pred: 0.6905; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6872;  Loss pred: 0.6872; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6872;  Loss pred: 0.6872; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6833;  Loss pred: 0.6833; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6809;  Loss pred: 0.6809; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6781;  Loss pred: 0.6781; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6742;  Loss pred: 0.6742; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6703;  Loss pred: 0.6703; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6965 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6662;  Loss pred: 0.6662; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6629;  Loss pred: 0.6629; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6971 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6561;  Loss pred: 0.6561; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6974 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6512;  Loss pred: 0.6512; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6978 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6470;  Loss pred: 0.6470; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6983 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6433;  Loss pred: 0.6433; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6989 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6341;  Loss pred: 0.6341; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6996 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6303;  Loss pred: 0.6303; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7004 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6949,   Val_Loss: 0.6956,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.4898,   Val_Loss: 0.6956,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.5000,   Test_loss: 0.6945


[0.07893816498108208, 0.07403193099889904, 0.07486623909790069, 0.07473262900020927, 0.0751354640815407, 0.07692626502830535, 0.07579160400200635, 0.07541519799269736, 0.1975945649901405, 0.0742039909819141, 0.07432586990762502, 0.07441400503739715, 0.07459088193718344, 0.07519129395950586, 0.07367003394756466, 0.0744550060480833, 0.07869485893752426, 0.07938422402366996, 0.07889562693890184, 0.07940660393796861, 0.07592196599580348, 0.07410074002109468, 0.07500873401295394, 0.07513771404046565, 0.07437845098320395, 0.07416161010041833, 0.07468028797302395, 0.07472636306192726, 0.07486346899531782, 0.0743516490329057, 0.07491507800295949, 0.0760219469666481, 0.07529263594187796, 0.0749096650397405, 0.07559530099388212, 0.07567189098335803, 0.07615141500718892, 0.07504054391756654, 0.0761786769144237, 0.07584341696929187, 0.0760900330496952, 0.07590217504184693, 0.07647302595432848, 0.07850468496326357, 0.07672111899591982, 0.07644483796320856, 0.23223313398193568, 0.08062189596239477, 0.07558678998611867, 0.07427726907189935, 0.07604201801586896, 0.07537905604112893, 0.0754797700792551, 0.07570098200812936, 0.07607632200233638, 0.07550338108558208, 0.07597431796602905, 0.07564383395947516, 0.07604937697760761, 0.07590700802393258, 0.07639593991916627, 0.07590653200168163, 0.07603675394784659, 0.07607007899787277, 0.07651669206097722, 0.07632295007351786, 0.07618582400027663, 0.07622368296142668, 0.07661276904400438, 0.07619526993948966, 0.07649798400234431, 0.07658538699615747, 0.07657614001072943, 0.07650889607612044, 0.07675281702540815, 0.07648700603749603, 0.0766114640282467, 0.07632816606201231, 0.07741219806484878, 0.07785992801655084, 0.0769164509838447, 0.07714935601688921, 0.0759194940328598, 0.07621081301476806, 0.07607218902558088, 0.07638385996688157, 0.07640665408689529, 0.07667597301770002, 0.07620792801026255, 0.07689316500909626, 0.07770808797795326, 0.0773852450074628, 0.07728121499530971, 0.0769625490065664, 0.07713165297172964, 0.07752628694288433, 0.07719632098451257, 0.07728804706130177, 0.07732867600861937, 0.07757244096137583, 0.0763980170013383, 0.07645734096877277, 0.07666735502425581, 0.0769381410209462, 0.0770021709613502, 0.07690287195146084, 0.07644702703692019, 0.07647775497753173, 0.07677635294385254, 0.07645727193448693, 0.0769813519436866, 0.0770897869952023, 0.07744388794526458, 0.07738953200168908, 0.07671818800736219, 0.0768815919291228, 0.07662901096045971, 0.07678938203025609, 0.07686558598652482, 0.0763223230605945, 0.07662521698512137, 0.07623722602147609, 0.07681450992822647, 0.07675787701737136, 0.07600306300446391, 0.07623052597045898, 0.07685029006097466, 0.07710484904237092, 0.0769933060510084, 0.07682748197112232, 0.07651922397781163, 0.07663239794783294, 0.07689537294209003, 0.07673545507714152, 0.07704090303741395, 0.07708561304025352, 0.07697418506722897, 0.0768077940447256, 0.076781713985838, 0.07651441101916134, 0.07675541599746794, 0.07668225490488112, 0.0770800719037652, 0.07495411403942853, 0.07602147001307458, 0.07581031403969973, 0.07631239807233214, 0.07582855294458568, 0.07665363396517932, 0.07727397396229208, 0.07596707798074931, 0.0751260599354282, 0.17492842103820294, 0.07599642197601497, 0.0763886549975723, 0.0763129839906469, 0.07674711395520717, 0.07729481800924987, 0.0752035640180111, 0.07669741590507329, 0.08204839401878417, 0.08257865102495998, 0.08266659895889461, 0.0830600670306012, 0.08077708689961582, 0.23341552598867565, 0.0849187069106847, 0.07640909508336335, 0.07547529297880828, 0.08186447201296687, 0.07555372198112309, 0.07513943698722869, 0.07655897701624781, 0.07591266208328307, 0.07610401103738695, 0.07613781199324876, 0.07868057396262884, 0.07544138201046735, 0.07444567093625665, 0.07388777995947748, 0.07532382104545832, 0.07558518298901618, 0.07583800808060914, 0.07546541199553758, 0.07747730205301195, 0.0749916429631412, 0.127258519991301, 0.07987786596640944, 0.07972238992806524, 0.07954330602660775, 0.07968157809227705, 0.08231298497412354, 0.0809394660172984, 0.08043338602874428, 0.11543223995249718, 0.07635188696440309, 0.07671091996598989, 0.07688894507009536, 0.07667876791674644, 0.07799717993475497, 0.07580824405886233, 0.17499428102746606, 0.07601986196823418, 0.07585819403175265, 0.07429727294947952, 0.07497287099249661, 0.07736204599495977, 0.0755813290597871, 0.07707959797699004, 0.07615944801364094, 0.07562688295729458, 0.07528133597224951, 0.07583725498989224, 0.07646392600145191, 0.07447764498647302, 0.07436770503409207, 0.07495907600969076, 0.07480977394152433, 0.07547420205082744, 0.07564839499536902, 0.07694658997934312, 0.07555719709489495, 0.07556559005752206, 0.0813154170755297, 0.08061745902523398, 0.08045241795480251, 0.08095874695573002, 0.08353381603956223, 0.08135306206531823, 0.08061918499879539, 0.07837919006124139, 0.07837493706028908, 0.07871390494983643, 0.07891746901441365, 0.08074775303248316, 0.08112208289094269, 0.0818669319851324, 0.0799864890286699, 0.07820003805682063, 0.07828337501268834, 0.0785066430689767, 0.07974116306286305, 0.07951374305412173, 0.07983085606247187, 0.18390959699172527, 0.08112283900845796, 0.08089167007710785, 0.08152298699133098, 0.08130935905501246, 0.08206050796434283, 0.08096293697599322, 0.0817766230320558, 0.08313753094989806, 0.07991277298424393, 0.08387386391405016, 0.08894030493684113, 0.08112967608030885, 0.08020913903601468, 0.07718988205306232, 0.0785903240321204, 0.07971918198745698, 0.07912474300246686, 0.08088255499023944, 0.08008008496835828, 0.07974305097013712, 0.07981929404195398, 0.0797984020318836, 0.08043178694788367, 0.0803730629850179, 0.0801728890510276, 0.08002535300329328, 0.07408228097483516, 0.07414002204313874, 0.07399072009138763, 0.0741339250234887, 0.06847293209284544, 0.06822061503771693, 0.06804239598568529, 0.06814138300251216, 0.06783787603490055, 0.06827381101902574, 0.06827883596997708, 0.06833063391968608, 0.06814801797736436, 0.06841067993082106, 0.0681007020175457, 0.06826173502486199, 0.06830913200974464, 0.06829601700883359, 0.06844294094480574, 0.06816889496985823, 0.06814793008379638, 0.06829731003381312, 0.06989576597698033, 0.07002003001980484, 0.06996629992499948]
[0.0016109829587975936, 0.001510855734671409, 0.001527882430569402, 0.0015251556938818218, 0.0015333768179906265, 0.0015699237760878643, 0.0015467674286123744, 0.0015390856733203543, 0.004032542142655929, 0.0015143671628962063, 0.0015168544879107146, 0.0015186531640285132, 0.001522262896677213, 0.0015345162032552216, 0.001503470080562544, 0.0015194899193486388, 0.0016060175293372298, 0.001620086204564693, 0.0016101148354877926, 0.0016205429375095635, 0.001549427877465377, 0.0015122600004305036, 0.0015307904900602844, 0.0015334227355197072, 0.0015179275710857948, 0.0015135022469473128, 0.00152408750965355, 0.0015250278175903522, 0.001527825897863629, 0.0015173805925082795, 0.0015288791429175406, 0.001551468305441798, 0.0015365844069771012, 0.0015287686742804184, 0.0015427612447731045, 0.001544324305782817, 0.0015541105103507942, 0.0015314396717870723, 0.0015546668758045655, 0.0015478248361079972, 0.0015528578173407183, 0.0015490239804458556, 0.001560673999067928, 0.0016021364278217055, 0.0015657371223657107, 0.0015600987339430318, 0.004739451713917054, 0.001645344815559077, 0.0015425875507371158, 0.001515862634120395, 0.0015518779186912033, 0.001538348082472019, 0.0015404034710052063, 0.0015449180001659052, 0.0015525780000476812, 0.0015408853282771853, 0.0015504962850210009, 0.0015437517134586768, 0.0015520281015838288, 0.0015491226127333179, 0.0015591008146768625, 0.0015491128979935025, 0.001551770488731563, 0.0015524505917933217, 0.001561565144101576, 0.0015576112259901604, 0.001554812734699523, 0.001555585366559728, 0.0015635258988572322, 0.0015550055089691768, 0.0015611833469866185, 0.001562967081554234, 0.0015627783675659069, 0.001561406042369805, 0.0015663840209266969, 0.0015609593068876741, 0.0015634992658825858, 0.0015577176747349451, 0.0015798407768336485, 0.001588978122786752, 0.0015697234894662183, 0.0015744766534059023, 0.0015493774292420369, 0.0015553227145871033, 0.0015524936535832833, 0.0015588542850383995, 0.0015593194711611283, 0.001564815775871429, 0.0015552638369441337, 0.0015692482654917606, 0.0015858793464888418, 0.0015792907144380162, 0.0015771676529655043, 0.0015706642654401306, 0.0015741153667699925, 0.0015821691212833536, 0.0015754351221329095, 0.0015773070828837095, 0.0015781362450738646, 0.0015831110400280782, 0.001559143204108945, 0.0015603538973218932, 0.0015646398984542002, 0.0015701661432846164, 0.001571472876762249, 0.0015694463663563436, 0.0015601434089167385, 0.0015607705097455456, 0.0015668643457929091, 0.0015603524884589169, 0.001571047998850747, 0.0015732609590857613, 0.0015804875090870323, 0.0015793782041161036, 0.0015656773062726977, 0.0015690120801861798, 0.001563857366539994, 0.0015671302455154304, 0.0015686854282964248, 0.001557598429808051, 0.0015637799384718646, 0.0015558617555403284, 0.001567643059759724, 0.0015664872860688033, 0.0015510829184584472, 0.0015557250198052854, 0.0015683732665505033, 0.001573568347803488, 0.0015712919602246613, 0.001567907795329027, 0.0015616168158737067, 0.0015639264887312846, 0.0015692933253487762, 0.0015660296954518678, 0.0015722633272941624, 0.0015731757763317044, 0.0015709017360658975, 0.0015675060009127672, 0.0015669737548130204, 0.0015615185922277825, 0.001566437061172815, 0.001564943977650635, 0.0015730626919135756, 0.0015296757967230312, 0.0015514585716953995, 0.001547149266116321, 0.0015573958790271866, 0.0015475214886650139, 0.0015643598768403943, 0.001577019876781471, 0.0015503485302193736, 0.001533184896641392, 0.003569967776289856, 0.0015509473872656117, 0.001558952142807598, 0.0015574078365438143, 0.001566267631738922, 0.0015774452654948952, 0.0015347666126124713, 0.001565253385817822, 0.0016744570207915135, 0.0016852785923461221, 0.0016870734481407063, 0.0016951034087877796, 0.0016485119775431802, 0.004763582163034197, 0.0017330348349119328, 0.0015593692874155787, 0.0015403121016083323, 0.0016707035104687117, 0.001541912693492308, 0.0015334578976985446, 0.0015624281023724042, 0.0015492380016996544, 0.001553143082395652, 0.0015538328978214034, 0.0016057259992373232, 0.001539620041029946, 0.0015192994068623806, 0.0015079138767240302, 0.0015372208376624146, 0.0015425547548778811, 0.0015477144506246764, 0.001540110448888522, 0.0015811694296533052, 0.0015304416931253306, 0.0025971126528836937, 0.0016301605299267235, 0.0016269875495523519, 0.0016233327760532194, 0.0016261546549444295, 0.0016798568362066028, 0.0016518258370877225, 0.0016414976740560057, 0.0023557599990305547, 0.0015582017747837367, 0.0015655289788977528, 0.0015691621442876604, 0.0015648728146274782, 0.0015917791823419382, 0.0015471070216094352, 0.003571311857703389, 0.0015514257544537587, 0.0015481264088112786, 0.0015162708765199902, 0.0015300585916836042, 0.0015788172652032605, 0.001542476103260961, 0.0015730530199385723, 0.0015542744492579783, 0.001543405774638665, 0.0015363537953520308, 0.0015476990814263724, 0.0015604882857439164, 0.0015199519384994494, 0.001517708266001879, 0.0015297770614222605, 0.001526730080439272, 0.0015402898377719887, 0.0015438447958238575, 0.0015703385710070024, 0.0015419836141815294, 0.0015421548991331033, 0.0016594983076638713, 0.0016452542658211017, 0.0016418860807102553, 0.0016522193256271432, 0.0017047717559094332, 0.0016602665727615965, 0.0016452894897713345, 0.0015995753073722732, 0.0015994885114344712, 0.0016064062234660496, 0.001610560592130891, 0.001647913327193534, 0.001655552712060055, 0.0016707537139822937, 0.001632377327115712, 0.0015959191440167476, 0.0015976198982181294, 0.0016021763891627897, 0.0016273706747523071, 0.001622729450084117, 0.001629201144132079, 0.003753257081463781, 0.0016555681430297543, 0.0016508504097368947, 0.0016637344283945098, 0.001659374674592091, 0.0016747042441702619, 0.0016523048362447595, 0.0016689106741235877, 0.0016966843050999604, 0.0016308729180457946, 0.0017117115084500033, 0.001815108264017166, 0.001655707675108344, 0.001636921204816626, 0.0015753037153686188, 0.0016038841639208247, 0.001626922081376673, 0.0016147906735197318, 0.001650664387555907, 0.0016342874483338424, 0.0016274092034721862, 0.001628965184529673, 0.0016285388169772163, 0.001641465039752728, 0.0016402665915309774, 0.0016361814092046448, 0.001633170469454965, 0.0015118832852007175, 0.0015130616743497703, 0.0015100146957426046, 0.0015129372453773205, 0.0014265194186009467, 0.0014212628132857692, 0.0014175499163684435, 0.0014196121458856699, 0.001413289084060428, 0.0014223710628963697, 0.0014224757493745226, 0.0014235548733267933, 0.0014197503745284241, 0.001425222498558772, 0.0014187646253655355, 0.0014221194796846248, 0.0014231069168696802, 0.001422833687684033, 0.0014258946030167863, 0.0014201853118720464, 0.0014197485434124246, 0.00142286062570444, 0.00145616179118709, 0.0014587506254126008, 0.0014576312484374891]
[620.7390305024584, 661.8765624353186, 654.5006212469674, 655.670764638332, 652.1554182033506, 636.9736003947447, 646.5096054531697, 649.7364099573774, 247.98252928892546, 660.3418408039922, 659.2590179018293, 658.4781987661435, 656.9167534614385, 651.671189837335, 665.1279682438617, 658.1155868600108, 622.6582099715184, 617.2511050229539, 621.0737134764955, 617.0771393054179, 645.399514584599, 661.2619521215428, 653.2572592351412, 652.1358897558541, 658.7929615671227, 660.7192040956458, 656.1303033231447, 655.7257437966398, 654.5248391183236, 659.0304403109358, 654.0739368657438, 644.5507114083383, 650.7940569091708, 654.1212001682946, 648.1884370559691, 647.5323843932514, 643.454885183345, 652.9803415847763, 643.2246133001861, 646.0679378388179, 643.9739613202374, 645.5677979318111, 640.7488050657754, 624.166570733067, 638.6768159964653, 640.9850724463929, 210.99487036940852, 607.775337147312, 648.2614225183888, 659.6903818928599, 644.3805842945193, 650.0479386908775, 649.1805678335948, 647.2835450765751, 644.0900231545784, 648.9775596202659, 644.9547861937995, 647.77256036825, 644.3182304363628, 645.5266947756771, 641.3953418446894, 645.530742978937, 644.4251951314094, 644.1428830561651, 640.3831462153541, 642.0087267696138, 643.1642716080893, 642.8448232394735, 639.5800675453419, 643.0845384354338, 640.5397559038729, 639.8087405689872, 639.8860009545322, 640.4483989842016, 638.4130498269412, 640.6316907734479, 639.5909622864492, 641.9648542346775, 632.9751799445396, 629.3352851493, 637.0548741294865, 635.1316787307094, 645.4205289986734, 642.9533823567112, 644.1250163515435, 641.4967772150474, 641.3054018079837, 639.0528619531017, 642.9777226511317, 637.2477969167146, 630.5649936194789, 633.1956433719967, 634.0480025187734, 636.6732993188589, 635.2774524093179, 632.0436839197471, 634.7452750997107, 633.9919542945, 633.6588511425989, 631.6676308329351, 641.3779038157711, 640.8802526890507, 639.1246963521503, 636.8752786301385, 636.3456950401389, 637.1673613298548, 640.9667177290673, 640.7091841855926, 638.2173432467453, 640.8808313483389, 636.5177898648036, 635.6224593414628, 632.7161677966374, 633.1605674903234, 638.7012163960098, 637.3437226062272, 639.444505231626, 638.1090549822801, 637.4764385272508, 642.0140010819309, 639.4761663058589, 642.7306259306531, 637.9003139613122, 638.3709647012597, 644.7108585231896, 642.7871167908323, 637.6033188830173, 635.498293668578, 636.4189630659228, 637.7926067968486, 640.3619568098153, 639.4162431581022, 637.2294993211352, 638.5574953682193, 636.0257742072904, 635.6568763929084, 636.5770544657742, 637.9560903867, 638.1727817255786, 640.4022372691209, 638.3914328809898, 639.0005101021222, 635.7025725297286, 653.7332957364322, 644.5547552760124, 646.3500464374818, 642.0974997215486, 646.1945810281838, 639.2391001613667, 634.107416604598, 645.0162531250314, 652.2370538547625, 280.1145732019087, 644.767197269692, 641.456509498135, 642.0925698044458, 638.4604902354823, 633.9364172399781, 651.5648645091422, 638.8741970217906, 597.2085204834349, 593.3737036366628, 592.7424209669604, 589.9345106710219, 606.6076641374034, 209.92605265845629, 577.0224463207728, 641.2849144010977, 649.2190764169417, 598.550247685451, 648.5451505915556, 652.1209362844766, 640.0294506234184, 645.478615230784, 643.8556829275161, 643.5698467976056, 622.7712576585128, 649.5109009694619, 658.1981112367938, 663.1678476044784, 650.5246191696548, 648.2752050374812, 646.1140164430124, 649.3040812246207, 632.4432924429009, 653.4061405226681, 385.04298182431705, 613.4365184543823, 614.6328533830141, 616.0166385793568, 614.9476600884391, 595.288823694147, 605.3907001255445, 609.1997666552169, 424.4914594065275, 641.7654094501274, 638.7617306861182, 637.2827713441696, 639.029568826686, 628.2278415833591, 646.3676953386929, 280.0091506550963, 644.5683895147723, 645.942084773197, 659.5127661457898, 653.5697426460298, 633.3855234799814, 648.3082609097748, 635.706481170641, 643.387016030153, 647.9177520468429, 650.8917431813719, 646.1204325833105, 640.8250604222125, 657.9155397421549, 658.8881555177363, 653.690021388007, 654.9946272836121, 649.2284604347507, 647.7335044980088, 636.8053478803208, 648.5153219548255, 648.4432922802589, 602.591756425309, 607.8087872338244, 609.055653585549, 605.2465217476038, 586.5887891053994, 602.312915531784, 607.7957746748762, 625.1659396035346, 625.1998641135402, 622.5075484595409, 620.9018182153122, 606.828031243028, 604.0278830842356, 598.5322621946885, 612.6034608474529, 626.5981605328158, 625.9311123473915, 624.1510028259407, 614.4881528925205, 616.2456717280648, 613.7977521079682, 266.43525298032534, 604.0222531522992, 605.7484034300694, 601.0574662237361, 602.6366530185962, 597.1203592998914, 605.215198832637, 599.1932435360211, 589.3848354665395, 613.1685607964215, 584.2105956894129, 550.9313244967644, 603.9713501567016, 610.9029543129559, 634.7982235070152, 623.4864228320698, 614.6575865230236, 619.2753131403199, 605.816668451103, 611.8874626489367, 614.4736049583801, 613.8866622178468, 614.0473838112944, 609.2118782807834, 609.6569942734911, 611.1791726603865, 612.3059525646017, 661.4267184435736, 660.9115920074735, 662.2452104734077, 660.9659475668498, 701.0069312486094, 703.5996373451395, 705.4425304202722, 704.4177544537126, 707.5693227085329, 703.0514231382796, 702.9996823775101, 702.4667743667923, 704.3491714747066, 701.6448316043495, 704.8385490597897, 703.1757980150614, 702.6878923472862, 702.8228307046303, 701.3141068661633, 704.1334617676263, 704.3500799067266, 702.809524653838, 686.7368763911745, 685.5181294041637, 686.0445679056018]
Elapsed: 0.07937000827498834~0.0182921704479087
Time per graph: 0.0016218617012404913~0.00037215346567505
Speed: 630.4542075524896~63.162896227989435
Total Time: 0.0709
best val loss: 0.6956088542938232 test_score: 0.5000

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.06s
test Score 0.5000
Epoch Time List: [0.25548477401025593, 0.3494161950657144, 0.2411726809805259, 0.24112801009323448, 0.2429196499288082, 0.24673061398789287, 0.24831568519584835, 0.24407313391566277, 0.36780757002998143, 0.24130217300262302, 0.24199698015581816, 0.24269700306467712, 0.24280981009360403, 0.2488495911238715, 0.2417602970963344, 0.24031610798556358, 0.38509826303925365, 0.2527664400404319, 0.2537275879876688, 0.25494986993726343, 0.2520710799144581, 0.24313935299869627, 0.23940398183185607, 0.3289638600545004, 0.24097133905161172, 0.2385966150322929, 0.24002682301215827, 0.2467922680079937, 0.2462941890116781, 0.2425900740781799, 0.241078382008709, 0.30186566011980176, 0.24304277694318444, 0.2429790268652141, 0.24585287005174905, 0.24558660294860601, 0.24964161089155823, 0.24511994584463537, 0.24380555213429034, 0.3746585400076583, 0.24499999394174665, 0.2451915011042729, 0.24634094606153667, 0.24720933905337006, 0.25308188097551465, 0.24690508504863828, 0.4025066838366911, 0.2536544568138197, 0.24849699984770268, 0.2406896719476208, 0.24601358082145452, 0.2498727791244164, 0.24748146103229374, 0.24656253005377948, 0.24743031291291118, 0.24718802201095968, 0.2467696830863133, 0.24679096799809486, 0.24732032092288136, 0.24461416120175272, 0.24493671394884586, 0.24591115687508136, 0.24726638500578701, 0.24699281889479607, 0.24716904805973172, 0.2469851749483496, 0.24839956196956336, 0.2465850559528917, 0.2460406409809366, 0.24591257888823748, 0.24647960299625993, 0.24828217003960162, 0.2465324611403048, 0.2476383929606527, 0.24965017789509147, 0.2486682808957994, 0.249403360998258, 0.2493203921476379, 0.25065526901744306, 0.25056909408885986, 0.2509932171087712, 0.251838814932853, 0.2482374939136207, 0.2480910299345851, 0.24884032981935889, 0.24875075893942267, 0.2478486900217831, 0.24837085709441453, 0.24921688996255398, 0.25228985119611025, 0.2532021610531956, 0.2509544799104333, 0.25140457006637007, 0.25173505197744817, 0.24964242801070213, 0.25071428425144404, 0.2511280319886282, 0.25184072996489704, 0.25217435194645077, 0.25191262690350413, 0.24871931900270283, 0.2473246098961681, 0.24847193202003837, 0.2483171639032662, 0.24898426025174558, 0.24998478102497756, 0.248587831039913, 0.24976177199278027, 0.25038197496905923, 0.2492449899436906, 0.24947091890498996, 0.2527983139734715, 0.25260171794798225, 0.25391052407212555, 0.25103009096346796, 0.25215579802170396, 0.25194272911176085, 0.2510538150090724, 0.25199120305478573, 0.24846289888955653, 0.25039327901322395, 0.25028821488376707, 0.25116473506204784, 0.2510213280329481, 0.25025139399804175, 0.2499516699463129, 0.250913891941309, 0.25156735198106617, 0.251678912085481, 0.2510161300888285, 0.2501432579010725, 0.2505947971949354, 0.2500466980272904, 0.24941778101492673, 0.2503620338393375, 0.24994455510750413, 0.24986577103845775, 0.2501135270576924, 0.25169499695766717, 0.24886978894937783, 0.24969299288932234, 0.2491156451869756, 0.25127372390124947, 0.245438412996009, 0.24465963197872043, 0.35158834396861494, 0.24774616386275738, 0.24764447892084718, 0.24880983086768538, 0.25157734495587647, 0.24970852595288306, 0.24385594099294394, 0.351532629923895, 0.24686982296407223, 0.24614832003135234, 0.24759719078429043, 0.24928584997542202, 0.25133160897530615, 0.24816489312797785, 0.24477547802962363, 0.26978611398953944, 0.27185937901958823, 0.2732125459006056, 0.2757919149007648, 0.26905846293084323, 0.4175381548702717, 0.28862210491206497, 0.2711036920081824, 0.24954102898482233, 0.25523453194182366, 0.2526243559550494, 0.24961129995062947, 0.38119901716709137, 0.25217569211963564, 0.25383290788158774, 0.2532345241634175, 0.257468338124454, 0.2560609879437834, 0.24937367404345423, 0.3270660890266299, 0.24964130390435457, 0.2523066479479894, 0.2516874320572242, 0.25297253392636776, 0.26051077409647405, 0.2541294420370832, 0.30454089085105807, 0.2786464629461989, 0.2640776069601998, 0.2641084201168269, 0.265237329993397, 0.26751545688603073, 0.2720414139330387, 0.267438237904571, 0.3279629598837346, 0.25660487706772983, 0.25718514481559396, 0.2567959448788315, 0.2578309749951586, 0.26248878391925246, 0.257028469000943, 0.3529351931065321, 0.25304819212760776, 0.25300738599617034, 0.2523679961450398, 0.2497326349839568, 0.2552434030221775, 0.2573341669049114, 0.2521084559848532, 0.308852621819824, 0.2533476040698588, 0.2509131159167737, 0.25423240603413433, 0.25458940805401653, 0.2536910299677402, 0.24773270904552191, 0.35501582198776305, 0.2500645039835945, 0.37803569284733385, 0.25319667800795287, 0.2563025200506672, 0.256185520789586, 0.253507170942612, 0.3326055780053139, 0.2666076871100813, 0.26453050202690065, 0.26650840998627245, 0.26724439195822924, 0.2697874139994383, 0.2649229180533439, 0.35369601706042886, 0.25829905993305147, 0.2584998479578644, 0.2600168319186196, 0.2619676520116627, 0.27741959097329527, 0.26564510993193835, 0.34975450194906443, 0.2604460100410506, 0.2576210378902033, 0.2581615939270705, 0.25996990397106856, 0.2675767819164321, 0.26276217692065984, 0.36889360088389367, 0.26522699801716954, 0.26479901815764606, 0.26626948500052094, 0.2668193830177188, 0.26956640905700624, 0.2662651940481737, 0.2621889179572463, 0.3985128211788833, 0.2678258978994563, 0.2714901629369706, 0.28604796587023884, 0.2658861849922687, 0.2633303049951792, 0.37416411796584725, 0.25612452800851315, 0.2596034179441631, 0.26077125302981585, 0.26380635204259306, 0.2623038109159097, 0.26270650199148804, 0.2632200779626146, 0.26172162499278784, 0.2650399530539289, 0.2650875170947984, 0.26481077598873526, 0.2641087560914457, 0.2498637258540839, 0.24638427002355456, 0.24614360206760466, 0.24546081596054137, 0.2425088438903913, 0.238448326010257, 0.2424621299142018, 0.24228371703065932, 0.24265893106348813, 0.24458173592574894, 0.24455813108943403, 0.24443815799895674, 0.24364991392940283, 0.24391781899612397, 0.2436167619889602, 0.243701700004749, 0.24359983287286013, 0.24310709605924785, 0.24441050400491804, 0.2424964130623266, 0.24333792098332196, 0.24340186803601682, 0.24861326906830072, 0.24884579179342836, 0.24890561413485557]
Total Epoch List: [160, 115, 21]
Total Time List: [0.0773575030034408, 0.0750872140051797, 0.07090040296316147]
T-times Epoch Time: 0.26297537437797863 ~ 0.0020663966493267
T-times Total Epoch: 113.33333333333333 ~ 10.374470089099951
T-times Total Time: 0.07575388533425415 ~ 0.0009758335213704815
T-times Inference Elapsed: 0.07764149034828012 ~ 0.0012384233328675228
T-times Time Per Graph: 0.001592171462097924 ~ 2.1388393551374526e-05
T-times Speed: 640.5210232728326 ~ 7.206353528965365
T-times cross validation test micro f1 score:0.804912756000865 ~ 0.05108112935766591
T-times cross validation test precision:0.8495252734383169 ~ 0.14943536273283684
T-times cross validation test recall:0.7662962962962964 ~ 0.10870196856461099
T-times cross validation test f1_score:0.804912756000865 ~ 0.126837543700847
