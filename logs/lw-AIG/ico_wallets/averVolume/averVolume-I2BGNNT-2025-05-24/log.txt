Namespace(seed=15, model='I2BGNNT', dataset='ico_wallets/averVolume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/ico_wallets/averVolume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 342], edge_attr=[342, 2], x=[99, 14887], y=[1, 1], num_nodes=99)
Data(edge_index=[2, 342], edge_attr=[342, 2], x=[99, 14887], y=[1, 1], num_nodes=99)
Data(edge_index=[2, 306], edge_attr=[306, 2], x=[90, 14887], y=[1, 1], num_nodes=99)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe4bd990>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.30s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6956;  Loss pred: 0.6956; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6947;  Loss pred: 0.6947; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.06s
Epoch 5/1000, LR 0.000090
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.06s
Epoch 6/1000, LR 0.000120
Train loss: 0.6904;  Loss pred: 0.6904; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.06s
Epoch 7/1000, LR 0.000150
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.06s
Epoch 8/1000, LR 0.000180
Train loss: 0.6862;  Loss pred: 0.6862; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6808;  Loss pred: 0.6808; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.06s
Epoch 10/1000, LR 0.000240
Train loss: 0.6780;  Loss pred: 0.6780; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.06s
Epoch 11/1000, LR 0.000270
Train loss: 0.6755;  Loss pred: 0.6755; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.06s
Epoch 12/1000, LR 0.000270
Train loss: 0.6703;  Loss pred: 0.6703; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.06s
Epoch 13/1000, LR 0.000270
Train loss: 0.6647;  Loss pred: 0.6647; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.06s
Epoch 14/1000, LR 0.000270
Train loss: 0.6597;  Loss pred: 0.6597; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.06s
Epoch 15/1000, LR 0.000270
Train loss: 0.6560;  Loss pred: 0.6560; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.06s
Epoch 16/1000, LR 0.000270
Train loss: 0.6478;  Loss pred: 0.6478; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.06s
Epoch 17/1000, LR 0.000270
Train loss: 0.6392;  Loss pred: 0.6392; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6326;  Loss pred: 0.6326; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4898 time: 0.06s
Epoch 19/1000, LR 0.000270
Train loss: 0.6276;  Loss pred: 0.6276; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6169;  Loss pred: 0.6169; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.06s
Epoch 21/1000, LR 0.000270
Train loss: 0.6120;  Loss pred: 0.6120; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.06s
Epoch 22/1000, LR 0.000270
Train loss: 0.6042;  Loss pred: 0.6042; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4898 time: 0.06s
Epoch 23/1000, LR 0.000270
Train loss: 0.5984;  Loss pred: 0.5984; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.06s
Epoch 24/1000, LR 0.000270
Train loss: 0.5880;  Loss pred: 0.5880; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.06s
Epoch 25/1000, LR 0.000270
Train loss: 0.5737;  Loss pred: 0.5737; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5696;  Loss pred: 0.5696; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6906 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.06s
Epoch 27/1000, LR 0.000270
Train loss: 0.5574;  Loss pred: 0.5574; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4898 time: 0.06s
Epoch 28/1000, LR 0.000270
Train loss: 0.5477;  Loss pred: 0.5477; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4898 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5369;  Loss pred: 0.5369; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.4898 time: 0.06s
Epoch 30/1000, LR 0.000270
Train loss: 0.5239;  Loss pred: 0.5239; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6887 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.4898 time: 0.06s
Epoch 31/1000, LR 0.000270
Train loss: 0.5133;  Loss pred: 0.5133; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.4898 time: 0.06s
Epoch 32/1000, LR 0.000270
Train loss: 0.4971;  Loss pred: 0.4971; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.4898 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4887;  Loss pred: 0.4887; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6864 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.4898 time: 0.06s
Epoch 34/1000, LR 0.000270
Train loss: 0.4745;  Loss pred: 0.4745; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6854 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.4898 time: 0.06s
Epoch 35/1000, LR 0.000270
Train loss: 0.4644;  Loss pred: 0.4644; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6843 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.4898 time: 0.06s
Epoch 36/1000, LR 0.000270
Train loss: 0.4480;  Loss pred: 0.4480; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6830 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6863 score: 0.4898 time: 0.06s
Epoch 37/1000, LR 0.000270
Train loss: 0.4378;  Loss pred: 0.4378; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6815 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6852 score: 0.4898 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4237;  Loss pred: 0.4237; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6799 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6839 score: 0.4898 time: 0.06s
Epoch 39/1000, LR 0.000269
Train loss: 0.4011;  Loss pred: 0.4011; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6781 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6825 score: 0.4898 time: 0.06s
Epoch 40/1000, LR 0.000269
Train loss: 0.3924;  Loss pred: 0.3924; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6762 score: 0.5102 time: 0.07s
Test loss: 0.6810 score: 0.5102 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.3850;  Loss pred: 0.3850; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6741 score: 0.5102 time: 0.07s
Test loss: 0.6793 score: 0.5102 time: 0.06s
Epoch 42/1000, LR 0.000269
Train loss: 0.3607;  Loss pred: 0.3607; Loss self: 0.0000; time: 0.12s
Val loss: 0.6718 score: 0.5510 time: 0.07s
Test loss: 0.6775 score: 0.5714 time: 0.06s
Epoch 43/1000, LR 0.000269
Train loss: 0.3511;  Loss pred: 0.3511; Loss self: 0.0000; time: 0.12s
Val loss: 0.6692 score: 0.5918 time: 0.07s
Test loss: 0.6756 score: 0.6327 time: 0.06s
Epoch 44/1000, LR 0.000269
Train loss: 0.3339;  Loss pred: 0.3339; Loss self: 0.0000; time: 0.12s
Val loss: 0.6664 score: 0.6531 time: 0.07s
Test loss: 0.6734 score: 0.6327 time: 0.06s
Epoch 45/1000, LR 0.000269
Train loss: 0.3310;  Loss pred: 0.3310; Loss self: 0.0000; time: 0.12s
Val loss: 0.6632 score: 0.7347 time: 0.07s
Test loss: 0.6709 score: 0.6327 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2997;  Loss pred: 0.2997; Loss self: 0.0000; time: 0.12s
Val loss: 0.6595 score: 0.7959 time: 0.07s
Test loss: 0.6681 score: 0.6531 time: 0.06s
Epoch 47/1000, LR 0.000269
Train loss: 0.2982;  Loss pred: 0.2982; Loss self: 0.0000; time: 0.11s
Val loss: 0.6556 score: 0.7959 time: 0.07s
Test loss: 0.6650 score: 0.6531 time: 0.06s
Epoch 48/1000, LR 0.000269
Train loss: 0.2868;  Loss pred: 0.2868; Loss self: 0.0000; time: 0.11s
Val loss: 0.6513 score: 0.8367 time: 0.07s
Test loss: 0.6617 score: 0.6939 time: 0.06s
Epoch 49/1000, LR 0.000269
Train loss: 0.2702;  Loss pred: 0.2702; Loss self: 0.0000; time: 0.12s
Val loss: 0.6468 score: 0.8367 time: 0.07s
Test loss: 0.6583 score: 0.6939 time: 0.06s
Epoch 50/1000, LR 0.000269
Train loss: 0.2474;  Loss pred: 0.2474; Loss self: 0.0000; time: 0.12s
Val loss: 0.6421 score: 0.8776 time: 0.08s
Test loss: 0.6547 score: 0.7143 time: 0.06s
Epoch 51/1000, LR 0.000269
Train loss: 0.2345;  Loss pred: 0.2345; Loss self: 0.0000; time: 0.12s
Val loss: 0.6371 score: 0.8776 time: 0.07s
Test loss: 0.6508 score: 0.7347 time: 0.06s
Epoch 52/1000, LR 0.000269
Train loss: 0.2245;  Loss pred: 0.2245; Loss self: 0.0000; time: 0.11s
Val loss: 0.6319 score: 0.8776 time: 0.07s
Test loss: 0.6467 score: 0.7551 time: 0.06s
Epoch 53/1000, LR 0.000269
Train loss: 0.2094;  Loss pred: 0.2094; Loss self: 0.0000; time: 0.12s
Val loss: 0.6262 score: 0.8980 time: 0.08s
Test loss: 0.6422 score: 0.7755 time: 0.06s
Epoch 54/1000, LR 0.000269
Train loss: 0.2025;  Loss pred: 0.2025; Loss self: 0.0000; time: 0.12s
Val loss: 0.6202 score: 0.9184 time: 0.07s
Test loss: 0.6375 score: 0.7959 time: 0.06s
Epoch 55/1000, LR 0.000269
Train loss: 0.1850;  Loss pred: 0.1850; Loss self: 0.0000; time: 0.12s
Val loss: 0.6138 score: 0.9184 time: 0.07s
Test loss: 0.6323 score: 0.8163 time: 0.06s
Epoch 56/1000, LR 0.000269
Train loss: 0.1731;  Loss pred: 0.1731; Loss self: 0.0000; time: 0.12s
Val loss: 0.6070 score: 0.9184 time: 0.07s
Test loss: 0.6269 score: 0.8163 time: 0.06s
Epoch 57/1000, LR 0.000269
Train loss: 0.1629;  Loss pred: 0.1629; Loss self: 0.0000; time: 0.12s
Val loss: 0.5995 score: 0.9184 time: 0.07s
Test loss: 0.6209 score: 0.8367 time: 0.06s
Epoch 58/1000, LR 0.000269
Train loss: 0.1522;  Loss pred: 0.1522; Loss self: 0.0000; time: 0.12s
Val loss: 0.5914 score: 0.9184 time: 0.07s
Test loss: 0.6144 score: 0.8367 time: 0.06s
Epoch 59/1000, LR 0.000268
Train loss: 0.1467;  Loss pred: 0.1467; Loss self: 0.0000; time: 0.12s
Val loss: 0.5828 score: 0.9184 time: 0.07s
Test loss: 0.6073 score: 0.8367 time: 0.06s
Epoch 60/1000, LR 0.000268
Train loss: 0.1346;  Loss pred: 0.1346; Loss self: 0.0000; time: 0.12s
Val loss: 0.5734 score: 0.9184 time: 0.07s
Test loss: 0.5996 score: 0.8571 time: 0.06s
Epoch 61/1000, LR 0.000268
Train loss: 0.1228;  Loss pred: 0.1228; Loss self: 0.0000; time: 0.12s
Val loss: 0.5635 score: 0.9184 time: 0.07s
Test loss: 0.5915 score: 0.8571 time: 0.06s
Epoch 62/1000, LR 0.000268
Train loss: 0.1145;  Loss pred: 0.1145; Loss self: 0.0000; time: 0.12s
Val loss: 0.5528 score: 0.9184 time: 0.08s
Test loss: 0.5828 score: 0.8571 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1067;  Loss pred: 0.1067; Loss self: 0.0000; time: 0.12s
Val loss: 0.5412 score: 0.9184 time: 0.07s
Test loss: 0.5735 score: 0.8776 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0982;  Loss pred: 0.0982; Loss self: 0.0000; time: 0.12s
Val loss: 0.5288 score: 0.9388 time: 0.07s
Test loss: 0.5636 score: 0.8776 time: 0.06s
Epoch 65/1000, LR 0.000268
Train loss: 0.0876;  Loss pred: 0.0876; Loss self: 0.0000; time: 0.12s
Val loss: 0.5156 score: 0.9388 time: 0.07s
Test loss: 0.5531 score: 0.8776 time: 0.06s
Epoch 66/1000, LR 0.000268
Train loss: 0.0793;  Loss pred: 0.0793; Loss self: 0.0000; time: 0.11s
Val loss: 0.5016 score: 0.9592 time: 0.07s
Test loss: 0.5420 score: 0.8776 time: 0.06s
Epoch 67/1000, LR 0.000268
Train loss: 0.0745;  Loss pred: 0.0745; Loss self: 0.0000; time: 0.12s
Val loss: 0.4866 score: 0.9592 time: 0.07s
Test loss: 0.5303 score: 0.8776 time: 0.06s
Epoch 68/1000, LR 0.000268
Train loss: 0.0688;  Loss pred: 0.0688; Loss self: 0.0000; time: 0.12s
Val loss: 0.4710 score: 0.9592 time: 0.07s
Test loss: 0.5182 score: 0.8776 time: 0.06s
Epoch 69/1000, LR 0.000268
Train loss: 0.0626;  Loss pred: 0.0626; Loss self: 0.0000; time: 0.12s
Val loss: 0.4546 score: 0.9592 time: 0.07s
Test loss: 0.5057 score: 0.8980 time: 0.06s
Epoch 70/1000, LR 0.000268
Train loss: 0.0577;  Loss pred: 0.0577; Loss self: 0.0000; time: 0.12s
Val loss: 0.4375 score: 0.9592 time: 0.07s
Test loss: 0.4926 score: 0.8980 time: 0.06s
Epoch 71/1000, LR 0.000268
Train loss: 0.0508;  Loss pred: 0.0508; Loss self: 0.0000; time: 0.12s
Val loss: 0.4201 score: 0.9388 time: 0.07s
Test loss: 0.4794 score: 0.8980 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.0473;  Loss pred: 0.0473; Loss self: 0.0000; time: 0.12s
Val loss: 0.4025 score: 0.9388 time: 0.07s
Test loss: 0.4662 score: 0.8980 time: 0.06s
Epoch 73/1000, LR 0.000267
Train loss: 0.0430;  Loss pred: 0.0430; Loss self: 0.0000; time: 0.12s
Val loss: 0.3848 score: 0.9388 time: 0.07s
Test loss: 0.4531 score: 0.8980 time: 0.06s
Epoch 74/1000, LR 0.000267
Train loss: 0.0398;  Loss pred: 0.0398; Loss self: 0.0000; time: 0.12s
Val loss: 0.3669 score: 0.9388 time: 0.07s
Test loss: 0.4401 score: 0.8980 time: 0.06s
Epoch 75/1000, LR 0.000267
Train loss: 0.0353;  Loss pred: 0.0353; Loss self: 0.0000; time: 0.12s
Val loss: 0.3490 score: 0.9388 time: 0.07s
Test loss: 0.4274 score: 0.8980 time: 0.06s
Epoch 76/1000, LR 0.000267
Train loss: 0.0333;  Loss pred: 0.0333; Loss self: 0.0000; time: 0.12s
Val loss: 0.3312 score: 0.9388 time: 0.07s
Test loss: 0.4150 score: 0.8980 time: 0.06s
Epoch 77/1000, LR 0.000267
Train loss: 0.0303;  Loss pred: 0.0303; Loss self: 0.0000; time: 0.12s
Val loss: 0.3135 score: 0.9388 time: 0.07s
Test loss: 0.4029 score: 0.8980 time: 0.06s
Epoch 78/1000, LR 0.000267
Train loss: 0.0274;  Loss pred: 0.0274; Loss self: 0.0000; time: 0.12s
Val loss: 0.2965 score: 0.9388 time: 0.07s
Test loss: 0.3916 score: 0.8980 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0244;  Loss pred: 0.0244; Loss self: 0.0000; time: 0.12s
Val loss: 0.2800 score: 0.9388 time: 0.07s
Test loss: 0.3808 score: 0.8980 time: 0.06s
Epoch 80/1000, LR 0.000267
Train loss: 0.0223;  Loss pred: 0.0223; Loss self: 0.0000; time: 0.12s
Val loss: 0.2640 score: 0.9388 time: 0.08s
Test loss: 0.3707 score: 0.8980 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0204;  Loss pred: 0.0204; Loss self: 0.0000; time: 0.12s
Val loss: 0.2486 score: 0.9388 time: 0.08s
Test loss: 0.3613 score: 0.8980 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0194;  Loss pred: 0.0194; Loss self: 0.0000; time: 0.12s
Val loss: 0.2342 score: 0.9388 time: 0.07s
Test loss: 0.3529 score: 0.8980 time: 0.06s
Epoch 83/1000, LR 0.000266
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.12s
Val loss: 0.2204 score: 0.9388 time: 0.07s
Test loss: 0.3451 score: 0.8980 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0153;  Loss pred: 0.0153; Loss self: 0.0000; time: 0.22s
Val loss: 0.2075 score: 0.9388 time: 0.07s
Test loss: 0.3383 score: 0.8980 time: 0.06s
Epoch 85/1000, LR 0.000266
Train loss: 0.0175;  Loss pred: 0.0175; Loss self: 0.0000; time: 0.12s
Val loss: 0.1955 score: 0.9388 time: 0.08s
Test loss: 0.3321 score: 0.8980 time: 0.06s
Epoch 86/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.12s
Val loss: 0.1846 score: 0.9388 time: 0.07s
Test loss: 0.3270 score: 0.8980 time: 0.06s
Epoch 87/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.12s
Val loss: 0.1745 score: 0.9388 time: 0.07s
Test loss: 0.3226 score: 0.8980 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.12s
Val loss: 0.1650 score: 0.9388 time: 0.08s
Test loss: 0.3191 score: 0.8776 time: 0.06s
Epoch 89/1000, LR 0.000266
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.12s
Val loss: 0.1566 score: 0.9388 time: 0.07s
Test loss: 0.3165 score: 0.8776 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.1491 score: 0.9388 time: 0.08s
Test loss: 0.3148 score: 0.8776 time: 0.19s
Epoch 91/1000, LR 0.000266
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.1426 score: 0.9388 time: 0.08s
Test loss: 0.3139 score: 0.8776 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.12s
Val loss: 0.1368 score: 0.9388 time: 0.08s
Test loss: 0.3139 score: 0.8776 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.12s
Val loss: 0.1314 score: 0.9388 time: 0.08s
Test loss: 0.3142 score: 0.8776 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.12s
Val loss: 0.1267 score: 0.9388 time: 0.08s
Test loss: 0.3152 score: 0.8776 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.12s
Val loss: 0.1225 score: 0.9388 time: 0.08s
Test loss: 0.3167 score: 0.8776 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.12s
Val loss: 0.1189 score: 0.9388 time: 0.08s
Test loss: 0.3189 score: 0.8776 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.12s
Val loss: 0.1158 score: 0.9388 time: 0.17s
Test loss: 0.3216 score: 0.8776 time: 0.06s
Epoch 98/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.11s
Val loss: 0.1129 score: 0.9388 time: 0.07s
Test loss: 0.3246 score: 0.8776 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.11s
Val loss: 0.1106 score: 0.9388 time: 0.07s
Test loss: 0.3281 score: 0.8776 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.11s
Val loss: 0.1086 score: 0.9388 time: 0.07s
Test loss: 0.3317 score: 0.8776 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.12s
Val loss: 0.1069 score: 0.9388 time: 0.07s
Test loss: 0.3357 score: 0.8776 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.12s
Val loss: 0.1055 score: 0.9388 time: 0.07s
Test loss: 0.3400 score: 0.8776 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.11s
Val loss: 0.1042 score: 0.9388 time: 0.07s
Test loss: 0.3443 score: 0.8776 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.11s
Val loss: 0.1032 score: 0.9388 time: 0.08s
Test loss: 0.3487 score: 0.8776 time: 0.19s
Epoch 105/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.11s
Val loss: 0.1023 score: 0.9388 time: 0.07s
Test loss: 0.3531 score: 0.8776 time: 0.07s
Epoch 106/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.1016 score: 0.9388 time: 0.08s
Test loss: 0.3574 score: 0.8776 time: 0.07s
Epoch 107/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.1008 score: 0.9388 time: 0.07s
Test loss: 0.3616 score: 0.8776 time: 0.07s
Epoch 108/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.11s
Val loss: 0.1003 score: 0.9388 time: 0.07s
Test loss: 0.3660 score: 0.8776 time: 0.07s
Epoch 109/1000, LR 0.000264
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.12s
Val loss: 0.0998 score: 0.9388 time: 0.07s
Test loss: 0.3702 score: 0.8776 time: 0.07s
Epoch 110/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.0994 score: 0.9388 time: 0.07s
Test loss: 0.3743 score: 0.8776 time: 0.07s
Epoch 111/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.11s
Val loss: 0.0990 score: 0.9388 time: 0.07s
Test loss: 0.3784 score: 0.8776 time: 0.20s
Epoch 112/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.0986 score: 0.9388 time: 0.07s
Test loss: 0.3824 score: 0.8776 time: 0.06s
Epoch 113/1000, LR 0.000263
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.11s
Val loss: 0.0983 score: 0.9388 time: 0.07s
Test loss: 0.3860 score: 0.8776 time: 0.06s
Epoch 114/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.0980 score: 0.9388 time: 0.07s
Test loss: 0.3896 score: 0.8776 time: 0.06s
Epoch 115/1000, LR 0.000263
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.11s
Val loss: 0.0979 score: 0.9388 time: 0.07s
Test loss: 0.3931 score: 0.8776 time: 0.06s
Epoch 116/1000, LR 0.000263
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.0977 score: 0.9388 time: 0.07s
Test loss: 0.3964 score: 0.8776 time: 0.06s
Epoch 117/1000, LR 0.000262
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.11s
Val loss: 0.0977 score: 0.9388 time: 0.07s
Test loss: 0.3996 score: 0.8776 time: 0.06s
Epoch 118/1000, LR 0.000262
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.12s
Val loss: 0.0976 score: 0.9388 time: 0.16s
Test loss: 0.4028 score: 0.8776 time: 0.07s
Epoch 119/1000, LR 0.000262
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.12s
Val loss: 0.0976 score: 0.9388 time: 0.08s
Test loss: 0.4057 score: 0.8776 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.0977 score: 0.9388 time: 0.07s
Test loss: 0.4084 score: 0.8776 time: 0.06s
     INFO: Early stopping counter 2 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.0975 score: 0.9388 time: 0.07s
Test loss: 0.4110 score: 0.8776 time: 0.07s
Epoch 122/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.13s
Val loss: 0.0977 score: 0.9388 time: 0.08s
Test loss: 0.4135 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.12s
Val loss: 0.0978 score: 0.9388 time: 0.07s
Test loss: 0.4157 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 124/1000, LR 0.000261
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.14s
Val loss: 0.0980 score: 0.9388 time: 0.15s
Test loss: 0.4181 score: 0.8776 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 125/1000, LR 0.000261
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.13s
Val loss: 0.0984 score: 0.9388 time: 0.07s
Test loss: 0.4204 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 126/1000, LR 0.000261
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.0986 score: 0.9388 time: 0.08s
Test loss: 0.4225 score: 0.8776 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 127/1000, LR 0.000261
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.0987 score: 0.9388 time: 0.07s
Test loss: 0.4245 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 128/1000, LR 0.000261
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.0988 score: 0.9388 time: 0.07s
Test loss: 0.4263 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 129/1000, LR 0.000261
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.13s
Val loss: 0.0992 score: 0.9388 time: 0.07s
Test loss: 0.4281 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 130/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.13s
Val loss: 0.0994 score: 0.9388 time: 0.07s
Test loss: 0.4298 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 131/1000, LR 0.000260
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.13s
Val loss: 0.0994 score: 0.9388 time: 0.08s
Test loss: 0.4311 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 132/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.14s
Val loss: 0.0998 score: 0.9388 time: 0.09s
Test loss: 0.4325 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 133/1000, LR 0.000260
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.13s
Val loss: 0.1002 score: 0.9388 time: 0.08s
Test loss: 0.4342 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 134/1000, LR 0.000260
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.1002 score: 0.9388 time: 0.07s
Test loss: 0.4355 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 135/1000, LR 0.000260
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.12s
Val loss: 0.1001 score: 0.9388 time: 0.08s
Test loss: 0.4367 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 136/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.13s
Val loss: 0.1003 score: 0.9388 time: 0.07s
Test loss: 0.4379 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 137/1000, LR 0.000259
Train loss: 0.0018;  Loss pred: 0.0018; Loss self: 0.0000; time: 0.13s
Val loss: 0.1003 score: 0.9388 time: 0.08s
Test loss: 0.4392 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 138/1000, LR 0.000259
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.13s
Val loss: 0.1006 score: 0.9388 time: 0.07s
Test loss: 0.4403 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 139/1000, LR 0.000259
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.24s
Val loss: 0.1009 score: 0.9388 time: 0.07s
Test loss: 0.4416 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 140/1000, LR 0.000259
Train loss: 0.0018;  Loss pred: 0.0018; Loss self: 0.0000; time: 0.13s
Val loss: 0.1008 score: 0.9388 time: 0.07s
Test loss: 0.4423 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 141/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.13s
Val loss: 0.1007 score: 0.9388 time: 0.07s
Test loss: 0.4431 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 120,   Train_Loss: 0.0029,   Val_Loss: 0.0975,   Val_Precision: 0.9565,   Val_Recall: 0.9167,   Val_accuracy: 0.9362,   Val_Score: 0.9388,   Val_Loss: 0.0975,   Test_Precision: 0.9130,   Test_Recall: 0.8400,   Test_accuracy: 0.8750,   Test_Score: 0.8776,   Test_loss: 0.4110


[0.07083901192527264, 0.07123459305148572, 0.0728723609354347, 0.06717895099427551, 0.06833636702504009, 0.06857296102680266, 0.06849951494950801, 0.07125885400455445, 0.06915027694776654, 0.06812530697789043, 0.06815336598083377, 0.0682296110317111, 0.06875261489767581, 0.06872760003898293, 0.06877774698659778, 0.06877460691612214, 0.07478607399389148, 0.06874420191161335, 0.07009132008533925, 0.06937723106238991, 0.06938090501353145, 0.0693196589127183, 0.06954058597330004, 0.06822549202479422, 0.07430438103619963, 0.06917668005917221, 0.0686241330113262, 0.07121087296400219, 0.06846189498901367, 0.06806643004529178, 0.06828894698992372, 0.07085076696239412, 0.06805825501214713, 0.06862531299702823, 0.06863353203516454, 0.0677074680570513, 0.07268523098900914, 0.06834569794591516, 0.06869031197857112, 0.08459324296563864, 0.06816331099253148, 0.06865695700980723, 0.0687137299682945, 0.06909489503595978, 0.07375112897716463, 0.06798539694864303, 0.06736822496168315, 0.06742447300348431, 0.06874671299010515, 0.06839104497339576, 0.06762037996668369, 0.06765997793991119, 0.06799854699056596, 0.06824702699668705, 0.06722657394129783, 0.06821557495277375, 0.06745417392812669, 0.06793526699766517, 0.06761741102673113, 0.06755038595292717, 0.06925623200368136, 0.07224936399143189, 0.07029565493576229, 0.06720096501521766, 0.06756321305874735, 0.06782709097024053, 0.06828747305553406, 0.06740411592181772, 0.06827319099102169, 0.06861812900751829, 0.06824302510358393, 0.06770418700762093, 0.06776656105648726, 0.06730132992379367, 0.06752969906665385, 0.06726748798973858, 0.06950179999694228, 0.06993326998781413, 0.06983286305330694, 0.0705082630738616, 0.07423675700556487, 0.06943969603162259, 0.07159186492208391, 0.06978749297559261, 0.06910264398902655, 0.06896096502896398, 0.07004379597492516, 0.06974822003394365, 0.07564233406446874, 0.19399107701610774, 0.07370182301383466, 0.07365404104348272, 0.07469843502622098, 0.07527633907739073, 0.07472177699673921, 0.07494371000211686, 0.06954243197105825, 0.07100820797495544, 0.07694649300538003, 0.07104502397123724, 0.07024088501930237, 0.07089372898917645, 0.0732692830497399, 0.1907073080074042, 0.07049184700008482, 0.07456855697091669, 0.07162670197430998, 0.07039938995148987, 0.07097803498618305, 0.07039707899093628, 0.20132703299168497, 0.0654451900627464, 0.0665014690021053, 0.06673909199889749, 0.06807012599892914, 0.067712222924456, 0.06752297503408045, 0.0726597469765693, 0.06984604394529015, 0.07001034799031913, 0.07163795304950327, 0.07375469210091978, 0.07174312393181026, 0.06938905001152307, 0.0700039790244773, 0.06964202201925218, 0.07014602702111006, 0.07202155096456409, 0.0707657829625532, 0.07107859791722149, 0.07298957090824842, 0.0756541530136019, 0.07098619197495282, 0.07018235290888697, 0.0724826620426029, 0.07411599392071366, 0.07161576999351382, 0.07286076701711863, 0.07120346394367516, 0.07074075902346522, 0.07420500391162932]
[0.0014456941209239314, 0.0014537672051323615, 0.0014871910394986673, 0.0013709989998831737, 0.0013946197352048997, 0.0013994481842204624, 0.001397949284683837, 0.0014542623266235602, 0.001411230141791154, 0.0013903123873038863, 0.0013908850200170157, 0.0013924410414634918, 0.001403114589748486, 0.001402604082428223, 0.0014036274895224037, 0.0014035634064514721, 0.0015262464080386016, 0.0014029428961553744, 0.0014304351037824337, 0.0014158618584161206, 0.0014159368370108459, 0.0014146869165860877, 0.001419195632108164, 0.0013923569800978412, 0.0015164159395142781, 0.0014117689807994329, 0.0014004925104352285, 0.0014532831217143305, 0.0013971815303880342, 0.0013891108172508528, 0.0013936519793861983, 0.0014459340196406963, 0.0013889439798397372, 0.0014005165917760863, 0.0014006843272482558, 0.001381785062388802, 0.0014833720610001866, 0.001394810162161534, 0.0014018431016034922, 0.001726392713584462, 0.0013910879794394179, 0.0014011623879552496, 0.0014023210197611122, 0.0014100998986930568, 0.001505125081166625, 0.0013874570805845515, 0.001374861733911901, 0.0013760096531323328, 0.0014029941426552072, 0.0013957356117019544, 0.001380007754422116, 0.0013808158763247182, 0.0013877254487870603, 0.001392796469320144, 0.0013719708967611802, 0.0013921545908729337, 0.0013766157944515652, 0.0013864340203605136, 0.0013799471638108395, 0.001378579305161779, 0.001413392489871048, 0.0014744768161516712, 0.0014346052027706588, 0.001371448265616687, 0.0013788410828315786, 0.0013842263463314396, 0.001393621899092532, 0.0013755942024860758, 0.0013933304283881979, 0.0014003699797452713, 0.001392714798032325, 0.0013817181021963454, 0.001382991041969128, 0.0013734965290570138, 0.0013781571238092622, 0.0013728058773416038, 0.0014184040815702506, 0.0014272095915880433, 0.0014251604704756517, 0.0014389441443645225, 0.0015150358572564259, 0.0014171366537065835, 0.0014610584677976308, 0.0014242345505222982, 0.0014102580405923786, 0.001407366633244163, 0.0014294652239780646, 0.0014234330619172174, 0.0015437211033565048, 0.0039590015717573005, 0.0015041188370170338, 0.0015031436947649534, 0.001524457857677979, 0.0015362518179059333, 0.0015249342244232492, 0.0015294634694309563, 0.001419233305531801, 0.0014491471015297029, 0.0015703365919465314, 0.0014498984483925967, 0.0014334874493735178, 0.0014468107956974786, 0.0014952914908110183, 0.003891985877702127, 0.0014386091224507106, 0.0015218072851207486, 0.0014617694280471426, 0.0014367222439079564, 0.0014485313262486337, 0.0014366750814476792, 0.004108714959013979, 0.0013356161237295186, 0.0013571728367776591, 0.0013620222856917856, 0.001389186244876105, 0.001381882100499102, 0.001378019898654703, 0.0014828519791136592, 0.0014254294682712275, 0.0014287826120473292, 0.0014619990418265974, 0.0015051977979779548, 0.0014641453863634747, 0.0014161030614596544, 0.001428652633152598, 0.0014212657554949425, 0.001431551571859389, 0.0014698275707053896, 0.0014441996522970041, 0.001450583630963704, 0.0014895830797601718, 0.0015439623064000387, 0.0014486977954072003, 0.0014322929165078973, 0.0014792380008694468, 0.0015125713045043604, 0.0014615463263982413, 0.0014869544289207884, 0.0014531319172178603, 0.0014436889596625554, 0.0015143878349312106]
[691.7092526881883, 687.8680413683927, 672.4085698748564, 729.3951345589694, 717.0413373313396, 714.5673639621264, 715.3335324508299, 687.6338482354516, 708.6016450377012, 719.2628139775222, 718.9666907101827, 718.1632616552108, 712.7001652653715, 712.9595675130042, 712.4397373695343, 712.4722655232424, 655.2021971898447, 712.7873862438739, 699.0879889313021, 706.2835926088637, 706.2461925286715, 706.8701832722062, 704.6244910678988, 718.2066196340896, 659.4496760040053, 708.3311884595571, 714.0345218192076, 688.0971677565306, 715.7266097858262, 719.8849707175053, 717.5392528344321, 691.594489386516, 719.9714419838477, 714.0222442719046, 713.9367383117445, 723.7015562110797, 674.1397025677661, 716.9434430061094, 713.3465926794192, 579.2424818126852, 718.8617936321907, 713.6931511980738, 713.1034805214227, 709.1696133918202, 664.3966089681386, 720.7430154010159, 727.3458671038104, 726.7390877117841, 712.7613505979939, 716.4680700384251, 724.6336093370389, 724.2095178262826, 720.6036329981905, 717.9799935076825, 728.8784349294186, 718.3110313725734, 726.4190953136591, 721.2748571619518, 724.6654264924292, 725.384456487723, 707.5175559276076, 678.206662217967, 697.0558855277368, 729.1561957317718, 725.2467397812131, 722.4252035443918, 717.554740386297, 726.9585741148994, 717.7048456171292, 714.0969989815842, 718.0220971392233, 723.7366279058111, 723.0704824929176, 728.068822049779, 725.6066690247727, 728.4351098033388, 705.0177118025108, 700.6679368566384, 701.6753696980151, 694.9540077121115, 660.0503844251563, 705.648250212466, 684.4353063484032, 702.1315412080671, 709.0900893427633, 710.5469011261622, 699.5623140919064, 702.5268885163474, 647.7854049061744, 252.58893735577004, 664.8410852849888, 665.2723911111971, 655.970904648803, 650.9349498203369, 655.7659891056702, 653.8240500585832, 704.6057868725748, 690.0610703664325, 636.8061504320146, 689.7034762045794, 697.5994107496607, 691.17537896026, 668.765927008398, 256.93823960903256, 695.1158479354505, 657.1134267639246, 684.1024178046702, 696.0287586833416, 690.3544175256274, 696.0516075717974, 243.3850997149685, 748.7181250909445, 736.8258285910762, 734.202377233563, 719.8458836519687, 723.6507366575082, 725.6789259547368, 674.376144136603, 701.5429540774179, 699.8965353918196, 683.9949763240725, 664.3645116564581, 682.9922829478832, 706.1632922177611, 699.9602120169035, 703.5981808002962, 698.5427697174314, 680.3519133336755, 692.4250386084062, 689.377695056192, 671.3287856095972, 647.6842056666773, 690.2750892355157, 698.1812089374291, 676.0237361480933, 661.1258570237653, 684.206844448337, 672.5155664157015, 688.1687671650496, 692.6699780496608, 660.3328268583351]
Elapsed: 0.07274019246894523~0.018276138219853053
Time per graph: 0.0014844937238560247~0.0003729824126500623
Speed: 690.6341697851246~69.39073462643556
Total Time: 0.0749
best val loss: 0.09754174202680588 test_score: 0.8776

Testing...
Test loss: 0.5420 score: 0.8776 time: 0.07s
test Score 0.8776
Epoch Time List: [0.44224406115245074, 0.249535869108513, 0.26170355489011854, 0.2399571939604357, 0.24755443399772048, 0.24864490400068462, 0.2480351789854467, 0.2546479169977829, 0.2509292470058426, 0.24570817907806486, 0.246507802978158, 0.24682019103784114, 0.24808320601005107, 0.25360741396434605, 0.252684106817469, 0.248503508977592, 0.2627014520112425, 0.2477286010980606, 0.2525089009432122, 0.24984656600281596, 0.24886299401987344, 0.2488516381708905, 0.24972213001456112, 0.24695961398538202, 0.2630372919375077, 0.24908673495519906, 0.24922632507514209, 0.2532558188540861, 0.25215502199716866, 0.2488721840782091, 0.24734657304361463, 0.2494230429874733, 0.2467502240324393, 0.25659005099441856, 0.25268325221259147, 0.2556317129638046, 0.25258705811575055, 0.24776713398750871, 0.24759677704423666, 0.2665042649023235, 0.2811292731203139, 0.2505253099370748, 0.24857534584589303, 0.2487183550838381, 0.2586246069986373, 0.24676986085250974, 0.24549207603558898, 0.24538940691854805, 0.25147364707663655, 0.2538037330377847, 0.2542843701085076, 0.25100134685635567, 0.2557753960136324, 0.24843529309146106, 0.24727067607454956, 0.252139171003364, 0.25343468715436757, 0.25339331093709916, 0.24922359711490571, 0.2514854399487376, 0.2501105881528929, 0.26506952883210033, 0.25478637393098325, 0.24737167998682708, 0.24662180105224252, 0.2516180230304599, 0.24860082915984094, 0.24786741996649653, 0.24913719296455383, 0.2549196348991245, 0.2495561259565875, 0.25303120317403227, 0.24859604891389608, 0.2521776770008728, 0.24764476099517196, 0.2519747519399971, 0.25386614992748946, 0.2569857829948887, 0.2580515280133113, 0.2614923521177843, 0.2706689011538401, 0.25625487905927, 0.2525614529149607, 0.3519961411366239, 0.25845956488046795, 0.25245977099984884, 0.2540282600093633, 0.2628869339823723, 0.26347757293842733, 0.3916914751753211, 0.263379154028371, 0.26936172996647656, 0.268867974053137, 0.2719201899599284, 0.2705140550388023, 0.26706793485209346, 0.3631450969260186, 0.2526871010195464, 0.25897971517406404, 0.25263387395534664, 0.2520221760496497, 0.2564130541868508, 0.2545208039227873, 0.38438642711844295, 0.252117482945323, 0.2594891058979556, 0.2554272310808301, 0.25123310403432697, 0.25387974886689335, 0.2534021040191874, 0.38518220803234726, 0.24569500191137195, 0.23869768192525953, 0.2404964540619403, 0.24275641213171184, 0.24485456803813577, 0.24307452701032162, 0.34740671690087765, 0.25930940615944564, 0.25915410416200757, 0.26363554084673524, 0.27575151110067964, 0.2626050319522619, 0.3492409390164539, 0.26535477908328176, 0.26546524302102625, 0.2607652200385928, 0.2639623680151999, 0.2672341252909973, 0.2642421129858121, 0.2702181850327179, 0.29928989289328456, 0.27033332001883537, 0.2635538527974859, 0.26665147696621716, 0.27069883386138827, 0.2780768448719755, 0.26789853698574007, 0.38215262710582465, 0.2633851170539856, 0.26619974814821035]
Total Epoch List: [141]
Total Time List: [0.07489668997004628]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe6385e0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6938;  Loss pred: 0.6938; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6947;  Loss pred: 0.6947; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
Epoch 4/1000, LR 0.000060
Train loss: 0.6925;  Loss pred: 0.6925; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6884;  Loss pred: 0.6884; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6876;  Loss pred: 0.6876; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
Epoch 8/1000, LR 0.000180
Train loss: 0.6855;  Loss pred: 0.6855; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
Epoch 9/1000, LR 0.000210
Train loss: 0.6790;  Loss pred: 0.6790; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6738;  Loss pred: 0.6738; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6718;  Loss pred: 0.6718; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6648;  Loss pred: 0.6648; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4898 time: 0.08s
Epoch 13/1000, LR 0.000270
Train loss: 0.6585;  Loss pred: 0.6585; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4898 time: 0.08s
Epoch 14/1000, LR 0.000270
Train loss: 0.6550;  Loss pred: 0.6550; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4898 time: 0.09s
Epoch 15/1000, LR 0.000270
Train loss: 0.6491;  Loss pred: 0.6491; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4898 time: 0.08s
Epoch 16/1000, LR 0.000270
Train loss: 0.6380;  Loss pred: 0.6380; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.08s
Epoch 17/1000, LR 0.000270
Train loss: 0.6319;  Loss pred: 0.6319; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4898 time: 0.08s
Epoch 18/1000, LR 0.000270
Train loss: 0.6231;  Loss pred: 0.6231; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.08s
Epoch 19/1000, LR 0.000270
Train loss: 0.6156;  Loss pred: 0.6156; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4898 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6091;  Loss pred: 0.6091; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.6004;  Loss pred: 0.6004; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.5830;  Loss pred: 0.5830; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.5772;  Loss pred: 0.5772; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.5665;  Loss pred: 0.5665; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.08s
Epoch 25/1000, LR 0.000270
Train loss: 0.5539;  Loss pred: 0.5539; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4898 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.5430;  Loss pred: 0.5430; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5331;  Loss pred: 0.5331; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4898 time: 0.09s
Epoch 28/1000, LR 0.000270
Train loss: 0.5270;  Loss pred: 0.5270; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.4898 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5104;  Loss pred: 0.5104; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6900 score: 0.4898 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.4961;  Loss pred: 0.4961; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.5102 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.4898 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.4845;  Loss pred: 0.4845; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.4898 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.4734;  Loss pred: 0.4734; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6867 score: 0.4898 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.4631;  Loss pred: 0.4631; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6851 score: 0.4898 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4449;  Loss pred: 0.4449; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6834 score: 0.4898 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4334;  Loss pred: 0.4334; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6833 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6816 score: 0.4898 time: 0.08s
Epoch 36/1000, LR 0.000270
Train loss: 0.4177;  Loss pred: 0.4177; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6818 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6795 score: 0.4898 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4068;  Loss pred: 0.4068; Loss self: 0.0000; time: 0.26s
Val loss: 0.6802 score: 0.5306 time: 0.07s
Test loss: 0.6772 score: 0.5306 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.3929;  Loss pred: 0.3929; Loss self: 0.0000; time: 0.13s
Val loss: 0.6783 score: 0.5510 time: 0.07s
Test loss: 0.6747 score: 0.5306 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.3800;  Loss pred: 0.3800; Loss self: 0.0000; time: 0.13s
Val loss: 0.6763 score: 0.5714 time: 0.07s
Test loss: 0.6719 score: 0.5510 time: 0.08s
Epoch 40/1000, LR 0.000269
Train loss: 0.3697;  Loss pred: 0.3697; Loss self: 0.0000; time: 0.13s
Val loss: 0.6739 score: 0.5918 time: 0.08s
Test loss: 0.6687 score: 0.5918 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.3562;  Loss pred: 0.3562; Loss self: 0.0000; time: 0.13s
Val loss: 0.6713 score: 0.5918 time: 0.07s
Test loss: 0.6651 score: 0.6122 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3441;  Loss pred: 0.3441; Loss self: 0.0000; time: 0.13s
Val loss: 0.6684 score: 0.5918 time: 0.07s
Test loss: 0.6611 score: 0.6122 time: 0.20s
Epoch 43/1000, LR 0.000269
Train loss: 0.3281;  Loss pred: 0.3281; Loss self: 0.0000; time: 0.13s
Val loss: 0.6652 score: 0.6122 time: 0.07s
Test loss: 0.6567 score: 0.6531 time: 0.08s
Epoch 44/1000, LR 0.000269
Train loss: 0.3156;  Loss pred: 0.3156; Loss self: 0.0000; time: 0.13s
Val loss: 0.6616 score: 0.6122 time: 0.07s
Test loss: 0.6519 score: 0.6531 time: 0.08s
Epoch 45/1000, LR 0.000269
Train loss: 0.3032;  Loss pred: 0.3032; Loss self: 0.0000; time: 0.13s
Val loss: 0.6575 score: 0.6122 time: 0.07s
Test loss: 0.6464 score: 0.6939 time: 0.08s
Epoch 46/1000, LR 0.000269
Train loss: 0.2914;  Loss pred: 0.2914; Loss self: 0.0000; time: 0.13s
Val loss: 0.6532 score: 0.6327 time: 0.07s
Test loss: 0.6406 score: 0.7347 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2838;  Loss pred: 0.2838; Loss self: 0.0000; time: 0.13s
Val loss: 0.6486 score: 0.7143 time: 0.07s
Test loss: 0.6343 score: 0.7347 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.2695;  Loss pred: 0.2695; Loss self: 0.0000; time: 0.13s
Val loss: 0.6435 score: 0.7551 time: 0.07s
Test loss: 0.6274 score: 0.7755 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2555;  Loss pred: 0.2555; Loss self: 0.0000; time: 0.15s
Val loss: 0.6381 score: 0.7755 time: 0.15s
Test loss: 0.6201 score: 0.7755 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2497;  Loss pred: 0.2497; Loss self: 0.0000; time: 0.12s
Val loss: 0.6325 score: 0.7959 time: 0.07s
Test loss: 0.6124 score: 0.8571 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2343;  Loss pred: 0.2343; Loss self: 0.0000; time: 0.13s
Val loss: 0.6264 score: 0.7959 time: 0.08s
Test loss: 0.6042 score: 0.8776 time: 0.08s
Epoch 52/1000, LR 0.000269
Train loss: 0.2274;  Loss pred: 0.2274; Loss self: 0.0000; time: 0.13s
Val loss: 0.6200 score: 0.8163 time: 0.08s
Test loss: 0.5956 score: 0.9184 time: 0.09s
Epoch 53/1000, LR 0.000269
Train loss: 0.2146;  Loss pred: 0.2146; Loss self: 0.0000; time: 0.13s
Val loss: 0.6132 score: 0.8163 time: 0.08s
Test loss: 0.5866 score: 0.9184 time: 0.08s
Epoch 54/1000, LR 0.000269
Train loss: 0.2032;  Loss pred: 0.2032; Loss self: 0.0000; time: 0.16s
Val loss: 0.6060 score: 0.7959 time: 0.08s
Test loss: 0.5770 score: 0.9184 time: 0.08s
Epoch 55/1000, LR 0.000269
Train loss: 0.1958;  Loss pred: 0.1958; Loss self: 0.0000; time: 0.14s
Val loss: 0.5984 score: 0.8163 time: 0.08s
Test loss: 0.5670 score: 0.9184 time: 0.09s
Epoch 56/1000, LR 0.000269
Train loss: 0.1887;  Loss pred: 0.1887; Loss self: 0.0000; time: 0.13s
Val loss: 0.5904 score: 0.8367 time: 0.07s
Test loss: 0.5564 score: 0.9388 time: 0.08s
Epoch 57/1000, LR 0.000269
Train loss: 0.1780;  Loss pred: 0.1780; Loss self: 0.0000; time: 0.13s
Val loss: 0.5820 score: 0.8571 time: 0.07s
Test loss: 0.5453 score: 0.9388 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1669;  Loss pred: 0.1669; Loss self: 0.0000; time: 0.13s
Val loss: 0.5733 score: 0.8776 time: 0.07s
Test loss: 0.5335 score: 0.9388 time: 0.08s
Epoch 59/1000, LR 0.000268
Train loss: 0.1580;  Loss pred: 0.1580; Loss self: 0.0000; time: 0.13s
Val loss: 0.5640 score: 0.8776 time: 0.07s
Test loss: 0.5210 score: 0.9592 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1453;  Loss pred: 0.1453; Loss self: 0.0000; time: 0.13s
Val loss: 0.5547 score: 0.8776 time: 0.07s
Test loss: 0.5082 score: 0.9592 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.1378;  Loss pred: 0.1378; Loss self: 0.0000; time: 0.13s
Val loss: 0.5450 score: 0.8776 time: 0.07s
Test loss: 0.4948 score: 0.9796 time: 0.08s
Epoch 62/1000, LR 0.000268
Train loss: 0.1340;  Loss pred: 0.1340; Loss self: 0.0000; time: 0.13s
Val loss: 0.5351 score: 0.8776 time: 0.07s
Test loss: 0.4810 score: 0.9796 time: 0.08s
Epoch 63/1000, LR 0.000268
Train loss: 0.1248;  Loss pred: 0.1248; Loss self: 0.0000; time: 0.13s
Val loss: 0.5250 score: 0.8776 time: 0.07s
Test loss: 0.4669 score: 0.9796 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.1171;  Loss pred: 0.1171; Loss self: 0.0000; time: 0.13s
Val loss: 0.5146 score: 0.8776 time: 0.07s
Test loss: 0.4523 score: 0.9592 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.1069;  Loss pred: 0.1069; Loss self: 0.0000; time: 0.13s
Val loss: 0.5043 score: 0.8776 time: 0.07s
Test loss: 0.4377 score: 0.9592 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.1026;  Loss pred: 0.1026; Loss self: 0.0000; time: 0.13s
Val loss: 0.4940 score: 0.8980 time: 0.07s
Test loss: 0.4227 score: 0.9592 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0939;  Loss pred: 0.0939; Loss self: 0.0000; time: 0.13s
Val loss: 0.4838 score: 0.8980 time: 0.07s
Test loss: 0.4074 score: 0.9592 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0894;  Loss pred: 0.0894; Loss self: 0.0000; time: 0.13s
Val loss: 0.4736 score: 0.8980 time: 0.07s
Test loss: 0.3920 score: 0.9592 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0823;  Loss pred: 0.0823; Loss self: 0.0000; time: 0.13s
Val loss: 0.4639 score: 0.9184 time: 0.07s
Test loss: 0.3765 score: 0.9592 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0778;  Loss pred: 0.0778; Loss self: 0.0000; time: 0.13s
Val loss: 0.4544 score: 0.9184 time: 0.07s
Test loss: 0.3615 score: 0.9592 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0703;  Loss pred: 0.0703; Loss self: 0.0000; time: 0.13s
Val loss: 0.4450 score: 0.9184 time: 0.07s
Test loss: 0.3462 score: 0.9592 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0654;  Loss pred: 0.0654; Loss self: 0.0000; time: 0.13s
Val loss: 0.4360 score: 0.9184 time: 0.07s
Test loss: 0.3310 score: 0.9592 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0598;  Loss pred: 0.0598; Loss self: 0.0000; time: 0.13s
Val loss: 0.4273 score: 0.8980 time: 0.07s
Test loss: 0.3162 score: 0.9592 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0568;  Loss pred: 0.0568; Loss self: 0.0000; time: 0.13s
Val loss: 0.4186 score: 0.8980 time: 0.07s
Test loss: 0.3013 score: 0.9592 time: 0.08s
Epoch 75/1000, LR 0.000267
Train loss: 0.0525;  Loss pred: 0.0525; Loss self: 0.0000; time: 0.13s
Val loss: 0.4104 score: 0.8980 time: 0.07s
Test loss: 0.2867 score: 0.9592 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0477;  Loss pred: 0.0477; Loss self: 0.0000; time: 0.13s
Val loss: 0.4026 score: 0.8980 time: 0.07s
Test loss: 0.2724 score: 0.9592 time: 0.08s
Epoch 77/1000, LR 0.000267
Train loss: 0.0450;  Loss pred: 0.0450; Loss self: 0.0000; time: 0.13s
Val loss: 0.3952 score: 0.8980 time: 0.07s
Test loss: 0.2586 score: 0.9592 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0406;  Loss pred: 0.0406; Loss self: 0.0000; time: 0.13s
Val loss: 0.3883 score: 0.8980 time: 0.07s
Test loss: 0.2451 score: 0.9592 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0391;  Loss pred: 0.0391; Loss self: 0.0000; time: 0.13s
Val loss: 0.3821 score: 0.8776 time: 0.08s
Test loss: 0.2320 score: 0.9592 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0344;  Loss pred: 0.0344; Loss self: 0.0000; time: 0.13s
Val loss: 0.3769 score: 0.8776 time: 0.07s
Test loss: 0.2195 score: 0.9592 time: 0.08s
Epoch 81/1000, LR 0.000267
Train loss: 0.0342;  Loss pred: 0.0342; Loss self: 0.0000; time: 0.14s
Val loss: 0.3722 score: 0.8776 time: 0.08s
Test loss: 0.2074 score: 0.9592 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0290;  Loss pred: 0.0290; Loss self: 0.0000; time: 0.13s
Val loss: 0.3685 score: 0.8776 time: 0.07s
Test loss: 0.1962 score: 0.9592 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0271;  Loss pred: 0.0271; Loss self: 0.0000; time: 0.13s
Val loss: 0.3651 score: 0.8776 time: 0.07s
Test loss: 0.1856 score: 0.9592 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0267;  Loss pred: 0.0267; Loss self: 0.0000; time: 0.13s
Val loss: 0.3623 score: 0.8776 time: 0.07s
Test loss: 0.1758 score: 0.9592 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.13s
Val loss: 0.3601 score: 0.8776 time: 0.07s
Test loss: 0.1667 score: 0.9592 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0220;  Loss pred: 0.0220; Loss self: 0.0000; time: 0.13s
Val loss: 0.3582 score: 0.8776 time: 0.07s
Test loss: 0.1580 score: 0.9592 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0211;  Loss pred: 0.0211; Loss self: 0.0000; time: 0.13s
Val loss: 0.3567 score: 0.8776 time: 0.07s
Test loss: 0.1499 score: 0.9592 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0188;  Loss pred: 0.0188; Loss self: 0.0000; time: 0.13s
Val loss: 0.3559 score: 0.8776 time: 0.07s
Test loss: 0.1426 score: 0.9592 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0172;  Loss pred: 0.0172; Loss self: 0.0000; time: 0.13s
Val loss: 0.3559 score: 0.8776 time: 0.07s
Test loss: 0.1358 score: 0.9592 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0162;  Loss pred: 0.0162; Loss self: 0.0000; time: 0.13s
Val loss: 0.3565 score: 0.8776 time: 0.07s
Test loss: 0.1296 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.13s
Val loss: 0.3582 score: 0.8776 time: 0.07s
Test loss: 0.1241 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0144;  Loss pred: 0.0144; Loss self: 0.0000; time: 0.13s
Val loss: 0.3604 score: 0.8776 time: 0.07s
Test loss: 0.1191 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.13s
Val loss: 0.3633 score: 0.8776 time: 0.07s
Test loss: 0.1148 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.13s
Val loss: 0.3674 score: 0.8776 time: 0.07s
Test loss: 0.1111 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.13s
Val loss: 0.3718 score: 0.8776 time: 0.07s
Test loss: 0.1079 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.13s
Val loss: 0.3771 score: 0.8776 time: 0.07s
Test loss: 0.1054 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.13s
Val loss: 0.3822 score: 0.8776 time: 0.07s
Test loss: 0.1033 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.13s
Val loss: 0.3882 score: 0.8776 time: 0.07s
Test loss: 0.1017 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.13s
Val loss: 0.3941 score: 0.8776 time: 0.07s
Test loss: 0.1004 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.13s
Val loss: 0.4002 score: 0.8776 time: 0.07s
Test loss: 0.0993 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.13s
Val loss: 0.4064 score: 0.8776 time: 0.07s
Test loss: 0.0986 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.13s
Val loss: 0.4132 score: 0.8776 time: 0.07s
Test loss: 0.0983 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.13s
Val loss: 0.4196 score: 0.8776 time: 0.07s
Test loss: 0.0981 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.13s
Val loss: 0.4258 score: 0.8776 time: 0.07s
Test loss: 0.0983 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.13s
Val loss: 0.4323 score: 0.8776 time: 0.07s
Test loss: 0.0986 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.4385 score: 0.8776 time: 0.07s
Test loss: 0.0990 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.12s
Val loss: 0.4451 score: 0.8776 time: 0.07s
Test loss: 0.0996 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.12s
Val loss: 0.4516 score: 0.8776 time: 0.07s
Test loss: 0.1003 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.12s
Val loss: 0.4576 score: 0.8776 time: 0.07s
Test loss: 0.1010 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 088,   Train_Loss: 0.0172,   Val_Loss: 0.3559,   Val_Precision: 1.0000,   Val_Recall: 0.7600,   Val_accuracy: 0.8636,   Val_Score: 0.8776,   Val_Loss: 0.3559,   Test_Precision: 1.0000,   Test_Recall: 0.9167,   Test_accuracy: 0.9565,   Test_Score: 0.9592,   Test_loss: 0.1358


[0.07083901192527264, 0.07123459305148572, 0.0728723609354347, 0.06717895099427551, 0.06833636702504009, 0.06857296102680266, 0.06849951494950801, 0.07125885400455445, 0.06915027694776654, 0.06812530697789043, 0.06815336598083377, 0.0682296110317111, 0.06875261489767581, 0.06872760003898293, 0.06877774698659778, 0.06877460691612214, 0.07478607399389148, 0.06874420191161335, 0.07009132008533925, 0.06937723106238991, 0.06938090501353145, 0.0693196589127183, 0.06954058597330004, 0.06822549202479422, 0.07430438103619963, 0.06917668005917221, 0.0686241330113262, 0.07121087296400219, 0.06846189498901367, 0.06806643004529178, 0.06828894698992372, 0.07085076696239412, 0.06805825501214713, 0.06862531299702823, 0.06863353203516454, 0.0677074680570513, 0.07268523098900914, 0.06834569794591516, 0.06869031197857112, 0.08459324296563864, 0.06816331099253148, 0.06865695700980723, 0.0687137299682945, 0.06909489503595978, 0.07375112897716463, 0.06798539694864303, 0.06736822496168315, 0.06742447300348431, 0.06874671299010515, 0.06839104497339576, 0.06762037996668369, 0.06765997793991119, 0.06799854699056596, 0.06824702699668705, 0.06722657394129783, 0.06821557495277375, 0.06745417392812669, 0.06793526699766517, 0.06761741102673113, 0.06755038595292717, 0.06925623200368136, 0.07224936399143189, 0.07029565493576229, 0.06720096501521766, 0.06756321305874735, 0.06782709097024053, 0.06828747305553406, 0.06740411592181772, 0.06827319099102169, 0.06861812900751829, 0.06824302510358393, 0.06770418700762093, 0.06776656105648726, 0.06730132992379367, 0.06752969906665385, 0.06726748798973858, 0.06950179999694228, 0.06993326998781413, 0.06983286305330694, 0.0705082630738616, 0.07423675700556487, 0.06943969603162259, 0.07159186492208391, 0.06978749297559261, 0.06910264398902655, 0.06896096502896398, 0.07004379597492516, 0.06974822003394365, 0.07564233406446874, 0.19399107701610774, 0.07370182301383466, 0.07365404104348272, 0.07469843502622098, 0.07527633907739073, 0.07472177699673921, 0.07494371000211686, 0.06954243197105825, 0.07100820797495544, 0.07694649300538003, 0.07104502397123724, 0.07024088501930237, 0.07089372898917645, 0.0732692830497399, 0.1907073080074042, 0.07049184700008482, 0.07456855697091669, 0.07162670197430998, 0.07039938995148987, 0.07097803498618305, 0.07039707899093628, 0.20132703299168497, 0.0654451900627464, 0.0665014690021053, 0.06673909199889749, 0.06807012599892914, 0.067712222924456, 0.06752297503408045, 0.0726597469765693, 0.06984604394529015, 0.07001034799031913, 0.07163795304950327, 0.07375469210091978, 0.07174312393181026, 0.06938905001152307, 0.0700039790244773, 0.06964202201925218, 0.07014602702111006, 0.07202155096456409, 0.0707657829625532, 0.07107859791722149, 0.07298957090824842, 0.0756541530136019, 0.07098619197495282, 0.07018235290888697, 0.0724826620426029, 0.07411599392071366, 0.07161576999351382, 0.07286076701711863, 0.07120346394367516, 0.07074075902346522, 0.07420500391162932, 0.08305698004551232, 0.07881589094176888, 0.0805877490201965, 0.08059498807415366, 0.08101418009027839, 0.08170179696753621, 0.0807595249498263, 0.08045146707445383, 0.08010452601592988, 0.0798953790217638, 0.07981061900500208, 0.08033479400910437, 0.08243028295692056, 0.09620977099984884, 0.08288138010539114, 0.08246160193812102, 0.08223710802849382, 0.08264942199457437, 0.08249320101458579, 0.08450207393616438, 0.08270994201302528, 0.08641965291462839, 0.08365961199160665, 0.08331946993712336, 0.08320568001363426, 0.08323263307102025, 0.09332352399360389, 0.0832560210255906, 0.08118511294014752, 0.08134482300374657, 0.0808957819826901, 0.08042926294729114, 0.08185753598809242, 0.08386055694427341, 0.08040585496928543, 0.08064479799941182, 0.0844548400491476, 0.08495077909901738, 0.08487873605918139, 0.08863173797726631, 0.0857829280430451, 0.20761745399795473, 0.08496561704669148, 0.08536973199807107, 0.08495418494567275, 0.08791964699048549, 0.08523767406586558, 0.08483420591801405, 0.07990923500619829, 0.08032452908810228, 0.08555381000041962, 0.09114239492919296, 0.0834412220865488, 0.08524990803562105, 0.09045197197701782, 0.0812553649302572, 0.08095485402736813, 0.08099035790655762, 0.08215852698776871, 0.08136208890937269, 0.08660187502391636, 0.08043893706053495, 0.08096692699473351, 0.08038991095963866, 0.08718398003838956, 0.08090849593281746, 0.08038316597230732, 0.08010529691819102, 0.08093408204149455, 0.08127865509595722, 0.08073717600200325, 0.0807543839327991, 0.08050749602261931, 0.08110801596194506, 0.08176907699089497, 0.08069482096470892, 0.08026396494824439, 0.0805984390899539, 0.08414783608168364, 0.08285219105891883, 0.08263104094658047, 0.08854648901615292, 0.08857876900583506, 0.08036477607674897, 0.07993051200173795, 0.08022374799475074, 0.07955306302756071, 0.07956153305713087, 0.0804729099618271, 0.07956212502904236, 0.0797456520376727, 0.08013515290804207, 0.0809233330655843, 0.08084596693515778, 0.08001628401689231, 0.08129825594369322, 0.08018370694480836, 0.07995678298175335, 0.08168154105078429, 0.08172759099397808, 0.08013980300165713, 0.08065681997686625, 0.08147047192323953, 0.08054951298981905, 0.07940651208627969, 0.07830866903532296, 0.08143022703006864, 0.08021659206133336, 0.08106147707439959]
[0.0014456941209239314, 0.0014537672051323615, 0.0014871910394986673, 0.0013709989998831737, 0.0013946197352048997, 0.0013994481842204624, 0.001397949284683837, 0.0014542623266235602, 0.001411230141791154, 0.0013903123873038863, 0.0013908850200170157, 0.0013924410414634918, 0.001403114589748486, 0.001402604082428223, 0.0014036274895224037, 0.0014035634064514721, 0.0015262464080386016, 0.0014029428961553744, 0.0014304351037824337, 0.0014158618584161206, 0.0014159368370108459, 0.0014146869165860877, 0.001419195632108164, 0.0013923569800978412, 0.0015164159395142781, 0.0014117689807994329, 0.0014004925104352285, 0.0014532831217143305, 0.0013971815303880342, 0.0013891108172508528, 0.0013936519793861983, 0.0014459340196406963, 0.0013889439798397372, 0.0014005165917760863, 0.0014006843272482558, 0.001381785062388802, 0.0014833720610001866, 0.001394810162161534, 0.0014018431016034922, 0.001726392713584462, 0.0013910879794394179, 0.0014011623879552496, 0.0014023210197611122, 0.0014100998986930568, 0.001505125081166625, 0.0013874570805845515, 0.001374861733911901, 0.0013760096531323328, 0.0014029941426552072, 0.0013957356117019544, 0.001380007754422116, 0.0013808158763247182, 0.0013877254487870603, 0.001392796469320144, 0.0013719708967611802, 0.0013921545908729337, 0.0013766157944515652, 0.0013864340203605136, 0.0013799471638108395, 0.001378579305161779, 0.001413392489871048, 0.0014744768161516712, 0.0014346052027706588, 0.001371448265616687, 0.0013788410828315786, 0.0013842263463314396, 0.001393621899092532, 0.0013755942024860758, 0.0013933304283881979, 0.0014003699797452713, 0.001392714798032325, 0.0013817181021963454, 0.001382991041969128, 0.0013734965290570138, 0.0013781571238092622, 0.0013728058773416038, 0.0014184040815702506, 0.0014272095915880433, 0.0014251604704756517, 0.0014389441443645225, 0.0015150358572564259, 0.0014171366537065835, 0.0014610584677976308, 0.0014242345505222982, 0.0014102580405923786, 0.001407366633244163, 0.0014294652239780646, 0.0014234330619172174, 0.0015437211033565048, 0.0039590015717573005, 0.0015041188370170338, 0.0015031436947649534, 0.001524457857677979, 0.0015362518179059333, 0.0015249342244232492, 0.0015294634694309563, 0.001419233305531801, 0.0014491471015297029, 0.0015703365919465314, 0.0014498984483925967, 0.0014334874493735178, 0.0014468107956974786, 0.0014952914908110183, 0.003891985877702127, 0.0014386091224507106, 0.0015218072851207486, 0.0014617694280471426, 0.0014367222439079564, 0.0014485313262486337, 0.0014366750814476792, 0.004108714959013979, 0.0013356161237295186, 0.0013571728367776591, 0.0013620222856917856, 0.001389186244876105, 0.001381882100499102, 0.001378019898654703, 0.0014828519791136592, 0.0014254294682712275, 0.0014287826120473292, 0.0014619990418265974, 0.0015051977979779548, 0.0014641453863634747, 0.0014161030614596544, 0.001428652633152598, 0.0014212657554949425, 0.001431551571859389, 0.0014698275707053896, 0.0014441996522970041, 0.001450583630963704, 0.0014895830797601718, 0.0015439623064000387, 0.0014486977954072003, 0.0014322929165078973, 0.0014792380008694468, 0.0015125713045043604, 0.0014615463263982413, 0.0014869544289207884, 0.0014531319172178603, 0.0014436889596625554, 0.0015143878349312106, 0.0016950404090920882, 0.0016084875702401813, 0.0016446479391876835, 0.0016447956749827278, 0.001653350614087314, 0.0016673836115823717, 0.0016481535704046184, 0.0016418666749888537, 0.0016347862452230587, 0.0016305179392196694, 0.0016287881429592262, 0.0016394855920225382, 0.0016822506725902157, 0.0019634647142826294, 0.0016914567368447172, 0.0016828898354718576, 0.0016783083271121187, 0.0016867228978484565, 0.0016835347145833836, 0.0017245321211462117, 0.0016879580002658221, 0.0017636663860128242, 0.0017073390202368705, 0.0017003973456555788, 0.0016980751023190667, 0.001698625164714699, 0.0019045617141551813, 0.0016991024699100122, 0.0016568390395948474, 0.0016600984286478891, 0.001650934326177349, 0.0016414135295365537, 0.0016705619589406618, 0.0017114399376382328, 0.0016409358156997027, 0.001645812204069629, 0.0017235681642683185, 0.0017336893693677016, 0.0017322191032486, 0.001808810979127884, 0.0017506720008784715, 0.004237090897917443, 0.0017339921846263567, 0.0017422394285320627, 0.001733758876442301, 0.0017942785100099078, 0.0017395443686911342, 0.0017313103248574296, 0.00163080071441221, 0.0016392761038388221, 0.0017459961224575431, 0.0018600488761059788, 0.0017028820833989552, 0.0017397940415432866, 0.0018459586117758739, 0.0016582727536787183, 0.0016521398781095536, 0.0016528644470726044, 0.001676704632403443, 0.0016604507940688304, 0.0017673852045697216, 0.0016416109604190808, 0.001652386265198643, 0.0016406104277477277, 0.0017792648987426441, 0.0016511937945472952, 0.0016404727749450474, 0.0016348019779222657, 0.001651715960030501, 0.0016587480631828004, 0.0016476974694286377, 0.0016480486516897775, 0.001643010122910598, 0.0016552656318764298, 0.0016687566732835708, 0.001646833080912427, 0.0016380401009845795, 0.0016448661038766103, 0.001717302777177217, 0.0016908610420187516, 0.0016863477744200096, 0.001807071204411284, 0.0018077299797109195, 0.0016400974709540606, 0.0016312349388109787, 0.0016372193468316477, 0.0016235318985216472, 0.001623704756267977, 0.0016423042849352469, 0.0016237168373273952, 0.0016274622864831164, 0.0016354112838375934, 0.0016514965931751899, 0.0016499176925542404, 0.001632985388099843, 0.001659148080483535, 0.0016364021825471095, 0.0016317710812602723, 0.00166697022552621, 0.001667910020285267, 0.0016355061837072884, 0.0016460575505482908, 0.001662662692311011, 0.0016438676120371235, 0.0016205410629852998, 0.0015981361027616933, 0.0016618413679605844, 0.0016370733073741502, 0.001654315858661216]
[691.7092526881883, 687.8680413683927, 672.4085698748564, 729.3951345589694, 717.0413373313396, 714.5673639621264, 715.3335324508299, 687.6338482354516, 708.6016450377012, 719.2628139775222, 718.9666907101827, 718.1632616552108, 712.7001652653715, 712.9595675130042, 712.4397373695343, 712.4722655232424, 655.2021971898447, 712.7873862438739, 699.0879889313021, 706.2835926088637, 706.2461925286715, 706.8701832722062, 704.6244910678988, 718.2066196340896, 659.4496760040053, 708.3311884595571, 714.0345218192076, 688.0971677565306, 715.7266097858262, 719.8849707175053, 717.5392528344321, 691.594489386516, 719.9714419838477, 714.0222442719046, 713.9367383117445, 723.7015562110797, 674.1397025677661, 716.9434430061094, 713.3465926794192, 579.2424818126852, 718.8617936321907, 713.6931511980738, 713.1034805214227, 709.1696133918202, 664.3966089681386, 720.7430154010159, 727.3458671038104, 726.7390877117841, 712.7613505979939, 716.4680700384251, 724.6336093370389, 724.2095178262826, 720.6036329981905, 717.9799935076825, 728.8784349294186, 718.3110313725734, 726.4190953136591, 721.2748571619518, 724.6654264924292, 725.384456487723, 707.5175559276076, 678.206662217967, 697.0558855277368, 729.1561957317718, 725.2467397812131, 722.4252035443918, 717.554740386297, 726.9585741148994, 717.7048456171292, 714.0969989815842, 718.0220971392233, 723.7366279058111, 723.0704824929176, 728.068822049779, 725.6066690247727, 728.4351098033388, 705.0177118025108, 700.6679368566384, 701.6753696980151, 694.9540077121115, 660.0503844251563, 705.648250212466, 684.4353063484032, 702.1315412080671, 709.0900893427633, 710.5469011261622, 699.5623140919064, 702.5268885163474, 647.7854049061744, 252.58893735577004, 664.8410852849888, 665.2723911111971, 655.970904648803, 650.9349498203369, 655.7659891056702, 653.8240500585832, 704.6057868725748, 690.0610703664325, 636.8061504320146, 689.7034762045794, 697.5994107496607, 691.17537896026, 668.765927008398, 256.93823960903256, 695.1158479354505, 657.1134267639246, 684.1024178046702, 696.0287586833416, 690.3544175256274, 696.0516075717974, 243.3850997149685, 748.7181250909445, 736.8258285910762, 734.202377233563, 719.8458836519687, 723.6507366575082, 725.6789259547368, 674.376144136603, 701.5429540774179, 699.8965353918196, 683.9949763240725, 664.3645116564581, 682.9922829478832, 706.1632922177611, 699.9602120169035, 703.5981808002962, 698.5427697174314, 680.3519133336755, 692.4250386084062, 689.377695056192, 671.3287856095972, 647.6842056666773, 690.2750892355157, 698.1812089374291, 676.0237361480933, 661.1258570237653, 684.206844448337, 672.5155664157015, 688.1687671650496, 692.6699780496608, 660.3328268583351, 589.9564368118093, 621.7020376792086, 608.0328659846283, 607.9782523811057, 604.8323879276036, 599.7420108087696, 606.739576916065, 609.0628521994873, 611.7007669486201, 613.3020532595785, 613.9533887956558, 609.947415741762, 594.4417299356866, 509.303779551424, 591.2063715359479, 594.2159604996453, 595.8380732822255, 592.8656101577658, 593.9883456739205, 579.8674247571272, 592.4318021197912, 567.000657227885, 585.7067566236865, 588.0978363997949, 588.9021037021841, 588.7114007097381, 525.0551833357505, 588.5460222142823, 603.558931255346, 602.3739211743465, 605.7176134410187, 609.2309963366428, 598.6009645724969, 584.3032980637278, 609.4083573729515, 607.6027371332417, 580.191732901098, 576.804598141311, 577.2941760800364, 552.8493643278022, 571.209226798743, 236.01098586096094, 576.703868025496, 573.9739232296894, 576.7814738183287, 557.327078500471, 574.8631756673265, 577.5972023284435, 613.1957088088659, 610.0253628160755, 572.7389580868423, 537.6202812979328, 587.2397212636112, 574.7806787020311, 541.7239550338383, 603.0371045906629, 605.2756266280801, 605.0102909352938, 596.407966361116, 602.2460909844626, 565.8076108221437, 609.1577262280911, 605.1853740625132, 609.529223444487, 562.0298589078398, 605.6224310570209, 609.580369313656, 611.6948801780503, 605.4309725151131, 602.8643060364473, 606.9075291757073, 606.7782034072112, 608.6389767510967, 604.1326423641066, 599.2485399517983, 607.2260823458505, 610.4856647886265, 607.9522203316162, 582.3084975403874, 591.4146551073651, 592.9974914835897, 553.3816252280909, 553.179961179774, 609.7198597704624, 613.0324799988092, 610.7917072536452, 615.9410855497069, 615.8755131680846, 608.9005607383093, 615.8709308243546, 614.4535626450439, 611.4669807422622, 605.5113913843361, 606.0908398720777, 612.3753508680254, 602.7189566518765, 611.0967161162482, 612.8310591383112, 599.8907387109037, 599.5527263688765, 611.4315005115096, 607.5121733543925, 601.4449019783167, 608.3214929703336, 617.0778530954578, 625.7289340200304, 601.742151374654, 610.8461945445744, 604.4794860452268]
Elapsed: 0.07745322392554954~0.016831131043462934
Time per graph: 0.0015806780392969293~0.0003434924702747537
Speed: 647.6820496133536~76.15179969645635
Total Time: 0.0820
best val loss: 0.35587644577026367 test_score: 0.9592

Testing...
Test loss: 0.3765 score: 0.9592 time: 0.08s
test Score 0.9592
Epoch Time List: [0.44224406115245074, 0.249535869108513, 0.26170355489011854, 0.2399571939604357, 0.24755443399772048, 0.24864490400068462, 0.2480351789854467, 0.2546479169977829, 0.2509292470058426, 0.24570817907806486, 0.246507802978158, 0.24682019103784114, 0.24808320601005107, 0.25360741396434605, 0.252684106817469, 0.248503508977592, 0.2627014520112425, 0.2477286010980606, 0.2525089009432122, 0.24984656600281596, 0.24886299401987344, 0.2488516381708905, 0.24972213001456112, 0.24695961398538202, 0.2630372919375077, 0.24908673495519906, 0.24922632507514209, 0.2532558188540861, 0.25215502199716866, 0.2488721840782091, 0.24734657304361463, 0.2494230429874733, 0.2467502240324393, 0.25659005099441856, 0.25268325221259147, 0.2556317129638046, 0.25258705811575055, 0.24776713398750871, 0.24759677704423666, 0.2665042649023235, 0.2811292731203139, 0.2505253099370748, 0.24857534584589303, 0.2487183550838381, 0.2586246069986373, 0.24676986085250974, 0.24549207603558898, 0.24538940691854805, 0.25147364707663655, 0.2538037330377847, 0.2542843701085076, 0.25100134685635567, 0.2557753960136324, 0.24843529309146106, 0.24727067607454956, 0.252139171003364, 0.25343468715436757, 0.25339331093709916, 0.24922359711490571, 0.2514854399487376, 0.2501105881528929, 0.26506952883210033, 0.25478637393098325, 0.24737167998682708, 0.24662180105224252, 0.2516180230304599, 0.24860082915984094, 0.24786741996649653, 0.24913719296455383, 0.2549196348991245, 0.2495561259565875, 0.25303120317403227, 0.24859604891389608, 0.2521776770008728, 0.24764476099517196, 0.2519747519399971, 0.25386614992748946, 0.2569857829948887, 0.2580515280133113, 0.2614923521177843, 0.2706689011538401, 0.25625487905927, 0.2525614529149607, 0.3519961411366239, 0.25845956488046795, 0.25245977099984884, 0.2540282600093633, 0.2628869339823723, 0.26347757293842733, 0.3916914751753211, 0.263379154028371, 0.26936172996647656, 0.268867974053137, 0.2719201899599284, 0.2705140550388023, 0.26706793485209346, 0.3631450969260186, 0.2526871010195464, 0.25897971517406404, 0.25263387395534664, 0.2520221760496497, 0.2564130541868508, 0.2545208039227873, 0.38438642711844295, 0.252117482945323, 0.2594891058979556, 0.2554272310808301, 0.25123310403432697, 0.25387974886689335, 0.2534021040191874, 0.38518220803234726, 0.24569500191137195, 0.23869768192525953, 0.2404964540619403, 0.24275641213171184, 0.24485456803813577, 0.24307452701032162, 0.34740671690087765, 0.25930940615944564, 0.25915410416200757, 0.26363554084673524, 0.27575151110067964, 0.2626050319522619, 0.3492409390164539, 0.26535477908328176, 0.26546524302102625, 0.2607652200385928, 0.2639623680151999, 0.2672341252909973, 0.2642421129858121, 0.2702181850327179, 0.29928989289328456, 0.27033332001883537, 0.2635538527974859, 0.26665147696621716, 0.27069883386138827, 0.2780768448719755, 0.26789853698574007, 0.38215262710582465, 0.2633851170539856, 0.26619974814821035, 0.26841764396522194, 0.34806961205322295, 0.2677532029338181, 0.26678762794472277, 0.2697834951104596, 0.27010902005713433, 0.2705225980607793, 0.26704704901203513, 0.30456369288731366, 0.26327331305947155, 0.2644641640363261, 0.26671540294773877, 0.26858350599650294, 0.2850859249010682, 0.26899229595437646, 0.4014795790426433, 0.270622176816687, 0.26976390497293323, 0.270330399973318, 0.27304510411340743, 0.27387108688708395, 0.27318970195483416, 0.39511913002934307, 0.2746757488930598, 0.2743414060678333, 0.27188694092910737, 0.2986939859110862, 0.27970561699476093, 0.2663534199818969, 0.3598260418511927, 0.2685254050884396, 0.2664305721409619, 0.2680093130329624, 0.2761829470982775, 0.2697136470815167, 0.26452869491185993, 0.406242112047039, 0.2790846450952813, 0.2793474509380758, 0.28836362692527473, 0.2865397719433531, 0.40504834498278797, 0.2808203111635521, 0.2784998760325834, 0.2830941629363224, 0.28210411698091775, 0.2855651769787073, 0.2782476160209626, 0.3796145759988576, 0.2667112360941246, 0.28978834801819175, 0.29375479207374156, 0.28722066013142467, 0.315053747035563, 0.3028933899477124, 0.27207723702304065, 0.2703495160676539, 0.271157321985811, 0.2714483600575477, 0.27221254992764443, 0.2773242798866704, 0.2687206059927121, 0.27029368304647505, 0.26785375899635255, 0.2772277129115537, 0.2760780770331621, 0.26912531803827733, 0.2680695998715237, 0.268421080079861, 0.27012002910487354, 0.27019013511016965, 0.2696740000974387, 0.2691614639479667, 0.26900196191854775, 0.2718922400381416, 0.2711444030283019, 0.26843557006213814, 0.2688676880206913, 0.28525172313675284, 0.27496259519830346, 0.2911281898850575, 0.2879273931030184, 0.2827902880962938, 0.2745878469431773, 0.26895408192649484, 0.2681942998897284, 0.2659260290674865, 0.2658961539855227, 0.26911885803565383, 0.26793092500884086, 0.2678511789999902, 0.2683733421145007, 0.2702525488566607, 0.27006298187188804, 0.26780972396954894, 0.2709844179917127, 0.26998035702854395, 0.2685800939798355, 0.2696452259551734, 0.270225789048709, 0.2688569070305675, 0.26992326008621603, 0.27132229995913804, 0.27135105803608894, 0.27901568613015115, 0.2584122580010444, 0.2665644569788128, 0.26632986404001713, 0.26875867682974786]
Total Epoch List: [141, 109]
Total Time List: [0.07489668997004628, 0.08197484503034502]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe4bc520>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6863;  Loss pred: 0.6863; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6881;  Loss pred: 0.6881; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6871;  Loss pred: 0.6871; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6848;  Loss pred: 0.6848; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6851;  Loss pred: 0.6851; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6804;  Loss pred: 0.6804; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6791;  Loss pred: 0.6791; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6754;  Loss pred: 0.6754; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6682;  Loss pred: 0.6682; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6632;  Loss pred: 0.6632; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6593;  Loss pred: 0.6593; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6534;  Loss pred: 0.6534; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6439;  Loss pred: 0.6439; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6392;  Loss pred: 0.6392; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6303;  Loss pred: 0.6303; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6231;  Loss pred: 0.6231; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6131;  Loss pred: 0.6131; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6057;  Loss pred: 0.6057; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.5947;  Loss pred: 0.5947; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.5890;  Loss pred: 0.5890; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.5730;  Loss pred: 0.5730; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.5622;  Loss pred: 0.5622; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5528;  Loss pred: 0.5528; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5384;  Loss pred: 0.5384; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5306;  Loss pred: 0.5306; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5120;  Loss pred: 0.5120; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5022;  Loss pred: 0.5022; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.4897;  Loss pred: 0.4897; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.4742;  Loss pred: 0.4742; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.4591;  Loss pred: 0.4591; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.4428;  Loss pred: 0.4428; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.4274;  Loss pred: 0.4274; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 33/1000, LR 0.000270
Train loss: 0.4110;  Loss pred: 0.4110; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 34/1000, LR 0.000270
Train loss: 0.3995;  Loss pred: 0.3995; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.18s
     INFO: Early stopping counter 8 of 20
Epoch 35/1000, LR 0.000270
Train loss: 0.3844;  Loss pred: 0.3844; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 36/1000, LR 0.000270
Train loss: 0.3703;  Loss pred: 0.3703; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 37/1000, LR 0.000270
Train loss: 0.3496;  Loss pred: 0.3496; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 38/1000, LR 0.000270
Train loss: 0.3369;  Loss pred: 0.3369; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 39/1000, LR 0.000269
Train loss: 0.3170;  Loss pred: 0.3170; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 40/1000, LR 0.000269
Train loss: 0.3019;  Loss pred: 0.3019; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 41/1000, LR 0.000269
Train loss: 0.2874;  Loss pred: 0.2874; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6973 score: 0.5000 time: 0.19s
     INFO: Early stopping counter 15 of 20
Epoch 42/1000, LR 0.000269
Train loss: 0.2712;  Loss pred: 0.2712; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 43/1000, LR 0.000269
Train loss: 0.2552;  Loss pred: 0.2552; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 44/1000, LR 0.000269
Train loss: 0.2432;  Loss pred: 0.2432; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.5000 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 45/1000, LR 0.000269
Train loss: 0.2264;  Loss pred: 0.2264; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5000 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 46/1000, LR 0.000269
Train loss: 0.2129;  Loss pred: 0.2129; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 025,   Train_Loss: 0.5120,   Val_Loss: 0.6917,   Val_Precision: 0.5102,   Val_Recall: 1.0000,   Val_accuracy: 0.6757,   Val_Score: 0.5102,   Val_Loss: 0.6917,   Test_Precision: 0.5000,   Test_Recall: 1.0000,   Test_accuracy: 0.6667,   Test_Score: 0.5000,   Test_loss: 0.6928


[0.07083901192527264, 0.07123459305148572, 0.0728723609354347, 0.06717895099427551, 0.06833636702504009, 0.06857296102680266, 0.06849951494950801, 0.07125885400455445, 0.06915027694776654, 0.06812530697789043, 0.06815336598083377, 0.0682296110317111, 0.06875261489767581, 0.06872760003898293, 0.06877774698659778, 0.06877460691612214, 0.07478607399389148, 0.06874420191161335, 0.07009132008533925, 0.06937723106238991, 0.06938090501353145, 0.0693196589127183, 0.06954058597330004, 0.06822549202479422, 0.07430438103619963, 0.06917668005917221, 0.0686241330113262, 0.07121087296400219, 0.06846189498901367, 0.06806643004529178, 0.06828894698992372, 0.07085076696239412, 0.06805825501214713, 0.06862531299702823, 0.06863353203516454, 0.0677074680570513, 0.07268523098900914, 0.06834569794591516, 0.06869031197857112, 0.08459324296563864, 0.06816331099253148, 0.06865695700980723, 0.0687137299682945, 0.06909489503595978, 0.07375112897716463, 0.06798539694864303, 0.06736822496168315, 0.06742447300348431, 0.06874671299010515, 0.06839104497339576, 0.06762037996668369, 0.06765997793991119, 0.06799854699056596, 0.06824702699668705, 0.06722657394129783, 0.06821557495277375, 0.06745417392812669, 0.06793526699766517, 0.06761741102673113, 0.06755038595292717, 0.06925623200368136, 0.07224936399143189, 0.07029565493576229, 0.06720096501521766, 0.06756321305874735, 0.06782709097024053, 0.06828747305553406, 0.06740411592181772, 0.06827319099102169, 0.06861812900751829, 0.06824302510358393, 0.06770418700762093, 0.06776656105648726, 0.06730132992379367, 0.06752969906665385, 0.06726748798973858, 0.06950179999694228, 0.06993326998781413, 0.06983286305330694, 0.0705082630738616, 0.07423675700556487, 0.06943969603162259, 0.07159186492208391, 0.06978749297559261, 0.06910264398902655, 0.06896096502896398, 0.07004379597492516, 0.06974822003394365, 0.07564233406446874, 0.19399107701610774, 0.07370182301383466, 0.07365404104348272, 0.07469843502622098, 0.07527633907739073, 0.07472177699673921, 0.07494371000211686, 0.06954243197105825, 0.07100820797495544, 0.07694649300538003, 0.07104502397123724, 0.07024088501930237, 0.07089372898917645, 0.0732692830497399, 0.1907073080074042, 0.07049184700008482, 0.07456855697091669, 0.07162670197430998, 0.07039938995148987, 0.07097803498618305, 0.07039707899093628, 0.20132703299168497, 0.0654451900627464, 0.0665014690021053, 0.06673909199889749, 0.06807012599892914, 0.067712222924456, 0.06752297503408045, 0.0726597469765693, 0.06984604394529015, 0.07001034799031913, 0.07163795304950327, 0.07375469210091978, 0.07174312393181026, 0.06938905001152307, 0.0700039790244773, 0.06964202201925218, 0.07014602702111006, 0.07202155096456409, 0.0707657829625532, 0.07107859791722149, 0.07298957090824842, 0.0756541530136019, 0.07098619197495282, 0.07018235290888697, 0.0724826620426029, 0.07411599392071366, 0.07161576999351382, 0.07286076701711863, 0.07120346394367516, 0.07074075902346522, 0.07420500391162932, 0.08305698004551232, 0.07881589094176888, 0.0805877490201965, 0.08059498807415366, 0.08101418009027839, 0.08170179696753621, 0.0807595249498263, 0.08045146707445383, 0.08010452601592988, 0.0798953790217638, 0.07981061900500208, 0.08033479400910437, 0.08243028295692056, 0.09620977099984884, 0.08288138010539114, 0.08246160193812102, 0.08223710802849382, 0.08264942199457437, 0.08249320101458579, 0.08450207393616438, 0.08270994201302528, 0.08641965291462839, 0.08365961199160665, 0.08331946993712336, 0.08320568001363426, 0.08323263307102025, 0.09332352399360389, 0.0832560210255906, 0.08118511294014752, 0.08134482300374657, 0.0808957819826901, 0.08042926294729114, 0.08185753598809242, 0.08386055694427341, 0.08040585496928543, 0.08064479799941182, 0.0844548400491476, 0.08495077909901738, 0.08487873605918139, 0.08863173797726631, 0.0857829280430451, 0.20761745399795473, 0.08496561704669148, 0.08536973199807107, 0.08495418494567275, 0.08791964699048549, 0.08523767406586558, 0.08483420591801405, 0.07990923500619829, 0.08032452908810228, 0.08555381000041962, 0.09114239492919296, 0.0834412220865488, 0.08524990803562105, 0.09045197197701782, 0.0812553649302572, 0.08095485402736813, 0.08099035790655762, 0.08215852698776871, 0.08136208890937269, 0.08660187502391636, 0.08043893706053495, 0.08096692699473351, 0.08038991095963866, 0.08718398003838956, 0.08090849593281746, 0.08038316597230732, 0.08010529691819102, 0.08093408204149455, 0.08127865509595722, 0.08073717600200325, 0.0807543839327991, 0.08050749602261931, 0.08110801596194506, 0.08176907699089497, 0.08069482096470892, 0.08026396494824439, 0.0805984390899539, 0.08414783608168364, 0.08285219105891883, 0.08263104094658047, 0.08854648901615292, 0.08857876900583506, 0.08036477607674897, 0.07993051200173795, 0.08022374799475074, 0.07955306302756071, 0.07956153305713087, 0.0804729099618271, 0.07956212502904236, 0.0797456520376727, 0.08013515290804207, 0.0809233330655843, 0.08084596693515778, 0.08001628401689231, 0.08129825594369322, 0.08018370694480836, 0.07995678298175335, 0.08168154105078429, 0.08172759099397808, 0.08013980300165713, 0.08065681997686625, 0.08147047192323953, 0.08054951298981905, 0.07940651208627969, 0.07830866903532296, 0.08143022703006864, 0.08021659206133336, 0.08106147707439959, 0.07771602796856314, 0.07447331992443651, 0.07539884699508548, 0.07764213101472706, 0.07438618992455304, 0.07612841797526926, 0.075939183938317, 0.07428924308624119, 0.0754302010172978, 0.07423218502663076, 0.073930369107984, 0.07430608698632568, 0.07433505298104137, 0.0753632050473243, 0.07447381399106234, 0.07484976307023317, 0.07553961698431522, 0.07491198496427387, 0.07480668707285076, 0.0758846850367263, 0.07690606405958533, 0.07534361910074949, 0.07507058302871883, 0.07386594696436077, 0.0798784940270707, 0.08065869403071702, 0.07388247002381831, 0.08150663110427558, 0.07428897602949291, 0.07499956898391247, 0.07946195604745299, 0.07626672997139394, 0.07731734705157578, 0.18562342901714146, 0.07608788693323731, 0.07548330002464354, 0.07582654501311481, 0.07547838694881648, 0.07698715501464903, 0.07591582194436342, 0.19750945700798184, 0.08010305603966117, 0.08024429006036371, 0.08106740796938539, 0.08463838300667703, 0.08282873500138521]
[0.0014456941209239314, 0.0014537672051323615, 0.0014871910394986673, 0.0013709989998831737, 0.0013946197352048997, 0.0013994481842204624, 0.001397949284683837, 0.0014542623266235602, 0.001411230141791154, 0.0013903123873038863, 0.0013908850200170157, 0.0013924410414634918, 0.001403114589748486, 0.001402604082428223, 0.0014036274895224037, 0.0014035634064514721, 0.0015262464080386016, 0.0014029428961553744, 0.0014304351037824337, 0.0014158618584161206, 0.0014159368370108459, 0.0014146869165860877, 0.001419195632108164, 0.0013923569800978412, 0.0015164159395142781, 0.0014117689807994329, 0.0014004925104352285, 0.0014532831217143305, 0.0013971815303880342, 0.0013891108172508528, 0.0013936519793861983, 0.0014459340196406963, 0.0013889439798397372, 0.0014005165917760863, 0.0014006843272482558, 0.001381785062388802, 0.0014833720610001866, 0.001394810162161534, 0.0014018431016034922, 0.001726392713584462, 0.0013910879794394179, 0.0014011623879552496, 0.0014023210197611122, 0.0014100998986930568, 0.001505125081166625, 0.0013874570805845515, 0.001374861733911901, 0.0013760096531323328, 0.0014029941426552072, 0.0013957356117019544, 0.001380007754422116, 0.0013808158763247182, 0.0013877254487870603, 0.001392796469320144, 0.0013719708967611802, 0.0013921545908729337, 0.0013766157944515652, 0.0013864340203605136, 0.0013799471638108395, 0.001378579305161779, 0.001413392489871048, 0.0014744768161516712, 0.0014346052027706588, 0.001371448265616687, 0.0013788410828315786, 0.0013842263463314396, 0.001393621899092532, 0.0013755942024860758, 0.0013933304283881979, 0.0014003699797452713, 0.001392714798032325, 0.0013817181021963454, 0.001382991041969128, 0.0013734965290570138, 0.0013781571238092622, 0.0013728058773416038, 0.0014184040815702506, 0.0014272095915880433, 0.0014251604704756517, 0.0014389441443645225, 0.0015150358572564259, 0.0014171366537065835, 0.0014610584677976308, 0.0014242345505222982, 0.0014102580405923786, 0.001407366633244163, 0.0014294652239780646, 0.0014234330619172174, 0.0015437211033565048, 0.0039590015717573005, 0.0015041188370170338, 0.0015031436947649534, 0.001524457857677979, 0.0015362518179059333, 0.0015249342244232492, 0.0015294634694309563, 0.001419233305531801, 0.0014491471015297029, 0.0015703365919465314, 0.0014498984483925967, 0.0014334874493735178, 0.0014468107956974786, 0.0014952914908110183, 0.003891985877702127, 0.0014386091224507106, 0.0015218072851207486, 0.0014617694280471426, 0.0014367222439079564, 0.0014485313262486337, 0.0014366750814476792, 0.004108714959013979, 0.0013356161237295186, 0.0013571728367776591, 0.0013620222856917856, 0.001389186244876105, 0.001381882100499102, 0.001378019898654703, 0.0014828519791136592, 0.0014254294682712275, 0.0014287826120473292, 0.0014619990418265974, 0.0015051977979779548, 0.0014641453863634747, 0.0014161030614596544, 0.001428652633152598, 0.0014212657554949425, 0.001431551571859389, 0.0014698275707053896, 0.0014441996522970041, 0.001450583630963704, 0.0014895830797601718, 0.0015439623064000387, 0.0014486977954072003, 0.0014322929165078973, 0.0014792380008694468, 0.0015125713045043604, 0.0014615463263982413, 0.0014869544289207884, 0.0014531319172178603, 0.0014436889596625554, 0.0015143878349312106, 0.0016950404090920882, 0.0016084875702401813, 0.0016446479391876835, 0.0016447956749827278, 0.001653350614087314, 0.0016673836115823717, 0.0016481535704046184, 0.0016418666749888537, 0.0016347862452230587, 0.0016305179392196694, 0.0016287881429592262, 0.0016394855920225382, 0.0016822506725902157, 0.0019634647142826294, 0.0016914567368447172, 0.0016828898354718576, 0.0016783083271121187, 0.0016867228978484565, 0.0016835347145833836, 0.0017245321211462117, 0.0016879580002658221, 0.0017636663860128242, 0.0017073390202368705, 0.0017003973456555788, 0.0016980751023190667, 0.001698625164714699, 0.0019045617141551813, 0.0016991024699100122, 0.0016568390395948474, 0.0016600984286478891, 0.001650934326177349, 0.0016414135295365537, 0.0016705619589406618, 0.0017114399376382328, 0.0016409358156997027, 0.001645812204069629, 0.0017235681642683185, 0.0017336893693677016, 0.0017322191032486, 0.001808810979127884, 0.0017506720008784715, 0.004237090897917443, 0.0017339921846263567, 0.0017422394285320627, 0.001733758876442301, 0.0017942785100099078, 0.0017395443686911342, 0.0017313103248574296, 0.00163080071441221, 0.0016392761038388221, 0.0017459961224575431, 0.0018600488761059788, 0.0017028820833989552, 0.0017397940415432866, 0.0018459586117758739, 0.0016582727536787183, 0.0016521398781095536, 0.0016528644470726044, 0.001676704632403443, 0.0016604507940688304, 0.0017673852045697216, 0.0016416109604190808, 0.001652386265198643, 0.0016406104277477277, 0.0017792648987426441, 0.0016511937945472952, 0.0016404727749450474, 0.0016348019779222657, 0.001651715960030501, 0.0016587480631828004, 0.0016476974694286377, 0.0016480486516897775, 0.001643010122910598, 0.0016552656318764298, 0.0016687566732835708, 0.001646833080912427, 0.0016380401009845795, 0.0016448661038766103, 0.001717302777177217, 0.0016908610420187516, 0.0016863477744200096, 0.001807071204411284, 0.0018077299797109195, 0.0016400974709540606, 0.0016312349388109787, 0.0016372193468316477, 0.0016235318985216472, 0.001623704756267977, 0.0016423042849352469, 0.0016237168373273952, 0.0016274622864831164, 0.0016354112838375934, 0.0016514965931751899, 0.0016499176925542404, 0.001632985388099843, 0.001659148080483535, 0.0016364021825471095, 0.0016317710812602723, 0.00166697022552621, 0.001667910020285267, 0.0016355061837072884, 0.0016460575505482908, 0.001662662692311011, 0.0016438676120371235, 0.0016205410629852998, 0.0015981361027616933, 0.0016618413679605844, 0.0016370733073741502, 0.001654315858661216, 0.001619083916011732, 0.0015515274984257605, 0.0015708093123976141, 0.001617544396140147, 0.001549712290094855, 0.0015860087078181095, 0.0015820663320482709, 0.0015476925642966914, 0.0015714625211937043, 0.0015465038547214742, 0.0015402160230830002, 0.001548043478881785, 0.0015486469371050287, 0.0015700667718192562, 0.0015515377914804656, 0.0015593700639631909, 0.001573742020506567, 0.0015606663534223724, 0.0015584726473510575, 0.001580930938265131, 0.0016022096679080278, 0.0015696587312656145, 0.0015639704797649756, 0.0015388738950908494, 0.0016641352922306396, 0.001680389458973271, 0.001539218125496215, 0.001698054814672408, 0.0015476870006144357, 0.0015624910204981763, 0.0016554574176552705, 0.0015888902077373739, 0.0016107780635744955, 0.0038671547711904473, 0.0015851643111091107, 0.0015725687505134072, 0.0015797196877732251, 0.0015724663947670099, 0.0016038990628051881, 0.0015815796238409046, 0.004114780354332955, 0.001668813667492941, 0.001671756042924244, 0.0016889043326955289, 0.0017632996459724382, 0.001725598645862192]
[691.7092526881883, 687.8680413683927, 672.4085698748564, 729.3951345589694, 717.0413373313396, 714.5673639621264, 715.3335324508299, 687.6338482354516, 708.6016450377012, 719.2628139775222, 718.9666907101827, 718.1632616552108, 712.7001652653715, 712.9595675130042, 712.4397373695343, 712.4722655232424, 655.2021971898447, 712.7873862438739, 699.0879889313021, 706.2835926088637, 706.2461925286715, 706.8701832722062, 704.6244910678988, 718.2066196340896, 659.4496760040053, 708.3311884595571, 714.0345218192076, 688.0971677565306, 715.7266097858262, 719.8849707175053, 717.5392528344321, 691.594489386516, 719.9714419838477, 714.0222442719046, 713.9367383117445, 723.7015562110797, 674.1397025677661, 716.9434430061094, 713.3465926794192, 579.2424818126852, 718.8617936321907, 713.6931511980738, 713.1034805214227, 709.1696133918202, 664.3966089681386, 720.7430154010159, 727.3458671038104, 726.7390877117841, 712.7613505979939, 716.4680700384251, 724.6336093370389, 724.2095178262826, 720.6036329981905, 717.9799935076825, 728.8784349294186, 718.3110313725734, 726.4190953136591, 721.2748571619518, 724.6654264924292, 725.384456487723, 707.5175559276076, 678.206662217967, 697.0558855277368, 729.1561957317718, 725.2467397812131, 722.4252035443918, 717.554740386297, 726.9585741148994, 717.7048456171292, 714.0969989815842, 718.0220971392233, 723.7366279058111, 723.0704824929176, 728.068822049779, 725.6066690247727, 728.4351098033388, 705.0177118025108, 700.6679368566384, 701.6753696980151, 694.9540077121115, 660.0503844251563, 705.648250212466, 684.4353063484032, 702.1315412080671, 709.0900893427633, 710.5469011261622, 699.5623140919064, 702.5268885163474, 647.7854049061744, 252.58893735577004, 664.8410852849888, 665.2723911111971, 655.970904648803, 650.9349498203369, 655.7659891056702, 653.8240500585832, 704.6057868725748, 690.0610703664325, 636.8061504320146, 689.7034762045794, 697.5994107496607, 691.17537896026, 668.765927008398, 256.93823960903256, 695.1158479354505, 657.1134267639246, 684.1024178046702, 696.0287586833416, 690.3544175256274, 696.0516075717974, 243.3850997149685, 748.7181250909445, 736.8258285910762, 734.202377233563, 719.8458836519687, 723.6507366575082, 725.6789259547368, 674.376144136603, 701.5429540774179, 699.8965353918196, 683.9949763240725, 664.3645116564581, 682.9922829478832, 706.1632922177611, 699.9602120169035, 703.5981808002962, 698.5427697174314, 680.3519133336755, 692.4250386084062, 689.377695056192, 671.3287856095972, 647.6842056666773, 690.2750892355157, 698.1812089374291, 676.0237361480933, 661.1258570237653, 684.206844448337, 672.5155664157015, 688.1687671650496, 692.6699780496608, 660.3328268583351, 589.9564368118093, 621.7020376792086, 608.0328659846283, 607.9782523811057, 604.8323879276036, 599.7420108087696, 606.739576916065, 609.0628521994873, 611.7007669486201, 613.3020532595785, 613.9533887956558, 609.947415741762, 594.4417299356866, 509.303779551424, 591.2063715359479, 594.2159604996453, 595.8380732822255, 592.8656101577658, 593.9883456739205, 579.8674247571272, 592.4318021197912, 567.000657227885, 585.7067566236865, 588.0978363997949, 588.9021037021841, 588.7114007097381, 525.0551833357505, 588.5460222142823, 603.558931255346, 602.3739211743465, 605.7176134410187, 609.2309963366428, 598.6009645724969, 584.3032980637278, 609.4083573729515, 607.6027371332417, 580.191732901098, 576.804598141311, 577.2941760800364, 552.8493643278022, 571.209226798743, 236.01098586096094, 576.703868025496, 573.9739232296894, 576.7814738183287, 557.327078500471, 574.8631756673265, 577.5972023284435, 613.1957088088659, 610.0253628160755, 572.7389580868423, 537.6202812979328, 587.2397212636112, 574.7806787020311, 541.7239550338383, 603.0371045906629, 605.2756266280801, 605.0102909352938, 596.407966361116, 602.2460909844626, 565.8076108221437, 609.1577262280911, 605.1853740625132, 609.529223444487, 562.0298589078398, 605.6224310570209, 609.580369313656, 611.6948801780503, 605.4309725151131, 602.8643060364473, 606.9075291757073, 606.7782034072112, 608.6389767510967, 604.1326423641066, 599.2485399517983, 607.2260823458505, 610.4856647886265, 607.9522203316162, 582.3084975403874, 591.4146551073651, 592.9974914835897, 553.3816252280909, 553.179961179774, 609.7198597704624, 613.0324799988092, 610.7917072536452, 615.9410855497069, 615.8755131680846, 608.9005607383093, 615.8709308243546, 614.4535626450439, 611.4669807422622, 605.5113913843361, 606.0908398720777, 612.3753508680254, 602.7189566518765, 611.0967161162482, 612.8310591383112, 599.8907387109037, 599.5527263688765, 611.4315005115096, 607.5121733543925, 601.4449019783167, 608.3214929703336, 617.0778530954578, 625.7289340200304, 601.742151374654, 610.8461945445744, 604.4794860452268, 617.6332122817246, 644.5261208806407, 636.6145095445379, 618.2210530890171, 645.2810669384263, 630.5135621706085, 632.0847487509068, 646.1231533114097, 636.3498884086567, 646.6197914392527, 649.2595746396228, 645.9766884082228, 645.7249719354079, 636.9155872532016, 644.5218450307985, 641.2845950488921, 635.4281622842561, 640.7519440699854, 641.6538664953179, 632.5386996963774, 624.1380388783195, 637.0811566114762, 639.3982577920999, 649.8258260082862, 600.9126809993797, 595.1001386375076, 649.6804991025031, 588.909139657498, 646.1254760187282, 640.0036780250841, 604.0626532190502, 629.370106965433, 620.8179901462582, 258.5880470701111, 630.8494286628987, 635.9022457196376, 633.0236989130656, 635.9436381775068, 623.4806311632974, 632.2792636715158, 243.02633771131377, 599.2280740978711, 598.1734022930732, 592.0998487841983, 567.118584912159, 579.5090314876505]
Elapsed: 0.07808981056724726~0.018116762962694394
Time per graph: 0.0015990578841554727~0.0003730147692496904
Speed: 642.0377814856136~77.79692687974523
Total Time: 0.0838
best val loss: 0.6917139887809753 test_score: 0.5000

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.08s
test Score 0.5000
Epoch Time List: [0.44224406115245074, 0.249535869108513, 0.26170355489011854, 0.2399571939604357, 0.24755443399772048, 0.24864490400068462, 0.2480351789854467, 0.2546479169977829, 0.2509292470058426, 0.24570817907806486, 0.246507802978158, 0.24682019103784114, 0.24808320601005107, 0.25360741396434605, 0.252684106817469, 0.248503508977592, 0.2627014520112425, 0.2477286010980606, 0.2525089009432122, 0.24984656600281596, 0.24886299401987344, 0.2488516381708905, 0.24972213001456112, 0.24695961398538202, 0.2630372919375077, 0.24908673495519906, 0.24922632507514209, 0.2532558188540861, 0.25215502199716866, 0.2488721840782091, 0.24734657304361463, 0.2494230429874733, 0.2467502240324393, 0.25659005099441856, 0.25268325221259147, 0.2556317129638046, 0.25258705811575055, 0.24776713398750871, 0.24759677704423666, 0.2665042649023235, 0.2811292731203139, 0.2505253099370748, 0.24857534584589303, 0.2487183550838381, 0.2586246069986373, 0.24676986085250974, 0.24549207603558898, 0.24538940691854805, 0.25147364707663655, 0.2538037330377847, 0.2542843701085076, 0.25100134685635567, 0.2557753960136324, 0.24843529309146106, 0.24727067607454956, 0.252139171003364, 0.25343468715436757, 0.25339331093709916, 0.24922359711490571, 0.2514854399487376, 0.2501105881528929, 0.26506952883210033, 0.25478637393098325, 0.24737167998682708, 0.24662180105224252, 0.2516180230304599, 0.24860082915984094, 0.24786741996649653, 0.24913719296455383, 0.2549196348991245, 0.2495561259565875, 0.25303120317403227, 0.24859604891389608, 0.2521776770008728, 0.24764476099517196, 0.2519747519399971, 0.25386614992748946, 0.2569857829948887, 0.2580515280133113, 0.2614923521177843, 0.2706689011538401, 0.25625487905927, 0.2525614529149607, 0.3519961411366239, 0.25845956488046795, 0.25245977099984884, 0.2540282600093633, 0.2628869339823723, 0.26347757293842733, 0.3916914751753211, 0.263379154028371, 0.26936172996647656, 0.268867974053137, 0.2719201899599284, 0.2705140550388023, 0.26706793485209346, 0.3631450969260186, 0.2526871010195464, 0.25897971517406404, 0.25263387395534664, 0.2520221760496497, 0.2564130541868508, 0.2545208039227873, 0.38438642711844295, 0.252117482945323, 0.2594891058979556, 0.2554272310808301, 0.25123310403432697, 0.25387974886689335, 0.2534021040191874, 0.38518220803234726, 0.24569500191137195, 0.23869768192525953, 0.2404964540619403, 0.24275641213171184, 0.24485456803813577, 0.24307452701032162, 0.34740671690087765, 0.25930940615944564, 0.25915410416200757, 0.26363554084673524, 0.27575151110067964, 0.2626050319522619, 0.3492409390164539, 0.26535477908328176, 0.26546524302102625, 0.2607652200385928, 0.2639623680151999, 0.2672341252909973, 0.2642421129858121, 0.2702181850327179, 0.29928989289328456, 0.27033332001883537, 0.2635538527974859, 0.26665147696621716, 0.27069883386138827, 0.2780768448719755, 0.26789853698574007, 0.38215262710582465, 0.2633851170539856, 0.26619974814821035, 0.26841764396522194, 0.34806961205322295, 0.2677532029338181, 0.26678762794472277, 0.2697834951104596, 0.27010902005713433, 0.2705225980607793, 0.26704704901203513, 0.30456369288731366, 0.26327331305947155, 0.2644641640363261, 0.26671540294773877, 0.26858350599650294, 0.2850859249010682, 0.26899229595437646, 0.4014795790426433, 0.270622176816687, 0.26976390497293323, 0.270330399973318, 0.27304510411340743, 0.27387108688708395, 0.27318970195483416, 0.39511913002934307, 0.2746757488930598, 0.2743414060678333, 0.27188694092910737, 0.2986939859110862, 0.27970561699476093, 0.2663534199818969, 0.3598260418511927, 0.2685254050884396, 0.2664305721409619, 0.2680093130329624, 0.2761829470982775, 0.2697136470815167, 0.26452869491185993, 0.406242112047039, 0.2790846450952813, 0.2793474509380758, 0.28836362692527473, 0.2865397719433531, 0.40504834498278797, 0.2808203111635521, 0.2784998760325834, 0.2830941629363224, 0.28210411698091775, 0.2855651769787073, 0.2782476160209626, 0.3796145759988576, 0.2667112360941246, 0.28978834801819175, 0.29375479207374156, 0.28722066013142467, 0.315053747035563, 0.3028933899477124, 0.27207723702304065, 0.2703495160676539, 0.271157321985811, 0.2714483600575477, 0.27221254992764443, 0.2773242798866704, 0.2687206059927121, 0.27029368304647505, 0.26785375899635255, 0.2772277129115537, 0.2760780770331621, 0.26912531803827733, 0.2680695998715237, 0.268421080079861, 0.27012002910487354, 0.27019013511016965, 0.2696740000974387, 0.2691614639479667, 0.26900196191854775, 0.2718922400381416, 0.2711444030283019, 0.26843557006213814, 0.2688676880206913, 0.28525172313675284, 0.27496259519830346, 0.2911281898850575, 0.2879273931030184, 0.2827902880962938, 0.2745878469431773, 0.26895408192649484, 0.2681942998897284, 0.2659260290674865, 0.2658961539855227, 0.26911885803565383, 0.26793092500884086, 0.2678511789999902, 0.2683733421145007, 0.2702525488566607, 0.27006298187188804, 0.26780972396954894, 0.2709844179917127, 0.26998035702854395, 0.2685800939798355, 0.2696452259551734, 0.270225789048709, 0.2688569070305675, 0.26992326008621603, 0.27132229995913804, 0.27135105803608894, 0.27901568613015115, 0.2584122580010444, 0.2665644569788128, 0.26632986404001713, 0.26875867682974786, 0.27377105795312673, 0.26491720404010266, 0.26250341697596014, 0.27739904006011784, 0.2612439609365538, 0.26384996401611716, 0.27208668284583837, 0.2617602520622313, 0.25967610301449895, 0.2589378119446337, 0.25835475709754974, 0.2614194159395993, 0.25793269998393953, 0.2609742060303688, 0.25796903297305107, 0.2596419808687642, 0.26134434912819415, 0.2616990900132805, 0.2611061448697001, 0.2713274561101571, 0.27002790884580463, 0.26258277089800686, 0.26515590911731124, 0.2614595389459282, 0.26231813500635326, 0.3359692639205605, 0.258906535920687, 0.2881235940149054, 0.2574822640744969, 0.2591663919156417, 0.26583018398378044, 0.2674070339417085, 0.2646616930142045, 0.3734040459385142, 0.2633173998910934, 0.26450027502141893, 0.26434262504335493, 0.2664952410850674, 0.2731355580035597, 0.27061166195198894, 0.3891048700315878, 0.2768629348138347, 0.2777452999725938, 0.27586199901998043, 0.2804689839249477, 0.2871427829377353]
Total Epoch List: [141, 109, 46]
Total Time List: [0.07489668997004628, 0.08197484503034502, 0.08383265708107501]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe600940>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6936;  Loss pred: 0.6936; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6922;  Loss pred: 0.6922; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6924;  Loss pred: 0.6924; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6869;  Loss pred: 0.6869; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6859;  Loss pred: 0.6859; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6826;  Loss pred: 0.6826; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6779;  Loss pred: 0.6779; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6745;  Loss pred: 0.6745; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6716;  Loss pred: 0.6716; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6667;  Loss pred: 0.6667; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.11s
Epoch 13/1000, LR 0.000270
Train loss: 0.6612;  Loss pred: 0.6612; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6544;  Loss pred: 0.6544; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6504;  Loss pred: 0.6504; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6452;  Loss pred: 0.6452; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6387;  Loss pred: 0.6387; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.08s
Epoch 18/1000, LR 0.000270
Train loss: 0.6338;  Loss pred: 0.6338; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6246;  Loss pred: 0.6246; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6160;  Loss pred: 0.6160; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4898 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6112;  Loss pred: 0.6112; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4898 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6020;  Loss pred: 0.6020; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.5928;  Loss pred: 0.5928; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.5804;  Loss pred: 0.5804; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 25/1000, LR 0.000270
Train loss: 0.5717;  Loss pred: 0.5717; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.5625;  Loss pred: 0.5625; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5457;  Loss pred: 0.5457; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5347;  Loss pred: 0.5347; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5237;  Loss pred: 0.5237; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.5072;  Loss pred: 0.5072; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.4943;  Loss pred: 0.4943; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.4825;  Loss pred: 0.4825; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 33/1000, LR 0.000270
Train loss: 0.4689;  Loss pred: 0.4689; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 34/1000, LR 0.000270
Train loss: 0.4560;  Loss pred: 0.4560; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 35/1000, LR 0.000270
Train loss: 0.4299;  Loss pred: 0.4299; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 36/1000, LR 0.000270
Train loss: 0.4166;  Loss pred: 0.4166; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 37/1000, LR 0.000270
Train loss: 0.4021;  Loss pred: 0.4021; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 38/1000, LR 0.000270
Train loss: 0.3838;  Loss pred: 0.3838; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.4898 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.3712;  Loss pred: 0.3712; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.4898 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3485;  Loss pred: 0.3485; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4898 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3302;  Loss pred: 0.3302; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4898 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3104;  Loss pred: 0.3104; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.2978;  Loss pred: 0.2978; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.2793;  Loss pred: 0.2793; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2634;  Loss pred: 0.2634; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4898 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2454;  Loss pred: 0.2454; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.4898 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2303;  Loss pred: 0.2303; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.4898 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2136;  Loss pred: 0.2136; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6874 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6878 score: 0.4898 time: 0.21s
Epoch 49/1000, LR 0.000269
Train loss: 0.1991;  Loss pred: 0.1991; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6862 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6859 score: 0.4898 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.1822;  Loss pred: 0.1822; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6836 score: 0.4898 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.1695;  Loss pred: 0.1695; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6831 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6811 score: 0.4898 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1568;  Loss pred: 0.1568; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6815 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6785 score: 0.4898 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1427;  Loss pred: 0.1427; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6798 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6758 score: 0.4898 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1316;  Loss pred: 0.1316; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6780 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6730 score: 0.4898 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1202;  Loss pred: 0.1202; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6761 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6700 score: 0.4898 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1092;  Loss pred: 0.1092; Loss self: 0.0000; time: 0.23s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6742 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6670 score: 0.4898 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.0986;  Loss pred: 0.0986; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6725 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6639 score: 0.4898 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.0901;  Loss pred: 0.0901; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6705 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6606 score: 0.4898 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.0840;  Loss pred: 0.0840; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6682 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6569 score: 0.4898 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.0753;  Loss pred: 0.0753; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6659 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6529 score: 0.4898 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.0684;  Loss pred: 0.0684; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6634 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6485 score: 0.4898 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0614;  Loss pred: 0.0614; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6605 score: 0.5102 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6436 score: 0.4898 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0543;  Loss pred: 0.0543; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6570 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6379 score: 0.4898 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0484;  Loss pred: 0.0484; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6528 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6311 score: 0.4898 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0453;  Loss pred: 0.0453; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6478 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6233 score: 0.4898 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0415;  Loss pred: 0.0415; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6425 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6151 score: 0.4898 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0386;  Loss pred: 0.0386; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6364 score: 0.5102 time: 0.08s
Test loss: 0.6058 score: 0.5102 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0344;  Loss pred: 0.0344; Loss self: 0.0000; time: 0.12s
Val loss: 0.6300 score: 0.5306 time: 0.08s
Test loss: 0.5959 score: 0.5510 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0300;  Loss pred: 0.0300; Loss self: 0.0000; time: 0.17s
Val loss: 0.6227 score: 0.5510 time: 0.08s
Test loss: 0.5850 score: 0.5714 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0278;  Loss pred: 0.0278; Loss self: 0.0000; time: 0.12s
Val loss: 0.6146 score: 0.5510 time: 0.08s
Test loss: 0.5729 score: 0.5918 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0253;  Loss pred: 0.0253; Loss self: 0.0000; time: 0.12s
Val loss: 0.6056 score: 0.5714 time: 0.08s
Test loss: 0.5596 score: 0.5918 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0231;  Loss pred: 0.0231; Loss self: 0.0000; time: 0.12s
Val loss: 0.5964 score: 0.6327 time: 0.08s
Test loss: 0.5459 score: 0.6122 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0205;  Loss pred: 0.0205; Loss self: 0.0000; time: 0.12s
Val loss: 0.5864 score: 0.6735 time: 0.08s
Test loss: 0.5314 score: 0.6327 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0192;  Loss pred: 0.0192; Loss self: 0.0000; time: 0.12s
Val loss: 0.5764 score: 0.6735 time: 0.08s
Test loss: 0.5166 score: 0.6531 time: 0.08s
Epoch 75/1000, LR 0.000267
Train loss: 0.0174;  Loss pred: 0.0174; Loss self: 0.0000; time: 0.12s
Val loss: 0.5658 score: 0.6939 time: 0.08s
Test loss: 0.5011 score: 0.6735 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.23s
Val loss: 0.5553 score: 0.7143 time: 0.07s
Test loss: 0.4855 score: 0.7143 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0141;  Loss pred: 0.0141; Loss self: 0.0000; time: 0.11s
Val loss: 0.5447 score: 0.7143 time: 0.07s
Test loss: 0.4698 score: 0.7755 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.12s
Val loss: 0.5344 score: 0.7347 time: 0.07s
Test loss: 0.4543 score: 0.7755 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.12s
Val loss: 0.5246 score: 0.7551 time: 0.07s
Test loss: 0.4395 score: 0.7755 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.12s
Val loss: 0.5145 score: 0.7551 time: 0.07s
Test loss: 0.4245 score: 0.8163 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.11s
Val loss: 0.5048 score: 0.7551 time: 0.07s
Test loss: 0.4098 score: 0.8367 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.11s
Val loss: 0.4963 score: 0.7755 time: 0.08s
Test loss: 0.3965 score: 0.8571 time: 0.16s
Epoch 83/1000, LR 0.000266
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.12s
Val loss: 0.4885 score: 0.7959 time: 0.07s
Test loss: 0.3839 score: 0.8571 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.12s
Val loss: 0.4809 score: 0.7959 time: 0.07s
Test loss: 0.3716 score: 0.8571 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.12s
Val loss: 0.4743 score: 0.7959 time: 0.07s
Test loss: 0.3604 score: 0.8571 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.4686 score: 0.7755 time: 0.07s
Test loss: 0.3502 score: 0.8571 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.13s
Val loss: 0.4641 score: 0.8163 time: 0.08s
Test loss: 0.3412 score: 0.8571 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.4604 score: 0.8163 time: 0.07s
Test loss: 0.3332 score: 0.8571 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.4572 score: 0.8163 time: 0.09s
Test loss: 0.3259 score: 0.8571 time: 0.16s
Epoch 90/1000, LR 0.000266
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.12s
Val loss: 0.4551 score: 0.8163 time: 0.07s
Test loss: 0.3197 score: 0.8571 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.12s
Val loss: 0.4537 score: 0.8163 time: 0.07s
Test loss: 0.3142 score: 0.8571 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.12s
Val loss: 0.4530 score: 0.8163 time: 0.07s
Test loss: 0.3095 score: 0.8571 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.12s
Val loss: 0.4528 score: 0.8163 time: 0.07s
Test loss: 0.3056 score: 0.8571 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.12s
Val loss: 0.4535 score: 0.8163 time: 0.07s
Test loss: 0.3024 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.4553 score: 0.8163 time: 0.07s
Test loss: 0.3002 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.4576 score: 0.8163 time: 0.07s
Test loss: 0.2985 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.12s
Val loss: 0.4604 score: 0.8163 time: 0.07s
Test loss: 0.2974 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.12s
Val loss: 0.4633 score: 0.8163 time: 0.07s
Test loss: 0.2964 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.12s
Val loss: 0.4665 score: 0.8163 time: 0.09s
Test loss: 0.2959 score: 0.8367 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.13s
Val loss: 0.4700 score: 0.8163 time: 0.07s
Test loss: 0.2957 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.12s
Val loss: 0.4737 score: 0.8367 time: 0.08s
Test loss: 0.2957 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.12s
Val loss: 0.4776 score: 0.8367 time: 0.07s
Test loss: 0.2961 score: 0.8367 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.12s
Val loss: 0.4813 score: 0.8367 time: 0.07s
Test loss: 0.2965 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.12s
Val loss: 0.4853 score: 0.8367 time: 0.08s
Test loss: 0.2971 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.4897 score: 0.8367 time: 0.07s
Test loss: 0.2981 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.12s
Val loss: 0.4937 score: 0.8367 time: 0.08s
Test loss: 0.2990 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.4976 score: 0.8367 time: 0.08s
Test loss: 0.3000 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0025;  Loss pred: 0.0025; Loss self: 0.0000; time: 0.12s
Val loss: 0.5016 score: 0.8367 time: 0.07s
Test loss: 0.3011 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0025;  Loss pred: 0.0025; Loss self: 0.0000; time: 0.12s
Val loss: 0.5054 score: 0.8367 time: 0.08s
Test loss: 0.3022 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.5090 score: 0.8367 time: 0.07s
Test loss: 0.3032 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.5126 score: 0.8367 time: 0.08s
Test loss: 0.3043 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.5160 score: 0.8367 time: 0.07s
Test loss: 0.3054 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.5196 score: 0.8367 time: 0.07s
Test loss: 0.3066 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 092,   Train_Loss: 0.0047,   Val_Loss: 0.4528,   Val_Precision: 0.9412,   Val_Recall: 0.6667,   Val_accuracy: 0.7805,   Val_Score: 0.8163,   Val_Loss: 0.4528,   Test_Precision: 1.0000,   Test_Recall: 0.7200,   Test_accuracy: 0.8372,   Test_Score: 0.8571,   Test_loss: 0.3056


[0.0746619829442352, 0.07449029898270965, 0.07784961094148457, 0.0771165780024603, 0.07523227401543409, 0.07447496498934925, 0.07476246694568545, 0.07467747095506638, 0.07502717908937484, 0.07612147403415293, 0.07486636401154101, 0.11705538700334728, 0.07544379110913724, 0.07491415599361062, 0.07529404002707452, 0.07838286901824176, 0.0814824610715732, 0.07682678592391312, 0.0763964649522677, 0.07536423893179744, 0.07647452503442764, 0.07691709895152599, 0.07710950798355043, 0.07922298100311309, 0.07826387998647988, 0.07656211103312671, 0.07399826601613313, 0.07452979404479265, 0.07518304802943021, 0.07503728300798684, 0.07704080804251134, 0.07565916900057346, 0.075471629970707, 0.08788657409604639, 0.07983054500073195, 0.07948136702179909, 0.07995804399251938, 0.08104489999823272, 0.07497242407407612, 0.0739172101020813, 0.08380451798439026, 0.07359044800978154, 0.07387399801518768, 0.07387064199429005, 0.07536911102943122, 0.07405606203246862, 0.07263796799816191, 0.21192537189926952, 0.08067476900760084, 0.07408679509535432, 0.0743240260053426, 0.07466686004772782, 0.07576675002928823, 0.07447383599355817, 0.07635993498843163, 0.07910885696765035, 0.07908502093050629, 0.07921708701178432, 0.07976605708245188, 0.08048648200929165, 0.07789969106670469, 0.07804185198619962, 0.07953362504485995, 0.07975321204867214, 0.08021186199039221, 0.08092086797114462, 0.07901691505685449, 0.09101050300523639, 0.08045938704162836, 0.08064390299841762, 0.0801143900025636, 0.08054495404940099, 0.08152791298925877, 0.0802199220051989, 0.08130519604310393, 0.07261517201550305, 0.07278057700023055, 0.07243281998671591, 0.07328006811439991, 0.07264520903117955, 0.07260711304843426, 0.16178358194883913, 0.07753035996574908, 0.07805470493622124, 0.07827370299492031, 0.07889816106762737, 0.07912886305712163, 0.07720200403127819, 0.1599306819261983, 0.07705091394018382, 0.07757036807015538, 0.07787439203821123, 0.07855257706250995, 0.07854179409332573, 0.07826511305756867, 0.07831133890431374, 0.07864040194544941, 0.07894350704737008, 0.08113366703037173, 0.07844524504616857, 0.07892207894474268, 0.0781033260282129, 0.0778773840283975, 0.07896020903717726, 0.079054233036004, 0.07911860290914774, 0.0791552250739187, 0.07952661102171987, 0.07941901101730764, 0.07878235296811908, 0.07943613897077739, 0.07944757107179612, 0.07982370199169964]
[0.0015237139376374532, 0.001520210183320605, 0.001588767570234379, 0.0015738077143359246, 0.0015353525309272263, 0.0015198972446805968, 0.0015257646315446009, 0.0015240300194911507, 0.0015311669201913234, 0.0015534994700847535, 0.0015278849798273674, 0.0023888854490479038, 0.0015396692063089233, 0.0015288603264002167, 0.001536613061777031, 0.0015996503881273829, 0.0016629073688076163, 0.0015678935902839412, 0.0015591115296381165, 0.0015380456924856622, 0.0015607045925393396, 0.0015697367132964488, 0.001573663428235723, 0.0016167955306757773, 0.0015972220405404056, 0.0015624920619005452, 0.0015101686942067985, 0.0015210162049957684, 0.0015343479189679635, 0.0015313731226119765, 0.0015722613886226804, 0.001544064673481091, 0.0015402373463409592, 0.0017936035529805385, 0.001629194795933305, 0.0016220687147305937, 0.0016317968161738648, 0.0016539775509843413, 0.0015300494708995126, 0.0015085144918792102, 0.0017102962853957195, 0.0015018458777506436, 0.0015076326125548507, 0.00150756412233245, 0.0015381451230496168, 0.0015113482047442574, 0.0014824075101665696, 0.004325007589781011, 0.0016464238572979765, 0.0015119754101092719, 0.00151681685725189, 0.0015238134703617922, 0.0015462602046793516, 0.0015198742039501667, 0.0015583660201720741, 0.0016144664687275582, 0.0016139800189899243, 0.0016166752451384555, 0.0016278787159684058, 0.001642581265495748, 0.0015897896136062182, 0.0015926908568612167, 0.0016231352049971418, 0.0016276165724218804, 0.0016369767753141268, 0.0016514462851254003, 0.001612590103201112, 0.0018573572041884977, 0.0016420283069720073, 0.0016457939387432166, 0.0016349875510727264, 0.0016437745724367549, 0.0016638349589644646, 0.0016371412654122223, 0.0016592897151653863, 0.0014819422860306744, 0.001485317897963889, 0.0014782208160554267, 0.0014955115941714268, 0.001482555286350603, 0.0014817778173149849, 0.0033017057540579414, 0.0015822522441989609, 0.0015929531619636988, 0.0015974225101004146, 0.0016101665524005586, 0.0016148747562677885, 0.0015755511026791468, 0.003263891467881598, 0.0015724676314323228, 0.00158306873612562, 0.0015892733069022699, 0.001603113817602244, 0.0016028937570066477, 0.0015972472052565034, 0.001598190589883954, 0.001604906162152029, 0.001611091980558573, 0.0016557891230688107, 0.0016009233682891544, 0.0016106546723416873, 0.0015939454291472022, 0.0015893343679264796, 0.0016114328374934135, 0.0016133516946123267, 0.001614665365492811, 0.0016154127566105857, 0.0016229920616677525, 0.0016207961432103599, 0.0016078031217983486, 0.0016211456932811712, 0.0016213790014652269, 0.0016290551426877476]
[656.2911681115936, 657.803776722304, 629.4186882556254, 635.4016382630039, 651.3162155639152, 657.9392149698566, 655.4090842882198, 656.1550541726757, 653.0966590337828, 643.7079762540527, 654.4995292204443, 418.6052539264922, 649.4901605503419, 654.0819869101799, 650.7819208848455, 625.1365969851959, 601.3564067113657, 637.7983851690489, 641.3909338686686, 650.1757424279657, 640.7362448860057, 637.0495074298154, 635.4598969877105, 618.5073999938796, 626.0870277382718, 640.0032514620553, 662.1776784515059, 657.4551912829766, 651.7426638624584, 653.0087182765469, 636.0265584566773, 647.6412660523486, 649.2505862006492, 557.5368081414871, 613.8001437864508, 616.4966939554643, 612.8213942375114, 604.6031274154019, 653.573638643267, 662.9038072774922, 584.6940138612446, 665.8472848743493, 663.2915682988504, 663.3217023318618, 650.1337130122945, 661.6608911572531, 674.5783417460127, 231.21346708448974, 607.3770102196812, 661.3864176056469, 659.2753734368177, 656.2483003661691, 646.721681754314, 657.9491890848539, 641.6977700075753, 619.3996712661057, 619.586356853308, 618.55341881873, 614.2963785880768, 608.7978847720449, 629.0140477969522, 627.8682367592304, 616.0916212779458, 614.3953170199097, 610.8822159728599, 605.5298370931067, 620.1203877010811, 538.3993976737029, 609.0028994957196, 607.6094804211234, 611.6254520371689, 608.355924692025, 601.0211497313284, 610.820838205557, 602.6675093929133, 674.7901112117272, 673.2565475517565, 676.4889177169484, 668.6675007384614, 674.5111020187037, 674.8650089876651, 302.87374905257866, 632.0104797868465, 627.7648482565921, 626.0084565461267, 621.0537652202029, 619.243068924519, 634.6985497960361, 306.382736632184, 635.9431380403831, 631.6845107101198, 629.2183953867248, 623.7860275546042, 623.8716668704654, 626.077163703291, 625.7076010393797, 623.0893890139307, 620.6970254133445, 603.9416409177863, 624.6395172984836, 620.8655506186979, 627.3740503995945, 629.1942212919281, 620.5657330128022, 619.8276565112424, 619.3233727378494, 619.036834956146, 616.145958823989, 616.9807376387691, 621.966698809172, 616.8477047710727, 616.7589435266574, 613.8527627432665]
Elapsed: 0.08057937695772543~0.017204098580115186
Time per graph: 0.001644477080769907~0.000351104052655412
Speed: 621.3821583315744~64.46905179819875
Total Time: 0.0805
best val loss: 0.4528152048587799 test_score: 0.8571

Testing...
Test loss: 0.2957 score: 0.8367 time: 0.07s
test Score 0.8367
Epoch Time List: [0.2636579590616748, 0.25975602003745735, 0.26468017196748406, 0.2718527120305225, 0.2618885390693322, 0.3479452308965847, 0.2600003060651943, 0.2579977879067883, 0.2606184999458492, 0.2653235821053386, 0.26193044206593186, 0.3001001480733976, 0.27402778796385974, 0.26070440106559545, 0.261697799898684, 0.27947802701964974, 0.2813866949873045, 0.2809716969495639, 0.2634132548701018, 0.32986586494371295, 0.26469083002302796, 0.2669188821455464, 0.265883251093328, 0.26977924501989037, 0.2734037199988961, 0.264081779983826, 0.3590803889092058, 0.2572046739514917, 0.2596151839243248, 0.25835650612134486, 0.27727517706807703, 0.2660070880083367, 0.26601224206387997, 0.3873885910725221, 0.2693955939030275, 0.2690726799191907, 0.2687644619727507, 0.2710805289680138, 0.26242614700458944, 0.25665892695542425, 0.3201388049637899, 0.25592456792946905, 0.25425602099858224, 0.25378254998940974, 0.25521570700220764, 0.25895788706839085, 0.25186429906170815, 0.3908840990625322, 0.27473768207710236, 0.2602979780640453, 0.2572901080129668, 0.25905008509289473, 0.26044364098925143, 0.260414061951451, 0.2579698070185259, 0.3783162541221827, 0.2701006169663742, 0.2707481459947303, 0.2734974140767008, 0.2764650350436568, 0.2663395639974624, 0.37624370004050434, 0.2705489519285038, 0.2717439209809527, 0.2732144281035289, 0.27807989716529846, 0.2744881100952625, 0.2803119958844036, 0.3259502869332209, 0.27369889500550926, 0.2709058988839388, 0.27193602395709604, 0.2759713991545141, 0.275907858973369, 0.27235318324528635, 0.37115568993613124, 0.2511457520304248, 0.25220153690315783, 0.2524080699076876, 0.2531239369418472, 0.25003352388739586, 0.3554824689636007, 0.2664341061608866, 0.2672624848783016, 0.2692341869696975, 0.26978154096286744, 0.2748220820212737, 0.26833360898308456, 0.36871684493962675, 0.2639057911001146, 0.26489631016738713, 0.2660427598748356, 0.2674014859367162, 0.2716152409557253, 0.2686579128494486, 0.26825679501052946, 0.2702633938752115, 0.2706799589795992, 0.2874520701589063, 0.27357890096027404, 0.27117820107378066, 0.2699391399510205, 0.2681901209289208, 0.2708601279882714, 0.27281554287765175, 0.273714009905234, 0.27411945501808077, 0.27324683812912554, 0.27475852705538273, 0.27354637207463384, 0.27408537990413606, 0.27485892502591014, 0.273893766105175]
Total Epoch List: [113]
Total Time List: [0.08045368094462901]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe639ff0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6980;  Loss pred: 0.6980; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6967;  Loss pred: 0.6967; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6976;  Loss pred: 0.6976; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6960;  Loss pred: 0.6960; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6961;  Loss pred: 0.6961; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6936;  Loss pred: 0.6936; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6856;  Loss pred: 0.6856; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6826;  Loss pred: 0.6826; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6803;  Loss pred: 0.6803; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6772;  Loss pred: 0.6772; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6735;  Loss pred: 0.6735; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6712;  Loss pred: 0.6712; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6672;  Loss pred: 0.6672; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6669;  Loss pred: 0.6669; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6970 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6614;  Loss pred: 0.6614; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6971 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6562;  Loss pred: 0.6562; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6520;  Loss pred: 0.6520; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6484;  Loss pred: 0.6484; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6974 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6980,   Val_Loss: 0.6967,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.4898,   Val_Loss: 0.6967,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.5102,   Test_loss: 0.6940


[0.0746619829442352, 0.07449029898270965, 0.07784961094148457, 0.0771165780024603, 0.07523227401543409, 0.07447496498934925, 0.07476246694568545, 0.07467747095506638, 0.07502717908937484, 0.07612147403415293, 0.07486636401154101, 0.11705538700334728, 0.07544379110913724, 0.07491415599361062, 0.07529404002707452, 0.07838286901824176, 0.0814824610715732, 0.07682678592391312, 0.0763964649522677, 0.07536423893179744, 0.07647452503442764, 0.07691709895152599, 0.07710950798355043, 0.07922298100311309, 0.07826387998647988, 0.07656211103312671, 0.07399826601613313, 0.07452979404479265, 0.07518304802943021, 0.07503728300798684, 0.07704080804251134, 0.07565916900057346, 0.075471629970707, 0.08788657409604639, 0.07983054500073195, 0.07948136702179909, 0.07995804399251938, 0.08104489999823272, 0.07497242407407612, 0.0739172101020813, 0.08380451798439026, 0.07359044800978154, 0.07387399801518768, 0.07387064199429005, 0.07536911102943122, 0.07405606203246862, 0.07263796799816191, 0.21192537189926952, 0.08067476900760084, 0.07408679509535432, 0.0743240260053426, 0.07466686004772782, 0.07576675002928823, 0.07447383599355817, 0.07635993498843163, 0.07910885696765035, 0.07908502093050629, 0.07921708701178432, 0.07976605708245188, 0.08048648200929165, 0.07789969106670469, 0.07804185198619962, 0.07953362504485995, 0.07975321204867214, 0.08021186199039221, 0.08092086797114462, 0.07901691505685449, 0.09101050300523639, 0.08045938704162836, 0.08064390299841762, 0.0801143900025636, 0.08054495404940099, 0.08152791298925877, 0.0802199220051989, 0.08130519604310393, 0.07261517201550305, 0.07278057700023055, 0.07243281998671591, 0.07328006811439991, 0.07264520903117955, 0.07260711304843426, 0.16178358194883913, 0.07753035996574908, 0.07805470493622124, 0.07827370299492031, 0.07889816106762737, 0.07912886305712163, 0.07720200403127819, 0.1599306819261983, 0.07705091394018382, 0.07757036807015538, 0.07787439203821123, 0.07855257706250995, 0.07854179409332573, 0.07826511305756867, 0.07831133890431374, 0.07864040194544941, 0.07894350704737008, 0.08113366703037173, 0.07844524504616857, 0.07892207894474268, 0.0781033260282129, 0.0778773840283975, 0.07896020903717726, 0.079054233036004, 0.07911860290914774, 0.0791552250739187, 0.07952661102171987, 0.07941901101730764, 0.07878235296811908, 0.07943613897077739, 0.07944757107179612, 0.07982370199169964, 0.0784778599627316, 0.07844443991780281, 0.07793479796964675, 0.07817071303725243, 0.07836708601098508, 0.0779213469941169, 0.07810348097700626, 0.07844037504401058, 0.07833296398166567, 0.07819746492896229, 0.07833268493413925, 0.07829639595001936, 0.07817042898386717, 0.0782272539800033, 0.07832714391406626, 0.07871690508909523, 0.07808160106651485, 0.07820230396464467, 0.08275463501922786, 0.07830800500232726, 0.07768332003615797]
[0.0015237139376374532, 0.001520210183320605, 0.001588767570234379, 0.0015738077143359246, 0.0015353525309272263, 0.0015198972446805968, 0.0015257646315446009, 0.0015240300194911507, 0.0015311669201913234, 0.0015534994700847535, 0.0015278849798273674, 0.0023888854490479038, 0.0015396692063089233, 0.0015288603264002167, 0.001536613061777031, 0.0015996503881273829, 0.0016629073688076163, 0.0015678935902839412, 0.0015591115296381165, 0.0015380456924856622, 0.0015607045925393396, 0.0015697367132964488, 0.001573663428235723, 0.0016167955306757773, 0.0015972220405404056, 0.0015624920619005452, 0.0015101686942067985, 0.0015210162049957684, 0.0015343479189679635, 0.0015313731226119765, 0.0015722613886226804, 0.001544064673481091, 0.0015402373463409592, 0.0017936035529805385, 0.001629194795933305, 0.0016220687147305937, 0.0016317968161738648, 0.0016539775509843413, 0.0015300494708995126, 0.0015085144918792102, 0.0017102962853957195, 0.0015018458777506436, 0.0015076326125548507, 0.00150756412233245, 0.0015381451230496168, 0.0015113482047442574, 0.0014824075101665696, 0.004325007589781011, 0.0016464238572979765, 0.0015119754101092719, 0.00151681685725189, 0.0015238134703617922, 0.0015462602046793516, 0.0015198742039501667, 0.0015583660201720741, 0.0016144664687275582, 0.0016139800189899243, 0.0016166752451384555, 0.0016278787159684058, 0.001642581265495748, 0.0015897896136062182, 0.0015926908568612167, 0.0016231352049971418, 0.0016276165724218804, 0.0016369767753141268, 0.0016514462851254003, 0.001612590103201112, 0.0018573572041884977, 0.0016420283069720073, 0.0016457939387432166, 0.0016349875510727264, 0.0016437745724367549, 0.0016638349589644646, 0.0016371412654122223, 0.0016592897151653863, 0.0014819422860306744, 0.001485317897963889, 0.0014782208160554267, 0.0014955115941714268, 0.001482555286350603, 0.0014817778173149849, 0.0033017057540579414, 0.0015822522441989609, 0.0015929531619636988, 0.0015974225101004146, 0.0016101665524005586, 0.0016148747562677885, 0.0015755511026791468, 0.003263891467881598, 0.0015724676314323228, 0.00158306873612562, 0.0015892733069022699, 0.001603113817602244, 0.0016028937570066477, 0.0015972472052565034, 0.001598190589883954, 0.001604906162152029, 0.001611091980558573, 0.0016557891230688107, 0.0016009233682891544, 0.0016106546723416873, 0.0015939454291472022, 0.0015893343679264796, 0.0016114328374934135, 0.0016133516946123267, 0.001614665365492811, 0.0016154127566105857, 0.0016229920616677525, 0.0016207961432103599, 0.0016078031217983486, 0.0016211456932811712, 0.0016213790014652269, 0.0016290551426877476, 0.001601588978831257, 0.0016009069370980166, 0.001590506081013199, 0.0015953206742296414, 0.001599328285938471, 0.0015902315713085082, 0.0015939485913674747, 0.0016008239804900118, 0.001598631917993177, 0.001595866631203312, 0.001598626223145699, 0.0015978856316330482, 0.001595314877221779, 0.0015964745710204755, 0.001598513141103393, 0.001606467450797862, 0.0015935020625819356, 0.0015959653870335647, 0.0016888701024332217, 0.0015981225510679033, 0.001585373878288938]
[656.2911681115936, 657.803776722304, 629.4186882556254, 635.4016382630039, 651.3162155639152, 657.9392149698566, 655.4090842882198, 656.1550541726757, 653.0966590337828, 643.7079762540527, 654.4995292204443, 418.6052539264922, 649.4901605503419, 654.0819869101799, 650.7819208848455, 625.1365969851959, 601.3564067113657, 637.7983851690489, 641.3909338686686, 650.1757424279657, 640.7362448860057, 637.0495074298154, 635.4598969877105, 618.5073999938796, 626.0870277382718, 640.0032514620553, 662.1776784515059, 657.4551912829766, 651.7426638624584, 653.0087182765469, 636.0265584566773, 647.6412660523486, 649.2505862006492, 557.5368081414871, 613.8001437864508, 616.4966939554643, 612.8213942375114, 604.6031274154019, 653.573638643267, 662.9038072774922, 584.6940138612446, 665.8472848743493, 663.2915682988504, 663.3217023318618, 650.1337130122945, 661.6608911572531, 674.5783417460127, 231.21346708448974, 607.3770102196812, 661.3864176056469, 659.2753734368177, 656.2483003661691, 646.721681754314, 657.9491890848539, 641.6977700075753, 619.3996712661057, 619.586356853308, 618.55341881873, 614.2963785880768, 608.7978847720449, 629.0140477969522, 627.8682367592304, 616.0916212779458, 614.3953170199097, 610.8822159728599, 605.5298370931067, 620.1203877010811, 538.3993976737029, 609.0028994957196, 607.6094804211234, 611.6254520371689, 608.355924692025, 601.0211497313284, 610.820838205557, 602.6675093929133, 674.7901112117272, 673.2565475517565, 676.4889177169484, 668.6675007384614, 674.5111020187037, 674.8650089876651, 302.87374905257866, 632.0104797868465, 627.7648482565921, 626.0084565461267, 621.0537652202029, 619.243068924519, 634.6985497960361, 306.382736632184, 635.9431380403831, 631.6845107101198, 629.2183953867248, 623.7860275546042, 623.8716668704654, 626.077163703291, 625.7076010393797, 623.0893890139307, 620.6970254133445, 603.9416409177863, 624.6395172984836, 620.8655506186979, 627.3740503995945, 629.1942212919281, 620.5657330128022, 619.8276565112424, 619.3233727378494, 619.036834956146, 616.145958823989, 616.9807376387691, 621.966698809172, 616.8477047710727, 616.7589435266574, 613.8527627432665, 624.379920951841, 624.6459283965077, 628.7306989502176, 626.8332230339122, 625.2624985077465, 628.8392319976132, 627.3728057578593, 624.6782982935453, 625.534864370366, 626.6187790680115, 625.5370927371932, 625.8270180313183, 626.8355008018777, 626.3801617339851, 625.5813444922561, 622.4838228146757, 627.5486072353806, 626.5800048826303, 592.1118495491515, 625.7342400504745, 630.766038027118]
Elapsed: 0.08024597614169565~0.015822338561195824
Time per graph: 0.001637672982483585~0.0003229048685958332
Speed: 621.8989986653104~59.288457997062565
Total Time: 0.0783
best val loss: 0.6966668963432312 test_score: 0.5102

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.08s
test Score 0.5102
Epoch Time List: [0.2636579590616748, 0.25975602003745735, 0.26468017196748406, 0.2718527120305225, 0.2618885390693322, 0.3479452308965847, 0.2600003060651943, 0.2579977879067883, 0.2606184999458492, 0.2653235821053386, 0.26193044206593186, 0.3001001480733976, 0.27402778796385974, 0.26070440106559545, 0.261697799898684, 0.27947802701964974, 0.2813866949873045, 0.2809716969495639, 0.2634132548701018, 0.32986586494371295, 0.26469083002302796, 0.2669188821455464, 0.265883251093328, 0.26977924501989037, 0.2734037199988961, 0.264081779983826, 0.3590803889092058, 0.2572046739514917, 0.2596151839243248, 0.25835650612134486, 0.27727517706807703, 0.2660070880083367, 0.26601224206387997, 0.3873885910725221, 0.2693955939030275, 0.2690726799191907, 0.2687644619727507, 0.2710805289680138, 0.26242614700458944, 0.25665892695542425, 0.3201388049637899, 0.25592456792946905, 0.25425602099858224, 0.25378254998940974, 0.25521570700220764, 0.25895788706839085, 0.25186429906170815, 0.3908840990625322, 0.27473768207710236, 0.2602979780640453, 0.2572901080129668, 0.25905008509289473, 0.26044364098925143, 0.260414061951451, 0.2579698070185259, 0.3783162541221827, 0.2701006169663742, 0.2707481459947303, 0.2734974140767008, 0.2764650350436568, 0.2663395639974624, 0.37624370004050434, 0.2705489519285038, 0.2717439209809527, 0.2732144281035289, 0.27807989716529846, 0.2744881100952625, 0.2803119958844036, 0.3259502869332209, 0.27369889500550926, 0.2709058988839388, 0.27193602395709604, 0.2759713991545141, 0.275907858973369, 0.27235318324528635, 0.37115568993613124, 0.2511457520304248, 0.25220153690315783, 0.2524080699076876, 0.2531239369418472, 0.25003352388739586, 0.3554824689636007, 0.2664341061608866, 0.2672624848783016, 0.2692341869696975, 0.26978154096286744, 0.2748220820212737, 0.26833360898308456, 0.36871684493962675, 0.2639057911001146, 0.26489631016738713, 0.2660427598748356, 0.2674014859367162, 0.2716152409557253, 0.2686579128494486, 0.26825679501052946, 0.2702633938752115, 0.2706799589795992, 0.2874520701589063, 0.27357890096027404, 0.27117820107378066, 0.2699391399510205, 0.2681901209289208, 0.2708601279882714, 0.27281554287765175, 0.273714009905234, 0.27411945501808077, 0.27324683812912554, 0.27475852705538273, 0.27354637207463384, 0.27408537990413606, 0.27485892502591014, 0.273893766105175, 0.2598951800027862, 0.2558361040428281, 0.25657053594477475, 0.25687306199688464, 0.25608042592648417, 0.25662244588602334, 0.25571704213507473, 0.2575435320613906, 0.25643456901889294, 0.25629507505800575, 0.2562244370346889, 0.25752797699533403, 0.2572872079908848, 0.25709024199750274, 0.25627997098490596, 0.2579006489831954, 0.25603337795473635, 0.25587711692787707, 0.26095519913360476, 0.2640856570797041, 0.25579183001536876]
Total Epoch List: [113, 21]
Total Time List: [0.08045368094462901, 0.07826602703426033]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe4be050>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6969;  Loss pred: 0.6969; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6966;  Loss pred: 0.6966; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6956;  Loss pred: 0.6956; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6947;  Loss pred: 0.6947; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6951;  Loss pred: 0.6951; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6951;  Loss pred: 0.6951; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6905;  Loss pred: 0.6905; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6875;  Loss pred: 0.6875; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6866;  Loss pred: 0.6866; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6816;  Loss pred: 0.6816; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6816;  Loss pred: 0.6816; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6788;  Loss pred: 0.6788; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6771;  Loss pred: 0.6771; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6733;  Loss pred: 0.6733; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6693;  Loss pred: 0.6693; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6666;  Loss pred: 0.6666; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6655;  Loss pred: 0.6655; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6616;  Loss pred: 0.6616; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6578;  Loss pred: 0.6578; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6506;  Loss pred: 0.6506; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6476;  Loss pred: 0.6476; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6426;  Loss pred: 0.6426; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.6347;  Loss pred: 0.6347; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.6290;  Loss pred: 0.6290; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.6254;  Loss pred: 0.6254; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.6174;  Loss pred: 0.6174; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.6139;  Loss pred: 0.6139; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.6015;  Loss pred: 0.6015; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5000 time: 0.19s
Epoch 30/1000, LR 0.000270
Train loss: 0.5981;  Loss pred: 0.5981; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5886;  Loss pred: 0.5886; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5000 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5780;  Loss pred: 0.5780; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.5725;  Loss pred: 0.5725; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.5000 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.5634;  Loss pred: 0.5634; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5000 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.5427;  Loss pred: 0.5427; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.5000 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.5347;  Loss pred: 0.5347; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.5000 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.5276;  Loss pred: 0.5276; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6858 score: 0.4898 time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.5000 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.5104;  Loss pred: 0.5104; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6844 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6866 score: 0.5000 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4998;  Loss pred: 0.4998; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6829 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6855 score: 0.5000 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.4941;  Loss pred: 0.4941; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6812 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6842 score: 0.5000 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.4827;  Loss pred: 0.4827; Loss self: 0.0000; time: 0.12s
Val loss: 0.6793 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6829 score: 0.5000 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.4612;  Loss pred: 0.4612; Loss self: 0.0000; time: 0.12s
Val loss: 0.6772 score: 0.5714 time: 0.07s
Test loss: 0.6814 score: 0.6042 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.4533;  Loss pred: 0.4533; Loss self: 0.0000; time: 0.12s
Val loss: 0.6749 score: 0.6939 time: 0.07s
Test loss: 0.6797 score: 0.6458 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.4356;  Loss pred: 0.4356; Loss self: 0.0000; time: 0.25s
Val loss: 0.6724 score: 0.7347 time: 0.07s
Test loss: 0.6779 score: 0.7708 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.4293;  Loss pred: 0.4293; Loss self: 0.0000; time: 0.12s
Val loss: 0.6696 score: 0.8367 time: 0.07s
Test loss: 0.6759 score: 0.8750 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.4064;  Loss pred: 0.4064; Loss self: 0.0000; time: 0.12s
Val loss: 0.6665 score: 0.8980 time: 0.07s
Test loss: 0.6736 score: 0.8750 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.3996;  Loss pred: 0.3996; Loss self: 0.0000; time: 0.12s
Val loss: 0.6632 score: 0.8980 time: 0.07s
Test loss: 0.6712 score: 0.9167 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.3857;  Loss pred: 0.3857; Loss self: 0.0000; time: 0.12s
Val loss: 0.6595 score: 0.9796 time: 0.08s
Test loss: 0.6685 score: 0.9167 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.3661;  Loss pred: 0.3661; Loss self: 0.0000; time: 0.13s
Val loss: 0.6555 score: 0.9796 time: 0.07s
Test loss: 0.6654 score: 0.9167 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.3571;  Loss pred: 0.3571; Loss self: 0.0000; time: 0.12s
Val loss: 0.6511 score: 0.9796 time: 0.07s
Test loss: 0.6621 score: 0.9167 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.3463;  Loss pred: 0.3463; Loss self: 0.0000; time: 0.12s
Val loss: 0.6462 score: 0.9796 time: 0.08s
Test loss: 0.6584 score: 0.9167 time: 0.17s
Epoch 52/1000, LR 0.000269
Train loss: 0.3317;  Loss pred: 0.3317; Loss self: 0.0000; time: 0.12s
Val loss: 0.6410 score: 0.9796 time: 0.07s
Test loss: 0.6543 score: 0.9167 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.3152;  Loss pred: 0.3152; Loss self: 0.0000; time: 0.12s
Val loss: 0.6355 score: 0.9796 time: 0.07s
Test loss: 0.6501 score: 0.8958 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.3070;  Loss pred: 0.3070; Loss self: 0.0000; time: 0.12s
Val loss: 0.6296 score: 0.9796 time: 0.07s
Test loss: 0.6454 score: 0.8750 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.2870;  Loss pred: 0.2870; Loss self: 0.0000; time: 0.12s
Val loss: 0.6233 score: 0.9592 time: 0.07s
Test loss: 0.6405 score: 0.8750 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.2786;  Loss pred: 0.2786; Loss self: 0.0000; time: 0.12s
Val loss: 0.6167 score: 0.9592 time: 0.07s
Test loss: 0.6352 score: 0.8750 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.2629;  Loss pred: 0.2629; Loss self: 0.0000; time: 0.13s
Val loss: 0.6097 score: 0.9592 time: 0.07s
Test loss: 0.6297 score: 0.8750 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.2433;  Loss pred: 0.2433; Loss self: 0.0000; time: 0.12s
Val loss: 0.6022 score: 0.9592 time: 0.07s
Test loss: 0.6236 score: 0.8750 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.2351;  Loss pred: 0.2351; Loss self: 0.0000; time: 0.14s
Val loss: 0.5942 score: 0.9592 time: 0.12s
Test loss: 0.6172 score: 0.8750 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.2190;  Loss pred: 0.2190; Loss self: 0.0000; time: 0.12s
Val loss: 0.5855 score: 0.9592 time: 0.07s
Test loss: 0.6102 score: 0.8750 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.2104;  Loss pred: 0.2104; Loss self: 0.0000; time: 0.12s
Val loss: 0.5764 score: 0.9796 time: 0.07s
Test loss: 0.6026 score: 0.8958 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1921;  Loss pred: 0.1921; Loss self: 0.0000; time: 0.12s
Val loss: 0.5665 score: 0.9796 time: 0.07s
Test loss: 0.5943 score: 0.8958 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1801;  Loss pred: 0.1801; Loss self: 0.0000; time: 0.12s
Val loss: 0.5561 score: 0.9796 time: 0.07s
Test loss: 0.5855 score: 0.8958 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.1746;  Loss pred: 0.1746; Loss self: 0.0000; time: 0.12s
Val loss: 0.5448 score: 0.9796 time: 0.07s
Test loss: 0.5757 score: 0.8958 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.1576;  Loss pred: 0.1576; Loss self: 0.0000; time: 0.12s
Val loss: 0.5328 score: 0.9796 time: 0.07s
Test loss: 0.5652 score: 0.9167 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.1446;  Loss pred: 0.1446; Loss self: 0.0000; time: 0.12s
Val loss: 0.5201 score: 0.9796 time: 0.16s
Test loss: 0.5540 score: 0.9167 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.1343;  Loss pred: 0.1343; Loss self: 0.0000; time: 0.12s
Val loss: 0.5065 score: 0.9796 time: 0.07s
Test loss: 0.5418 score: 0.9167 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.1279;  Loss pred: 0.1279; Loss self: 0.0000; time: 0.12s
Val loss: 0.4922 score: 0.9796 time: 0.07s
Test loss: 0.5290 score: 0.9167 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.1181;  Loss pred: 0.1181; Loss self: 0.0000; time: 0.12s
Val loss: 0.4776 score: 0.9796 time: 0.07s
Test loss: 0.5159 score: 0.9167 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.1059;  Loss pred: 0.1059; Loss self: 0.0000; time: 0.12s
Val loss: 0.4622 score: 0.9796 time: 0.07s
Test loss: 0.5020 score: 0.9167 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0953;  Loss pred: 0.0953; Loss self: 0.0000; time: 0.12s
Val loss: 0.4466 score: 0.9796 time: 0.07s
Test loss: 0.4880 score: 0.9167 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0901;  Loss pred: 0.0901; Loss self: 0.0000; time: 0.12s
Val loss: 0.4308 score: 0.9796 time: 0.07s
Test loss: 0.4736 score: 0.9167 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0837;  Loss pred: 0.0837; Loss self: 0.0000; time: 0.12s
Val loss: 0.4151 score: 0.9796 time: 0.07s
Test loss: 0.4593 score: 0.9167 time: 0.17s
Epoch 74/1000, LR 0.000267
Train loss: 0.0769;  Loss pred: 0.0769; Loss self: 0.0000; time: 0.12s
Val loss: 0.3993 score: 0.9796 time: 0.07s
Test loss: 0.4449 score: 0.9167 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0722;  Loss pred: 0.0722; Loss self: 0.0000; time: 0.12s
Val loss: 0.3838 score: 0.9796 time: 0.07s
Test loss: 0.4305 score: 0.9167 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0655;  Loss pred: 0.0655; Loss self: 0.0000; time: 0.12s
Val loss: 0.3688 score: 0.9796 time: 0.07s
Test loss: 0.4164 score: 0.9167 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0578;  Loss pred: 0.0578; Loss self: 0.0000; time: 0.12s
Val loss: 0.3539 score: 0.9796 time: 0.07s
Test loss: 0.4025 score: 0.9167 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0531;  Loss pred: 0.0531; Loss self: 0.0000; time: 0.12s
Val loss: 0.3391 score: 0.9796 time: 0.07s
Test loss: 0.3887 score: 0.9167 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0478;  Loss pred: 0.0478; Loss self: 0.0000; time: 0.12s
Val loss: 0.3247 score: 0.9796 time: 0.07s
Test loss: 0.3753 score: 0.8958 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0443;  Loss pred: 0.0443; Loss self: 0.0000; time: 0.12s
Val loss: 0.3105 score: 0.9796 time: 0.07s
Test loss: 0.3621 score: 0.8958 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0411;  Loss pred: 0.0411; Loss self: 0.0000; time: 0.13s
Val loss: 0.2971 score: 0.9796 time: 0.18s
Test loss: 0.3494 score: 0.8958 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0373;  Loss pred: 0.0373; Loss self: 0.0000; time: 0.12s
Val loss: 0.2845 score: 0.9796 time: 0.07s
Test loss: 0.3373 score: 0.8958 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0335;  Loss pred: 0.0335; Loss self: 0.0000; time: 0.12s
Val loss: 0.2725 score: 0.9796 time: 0.07s
Test loss: 0.3257 score: 0.8958 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0313;  Loss pred: 0.0313; Loss self: 0.0000; time: 0.12s
Val loss: 0.2615 score: 0.9796 time: 0.07s
Test loss: 0.3148 score: 0.8958 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0293;  Loss pred: 0.0293; Loss self: 0.0000; time: 0.12s
Val loss: 0.2515 score: 0.9796 time: 0.07s
Test loss: 0.3045 score: 0.8958 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0269;  Loss pred: 0.0269; Loss self: 0.0000; time: 0.12s
Val loss: 0.2422 score: 0.9796 time: 0.07s
Test loss: 0.2949 score: 0.8958 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0245;  Loss pred: 0.0245; Loss self: 0.0000; time: 0.12s
Val loss: 0.2338 score: 0.9796 time: 0.07s
Test loss: 0.2860 score: 0.8958 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0223;  Loss pred: 0.0223; Loss self: 0.0000; time: 0.13s
Val loss: 0.2262 score: 0.9796 time: 0.15s
Test loss: 0.2777 score: 0.8958 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0193;  Loss pred: 0.0193; Loss self: 0.0000; time: 0.12s
Val loss: 0.2194 score: 0.9796 time: 0.07s
Test loss: 0.2702 score: 0.8958 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0176;  Loss pred: 0.0176; Loss self: 0.0000; time: 0.12s
Val loss: 0.2133 score: 0.9796 time: 0.07s
Test loss: 0.2635 score: 0.8958 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0172;  Loss pred: 0.0172; Loss self: 0.0000; time: 0.12s
Val loss: 0.2078 score: 0.9796 time: 0.07s
Test loss: 0.2575 score: 0.8958 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0158;  Loss pred: 0.0158; Loss self: 0.0000; time: 0.12s
Val loss: 0.2029 score: 0.9796 time: 0.07s
Test loss: 0.2521 score: 0.8958 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0141;  Loss pred: 0.0141; Loss self: 0.0000; time: 0.12s
Val loss: 0.1986 score: 0.9796 time: 0.07s
Test loss: 0.2473 score: 0.8958 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.12s
Val loss: 0.1951 score: 0.9796 time: 0.07s
Test loss: 0.2434 score: 0.8958 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.12s
Val loss: 0.1921 score: 0.9796 time: 0.07s
Test loss: 0.2402 score: 0.8958 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.24s
Val loss: 0.1898 score: 0.9796 time: 0.07s
Test loss: 0.2376 score: 0.8958 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.12s
Val loss: 0.1879 score: 0.9796 time: 0.07s
Test loss: 0.2356 score: 0.8958 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.12s
Val loss: 0.1864 score: 0.9796 time: 0.07s
Test loss: 0.2343 score: 0.8958 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.12s
Val loss: 0.1850 score: 0.9796 time: 0.07s
Test loss: 0.2332 score: 0.8958 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.12s
Val loss: 0.1840 score: 0.9796 time: 0.07s
Test loss: 0.2325 score: 0.8958 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.12s
Val loss: 0.1832 score: 0.9796 time: 0.07s
Test loss: 0.2321 score: 0.8958 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.12s
Val loss: 0.1826 score: 0.9796 time: 0.07s
Test loss: 0.2322 score: 0.8958 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.13s
Val loss: 0.1822 score: 0.9796 time: 0.14s
Test loss: 0.2326 score: 0.8958 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.12s
Val loss: 0.1820 score: 0.9796 time: 0.07s
Test loss: 0.2333 score: 0.8958 time: 0.07s
Epoch 105/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.1819 score: 0.9796 time: 0.07s
Test loss: 0.2340 score: 0.8958 time: 0.07s
Epoch 106/1000, LR 0.000264
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.12s
Val loss: 0.1820 score: 0.9796 time: 0.07s
Test loss: 0.2349 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.1822 score: 0.9796 time: 0.07s
Test loss: 0.2357 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.12s
Val loss: 0.1823 score: 0.9796 time: 0.07s
Test loss: 0.2365 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.1825 score: 0.9796 time: 0.07s
Test loss: 0.2374 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.12s
Val loss: 0.1827 score: 0.9796 time: 0.07s
Test loss: 0.2384 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.22s
Val loss: 0.1829 score: 0.9796 time: 0.07s
Test loss: 0.2393 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.12s
Val loss: 0.1834 score: 0.9796 time: 0.07s
Test loss: 0.2404 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.12s
Val loss: 0.1838 score: 0.9796 time: 0.07s
Test loss: 0.2414 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.1842 score: 0.9796 time: 0.07s
Test loss: 0.2424 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.1846 score: 0.9796 time: 0.07s
Test loss: 0.2435 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.12s
Val loss: 0.1848 score: 0.9796 time: 0.07s
Test loss: 0.2441 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.12s
Val loss: 0.1851 score: 0.9796 time: 0.07s
Test loss: 0.2448 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.13s
Val loss: 0.1856 score: 0.9796 time: 0.14s
Test loss: 0.2461 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.12s
Val loss: 0.1859 score: 0.9796 time: 0.07s
Test loss: 0.2468 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.12s
Val loss: 0.1863 score: 0.9796 time: 0.07s
Test loss: 0.2478 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.1866 score: 0.9796 time: 0.07s
Test loss: 0.2486 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 122/1000, LR 0.000262
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.12s
Val loss: 0.1866 score: 0.9796 time: 0.07s
Test loss: 0.2486 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.13s
Val loss: 0.1870 score: 0.9796 time: 0.07s
Test loss: 0.2495 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 124/1000, LR 0.000261
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.12s
Val loss: 0.1874 score: 0.9796 time: 0.07s
Test loss: 0.2505 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 125/1000, LR 0.000261
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.12s
Val loss: 0.1875 score: 0.9796 time: 0.17s
Test loss: 0.2508 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 104,   Train_Loss: 0.0065,   Val_Loss: 0.1819,   Val_Precision: 1.0000,   Val_Recall: 0.9600,   Val_accuracy: 0.9796,   Val_Score: 0.9796,   Val_Loss: 0.1819,   Test_Precision: 0.9524,   Test_Recall: 0.8333,   Test_accuracy: 0.8889,   Test_Score: 0.8958,   Test_loss: 0.2340


[0.0746619829442352, 0.07449029898270965, 0.07784961094148457, 0.0771165780024603, 0.07523227401543409, 0.07447496498934925, 0.07476246694568545, 0.07467747095506638, 0.07502717908937484, 0.07612147403415293, 0.07486636401154101, 0.11705538700334728, 0.07544379110913724, 0.07491415599361062, 0.07529404002707452, 0.07838286901824176, 0.0814824610715732, 0.07682678592391312, 0.0763964649522677, 0.07536423893179744, 0.07647452503442764, 0.07691709895152599, 0.07710950798355043, 0.07922298100311309, 0.07826387998647988, 0.07656211103312671, 0.07399826601613313, 0.07452979404479265, 0.07518304802943021, 0.07503728300798684, 0.07704080804251134, 0.07565916900057346, 0.075471629970707, 0.08788657409604639, 0.07983054500073195, 0.07948136702179909, 0.07995804399251938, 0.08104489999823272, 0.07497242407407612, 0.0739172101020813, 0.08380451798439026, 0.07359044800978154, 0.07387399801518768, 0.07387064199429005, 0.07536911102943122, 0.07405606203246862, 0.07263796799816191, 0.21192537189926952, 0.08067476900760084, 0.07408679509535432, 0.0743240260053426, 0.07466686004772782, 0.07576675002928823, 0.07447383599355817, 0.07635993498843163, 0.07910885696765035, 0.07908502093050629, 0.07921708701178432, 0.07976605708245188, 0.08048648200929165, 0.07789969106670469, 0.07804185198619962, 0.07953362504485995, 0.07975321204867214, 0.08021186199039221, 0.08092086797114462, 0.07901691505685449, 0.09101050300523639, 0.08045938704162836, 0.08064390299841762, 0.0801143900025636, 0.08054495404940099, 0.08152791298925877, 0.0802199220051989, 0.08130519604310393, 0.07261517201550305, 0.07278057700023055, 0.07243281998671591, 0.07328006811439991, 0.07264520903117955, 0.07260711304843426, 0.16178358194883913, 0.07753035996574908, 0.07805470493622124, 0.07827370299492031, 0.07889816106762737, 0.07912886305712163, 0.07720200403127819, 0.1599306819261983, 0.07705091394018382, 0.07757036807015538, 0.07787439203821123, 0.07855257706250995, 0.07854179409332573, 0.07826511305756867, 0.07831133890431374, 0.07864040194544941, 0.07894350704737008, 0.08113366703037173, 0.07844524504616857, 0.07892207894474268, 0.0781033260282129, 0.0778773840283975, 0.07896020903717726, 0.079054233036004, 0.07911860290914774, 0.0791552250739187, 0.07952661102171987, 0.07941901101730764, 0.07878235296811908, 0.07943613897077739, 0.07944757107179612, 0.07982370199169964, 0.0784778599627316, 0.07844443991780281, 0.07793479796964675, 0.07817071303725243, 0.07836708601098508, 0.0779213469941169, 0.07810348097700626, 0.07844037504401058, 0.07833296398166567, 0.07819746492896229, 0.07833268493413925, 0.07829639595001936, 0.07817042898386717, 0.0782272539800033, 0.07832714391406626, 0.07871690508909523, 0.07808160106651485, 0.07820230396464467, 0.08275463501922786, 0.07830800500232726, 0.07768332003615797, 0.07458359596785158, 0.07356116501614451, 0.07377498503774405, 0.07400524895638227, 0.07382624095771462, 0.0738464150344953, 0.07286959700286388, 0.07355468301102519, 0.07390375307295471, 0.07392553996760398, 0.07388181099668145, 0.0737645230256021, 0.07352456299122423, 0.07370108703617007, 0.07433358300477266, 0.07369196298532188, 0.07415098091587424, 0.07412203098647296, 0.07402733794879168, 0.0735579050378874, 0.07400633103679866, 0.07448039401788265, 0.07418959098868072, 0.07397545897401869, 0.07457616191823035, 0.07396154897287488, 0.07387481001205742, 0.07300643005874008, 0.19056947994977236, 0.0723930629901588, 0.07248282199725509, 0.0727104350226, 0.07276074192486703, 0.07817875198088586, 0.07269085699226707, 0.07705648895353079, 0.08458387199789286, 0.073672532918863, 0.07320008799433708, 0.07355626102071255, 0.07451946707442403, 0.07313051400706172, 0.07478870591148734, 0.07775056699756533, 0.07743698894046247, 0.07761032599955797, 0.07811576791573316, 0.07867581292521209, 0.07790388108696789, 0.07647654204629362, 0.17082571994978935, 0.0764095060294494, 0.07652808702550828, 0.07706015894655138, 0.07709356001578271, 0.07788058393634856, 0.07642809895332903, 0.07630626996979117, 0.07056356803514063, 0.07178844592999667, 0.07286329101771116, 0.07248937303666025, 0.07483979593962431, 0.07365426991600543, 0.0727498111082241, 0.0723588679684326, 0.07264007197227329, 0.07276151096448302, 0.07282970799133182, 0.07450913998764008, 0.07416659197770059, 0.0734712720150128, 0.17615739000029862, 0.07660384604241699, 0.07623403507750481, 0.07647814694792032, 0.07705918198917061, 0.0796558050205931, 0.0775650660507381, 0.07784816203638911, 0.07665540103334934, 0.07760212803259492, 0.0773858519969508, 0.07799471204634756, 0.07207075599581003, 0.07164237799588591, 0.07101424294523895, 0.07200029992964119, 0.07206668902654201, 0.07223493896890432, 0.0721286169718951, 0.07264465896878392, 0.07388381101191044, 0.07144708698615432, 0.07538462290540338, 0.07202853995840997, 0.07197633699979633, 0.07163850590586662, 0.07216934207826853, 0.07362068991642445, 0.07192305196076632, 0.07178487698547542, 0.07164424494840205, 0.0712113679619506, 0.07154250307939947, 0.07103064993862063, 0.07249970699194819, 0.07312411302700639, 0.07101465505547822, 0.07204038405325264, 0.0706588759785518, 0.07081016898155212, 0.07121929700952023, 0.07172195392195135, 0.07408726098947227, 0.0733363360632211, 0.07215252192690969, 0.07200118794571608, 0.07157228898722678, 0.07189397397451103, 0.07271610596217215, 0.07132268999703228, 0.07706331193912774, 0.07671541499439627, 0.07749693805817515]
[0.0015237139376374532, 0.001520210183320605, 0.001588767570234379, 0.0015738077143359246, 0.0015353525309272263, 0.0015198972446805968, 0.0015257646315446009, 0.0015240300194911507, 0.0015311669201913234, 0.0015534994700847535, 0.0015278849798273674, 0.0023888854490479038, 0.0015396692063089233, 0.0015288603264002167, 0.001536613061777031, 0.0015996503881273829, 0.0016629073688076163, 0.0015678935902839412, 0.0015591115296381165, 0.0015380456924856622, 0.0015607045925393396, 0.0015697367132964488, 0.001573663428235723, 0.0016167955306757773, 0.0015972220405404056, 0.0015624920619005452, 0.0015101686942067985, 0.0015210162049957684, 0.0015343479189679635, 0.0015313731226119765, 0.0015722613886226804, 0.001544064673481091, 0.0015402373463409592, 0.0017936035529805385, 0.001629194795933305, 0.0016220687147305937, 0.0016317968161738648, 0.0016539775509843413, 0.0015300494708995126, 0.0015085144918792102, 0.0017102962853957195, 0.0015018458777506436, 0.0015076326125548507, 0.00150756412233245, 0.0015381451230496168, 0.0015113482047442574, 0.0014824075101665696, 0.004325007589781011, 0.0016464238572979765, 0.0015119754101092719, 0.00151681685725189, 0.0015238134703617922, 0.0015462602046793516, 0.0015198742039501667, 0.0015583660201720741, 0.0016144664687275582, 0.0016139800189899243, 0.0016166752451384555, 0.0016278787159684058, 0.001642581265495748, 0.0015897896136062182, 0.0015926908568612167, 0.0016231352049971418, 0.0016276165724218804, 0.0016369767753141268, 0.0016514462851254003, 0.001612590103201112, 0.0018573572041884977, 0.0016420283069720073, 0.0016457939387432166, 0.0016349875510727264, 0.0016437745724367549, 0.0016638349589644646, 0.0016371412654122223, 0.0016592897151653863, 0.0014819422860306744, 0.001485317897963889, 0.0014782208160554267, 0.0014955115941714268, 0.001482555286350603, 0.0014817778173149849, 0.0033017057540579414, 0.0015822522441989609, 0.0015929531619636988, 0.0015974225101004146, 0.0016101665524005586, 0.0016148747562677885, 0.0015755511026791468, 0.003263891467881598, 0.0015724676314323228, 0.00158306873612562, 0.0015892733069022699, 0.001603113817602244, 0.0016028937570066477, 0.0015972472052565034, 0.001598190589883954, 0.001604906162152029, 0.001611091980558573, 0.0016557891230688107, 0.0016009233682891544, 0.0016106546723416873, 0.0015939454291472022, 0.0015893343679264796, 0.0016114328374934135, 0.0016133516946123267, 0.001614665365492811, 0.0016154127566105857, 0.0016229920616677525, 0.0016207961432103599, 0.0016078031217983486, 0.0016211456932811712, 0.0016213790014652269, 0.0016290551426877476, 0.001601588978831257, 0.0016009069370980166, 0.001590506081013199, 0.0015953206742296414, 0.001599328285938471, 0.0015902315713085082, 0.0015939485913674747, 0.0016008239804900118, 0.001598631917993177, 0.001595866631203312, 0.001598626223145699, 0.0015978856316330482, 0.001595314877221779, 0.0015964745710204755, 0.001598513141103393, 0.001606467450797862, 0.0015935020625819356, 0.0015959653870335647, 0.0016888701024332217, 0.0015981225510679033, 0.001585373878288938, 0.001553824915996908, 0.0015325242711696774, 0.001536978854953001, 0.0015417760199246306, 0.0015380466866190545, 0.0015384669798853186, 0.001518116604226331, 0.0015323892293963581, 0.0015396615223532233, 0.0015401154159917496, 0.001539204395764197, 0.0015367608963667105, 0.0015317617289838381, 0.001535439313253543, 0.0015486163125994306, 0.0015352492288608726, 0.0015448121024140467, 0.0015442089788848534, 0.0015422362072664935, 0.0015324563549559873, 0.0015417985632666387, 0.001551674875372555, 0.0015456164789308484, 0.001541155395292056, 0.0015536700399631325, 0.00154086560360156, 0.001539058541917863, 0.0015209672928904183, 0.003970197498953591, 0.001508188812294975, 0.001510058791609481, 0.0015148007296375, 0.0015158487901013966, 0.0016287239996017888, 0.001514392854005564, 0.0016053435198652248, 0.0017621639999561012, 0.0015348444358096458, 0.0015250018332153559, 0.0015324221045981783, 0.001552488897383834, 0.0015235523751471192, 0.001558098039822653, 0.0016198034791159444, 0.0016132706029263015, 0.0016168817916574578, 0.0016274118315777741, 0.0016390794359419185, 0.0016229975226451643, 0.001593261292631117, 0.0035588691656206115, 0.0015918647089468625, 0.001594335146364756, 0.0016054199780531537, 0.00160611583366214, 0.001622512165340595, 0.001592252061527688, 0.0015897139577039827, 0.0014700743340654299, 0.0014955926235415973, 0.0015179852295356493, 0.0015101952715970886, 0.0015591624154088397, 0.0015344639565834466, 0.0015156210647546686, 0.0015074764160090126, 0.0015133348327556935, 0.001515864811760063, 0.001517285583152746, 0.0015522737497425017, 0.0015451373328687623, 0.0015306515003127668, 0.0036699456250062212, 0.0015959134592170205, 0.0015882090641146835, 0.0015932947280816734, 0.0016053996247743878, 0.001659495937929023, 0.0016159388760570437, 0.0016218367090914398, 0.001596987521528111, 0.0016167110006790608, 0.0016122052499364752, 0.0016248898342989075, 0.0015014740832460423, 0.0014925495415809564, 0.001479463394692478, 0.0015000062485341914, 0.001501389354719625, 0.0015048945618521732, 0.0015026795202478145, 0.0015134303951829982, 0.0015392460627481341, 0.001488480978878215, 0.0015705129771959037, 0.0015005945824668743, 0.0014995070208290902, 0.001492468873038888, 0.0015035279599639277, 0.0015337643732588428, 0.0014983969158492982, 0.001495518270530738, 0.0014925884364250426, 0.0014835701658739708, 0.0014904688141541556, 0.0014798052070545964, 0.001510410562332254, 0.0015234190213959664, 0.0014794719803224627, 0.0015008413344427634, 0.0014720599162198293, 0.001475211853782336, 0.001483735354365005, 0.0014942073733739865, 0.0015434846039473389, 0.0015278403346504394, 0.0015031775401439518, 0.001500024748869085, 0.001491089353900558, 0.0014977911244689797, 0.0015149188742119197, 0.0014858893749381725, 0.0016054856653984946, 0.0015982378123832557, 0.001614519542878649]
[656.2911681115936, 657.803776722304, 629.4186882556254, 635.4016382630039, 651.3162155639152, 657.9392149698566, 655.4090842882198, 656.1550541726757, 653.0966590337828, 643.7079762540527, 654.4995292204443, 418.6052539264922, 649.4901605503419, 654.0819869101799, 650.7819208848455, 625.1365969851959, 601.3564067113657, 637.7983851690489, 641.3909338686686, 650.1757424279657, 640.7362448860057, 637.0495074298154, 635.4598969877105, 618.5073999938796, 626.0870277382718, 640.0032514620553, 662.1776784515059, 657.4551912829766, 651.7426638624584, 653.0087182765469, 636.0265584566773, 647.6412660523486, 649.2505862006492, 557.5368081414871, 613.8001437864508, 616.4966939554643, 612.8213942375114, 604.6031274154019, 653.573638643267, 662.9038072774922, 584.6940138612446, 665.8472848743493, 663.2915682988504, 663.3217023318618, 650.1337130122945, 661.6608911572531, 674.5783417460127, 231.21346708448974, 607.3770102196812, 661.3864176056469, 659.2753734368177, 656.2483003661691, 646.721681754314, 657.9491890848539, 641.6977700075753, 619.3996712661057, 619.586356853308, 618.55341881873, 614.2963785880768, 608.7978847720449, 629.0140477969522, 627.8682367592304, 616.0916212779458, 614.3953170199097, 610.8822159728599, 605.5298370931067, 620.1203877010811, 538.3993976737029, 609.0028994957196, 607.6094804211234, 611.6254520371689, 608.355924692025, 601.0211497313284, 610.820838205557, 602.6675093929133, 674.7901112117272, 673.2565475517565, 676.4889177169484, 668.6675007384614, 674.5111020187037, 674.8650089876651, 302.87374905257866, 632.0104797868465, 627.7648482565921, 626.0084565461267, 621.0537652202029, 619.243068924519, 634.6985497960361, 306.382736632184, 635.9431380403831, 631.6845107101198, 629.2183953867248, 623.7860275546042, 623.8716668704654, 626.077163703291, 625.7076010393797, 623.0893890139307, 620.6970254133445, 603.9416409177863, 624.6395172984836, 620.8655506186979, 627.3740503995945, 629.1942212919281, 620.5657330128022, 619.8276565112424, 619.3233727378494, 619.036834956146, 616.145958823989, 616.9807376387691, 621.966698809172, 616.8477047710727, 616.7589435266574, 613.8527627432665, 624.379920951841, 624.6459283965077, 628.7306989502176, 626.8332230339122, 625.2624985077465, 628.8392319976132, 627.3728057578593, 624.6782982935453, 625.534864370366, 626.6187790680115, 625.5370927371932, 625.8270180313183, 626.8355008018777, 626.3801617339851, 625.5813444922561, 622.4838228146757, 627.5486072353806, 626.5800048826303, 592.1118495491515, 625.7342400504745, 630.766038027118, 643.5731527437998, 652.5182137812175, 650.6270380867269, 648.6026420678697, 650.1753221797235, 649.9977010065843, 658.7109298561584, 652.5757169370878, 649.4934019469403, 649.3019871215658, 649.6862942647144, 650.719316429935, 652.8430506377739, 651.2794034698998, 645.7377414044216, 651.3600405726842, 647.327916733252, 647.5807443641129, 648.4091057442041, 652.5471324295695, 648.593158551971, 644.4649042602441, 646.9910314955567, 648.8638349220427, 643.6373066856135, 648.9858672051855, 649.74786388169, 657.4763340897479, 251.87663844520733, 663.0469552935642, 662.225871970296, 660.1528375546171, 659.6964067458925, 613.977567865699, 660.3306383512067, 622.9196353463053, 567.484070736272, 651.5318273753848, 655.7369166511573, 652.5617171661809, 644.1269896906465, 656.3607633793599, 641.8081368704005, 617.3588419169093, 619.8588123939693, 618.474402494758, 614.472612645627, 610.098557807442, 616.1438856482036, 627.6434409252463, 280.988132314669, 628.194088592852, 627.2206958995417, 622.8899687748193, 622.6200993983591, 616.328198556269, 628.0412656778406, 629.0439831353659, 680.2377109969271, 668.6312731551037, 658.767938279544, 662.1660250216928, 641.3700010449408, 651.693378465888, 659.7955275594355, 663.360294980576, 660.7922968237366, 659.6894342041657, 659.0717074646648, 644.2162667286518, 647.1916629852966, 653.3165778073352, 272.4836011700595, 626.6003925367075, 629.6400282524711, 627.6302697643391, 622.8978657825047, 602.5926169171317, 618.8352881515175, 616.5848845289761, 626.1789691650996, 618.5397387535397, 620.268418081012, 615.4263377685976, 666.0121617537989, 669.9945108292807, 675.9207450400356, 666.6638895519279, 666.0497470935802, 664.4983810488583, 665.4778923419977, 660.7505724629535, 649.6687074285077, 671.8258507768397, 636.7346303533673, 666.4025125001243, 666.8858405525114, 670.030724301708, 665.1023636593973, 651.9906300048325, 667.3799107716366, 668.6645156432053, 669.9770516748337, 674.0496829894798, 670.9298379835624, 675.7646176893779, 662.0716412734038, 656.4182184647151, 675.9168225558702, 666.2929498615407, 679.3201750700109, 677.8687396227685, 673.9746391147838, 669.25114801298, 647.884661397062, 654.5186544173765, 665.257411911726, 666.655667350776, 670.6506202221137, 667.6498369253827, 660.1013539554801, 672.9976113071067, 622.8644836587762, 625.6891135048437, 619.3793097214694]
Elapsed: 0.07849380436612285~0.016158482100224553
Time per graph: 0.0016176357103581903~0.00033174382068903297
Speed: 630.3205531846945~60.97429847023546
Total Time: 0.0784
best val loss: 0.18192139267921448 test_score: 0.8958

Testing...
Test loss: 0.6685 score: 0.9167 time: 0.07s
test Score 0.9167
Epoch Time List: [0.2636579590616748, 0.25975602003745735, 0.26468017196748406, 0.2718527120305225, 0.2618885390693322, 0.3479452308965847, 0.2600003060651943, 0.2579977879067883, 0.2606184999458492, 0.2653235821053386, 0.26193044206593186, 0.3001001480733976, 0.27402778796385974, 0.26070440106559545, 0.261697799898684, 0.27947802701964974, 0.2813866949873045, 0.2809716969495639, 0.2634132548701018, 0.32986586494371295, 0.26469083002302796, 0.2669188821455464, 0.265883251093328, 0.26977924501989037, 0.2734037199988961, 0.264081779983826, 0.3590803889092058, 0.2572046739514917, 0.2596151839243248, 0.25835650612134486, 0.27727517706807703, 0.2660070880083367, 0.26601224206387997, 0.3873885910725221, 0.2693955939030275, 0.2690726799191907, 0.2687644619727507, 0.2710805289680138, 0.26242614700458944, 0.25665892695542425, 0.3201388049637899, 0.25592456792946905, 0.25425602099858224, 0.25378254998940974, 0.25521570700220764, 0.25895788706839085, 0.25186429906170815, 0.3908840990625322, 0.27473768207710236, 0.2602979780640453, 0.2572901080129668, 0.25905008509289473, 0.26044364098925143, 0.260414061951451, 0.2579698070185259, 0.3783162541221827, 0.2701006169663742, 0.2707481459947303, 0.2734974140767008, 0.2764650350436568, 0.2663395639974624, 0.37624370004050434, 0.2705489519285038, 0.2717439209809527, 0.2732144281035289, 0.27807989716529846, 0.2744881100952625, 0.2803119958844036, 0.3259502869332209, 0.27369889500550926, 0.2709058988839388, 0.27193602395709604, 0.2759713991545141, 0.275907858973369, 0.27235318324528635, 0.37115568993613124, 0.2511457520304248, 0.25220153690315783, 0.2524080699076876, 0.2531239369418472, 0.25003352388739586, 0.3554824689636007, 0.2664341061608866, 0.2672624848783016, 0.2692341869696975, 0.26978154096286744, 0.2748220820212737, 0.26833360898308456, 0.36871684493962675, 0.2639057911001146, 0.26489631016738713, 0.2660427598748356, 0.2674014859367162, 0.2716152409557253, 0.2686579128494486, 0.26825679501052946, 0.2702633938752115, 0.2706799589795992, 0.2874520701589063, 0.27357890096027404, 0.27117820107378066, 0.2699391399510205, 0.2681901209289208, 0.2708601279882714, 0.27281554287765175, 0.273714009905234, 0.27411945501808077, 0.27324683812912554, 0.27475852705538273, 0.27354637207463384, 0.27408537990413606, 0.27485892502591014, 0.273893766105175, 0.2598951800027862, 0.2558361040428281, 0.25657053594477475, 0.25687306199688464, 0.25608042592648417, 0.25662244588602334, 0.25571704213507473, 0.2575435320613906, 0.25643456901889294, 0.25629507505800575, 0.2562244370346889, 0.25752797699533403, 0.2572872079908848, 0.25709024199750274, 0.25627997098490596, 0.2579006489831954, 0.25603337795473635, 0.25587711692787707, 0.26095519913360476, 0.2640856570797041, 0.25579183001536876, 0.26434666791465133, 0.26032491598743945, 0.2606525250012055, 0.259588101063855, 0.2589586990652606, 0.2600610088557005, 0.2586354030063376, 0.2596414618892595, 0.26006896793842316, 0.2606269399402663, 0.26072651403956115, 0.2600014170166105, 0.2594088459154591, 0.25947437004651874, 0.2610613589640707, 0.2587714451365173, 0.2594443450216204, 0.26092040294315666, 0.26125779491849244, 0.2607042919844389, 0.26025545806623995, 0.2603037740336731, 0.2599072679877281, 0.26026261097285897, 0.26114101498387754, 0.26085490884725004, 0.2605968330753967, 0.25631296390201896, 0.37477829796262085, 0.2546767658786848, 0.2537358009722084, 0.2556338729336858, 0.2549351130146533, 0.26442022097762674, 0.2583765231538564, 0.2636299029691145, 0.393635218963027, 0.2632772648939863, 0.2557191870873794, 0.25435380497947335, 0.25872488191816956, 0.2584023588569835, 0.25653152901213616, 0.39776157203596085, 0.27026081283111125, 0.26869807089678943, 0.27189151803031564, 0.27432765485718846, 0.2721727751195431, 0.26508059189654887, 0.37095102190505713, 0.2651885600062087, 0.26639631495345384, 0.2666718919062987, 0.26637216901872307, 0.2720138469012454, 0.26949684391729534, 0.2643299368210137, 0.3194819249911234, 0.25279645412229, 0.25455881806556135, 0.25437695998698473, 0.25923828687518835, 0.26074342196807265, 0.2552651269361377, 0.3444627139251679, 0.2535975428763777, 0.25238572410307825, 0.2553577439393848, 0.25610657304059714, 0.25903778907377273, 0.25609486596658826, 0.35788759391289204, 0.26416417700238526, 0.26445616607088596, 0.2630161348497495, 0.26663351990282536, 0.2691216850653291, 0.27092025498859584, 0.27043699484784156, 0.38242976914625615, 0.26823892700485885, 0.26990146411117166, 0.2695428590523079, 0.2668057889677584, 0.24914410908240825, 0.24904736608732492, 0.3457536270143464, 0.2495207181200385, 0.24987681000493467, 0.2504377879668027, 0.2540368379559368, 0.25937783787958324, 0.25300169293768704, 0.2497003930620849, 0.3737105990294367, 0.2516179090598598, 0.2515314859338105, 0.2526769370306283, 0.2548949100309983, 0.2566456280183047, 0.25168378197122365, 0.34258859092369676, 0.2505161960143596, 0.2493010580074042, 0.24996892001945525, 0.25049454788677394, 0.2599201661068946, 0.25185697490815073, 0.250957272015512, 0.35344095120672137, 0.24784335400909185, 0.2489324159687385, 0.2508052900666371, 0.25421191297937185, 0.25815993594005704, 0.25316260708495975, 0.34281416598241776, 0.2528679589740932, 0.2524907869519666, 0.2539110449142754, 0.2511709339451045, 0.2756071271141991, 0.2692641409812495, 0.36838696198537946]
Total Epoch List: [113, 21, 125]
Total Time List: [0.08045368094462901, 0.07826602703426033, 0.07836516597308218]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe46a830>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6884;  Loss pred: 0.6884; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4898 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6888;  Loss pred: 0.6888; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6866;  Loss pred: 0.6866; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 6/1000, LR 0.000120
Train loss: 0.6856;  Loss pred: 0.6856; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 7/1000, LR 0.000150
Train loss: 0.6838;  Loss pred: 0.6838; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 8/1000, LR 0.000180
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 9/1000, LR 0.000210
Train loss: 0.6801;  Loss pred: 0.6801; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6746;  Loss pred: 0.6746; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 11/1000, LR 0.000270
Train loss: 0.6714;  Loss pred: 0.6714; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6635;  Loss pred: 0.6635; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6599;  Loss pred: 0.6599; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6575;  Loss pred: 0.6575; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6497;  Loss pred: 0.6497; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6446;  Loss pred: 0.6446; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6414;  Loss pred: 0.6414; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4898 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6363;  Loss pred: 0.6363; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6288;  Loss pred: 0.6288; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.22s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6246;  Loss pred: 0.6246; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4898 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.6156;  Loss pred: 0.6156; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4898 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.6098;  Loss pred: 0.6098; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.5958;  Loss pred: 0.5958; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5102 time: 0.08s
Test loss: 0.6919 score: 0.5102 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.5891;  Loss pred: 0.5891; Loss self: 0.0000; time: 0.11s
Val loss: 0.6912 score: 0.6939 time: 0.08s
Test loss: 0.6915 score: 0.6735 time: 0.08s
Epoch 25/1000, LR 0.000270
Train loss: 0.5795;  Loss pred: 0.5795; Loss self: 0.0000; time: 0.11s
Val loss: 0.6908 score: 1.0000 time: 0.08s
Test loss: 0.6912 score: 0.8980 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.5728;  Loss pred: 0.5728; Loss self: 0.0000; time: 0.11s
Val loss: 0.6905 score: 0.9592 time: 0.08s
Test loss: 0.6908 score: 0.8776 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5650;  Loss pred: 0.5650; Loss self: 0.0000; time: 0.11s
Val loss: 0.6901 score: 0.8980 time: 0.08s
Test loss: 0.6904 score: 0.8367 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5549;  Loss pred: 0.5549; Loss self: 0.0000; time: 0.11s
Val loss: 0.6896 score: 0.7143 time: 0.08s
Test loss: 0.6899 score: 0.7755 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5460;  Loss pred: 0.5460; Loss self: 0.0000; time: 0.11s
Val loss: 0.6891 score: 0.6327 time: 0.08s
Test loss: 0.6894 score: 0.6735 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.5306;  Loss pred: 0.5306; Loss self: 0.0000; time: 0.11s
Val loss: 0.6884 score: 0.6122 time: 0.08s
Test loss: 0.6888 score: 0.5918 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.5218;  Loss pred: 0.5218; Loss self: 0.0000; time: 0.11s
Val loss: 0.6877 score: 0.5714 time: 0.08s
Test loss: 0.6881 score: 0.5510 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.5083;  Loss pred: 0.5083; Loss self: 0.0000; time: 0.11s
Val loss: 0.6869 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.5102 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.4974;  Loss pred: 0.4974; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6861 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.5102 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4790;  Loss pred: 0.4790; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6850 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6855 score: 0.5102 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4699;  Loss pred: 0.4699; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6839 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6844 score: 0.5102 time: 0.08s
Epoch 36/1000, LR 0.000270
Train loss: 0.4527;  Loss pred: 0.4527; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6826 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6832 score: 0.5102 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4410;  Loss pred: 0.4410; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6811 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6818 score: 0.5102 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4285;  Loss pred: 0.4285; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6794 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6803 score: 0.5102 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.4071;  Loss pred: 0.4071; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6776 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6786 score: 0.5102 time: 0.08s
Epoch 40/1000, LR 0.000269
Train loss: 0.3993;  Loss pred: 0.3993; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6756 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6768 score: 0.5102 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.3795;  Loss pred: 0.3795; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6734 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6747 score: 0.5102 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3593;  Loss pred: 0.3593; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6708 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6724 score: 0.5102 time: 0.08s
Epoch 43/1000, LR 0.000269
Train loss: 0.3396;  Loss pred: 0.3396; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6679 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6697 score: 0.5102 time: 0.08s
Epoch 44/1000, LR 0.000269
Train loss: 0.3320;  Loss pred: 0.3320; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6644 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6667 score: 0.5102 time: 0.08s
Epoch 45/1000, LR 0.000269
Train loss: 0.3193;  Loss pred: 0.3193; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6605 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6631 score: 0.5102 time: 0.08s
Epoch 46/1000, LR 0.000269
Train loss: 0.3000;  Loss pred: 0.3000; Loss self: 0.0000; time: 0.11s
Val loss: 0.6562 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6593 score: 0.5102 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2850;  Loss pred: 0.2850; Loss self: 0.0000; time: 0.11s
Val loss: 0.6516 score: 0.5102 time: 0.08s
Test loss: 0.6551 score: 0.5306 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.2703;  Loss pred: 0.2703; Loss self: 0.0000; time: 0.11s
Val loss: 0.6468 score: 0.5102 time: 0.08s
Test loss: 0.6508 score: 0.5306 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2575;  Loss pred: 0.2575; Loss self: 0.0000; time: 0.11s
Val loss: 0.6416 score: 0.5510 time: 0.08s
Test loss: 0.6461 score: 0.5510 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2383;  Loss pred: 0.2383; Loss self: 0.0000; time: 0.11s
Val loss: 0.6359 score: 0.5510 time: 0.08s
Test loss: 0.6410 score: 0.5510 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2256;  Loss pred: 0.2256; Loss self: 0.0000; time: 0.11s
Val loss: 0.6297 score: 0.5510 time: 0.08s
Test loss: 0.6356 score: 0.5510 time: 0.08s
Epoch 52/1000, LR 0.000269
Train loss: 0.2070;  Loss pred: 0.2070; Loss self: 0.0000; time: 0.11s
Val loss: 0.6229 score: 0.5714 time: 0.08s
Test loss: 0.6296 score: 0.5510 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.1956;  Loss pred: 0.1956; Loss self: 0.0000; time: 0.11s
Val loss: 0.6156 score: 0.5714 time: 0.08s
Test loss: 0.6232 score: 0.5510 time: 0.08s
Epoch 54/1000, LR 0.000269
Train loss: 0.1863;  Loss pred: 0.1863; Loss self: 0.0000; time: 0.11s
Val loss: 0.6080 score: 0.5918 time: 0.08s
Test loss: 0.6165 score: 0.6122 time: 0.08s
Epoch 55/1000, LR 0.000269
Train loss: 0.1700;  Loss pred: 0.1700; Loss self: 0.0000; time: 0.11s
Val loss: 0.5997 score: 0.6122 time: 0.08s
Test loss: 0.6093 score: 0.6327 time: 0.08s
Epoch 56/1000, LR 0.000269
Train loss: 0.1634;  Loss pred: 0.1634; Loss self: 0.0000; time: 0.11s
Val loss: 0.5910 score: 0.6327 time: 0.08s
Test loss: 0.6018 score: 0.6735 time: 0.08s
Epoch 57/1000, LR 0.000269
Train loss: 0.1535;  Loss pred: 0.1535; Loss self: 0.0000; time: 0.11s
Val loss: 0.5818 score: 0.6735 time: 0.08s
Test loss: 0.5937 score: 0.6939 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1372;  Loss pred: 0.1372; Loss self: 0.0000; time: 0.11s
Val loss: 0.5720 score: 0.7551 time: 0.08s
Test loss: 0.5853 score: 0.7347 time: 0.08s
Epoch 59/1000, LR 0.000268
Train loss: 0.1284;  Loss pred: 0.1284; Loss self: 0.0000; time: 0.11s
Val loss: 0.5612 score: 0.7959 time: 0.08s
Test loss: 0.5760 score: 0.7551 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1218;  Loss pred: 0.1218; Loss self: 0.0000; time: 0.11s
Val loss: 0.5502 score: 0.7959 time: 0.08s
Test loss: 0.5665 score: 0.7959 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.1118;  Loss pred: 0.1118; Loss self: 0.0000; time: 0.11s
Val loss: 0.5383 score: 0.8367 time: 0.08s
Test loss: 0.5563 score: 0.7959 time: 0.08s
Epoch 62/1000, LR 0.000268
Train loss: 0.1008;  Loss pred: 0.1008; Loss self: 0.0000; time: 0.11s
Val loss: 0.5262 score: 0.8367 time: 0.08s
Test loss: 0.5459 score: 0.7959 time: 0.08s
Epoch 63/1000, LR 0.000268
Train loss: 0.0926;  Loss pred: 0.0926; Loss self: 0.0000; time: 0.11s
Val loss: 0.5139 score: 0.8367 time: 0.08s
Test loss: 0.5354 score: 0.7959 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.0840;  Loss pred: 0.0840; Loss self: 0.0000; time: 0.11s
Val loss: 0.5008 score: 0.8367 time: 0.08s
Test loss: 0.5242 score: 0.8163 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.0784;  Loss pred: 0.0784; Loss self: 0.0000; time: 0.11s
Val loss: 0.4872 score: 0.8367 time: 0.08s
Test loss: 0.5127 score: 0.8163 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0742;  Loss pred: 0.0742; Loss self: 0.0000; time: 0.11s
Val loss: 0.4736 score: 0.8367 time: 0.08s
Test loss: 0.5011 score: 0.8163 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0693;  Loss pred: 0.0693; Loss self: 0.0000; time: 0.11s
Val loss: 0.4600 score: 0.8367 time: 0.08s
Test loss: 0.4895 score: 0.8367 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0638;  Loss pred: 0.0638; Loss self: 0.0000; time: 0.11s
Val loss: 0.4458 score: 0.8367 time: 0.08s
Test loss: 0.4773 score: 0.8571 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0610;  Loss pred: 0.0610; Loss self: 0.0000; time: 0.11s
Val loss: 0.4324 score: 0.8571 time: 0.08s
Test loss: 0.4655 score: 0.8571 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0579;  Loss pred: 0.0579; Loss self: 0.0000; time: 0.11s
Val loss: 0.4197 score: 0.8776 time: 0.08s
Test loss: 0.4544 score: 0.8571 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0531;  Loss pred: 0.0531; Loss self: 0.0000; time: 0.11s
Val loss: 0.4079 score: 0.8776 time: 0.08s
Test loss: 0.4438 score: 0.8776 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0517;  Loss pred: 0.0517; Loss self: 0.0000; time: 0.11s
Val loss: 0.3972 score: 0.8776 time: 0.08s
Test loss: 0.4340 score: 0.8776 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0461;  Loss pred: 0.0461; Loss self: 0.0000; time: 0.11s
Val loss: 0.3873 score: 0.8776 time: 0.08s
Test loss: 0.4246 score: 0.8776 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0393;  Loss pred: 0.0393; Loss self: 0.0000; time: 0.11s
Val loss: 0.3766 score: 0.8776 time: 0.08s
Test loss: 0.4146 score: 0.8776 time: 0.08s
Epoch 75/1000, LR 0.000267
Train loss: 0.0376;  Loss pred: 0.0376; Loss self: 0.0000; time: 0.11s
Val loss: 0.3663 score: 0.8980 time: 0.08s
Test loss: 0.4046 score: 0.8776 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0326;  Loss pred: 0.0326; Loss self: 0.0000; time: 0.11s
Val loss: 0.3564 score: 0.9184 time: 0.08s
Test loss: 0.3948 score: 0.8980 time: 0.08s
Epoch 77/1000, LR 0.000267
Train loss: 0.0290;  Loss pred: 0.0290; Loss self: 0.0000; time: 0.11s
Val loss: 0.3467 score: 0.9184 time: 0.08s
Test loss: 0.3850 score: 0.8980 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0325;  Loss pred: 0.0325; Loss self: 0.0000; time: 0.11s
Val loss: 0.3384 score: 0.9184 time: 0.08s
Test loss: 0.3761 score: 0.8980 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0285;  Loss pred: 0.0285; Loss self: 0.0000; time: 0.11s
Val loss: 0.3303 score: 0.9184 time: 0.08s
Test loss: 0.3673 score: 0.8980 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0241;  Loss pred: 0.0241; Loss self: 0.0000; time: 0.11s
Val loss: 0.3221 score: 0.9184 time: 0.08s
Test loss: 0.3583 score: 0.8980 time: 0.08s
Epoch 81/1000, LR 0.000267
Train loss: 0.0287;  Loss pred: 0.0287; Loss self: 0.0000; time: 0.11s
Val loss: 0.3108 score: 0.9184 time: 0.08s
Test loss: 0.3471 score: 0.8980 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0225;  Loss pred: 0.0225; Loss self: 0.0000; time: 0.11s
Val loss: 0.2992 score: 0.9184 time: 0.08s
Test loss: 0.3359 score: 0.8980 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0221;  Loss pred: 0.0221; Loss self: 0.0000; time: 0.11s
Val loss: 0.2838 score: 0.9184 time: 0.08s
Test loss: 0.3227 score: 0.8980 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0189;  Loss pred: 0.0189; Loss self: 0.0000; time: 0.11s
Val loss: 0.2663 score: 0.9184 time: 0.08s
Test loss: 0.3092 score: 0.8980 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.11s
Val loss: 0.2484 score: 0.9184 time: 0.08s
Test loss: 0.2966 score: 0.8980 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0155;  Loss pred: 0.0155; Loss self: 0.0000; time: 0.11s
Val loss: 0.2309 score: 0.9184 time: 0.08s
Test loss: 0.2850 score: 0.8980 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.11s
Val loss: 0.2140 score: 0.9184 time: 0.08s
Test loss: 0.2747 score: 0.8980 time: 0.08s
Epoch 88/1000, LR 0.000266
Train loss: 0.0153;  Loss pred: 0.0153; Loss self: 0.0000; time: 0.11s
Val loss: 0.2002 score: 0.9184 time: 0.08s
Test loss: 0.2664 score: 0.8980 time: 0.08s
Epoch 89/1000, LR 0.000266
Train loss: 0.0132;  Loss pred: 0.0132; Loss self: 0.0000; time: 0.11s
Val loss: 0.1881 score: 0.9184 time: 0.08s
Test loss: 0.2596 score: 0.8980 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.11s
Val loss: 0.1774 score: 0.9184 time: 0.08s
Test loss: 0.2538 score: 0.8980 time: 0.08s
Epoch 91/1000, LR 0.000266
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.11s
Val loss: 0.1683 score: 0.9184 time: 0.08s
Test loss: 0.2492 score: 0.9184 time: 0.08s
Epoch 92/1000, LR 0.000266
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.11s
Val loss: 0.1612 score: 0.9184 time: 0.08s
Test loss: 0.2457 score: 0.9184 time: 0.08s
Epoch 93/1000, LR 0.000265
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.11s
Val loss: 0.1551 score: 0.9184 time: 0.08s
Test loss: 0.2429 score: 0.9388 time: 0.08s
Epoch 94/1000, LR 0.000265
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.11s
Val loss: 0.1504 score: 0.9184 time: 0.08s
Test loss: 0.2408 score: 0.9388 time: 0.08s
Epoch 95/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.11s
Val loss: 0.1463 score: 0.9184 time: 0.08s
Test loss: 0.2392 score: 0.9184 time: 0.08s
Epoch 96/1000, LR 0.000265
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.11s
Val loss: 0.1441 score: 0.9184 time: 0.08s
Test loss: 0.2382 score: 0.9184 time: 0.08s
Epoch 97/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.11s
Val loss: 0.1421 score: 0.9184 time: 0.08s
Test loss: 0.2374 score: 0.9184 time: 0.08s
Epoch 98/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.11s
Val loss: 0.1403 score: 0.9184 time: 0.08s
Test loss: 0.2369 score: 0.9184 time: 0.08s
Epoch 99/1000, LR 0.000265
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.11s
Val loss: 0.1426 score: 0.9184 time: 0.08s
Test loss: 0.2371 score: 0.9184 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.11s
Val loss: 0.1444 score: 0.9184 time: 0.08s
Test loss: 0.2373 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.11s
Val loss: 0.1481 score: 0.9184 time: 0.08s
Test loss: 0.2378 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.11s
Val loss: 0.1511 score: 0.9184 time: 0.08s
Test loss: 0.2382 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.11s
Val loss: 0.1541 score: 0.9184 time: 0.08s
Test loss: 0.2387 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.11s
Val loss: 0.1587 score: 0.9184 time: 0.08s
Test loss: 0.2392 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0088;  Loss pred: 0.0088; Loss self: 0.0000; time: 0.11s
Val loss: 0.1639 score: 0.9184 time: 0.08s
Test loss: 0.2398 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.11s
Val loss: 0.1672 score: 0.9184 time: 0.08s
Test loss: 0.2403 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.11s
Val loss: 0.1705 score: 0.9184 time: 0.11s
Test loss: 0.2407 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.1730 score: 0.9184 time: 0.08s
Test loss: 0.2411 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.1757 score: 0.9184 time: 0.08s
Test loss: 0.2415 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.11s
Val loss: 0.1788 score: 0.9184 time: 0.08s
Test loss: 0.2418 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.1800 score: 0.9184 time: 0.08s
Test loss: 0.2421 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.11s
Val loss: 0.1802 score: 0.9184 time: 0.08s
Test loss: 0.2422 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.1802 score: 0.9184 time: 0.08s
Test loss: 0.2425 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.11s
Val loss: 0.1801 score: 0.9184 time: 0.08s
Test loss: 0.2428 score: 0.9388 time: 0.10s
     INFO: Early stopping counter 16 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.17s
Val loss: 0.1793 score: 0.9184 time: 0.08s
Test loss: 0.2431 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.11s
Val loss: 0.1774 score: 0.9184 time: 0.08s
Test loss: 0.2435 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.11s
Val loss: 0.1754 score: 0.9184 time: 0.08s
Test loss: 0.2440 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.1734 score: 0.9184 time: 0.07s
Test loss: 0.2445 score: 0.9388 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 097,   Train_Loss: 0.0075,   Val_Loss: 0.1403,   Val_Precision: 0.8571,   Val_Recall: 1.0000,   Val_accuracy: 0.9231,   Val_Score: 0.9184,   Val_Loss: 0.1403,   Test_Precision: 0.9200,   Test_Recall: 0.9200,   Test_accuracy: 0.9200,   Test_Score: 0.9184,   Test_loss: 0.2369


[0.08130666404031217, 0.0822259800042957, 0.08247798995580524, 0.0813729630317539, 0.08193867199588567, 0.08290606108494103, 0.08303875802084804, 0.08341728907544166, 0.08333099307492375, 0.08419168996624649, 0.08169648505281657, 0.07640662603080273, 0.07613991701509804, 0.0756448470056057, 0.07649089896585792, 0.07687133096624166, 0.07608142006210983, 0.07585918705444783, 0.08265544101595879, 0.08310862397775054, 0.08372052002232522, 0.08507303311489522, 0.08335881703533232, 0.08376629208214581, 0.08380790892988443, 0.08353550604078919, 0.08414001297205687, 0.0840749170165509, 0.08417534292675555, 0.0842644179938361, 0.08388468297198415, 0.08453306695446372, 0.08487929496914148, 0.08464671298861504, 0.08458988706115633, 0.0851032619830221, 0.0838476560311392, 0.0840995559701696, 0.08418219396844506, 0.08409199200104922, 0.08407610596623272, 0.08394573989789933, 0.08432338701095432, 0.08438613102771342, 0.08404462097678334, 0.0839559530140832, 0.0837594949407503, 0.08374761592131108, 0.08348970499355346, 0.0843551509315148, 0.08489478891715407, 0.08390811597928405, 0.08432180399540812, 0.08478476305026561, 0.08488708105869591, 0.08443687902763486, 0.08461920695845038, 0.08442359801847488, 0.08445659396238625, 0.08419876103289425, 0.08351990603841841, 0.08342217595782131, 0.08338164002634585, 0.08394210203550756, 0.0841186559991911, 0.08426265104208142, 0.08399951097089797, 0.08512688498012722, 0.08389519597403705, 0.08457535004708916, 0.08383860206231475, 0.08398901904001832, 0.08387294900603592, 0.08406232495326549, 0.0842521240701899, 0.08420637995004654, 0.08494354202412069, 0.08436930307652801, 0.08391791302710772, 0.0844784100772813, 0.08384254202246666, 0.08445941202808172, 0.08379940991289914, 0.0846183019457385, 0.08398005797062069, 0.08508286403957754, 0.08367936802096665, 0.08438487106468529, 0.08347895496990532, 0.0842649950645864, 0.08450500399339944, 0.08411535201594234, 0.08417397900484502, 0.08378756802994758, 0.08361021894961596, 0.08357543789315969, 0.083963270066306, 0.08367242990061641, 0.08369225403293967, 0.08425147796515375, 0.08407339605037123, 0.08413543202914298, 0.08456295297946781, 0.08554695907514542, 0.08388423197902739, 0.0829955090302974, 0.0898211789317429, 0.08404386800248176, 0.08374615001957864, 0.08343284099828452, 0.08379437506664544, 0.08481201610993594, 0.08338013594038785, 0.11134479509200901, 0.08200447994749993, 0.08183781604748219, 0.08172046800609678, 0.07705881900619715]
[0.001659319674292085, 0.0016780812245774635, 0.001683224284812352, 0.001660672714933753, 0.0016722177958344013, 0.001691960430304919, 0.001694668531037715, 0.0017023936546008503, 0.0017006325117331377, 0.0017181977544131937, 0.001667275205159522, 0.0015593188985878108, 0.0015538758574509804, 0.001543772387869504, 0.0015610387544052638, 0.001568802672780442, 0.001552682042083874, 0.0015481466745805679, 0.001686845735019567, 0.001696094366892868, 0.0017085820412719433, 0.001736184349283576, 0.0017012003476598433, 0.0017095161649417511, 0.0017103654883649884, 0.0017048062457303917, 0.0017171431218787115, 0.0017158146329908346, 0.0017178641413623582, 0.0017196819998742062, 0.001711932305550697, 0.0017251646317237494, 0.001732230509574316, 0.001727483938543164, 0.0017263242257378843, 0.0017368012649596346, 0.0017111766536967183, 0.0017163174687789716, 0.0017180039585396952, 0.001716163102062229, 0.0017158388972700555, 0.0017131783652632516, 0.0017208854492031494, 0.0017221659393410903, 0.001715196346464966, 0.0017133867962057798, 0.0017093774477704143, 0.001709135018802267, 0.0017038715304806828, 0.0017215336924798939, 0.001732546712594981, 0.0017124105301894704, 0.001720853142763431, 0.0017303012867401146, 0.001732389409361141, 0.0017232016128088748, 0.0017269225909887832, 0.0017229305718056097, 0.001723603958416046, 0.001718342061895801, 0.0017044878783350696, 0.0017024933868943124, 0.00170166612298665, 0.0017131041231736237, 0.0017167072652896143, 0.0017196459396343147, 0.0017142757340999587, 0.0017372833669413717, 0.0017121468566130011, 0.0017260275519814115, 0.00171099187882275, 0.0017140616130615985, 0.001711692836857876, 0.001715557652107459, 0.0017194311034732632, 0.0017184975500009498, 0.0017335416739616468, 0.0017218225117658777, 0.0017126104699409738, 0.0017240491852506387, 0.001711072286172789, 0.0017236614699608513, 0.0017101920390387578, 0.001726904121341602, 0.0017138787340942997, 0.0017363849803995416, 0.0017077422045095234, 0.0017221402258099038, 0.0017036521422429656, 0.001719693776828294, 0.0017245919182326418, 0.0017166398370600476, 0.001717836306221327, 0.0017099503679581139, 0.001706330998971754, 0.0017056211814930548, 0.001713536123802163, 0.0017076006102166614, 0.0017080051843457076, 0.001719417917656199, 0.001715783592864719, 0.0017170496332478157, 0.001725774550601384, 0.001745856307656029, 0.0017119231016128039, 0.001693785898577498, 0.0018330852843212839, 0.001715180979642485, 0.0017091051024403802, 0.0017027110407813167, 0.0017100892870743967, 0.0017308574716313457, 0.001701635427354854, 0.002272342756979776, 0.0016735608152551006, 0.001670159511173106, 0.0016677646531856485, 0.001572628959310146]
[602.6566281910866, 595.9187108191365, 594.0978923741475, 602.1656109644047, 598.0082274516287, 591.0303705032769, 590.0858968494913, 587.408204499249, 588.0165133270834, 582.0051838803179, 599.7810061023021, 641.3056372917977, 643.5520541778845, 647.7638853095814, 640.5990864595719, 637.4287967190076, 644.046864004357, 645.9336291704565, 592.8224373098351, 589.5898362258778, 585.2806454968684, 575.9757023570929, 587.8202419694961, 584.960833075289, 584.6703566007653, 586.5769218669005, 582.3626390011734, 582.8135398617629, 582.1182105861681, 581.5028592920955, 584.1352469123004, 579.65482343608, 577.2903747352558, 578.8765832713491, 579.2654618935032, 575.7711145052864, 584.3931997550709, 582.642790853503, 582.0708357680392, 582.6951988411528, 582.8052980912288, 583.7103831546094, 581.0962028082967, 580.6641376164978, 583.0236299540915, 583.6393756590493, 585.0083030546157, 585.0912824317315, 586.8987080956085, 580.8773911125061, 577.1850148283828, 583.9721155471723, 581.107112018955, 577.9340324504981, 577.2374239858539, 580.3151485971322, 579.0647509147648, 580.4064402618455, 580.1796840377287, 581.9563067069001, 586.6864837881934, 587.3737940469769, 587.6593454448439, 583.7356798531561, 582.5104956559362, 581.5150531583563, 583.3367293885351, 575.61133608306, 584.0620482627393, 579.3650274307844, 584.4563100369893, 583.4095999698833, 584.2169684110393, 582.9008420507236, 581.587711179583, 581.9036518262405, 576.8537411129605, 580.7799544765004, 583.9039393671729, 580.0298556184301, 584.4288450470626, 580.1603258107942, 584.729654432298, 579.0709441489532, 583.4718525336336, 575.9091510742625, 585.5684759440653, 580.6728075988765, 586.974286125944, 581.4988769944516, 579.8473189093904, 582.5333761988306, 582.1276429997396, 584.8122955721342, 586.0527650277738, 586.2966588657318, 583.5885138978578, 585.6170312993268, 585.4783165562077, 581.5921712407977, 582.8240835024963, 582.3943470454552, 579.4499632941789, 572.7848251970926, 584.1383874415267, 590.3933908292871, 545.5283551470214, 583.0288534382195, 585.1015239332735, 587.2987113192934, 584.7647883408414, 577.748322083096, 587.6699461731781, 440.0744548455021, 597.5283305420664, 598.7452056585951, 599.6049850857969, 635.877899920311]
Elapsed: 0.0836547478023222~0.003334073591044556
Time per graph: 0.0017072397510678~6.804231818458279e-05
Speed: 586.5640088497844~20.980545399409507
Total Time: 0.0776
best val loss: 0.14029967784881592 test_score: 0.9184

Testing...
Test loss: 0.6912 score: 0.8980 time: 0.07s
test Score 0.8980
Epoch Time List: [0.2585912949871272, 0.2636762351030484, 0.2666517689358443, 0.264044001000002, 0.3631483339704573, 0.26449008693452924, 0.2647828150074929, 0.2655341239878908, 0.2674151589162648, 0.2688815090805292, 0.2620687480084598, 0.3725732129532844, 0.24565964308567345, 0.24647613591514528, 0.24678855703677982, 0.25021466612815857, 0.24890182993840426, 0.24454928189516068, 0.39920764905400574, 0.26504675892647356, 0.26737631496507674, 0.27127470390405506, 0.27326649299357086, 0.269692077068612, 0.26884203602094203, 0.27114358998369426, 0.27154727512970567, 0.2695925988955423, 0.2714511880185455, 0.27188421797472984, 0.27032638480886817, 0.2709738939302042, 0.271332020056434, 0.2727815790567547, 0.27097001613583416, 0.2725289069348946, 0.27177899691741914, 0.2716720289317891, 0.2706974019529298, 0.27008703991305083, 0.27067692298442125, 0.2702614008449018, 0.27056273189373314, 0.2702282859245315, 0.2698757549514994, 0.27011089003644884, 0.2692750310525298, 0.2701240157475695, 0.27032909099943936, 0.2719096989603713, 0.2726719449274242, 0.272472096956335, 0.2717965330230072, 0.27414073911495507, 0.2734424890950322, 0.27214644209016114, 0.2721663569100201, 0.2741073650540784, 0.272680839872919, 0.2713122410932556, 0.2710627330234274, 0.27020718390122056, 0.2697495670290664, 0.27015921007841825, 0.2707666299538687, 0.27203503903001547, 0.27100660908035934, 0.27275092201307416, 0.27016831189393997, 0.271871647099033, 0.2714761398965493, 0.27298268605954945, 0.271074972813949, 0.27249525988008827, 0.27246175601612777, 0.2738945399178192, 0.27317001495976, 0.2723112179664895, 0.2727937310701236, 0.27301768213510513, 0.27363113407045603, 0.2725254959659651, 0.27281185414176434, 0.2738700301852077, 0.2730553769506514, 0.27499344607349485, 0.27269184798933566, 0.2734788110246882, 0.272584684076719, 0.27262844901997596, 0.2737057479098439, 0.27339794486761093, 0.274374911095947, 0.27194561203941703, 0.2715846858918667, 0.2713403159286827, 0.27350104483775795, 0.2709582820534706, 0.27125576813705266, 0.27207500592339784, 0.27266525488812476, 0.2723695560125634, 0.2721400238806382, 0.2756269659148529, 0.27280901290941983, 0.26776835694909096, 0.3082755560753867, 0.27095189702231437, 0.2708449469646439, 0.26939893001690507, 0.27183159708511084, 0.27456782502122223, 0.2704115549568087, 0.293164843111299, 0.32335987500846386, 0.26450769300572574, 0.26424814597703516, 0.2517891810275614]
Total Epoch List: [118]
Total Time List: [0.07761115906760097]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3fe478f70>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7001;  Loss pred: 0.7001; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6965;  Loss pred: 0.6965; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5102 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6979;  Loss pred: 0.6979; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6966;  Loss pred: 0.6966; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6957;  Loss pred: 0.6957; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6872;  Loss pred: 0.6872; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.4898 time: 0.09s
Epoch 10/1000, LR 0.000240
Train loss: 0.6830;  Loss pred: 0.6830; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6755;  Loss pred: 0.6755; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6725;  Loss pred: 0.6725; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6670;  Loss pred: 0.6670; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6607;  Loss pred: 0.6607; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6581;  Loss pred: 0.6581; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6511;  Loss pred: 0.6511; Loss self: 0.0000; time: 0.24s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6455;  Loss pred: 0.6455; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.08s
Epoch 19/1000, LR 0.000270
Train loss: 0.6368;  Loss pred: 0.6368; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4898 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6343;  Loss pred: 0.6343; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4898 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.6248;  Loss pred: 0.6248; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.6188;  Loss pred: 0.6188; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.6135;  Loss pred: 0.6135; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.18s
Epoch 24/1000, LR 0.000270
Train loss: 0.5994;  Loss pred: 0.5994; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4898 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5926;  Loss pred: 0.5926; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5838;  Loss pred: 0.5838; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4898 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5743;  Loss pred: 0.5743; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4898 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5672;  Loss pred: 0.5672; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.4898 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5520;  Loss pred: 0.5520; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.4898 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.5403;  Loss pred: 0.5403; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6890 score: 0.5102 time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.4898 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.5329;  Loss pred: 0.5329; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6884 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.4898 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.5216;  Loss pred: 0.5216; Loss self: 0.0000; time: 0.12s
Val loss: 0.6876 score: 0.5306 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.4898 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.5095;  Loss pred: 0.5095; Loss self: 0.0000; time: 0.12s
Val loss: 0.6866 score: 0.5306 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6879 score: 0.4898 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4933;  Loss pred: 0.4933; Loss self: 0.0000; time: 0.12s
Val loss: 0.6855 score: 0.5306 time: 0.07s
Test loss: 0.6869 score: 0.5306 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4734;  Loss pred: 0.4734; Loss self: 0.0000; time: 0.12s
Val loss: 0.6844 score: 0.5510 time: 0.07s
Test loss: 0.6858 score: 0.5306 time: 0.08s
Epoch 36/1000, LR 0.000270
Train loss: 0.4670;  Loss pred: 0.4670; Loss self: 0.0000; time: 0.12s
Val loss: 0.6831 score: 0.5714 time: 0.07s
Test loss: 0.6846 score: 0.5510 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4536;  Loss pred: 0.4536; Loss self: 0.0000; time: 0.12s
Val loss: 0.6817 score: 0.6122 time: 0.15s
Test loss: 0.6832 score: 0.5714 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4424;  Loss pred: 0.4424; Loss self: 0.0000; time: 0.12s
Val loss: 0.6802 score: 0.6939 time: 0.07s
Test loss: 0.6817 score: 0.5918 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.4296;  Loss pred: 0.4296; Loss self: 0.0000; time: 0.12s
Val loss: 0.6784 score: 0.7755 time: 0.07s
Test loss: 0.6800 score: 0.6122 time: 0.08s
Epoch 40/1000, LR 0.000269
Train loss: 0.4113;  Loss pred: 0.4113; Loss self: 0.0000; time: 0.12s
Val loss: 0.6765 score: 0.7755 time: 0.07s
Test loss: 0.6781 score: 0.6327 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.3919;  Loss pred: 0.3919; Loss self: 0.0000; time: 0.12s
Val loss: 0.6744 score: 0.7959 time: 0.07s
Test loss: 0.6761 score: 0.6735 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3849;  Loss pred: 0.3849; Loss self: 0.0000; time: 0.12s
Val loss: 0.6720 score: 0.8163 time: 0.08s
Test loss: 0.6737 score: 0.7143 time: 0.08s
Epoch 43/1000, LR 0.000269
Train loss: 0.3668;  Loss pred: 0.3668; Loss self: 0.0000; time: 0.12s
Val loss: 0.6695 score: 0.8367 time: 0.07s
Test loss: 0.6711 score: 0.8367 time: 0.08s
Epoch 44/1000, LR 0.000269
Train loss: 0.3508;  Loss pred: 0.3508; Loss self: 0.0000; time: 0.12s
Val loss: 0.6666 score: 0.8367 time: 0.08s
Test loss: 0.6682 score: 0.8776 time: 0.21s
Epoch 45/1000, LR 0.000269
Train loss: 0.3312;  Loss pred: 0.3312; Loss self: 0.0000; time: 0.12s
Val loss: 0.6634 score: 0.8367 time: 0.07s
Test loss: 0.6649 score: 0.8980 time: 0.08s
Epoch 46/1000, LR 0.000269
Train loss: 0.3190;  Loss pred: 0.3190; Loss self: 0.0000; time: 0.12s
Val loss: 0.6600 score: 0.8367 time: 0.08s
Test loss: 0.6613 score: 0.9388 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.3027;  Loss pred: 0.3027; Loss self: 0.0000; time: 0.12s
Val loss: 0.6562 score: 0.8571 time: 0.08s
Test loss: 0.6574 score: 0.9796 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.2866;  Loss pred: 0.2866; Loss self: 0.0000; time: 0.12s
Val loss: 0.6521 score: 0.8980 time: 0.07s
Test loss: 0.6531 score: 0.9796 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2840;  Loss pred: 0.2840; Loss self: 0.0000; time: 0.12s
Val loss: 0.6477 score: 0.8980 time: 0.08s
Test loss: 0.6483 score: 0.9796 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2587;  Loss pred: 0.2587; Loss self: 0.0000; time: 0.12s
Val loss: 0.6429 score: 0.8980 time: 0.07s
Test loss: 0.6430 score: 0.9796 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2541;  Loss pred: 0.2541; Loss self: 0.0000; time: 0.13s
Val loss: 0.6377 score: 0.8980 time: 0.13s
Test loss: 0.6374 score: 1.0000 time: 0.08s
Epoch 52/1000, LR 0.000269
Train loss: 0.2346;  Loss pred: 0.2346; Loss self: 0.0000; time: 0.12s
Val loss: 0.6321 score: 0.9184 time: 0.07s
Test loss: 0.6311 score: 1.0000 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.2230;  Loss pred: 0.2230; Loss self: 0.0000; time: 0.12s
Val loss: 0.6261 score: 0.9184 time: 0.08s
Test loss: 0.6245 score: 1.0000 time: 0.08s
Epoch 54/1000, LR 0.000269
Train loss: 0.2060;  Loss pred: 0.2060; Loss self: 0.0000; time: 0.12s
Val loss: 0.6198 score: 0.9388 time: 0.08s
Test loss: 0.6173 score: 1.0000 time: 0.08s
Epoch 55/1000, LR 0.000269
Train loss: 0.1988;  Loss pred: 0.1988; Loss self: 0.0000; time: 0.12s
Val loss: 0.6130 score: 0.9388 time: 0.08s
Test loss: 0.6096 score: 1.0000 time: 0.08s
Epoch 56/1000, LR 0.000269
Train loss: 0.1769;  Loss pred: 0.1769; Loss self: 0.0000; time: 0.12s
Val loss: 0.6058 score: 0.9388 time: 0.07s
Test loss: 0.6014 score: 1.0000 time: 0.08s
Epoch 57/1000, LR 0.000269
Train loss: 0.1711;  Loss pred: 0.1711; Loss self: 0.0000; time: 0.12s
Val loss: 0.5982 score: 0.9388 time: 0.07s
Test loss: 0.5927 score: 1.0000 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1537;  Loss pred: 0.1537; Loss self: 0.0000; time: 0.21s
Val loss: 0.5900 score: 0.9388 time: 0.07s
Test loss: 0.5833 score: 1.0000 time: 0.08s
Epoch 59/1000, LR 0.000268
Train loss: 0.1484;  Loss pred: 0.1484; Loss self: 0.0000; time: 0.12s
Val loss: 0.5813 score: 0.9388 time: 0.07s
Test loss: 0.5732 score: 1.0000 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1336;  Loss pred: 0.1336; Loss self: 0.0000; time: 0.12s
Val loss: 0.5720 score: 0.9388 time: 0.07s
Test loss: 0.5623 score: 1.0000 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.1298;  Loss pred: 0.1298; Loss self: 0.0000; time: 0.12s
Val loss: 0.5622 score: 0.9388 time: 0.07s
Test loss: 0.5505 score: 1.0000 time: 0.08s
Epoch 62/1000, LR 0.000268
Train loss: 0.1139;  Loss pred: 0.1139; Loss self: 0.0000; time: 0.12s
Val loss: 0.5518 score: 0.9388 time: 0.08s
Test loss: 0.5381 score: 1.0000 time: 0.08s
Epoch 63/1000, LR 0.000268
Train loss: 0.1048;  Loss pred: 0.1048; Loss self: 0.0000; time: 0.12s
Val loss: 0.5409 score: 0.9388 time: 0.08s
Test loss: 0.5250 score: 1.0000 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.0994;  Loss pred: 0.0994; Loss self: 0.0000; time: 0.12s
Val loss: 0.5292 score: 0.9388 time: 0.08s
Test loss: 0.5107 score: 1.0000 time: 0.17s
Epoch 65/1000, LR 0.000268
Train loss: 0.0963;  Loss pred: 0.0963; Loss self: 0.0000; time: 0.12s
Val loss: 0.5173 score: 0.9388 time: 0.07s
Test loss: 0.4959 score: 1.0000 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0890;  Loss pred: 0.0890; Loss self: 0.0000; time: 0.12s
Val loss: 0.5051 score: 0.9388 time: 0.07s
Test loss: 0.4805 score: 1.0000 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0807;  Loss pred: 0.0807; Loss self: 0.0000; time: 0.12s
Val loss: 0.4926 score: 0.9388 time: 0.07s
Test loss: 0.4646 score: 1.0000 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0742;  Loss pred: 0.0742; Loss self: 0.0000; time: 0.12s
Val loss: 0.4802 score: 0.9388 time: 0.08s
Test loss: 0.4486 score: 1.0000 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0724;  Loss pred: 0.0724; Loss self: 0.0000; time: 0.12s
Val loss: 0.4677 score: 0.9388 time: 0.08s
Test loss: 0.4323 score: 1.0000 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0589;  Loss pred: 0.0589; Loss self: 0.0000; time: 0.12s
Val loss: 0.4552 score: 0.9184 time: 0.07s
Test loss: 0.4157 score: 1.0000 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0590;  Loss pred: 0.0590; Loss self: 0.0000; time: 0.14s
Val loss: 0.4426 score: 0.9184 time: 0.09s
Test loss: 0.3987 score: 1.0000 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0559;  Loss pred: 0.0559; Loss self: 0.0000; time: 0.12s
Val loss: 0.4298 score: 0.9184 time: 0.07s
Test loss: 0.3813 score: 1.0000 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0508;  Loss pred: 0.0508; Loss self: 0.0000; time: 0.12s
Val loss: 0.4173 score: 0.9184 time: 0.07s
Test loss: 0.3639 score: 1.0000 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0479;  Loss pred: 0.0479; Loss self: 0.0000; time: 0.12s
Val loss: 0.4050 score: 0.9184 time: 0.08s
Test loss: 0.3466 score: 1.0000 time: 0.08s
Epoch 75/1000, LR 0.000267
Train loss: 0.0453;  Loss pred: 0.0453; Loss self: 0.0000; time: 0.12s
Val loss: 0.3931 score: 0.9184 time: 0.08s
Test loss: 0.3293 score: 1.0000 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0417;  Loss pred: 0.0417; Loss self: 0.0000; time: 0.12s
Val loss: 0.3819 score: 0.9184 time: 0.07s
Test loss: 0.3126 score: 1.0000 time: 0.08s
Epoch 77/1000, LR 0.000267
Train loss: 0.0364;  Loss pred: 0.0364; Loss self: 0.0000; time: 0.12s
Val loss: 0.3712 score: 0.9184 time: 0.07s
Test loss: 0.2961 score: 1.0000 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0339;  Loss pred: 0.0339; Loss self: 0.0000; time: 0.19s
Val loss: 0.3606 score: 0.9184 time: 0.07s
Test loss: 0.2796 score: 1.0000 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0316;  Loss pred: 0.0316; Loss self: 0.0000; time: 0.12s
Val loss: 0.3506 score: 0.9184 time: 0.07s
Test loss: 0.2636 score: 1.0000 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0272;  Loss pred: 0.0272; Loss self: 0.0000; time: 0.11s
Val loss: 0.3409 score: 0.9184 time: 0.07s
Test loss: 0.2477 score: 1.0000 time: 0.08s
Epoch 81/1000, LR 0.000267
Train loss: 0.0303;  Loss pred: 0.0303; Loss self: 0.0000; time: 0.12s
Val loss: 0.3318 score: 0.9184 time: 0.07s
Test loss: 0.2321 score: 1.0000 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0258;  Loss pred: 0.0258; Loss self: 0.0000; time: 0.12s
Val loss: 0.3231 score: 0.9184 time: 0.08s
Test loss: 0.2170 score: 1.0000 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0226;  Loss pred: 0.0226; Loss self: 0.0000; time: 0.12s
Val loss: 0.3147 score: 0.9184 time: 0.07s
Test loss: 0.2018 score: 1.0000 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0226;  Loss pred: 0.0226; Loss self: 0.0000; time: 0.12s
Val loss: 0.3071 score: 0.9184 time: 0.07s
Test loss: 0.1875 score: 1.0000 time: 0.20s
Epoch 85/1000, LR 0.000266
Train loss: 0.0195;  Loss pred: 0.0195; Loss self: 0.0000; time: 0.12s
Val loss: 0.3002 score: 0.9184 time: 0.07s
Test loss: 0.1738 score: 1.0000 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.12s
Val loss: 0.2939 score: 0.9184 time: 0.07s
Test loss: 0.1605 score: 1.0000 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.12s
Val loss: 0.2883 score: 0.9184 time: 0.07s
Test loss: 0.1481 score: 1.0000 time: 0.08s
Epoch 88/1000, LR 0.000266
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.12s
Val loss: 0.2835 score: 0.9184 time: 0.08s
Test loss: 0.1366 score: 1.0000 time: 0.08s
Epoch 89/1000, LR 0.000266
Train loss: 0.0156;  Loss pred: 0.0156; Loss self: 0.0000; time: 0.12s
Val loss: 0.2793 score: 0.9184 time: 0.07s
Test loss: 0.1257 score: 1.0000 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.12s
Val loss: 0.2759 score: 0.9184 time: 0.07s
Test loss: 0.1157 score: 1.0000 time: 0.08s
Epoch 91/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.22s
Val loss: 0.2731 score: 0.9184 time: 0.07s
Test loss: 0.1064 score: 1.0000 time: 0.08s
Epoch 92/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.12s
Val loss: 0.2712 score: 0.9184 time: 0.07s
Test loss: 0.0979 score: 1.0000 time: 0.08s
Epoch 93/1000, LR 0.000265
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.12s
Val loss: 0.2700 score: 0.9184 time: 0.07s
Test loss: 0.0900 score: 1.0000 time: 0.08s
Epoch 94/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.12s
Val loss: 0.2694 score: 0.9184 time: 0.08s
Test loss: 0.0829 score: 1.0000 time: 0.08s
Epoch 95/1000, LR 0.000265
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.2696 score: 0.9184 time: 0.08s
Test loss: 0.0764 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.12s
Val loss: 0.2699 score: 0.9184 time: 0.07s
Test loss: 0.0706 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.12s
Val loss: 0.2707 score: 0.9184 time: 0.07s
Test loss: 0.0656 score: 1.0000 time: 0.20s
     INFO: Early stopping counter 3 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.12s
Val loss: 0.2718 score: 0.9184 time: 0.07s
Test loss: 0.0610 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.12s
Val loss: 0.2734 score: 0.9184 time: 0.07s
Test loss: 0.0568 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.12s
Val loss: 0.2751 score: 0.9184 time: 0.07s
Test loss: 0.0529 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.12s
Val loss: 0.2773 score: 0.9184 time: 0.07s
Test loss: 0.0493 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.12s
Val loss: 0.2796 score: 0.9184 time: 0.07s
Test loss: 0.0461 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.12s
Val loss: 0.2821 score: 0.9184 time: 0.07s
Test loss: 0.0432 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.2847 score: 0.9184 time: 0.07s
Test loss: 0.0406 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.12s
Val loss: 0.2870 score: 0.9184 time: 0.07s
Test loss: 0.0382 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.2895 score: 0.9388 time: 0.07s
Test loss: 0.0360 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.12s
Val loss: 0.2922 score: 0.9388 time: 0.07s
Test loss: 0.0341 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.12s
Val loss: 0.2949 score: 0.9388 time: 0.07s
Test loss: 0.0323 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.12s
Val loss: 0.2975 score: 0.9388 time: 0.07s
Test loss: 0.0308 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.12s
Val loss: 0.3002 score: 0.9388 time: 0.07s
Test loss: 0.0294 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.12s
Val loss: 0.3028 score: 0.9388 time: 0.07s
Test loss: 0.0281 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.12s
Val loss: 0.3055 score: 0.9388 time: 0.07s
Test loss: 0.0269 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.12s
Val loss: 0.3084 score: 0.9388 time: 0.07s
Test loss: 0.0258 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.3110 score: 0.9388 time: 0.07s
Test loss: 0.0248 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 093,   Train_Loss: 0.0105,   Val_Loss: 0.2694,   Val_Precision: 0.9200,   Val_Recall: 0.9200,   Val_accuracy: 0.9200,   Val_Score: 0.9184,   Val_Loss: 0.2694,   Test_Precision: 1.0000,   Test_Recall: 1.0000,   Test_accuracy: 1.0000,   Test_Score: 1.0000,   Test_loss: 0.0829


[0.08130666404031217, 0.0822259800042957, 0.08247798995580524, 0.0813729630317539, 0.08193867199588567, 0.08290606108494103, 0.08303875802084804, 0.08341728907544166, 0.08333099307492375, 0.08419168996624649, 0.08169648505281657, 0.07640662603080273, 0.07613991701509804, 0.0756448470056057, 0.07649089896585792, 0.07687133096624166, 0.07608142006210983, 0.07585918705444783, 0.08265544101595879, 0.08310862397775054, 0.08372052002232522, 0.08507303311489522, 0.08335881703533232, 0.08376629208214581, 0.08380790892988443, 0.08353550604078919, 0.08414001297205687, 0.0840749170165509, 0.08417534292675555, 0.0842644179938361, 0.08388468297198415, 0.08453306695446372, 0.08487929496914148, 0.08464671298861504, 0.08458988706115633, 0.0851032619830221, 0.0838476560311392, 0.0840995559701696, 0.08418219396844506, 0.08409199200104922, 0.08407610596623272, 0.08394573989789933, 0.08432338701095432, 0.08438613102771342, 0.08404462097678334, 0.0839559530140832, 0.0837594949407503, 0.08374761592131108, 0.08348970499355346, 0.0843551509315148, 0.08489478891715407, 0.08390811597928405, 0.08432180399540812, 0.08478476305026561, 0.08488708105869591, 0.08443687902763486, 0.08461920695845038, 0.08442359801847488, 0.08445659396238625, 0.08419876103289425, 0.08351990603841841, 0.08342217595782131, 0.08338164002634585, 0.08394210203550756, 0.0841186559991911, 0.08426265104208142, 0.08399951097089797, 0.08512688498012722, 0.08389519597403705, 0.08457535004708916, 0.08383860206231475, 0.08398901904001832, 0.08387294900603592, 0.08406232495326549, 0.0842521240701899, 0.08420637995004654, 0.08494354202412069, 0.08436930307652801, 0.08391791302710772, 0.0844784100772813, 0.08384254202246666, 0.08445941202808172, 0.08379940991289914, 0.0846183019457385, 0.08398005797062069, 0.08508286403957754, 0.08367936802096665, 0.08438487106468529, 0.08347895496990532, 0.0842649950645864, 0.08450500399339944, 0.08411535201594234, 0.08417397900484502, 0.08378756802994758, 0.08361021894961596, 0.08357543789315969, 0.083963270066306, 0.08367242990061641, 0.08369225403293967, 0.08425147796515375, 0.08407339605037123, 0.08413543202914298, 0.08456295297946781, 0.08554695907514542, 0.08388423197902739, 0.0829955090302974, 0.0898211789317429, 0.08404386800248176, 0.08374615001957864, 0.08343284099828452, 0.08379437506664544, 0.08481201610993594, 0.08338013594038785, 0.11134479509200901, 0.08200447994749993, 0.08183781604748219, 0.08172046800609678, 0.07705881900619715, 0.0731826729606837, 0.07408047397620976, 0.07576771499589086, 0.07651078002527356, 0.07664653903339058, 0.07765694602858275, 0.07641796790994704, 0.07528274809010327, 0.09104827104602009, 0.07516400993335992, 0.0751850779633969, 0.07567787007428706, 0.07508519501425326, 0.07841505494434386, 0.0757587649859488, 0.07662701094523072, 0.0798207629704848, 0.08008845907170326, 0.08024927403312176, 0.08003195596393198, 0.08210436499211937, 0.08015766204334795, 0.18689177895430475, 0.07931856706272811, 0.07953456905670464, 0.08026900002732873, 0.08072435192298144, 0.0818916349671781, 0.0815137029858306, 0.08075263595674187, 0.08125329203903675, 0.08107543794903904, 0.08081398997455835, 0.08072015992365777, 0.08107582398224622, 0.08150352898519486, 0.08103358501102775, 0.08099634700920433, 0.08098581701051444, 0.08130528905894607, 0.0815529900137335, 0.08267519297078252, 0.08256656490266323, 0.21805701893754303, 0.0825463819783181, 0.08271988097112626, 0.0831359950825572, 0.08478934899903834, 0.0830576439620927, 0.08292773808352649, 0.08100929902866483, 0.0822678740369156, 0.08276556804776192, 0.08303715998772532, 0.08243142801802605, 0.08168333605863154, 0.08167215797584504, 0.08130841003730893, 0.08206455502659082, 0.08174591592978686, 0.08317363704554737, 0.08311343693640083, 0.08260678593069315, 0.1704507659887895, 0.08177040901500732, 0.08204918296542019, 0.08312135492451489, 0.08335812401492149, 0.08265293191652745, 0.0831135850166902, 0.08205993799492717, 0.08255413104780018, 0.08226589194964617, 0.08304938697256148, 0.08329488197341561, 0.08098234096542001, 0.08554433204699308, 0.0808718359330669, 0.08076205407269299, 0.08077584998682141, 0.08177072298713028, 0.08172377594746649, 0.0808320640353486, 0.20715023996308446, 0.08063537999987602, 0.08037415600847453, 0.08083680702839047, 0.08239077194593847, 0.08131189097184688, 0.08231400104705244, 0.08147879096213728, 0.08146015799138695, 0.08186333195772022, 0.0826015139464289, 0.0830563580384478, 0.0812774799996987, 0.20376955100800842, 0.08095758594572544, 0.08173770701978356, 0.08197410695720464, 0.08354068209882826, 0.08230075798928738, 0.08267177396919578, 0.08271326404064894, 0.08279418293386698, 0.08368811302352697, 0.08269777405075729, 0.08289013197645545, 0.08294877002481371, 0.08331797609571368, 0.08304104395210743, 0.08294131001457572, 0.08242440002504736, 0.08340093202423304]
[0.001659319674292085, 0.0016780812245774635, 0.001683224284812352, 0.001660672714933753, 0.0016722177958344013, 0.001691960430304919, 0.001694668531037715, 0.0017023936546008503, 0.0017006325117331377, 0.0017181977544131937, 0.001667275205159522, 0.0015593188985878108, 0.0015538758574509804, 0.001543772387869504, 0.0015610387544052638, 0.001568802672780442, 0.001552682042083874, 0.0015481466745805679, 0.001686845735019567, 0.001696094366892868, 0.0017085820412719433, 0.001736184349283576, 0.0017012003476598433, 0.0017095161649417511, 0.0017103654883649884, 0.0017048062457303917, 0.0017171431218787115, 0.0017158146329908346, 0.0017178641413623582, 0.0017196819998742062, 0.001711932305550697, 0.0017251646317237494, 0.001732230509574316, 0.001727483938543164, 0.0017263242257378843, 0.0017368012649596346, 0.0017111766536967183, 0.0017163174687789716, 0.0017180039585396952, 0.001716163102062229, 0.0017158388972700555, 0.0017131783652632516, 0.0017208854492031494, 0.0017221659393410903, 0.001715196346464966, 0.0017133867962057798, 0.0017093774477704143, 0.001709135018802267, 0.0017038715304806828, 0.0017215336924798939, 0.001732546712594981, 0.0017124105301894704, 0.001720853142763431, 0.0017303012867401146, 0.001732389409361141, 0.0017232016128088748, 0.0017269225909887832, 0.0017229305718056097, 0.001723603958416046, 0.001718342061895801, 0.0017044878783350696, 0.0017024933868943124, 0.00170166612298665, 0.0017131041231736237, 0.0017167072652896143, 0.0017196459396343147, 0.0017142757340999587, 0.0017372833669413717, 0.0017121468566130011, 0.0017260275519814115, 0.00171099187882275, 0.0017140616130615985, 0.001711692836857876, 0.001715557652107459, 0.0017194311034732632, 0.0017184975500009498, 0.0017335416739616468, 0.0017218225117658777, 0.0017126104699409738, 0.0017240491852506387, 0.001711072286172789, 0.0017236614699608513, 0.0017101920390387578, 0.001726904121341602, 0.0017138787340942997, 0.0017363849803995416, 0.0017077422045095234, 0.0017221402258099038, 0.0017036521422429656, 0.001719693776828294, 0.0017245919182326418, 0.0017166398370600476, 0.001717836306221327, 0.0017099503679581139, 0.001706330998971754, 0.0017056211814930548, 0.001713536123802163, 0.0017076006102166614, 0.0017080051843457076, 0.001719417917656199, 0.001715783592864719, 0.0017170496332478157, 0.001725774550601384, 0.001745856307656029, 0.0017119231016128039, 0.001693785898577498, 0.0018330852843212839, 0.001715180979642485, 0.0017091051024403802, 0.0017027110407813167, 0.0017100892870743967, 0.0017308574716313457, 0.001701635427354854, 0.002272342756979776, 0.0016735608152551006, 0.001670159511173106, 0.0016677646531856485, 0.001572628959310146, 0.0014935239379731367, 0.0015118464076777501, 0.0015462798978753236, 0.0015614444903117052, 0.0015642150823140936, 0.0015848356332363828, 0.0015595503655091232, 0.0015363826140837402, 0.0018581279805310223, 0.0015339593863951005, 0.0015343893461917735, 0.0015444463280466746, 0.0015323509186582298, 0.0016003072437621197, 0.0015460972446112, 0.0015638165499026679, 0.001628995162662955, 0.0016344583484021072, 0.00163774028639024, 0.0016333052237537137, 0.0016755992855534566, 0.0016358706539458766, 0.003814117937842954, 0.0016187462665862879, 0.0016231544705449926, 0.0016381428577005863, 0.0016474357535302335, 0.0016712578564730225, 0.001663544958894502, 0.0016480129787090178, 0.0016582304497762602, 0.0016546007744701846, 0.001649265101521599, 0.001647350202523628, 0.0016546086526989024, 0.0016633373262284665, 0.0016537466328781173, 0.001652986673657231, 0.0016527717757247845, 0.001659291613447879, 0.0016643467349741533, 0.0016872488361384188, 0.0016850319367890455, 0.004450143243623327, 0.0016846200403738388, 0.0016881608361454339, 0.0016966529608685144, 0.0017303948775313947, 0.001695053958410055, 0.001692402818031153, 0.0016532510005849966, 0.0016789362048350122, 0.001689093225464529, 0.0016946359181168433, 0.0016822740411842052, 0.0016670068583394192, 0.001666778734200919, 0.0016593553068838557, 0.0016747868372773637, 0.0016682839985670789, 0.0016974211641948443, 0.0016961925905387924, 0.0016858527740957786, 0.003478587060995704, 0.001668783857449129, 0.0016744731217432692, 0.001696354182132957, 0.0017011862043861527, 0.0016867945289087234, 0.0016961956125855142, 0.0016746926121413708, 0.0016847781846489832, 0.0016788957540744118, 0.001694885448419622, 0.0016998955504778698, 0.0016527008360289798, 0.0017458026948365935, 0.0016504456312870796, 0.0016482051851569998, 0.0016484867344249267, 0.001668790265043475, 0.0016678321621931937, 0.0016496339599050734, 0.004227555917613968, 0.0016456199999974699, 0.0016402888981321333, 0.001649730755681438, 0.0016814443254273158, 0.0016594263463642221, 0.0016798775723888253, 0.0016628324686150467, 0.0016624522039058562, 0.0016706802440351065, 0.0016857451825801814, 0.0016950277150703632, 0.001658724081626504, 0.00415856226546956, 0.001652195631545417, 0.0016681164697915011, 0.0016729409583102987, 0.0017049118795679236, 0.001679607305903824, 0.0016871790605958324, 0.0016880257967479375, 0.001689677202731979, 0.00170792067394953, 0.0016877096745052508, 0.0016916353464582745, 0.001692832041322729, 0.0017003668590961974, 0.00169471518269607, 0.001692679796215831, 0.0016821306127560685, 0.0017020598372292457]
[602.6566281910866, 595.9187108191365, 594.0978923741475, 602.1656109644047, 598.0082274516287, 591.0303705032769, 590.0858968494913, 587.408204499249, 588.0165133270834, 582.0051838803179, 599.7810061023021, 641.3056372917977, 643.5520541778845, 647.7638853095814, 640.5990864595719, 637.4287967190076, 644.046864004357, 645.9336291704565, 592.8224373098351, 589.5898362258778, 585.2806454968684, 575.9757023570929, 587.8202419694961, 584.960833075289, 584.6703566007653, 586.5769218669005, 582.3626390011734, 582.8135398617629, 582.1182105861681, 581.5028592920955, 584.1352469123004, 579.65482343608, 577.2903747352558, 578.8765832713491, 579.2654618935032, 575.7711145052864, 584.3931997550709, 582.642790853503, 582.0708357680392, 582.6951988411528, 582.8052980912288, 583.7103831546094, 581.0962028082967, 580.6641376164978, 583.0236299540915, 583.6393756590493, 585.0083030546157, 585.0912824317315, 586.8987080956085, 580.8773911125061, 577.1850148283828, 583.9721155471723, 581.107112018955, 577.9340324504981, 577.2374239858539, 580.3151485971322, 579.0647509147648, 580.4064402618455, 580.1796840377287, 581.9563067069001, 586.6864837881934, 587.3737940469769, 587.6593454448439, 583.7356798531561, 582.5104956559362, 581.5150531583563, 583.3367293885351, 575.61133608306, 584.0620482627393, 579.3650274307844, 584.4563100369893, 583.4095999698833, 584.2169684110393, 582.9008420507236, 581.587711179583, 581.9036518262405, 576.8537411129605, 580.7799544765004, 583.9039393671729, 580.0298556184301, 584.4288450470626, 580.1603258107942, 584.729654432298, 579.0709441489532, 583.4718525336336, 575.9091510742625, 585.5684759440653, 580.6728075988765, 586.974286125944, 581.4988769944516, 579.8473189093904, 582.5333761988306, 582.1276429997396, 584.8122955721342, 586.0527650277738, 586.2966588657318, 583.5885138978578, 585.6170312993268, 585.4783165562077, 581.5921712407977, 582.8240835024963, 582.3943470454552, 579.4499632941789, 572.7848251970926, 584.1383874415267, 590.3933908292871, 545.5283551470214, 583.0288534382195, 585.1015239332735, 587.2987113192934, 584.7647883408414, 577.748322083096, 587.6699461731781, 440.0744548455021, 597.5283305420664, 598.7452056585951, 599.6049850857969, 635.877899920311, 669.5573968215743, 661.4428522114462, 646.7134452009993, 640.432629020564, 639.2982725371783, 630.9802600525245, 641.2104553439958, 650.8795340647451, 538.1760624013726, 651.9077420622341, 651.7250673578493, 647.4812247213158, 652.5920321669064, 624.880005947562, 646.7898468129487, 639.4611951524878, 613.875364961353, 611.8234832827819, 610.5974239689189, 612.2554348425876, 596.8014003238825, 611.2952742247098, 262.1838171489638, 617.7620425397871, 616.0843087622083, 610.447370508132, 607.003944073166, 598.3517122309139, 601.1259236808023, 606.7913377620101, 603.0524889558787, 604.3753970320771, 606.3306615033616, 607.0354673026222, 604.3725193681645, 601.2009616037714, 604.6875501476536, 604.9655547358414, 605.0442140213057, 602.6668199220737, 600.836339559695, 592.6808059258675, 593.4605618844084, 224.7118677433393, 593.6056653927061, 592.3606202613331, 589.3957238539232, 577.9027740920118, 589.9517210283918, 590.8758773891337, 604.8688309555862, 595.6152456062315, 592.0336337415498, 590.0972529316183, 594.4334725013464, 599.8775559904685, 599.9596584002593, 602.643686889413, 597.0909119548977, 599.4183249727979, 589.1289805346221, 589.5556940750176, 593.1716074888915, 287.4730407678116, 599.2387783092419, 597.2027780051285, 589.4995340787989, 587.8251289727774, 592.8404336519593, 589.5546436862303, 597.1245067602795, 593.5499456911273, 595.6295961635258, 590.0103755875888, 588.2714380415214, 605.0701846335032, 572.8024151627282, 605.8969656699096, 606.7205764218883, 606.6169530620149, 599.2364774335186, 599.5807148154544, 606.1950858828974, 236.5432934508409, 607.6737035290878, 609.6487034319031, 606.1595181857053, 594.7267981923005, 602.6178879171015, 595.2814755291819, 601.383494052704, 601.5210528462384, 598.5585832898535, 593.209466254806, 589.9608549813526, 602.8730221480987, 240.46772325701514, 605.2552015675216, 599.4785244971478, 597.7497263322541, 586.5405784218187, 595.3772625809601, 592.7053170318786, 592.4080081753181, 591.8290182190631, 585.5072868738812, 592.5189711868828, 591.1439496069112, 590.7260588112625, 588.1083806417715, 590.0696531255069, 590.779190627553, 594.4841574231629, 587.5234102391388]
Elapsed: 0.0849411730701706~0.01715194995698939
Time per graph: 0.001733493327962665~0.0003500397950405998
Speed: 587.6080094717797~54.775379310845835
Total Time: 0.0842
best val loss: 0.269440233707428 test_score: 1.0000

Testing...
Test loss: 0.6173 score: 1.0000 time: 0.08s
test Score 1.0000
Epoch Time List: [0.2585912949871272, 0.2636762351030484, 0.2666517689358443, 0.264044001000002, 0.3631483339704573, 0.26449008693452924, 0.2647828150074929, 0.2655341239878908, 0.2674151589162648, 0.2688815090805292, 0.2620687480084598, 0.3725732129532844, 0.24565964308567345, 0.24647613591514528, 0.24678855703677982, 0.25021466612815857, 0.24890182993840426, 0.24454928189516068, 0.39920764905400574, 0.26504675892647356, 0.26737631496507674, 0.27127470390405506, 0.27326649299357086, 0.269692077068612, 0.26884203602094203, 0.27114358998369426, 0.27154727512970567, 0.2695925988955423, 0.2714511880185455, 0.27188421797472984, 0.27032638480886817, 0.2709738939302042, 0.271332020056434, 0.2727815790567547, 0.27097001613583416, 0.2725289069348946, 0.27177899691741914, 0.2716720289317891, 0.2706974019529298, 0.27008703991305083, 0.27067692298442125, 0.2702614008449018, 0.27056273189373314, 0.2702282859245315, 0.2698757549514994, 0.27011089003644884, 0.2692750310525298, 0.2701240157475695, 0.27032909099943936, 0.2719096989603713, 0.2726719449274242, 0.272472096956335, 0.2717965330230072, 0.27414073911495507, 0.2734424890950322, 0.27214644209016114, 0.2721663569100201, 0.2741073650540784, 0.272680839872919, 0.2713122410932556, 0.2710627330234274, 0.27020718390122056, 0.2697495670290664, 0.27015921007841825, 0.2707666299538687, 0.27203503903001547, 0.27100660908035934, 0.27275092201307416, 0.27016831189393997, 0.271871647099033, 0.2714761398965493, 0.27298268605954945, 0.271074972813949, 0.27249525988008827, 0.27246175601612777, 0.2738945399178192, 0.27317001495976, 0.2723112179664895, 0.2727937310701236, 0.27301768213510513, 0.27363113407045603, 0.2725254959659651, 0.27281185414176434, 0.2738700301852077, 0.2730553769506514, 0.27499344607349485, 0.27269184798933566, 0.2734788110246882, 0.272584684076719, 0.27262844901997596, 0.2737057479098439, 0.27339794486761093, 0.274374911095947, 0.27194561203941703, 0.2715846858918667, 0.2713403159286827, 0.27350104483775795, 0.2709582820534706, 0.27125576813705266, 0.27207500592339784, 0.27266525488812476, 0.2723695560125634, 0.2721400238806382, 0.2756269659148529, 0.27280901290941983, 0.26776835694909096, 0.3082755560753867, 0.27095189702231437, 0.2708449469646439, 0.26939893001690507, 0.27183159708511084, 0.27456782502122223, 0.2704115549568087, 0.293164843111299, 0.32335987500846386, 0.26450769300572574, 0.26424814597703516, 0.2517891810275614, 0.24412179505452514, 0.33753902395255864, 0.24861660099122673, 0.2504335909616202, 0.25275876896921545, 0.25495653797406703, 0.25933399400673807, 0.2512899430003017, 0.33314073004294187, 0.2495840861229226, 0.24811906507238746, 0.2498384079663083, 0.2502687310334295, 0.25674802309367806, 0.25754052808042616, 0.25200502504594624, 0.38911498500965536, 0.26417364715598524, 0.2646574820391834, 0.2647921380121261, 0.2701308389659971, 0.2657114041503519, 0.37184626411180943, 0.2638373050140217, 0.26251801394391805, 0.264382730005309, 0.26472981891129166, 0.27677399304229766, 0.2710685059428215, 0.3946397420950234, 0.2671588659286499, 0.2649727939860895, 0.26706937595736235, 0.2667823350057006, 0.27301390399225056, 0.27047251584008336, 0.3439732809783891, 0.26749226299580187, 0.26833605696447194, 0.2684848109493032, 0.2699328640010208, 0.2748599109472707, 0.27406537206843495, 0.40815815108362585, 0.2744708020472899, 0.27400260511785746, 0.2754145299550146, 0.27746250992640853, 0.2758809400256723, 0.27378813503310084, 0.3436944881686941, 0.27133779297582805, 0.2738103929441422, 0.27502222394105047, 0.27459802699740976, 0.27116278395988047, 0.26964506588410586, 0.36357297596987337, 0.270231349975802, 0.2703728540800512, 0.2738108990015462, 0.2757712979800999, 0.27329661196563393, 0.36031927505973727, 0.2711006229510531, 0.272979406057857, 0.27396285615395755, 0.2750202401075512, 0.27532128512393683, 0.27286286908201873, 0.29941478301770985, 0.2733034690609202, 0.2715137619525194, 0.27383136097341776, 0.27557066490408033, 0.27060815901495516, 0.27062051894608885, 0.3374436520971358, 0.2647254371549934, 0.26362215890549123, 0.268643865827471, 0.27280109701678157, 0.26762076292652637, 0.39429188787471503, 0.2648369229864329, 0.26465360703878105, 0.2661936179501936, 0.26948151097167283, 0.27094204898457974, 0.26785846904385835, 0.3691446949960664, 0.26836267893668264, 0.26738440501503646, 0.27151821996085346, 0.27461161999963224, 0.2721155198523775, 0.39079070498701185, 0.26664362591691315, 0.26914786791894585, 0.2686893721111119, 0.27496757090557367, 0.27452910610008985, 0.27517029899172485, 0.27391040802467614, 0.27521514904219657, 0.2745974430581555, 0.27465988497715443, 0.27369704097509384, 0.27322545903734863, 0.2747643761103973, 0.2748836660757661, 0.2754033539677039, 0.2739604930393398, 0.2753625169862062]
Total Epoch List: [118, 114]
Total Time List: [0.07761115906760097, 0.08418258605524898]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7cb3ff8080a0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6924;  Loss pred: 0.6924; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6932;  Loss pred: 0.6932; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6883;  Loss pred: 0.6883; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6858;  Loss pred: 0.6858; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6836;  Loss pred: 0.6836; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6767;  Loss pred: 0.6767; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6722;  Loss pred: 0.6722; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6670;  Loss pred: 0.6670; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6624;  Loss pred: 0.6624; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6581;  Loss pred: 0.6581; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6536;  Loss pred: 0.6536; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6497;  Loss pred: 0.6497; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6439;  Loss pred: 0.6439; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6348;  Loss pred: 0.6348; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6299;  Loss pred: 0.6299; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6242;  Loss pred: 0.6242; Loss self: 0.0000; time: 0.12s
Val loss: 0.6924 score: 0.8776 time: 0.08s
Test loss: 0.6924 score: 0.8542 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6158;  Loss pred: 0.6158; Loss self: 0.0000; time: 0.12s
Val loss: 0.6923 score: 0.6122 time: 0.08s
Test loss: 0.6922 score: 0.6458 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6055;  Loss pred: 0.6055; Loss self: 0.0000; time: 0.12s
Val loss: 0.6921 score: 0.5714 time: 0.08s
Test loss: 0.6921 score: 0.5625 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6012;  Loss pred: 0.6012; Loss self: 0.0000; time: 0.12s
Val loss: 0.6919 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5942;  Loss pred: 0.5942; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5843;  Loss pred: 0.5843; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5763;  Loss pred: 0.5763; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5000 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5670;  Loss pred: 0.5670; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5552;  Loss pred: 0.5552; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5462;  Loss pred: 0.5462; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5351;  Loss pred: 0.5351; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5251;  Loss pred: 0.5251; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.5000 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5068;  Loss pred: 0.5068; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6885 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.5030;  Loss pred: 0.5030; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6878 score: 0.5000 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4869;  Loss pred: 0.4869; Loss self: 0.0000; time: 0.12s
Val loss: 0.6872 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.5000 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4720;  Loss pred: 0.4720; Loss self: 0.0000; time: 0.12s
Val loss: 0.6863 score: 0.5306 time: 0.08s
Test loss: 0.6861 score: 0.5417 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4567;  Loss pred: 0.4567; Loss self: 0.0000; time: 0.11s
Val loss: 0.6853 score: 0.5510 time: 0.08s
Test loss: 0.6850 score: 0.5625 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4445;  Loss pred: 0.4445; Loss self: 0.0000; time: 0.12s
Val loss: 0.6842 score: 0.5510 time: 0.08s
Test loss: 0.6838 score: 0.5625 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4281;  Loss pred: 0.4281; Loss self: 0.0000; time: 0.12s
Val loss: 0.6829 score: 0.5714 time: 0.08s
Test loss: 0.6824 score: 0.5625 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4173;  Loss pred: 0.4173; Loss self: 0.0000; time: 0.12s
Val loss: 0.6815 score: 0.5714 time: 0.08s
Test loss: 0.6809 score: 0.5833 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3986;  Loss pred: 0.3986; Loss self: 0.0000; time: 0.12s
Val loss: 0.6799 score: 0.5918 time: 0.08s
Test loss: 0.6792 score: 0.6042 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3857;  Loss pred: 0.3857; Loss self: 0.0000; time: 0.12s
Val loss: 0.6780 score: 0.6327 time: 0.08s
Test loss: 0.6772 score: 0.6042 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3666;  Loss pred: 0.3666; Loss self: 0.0000; time: 0.12s
Val loss: 0.6760 score: 0.6327 time: 0.08s
Test loss: 0.6749 score: 0.6250 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3582;  Loss pred: 0.3582; Loss self: 0.0000; time: 0.12s
Val loss: 0.6737 score: 0.6327 time: 0.08s
Test loss: 0.6724 score: 0.6458 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3433;  Loss pred: 0.3433; Loss self: 0.0000; time: 0.12s
Val loss: 0.6711 score: 0.6327 time: 0.08s
Test loss: 0.6695 score: 0.6667 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3275;  Loss pred: 0.3275; Loss self: 0.0000; time: 0.12s
Val loss: 0.6682 score: 0.6327 time: 0.08s
Test loss: 0.6664 score: 0.6875 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3044;  Loss pred: 0.3044; Loss self: 0.0000; time: 0.12s
Val loss: 0.6650 score: 0.6735 time: 0.08s
Test loss: 0.6629 score: 0.6875 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2944;  Loss pred: 0.2944; Loss self: 0.0000; time: 0.12s
Val loss: 0.6614 score: 0.6735 time: 0.08s
Test loss: 0.6589 score: 0.6875 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2769;  Loss pred: 0.2769; Loss self: 0.0000; time: 0.12s
Val loss: 0.6573 score: 0.6939 time: 0.08s
Test loss: 0.6545 score: 0.7083 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2656;  Loss pred: 0.2656; Loss self: 0.0000; time: 0.12s
Val loss: 0.6529 score: 0.7347 time: 0.08s
Test loss: 0.6498 score: 0.7083 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2470;  Loss pred: 0.2470; Loss self: 0.0000; time: 0.12s
Val loss: 0.6479 score: 0.7551 time: 0.08s
Test loss: 0.6445 score: 0.7083 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2444;  Loss pred: 0.2444; Loss self: 0.0000; time: 0.12s
Val loss: 0.6426 score: 0.7755 time: 0.08s
Test loss: 0.6387 score: 0.8125 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2260;  Loss pred: 0.2260; Loss self: 0.0000; time: 0.12s
Val loss: 0.6367 score: 0.8367 time: 0.08s
Test loss: 0.6324 score: 0.8333 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.2085;  Loss pred: 0.2085; Loss self: 0.0000; time: 0.12s
Val loss: 0.6302 score: 0.8571 time: 0.08s
Test loss: 0.6255 score: 0.8333 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1960;  Loss pred: 0.1960; Loss self: 0.0000; time: 0.12s
Val loss: 0.6232 score: 0.8776 time: 0.08s
Test loss: 0.6180 score: 0.8333 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1870;  Loss pred: 0.1870; Loss self: 0.0000; time: 0.12s
Val loss: 0.6156 score: 0.8776 time: 0.08s
Test loss: 0.6101 score: 0.8333 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1824;  Loss pred: 0.1824; Loss self: 0.0000; time: 0.12s
Val loss: 0.6075 score: 0.8776 time: 0.08s
Test loss: 0.6016 score: 0.8333 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1612;  Loss pred: 0.1612; Loss self: 0.0000; time: 0.12s
Val loss: 0.5990 score: 0.8776 time: 0.08s
Test loss: 0.5927 score: 0.8542 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1538;  Loss pred: 0.1538; Loss self: 0.0000; time: 0.12s
Val loss: 0.5898 score: 0.8980 time: 0.08s
Test loss: 0.5832 score: 0.8542 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1401;  Loss pred: 0.1401; Loss self: 0.0000; time: 0.12s
Val loss: 0.5801 score: 0.8980 time: 0.08s
Test loss: 0.5732 score: 0.8542 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1313;  Loss pred: 0.1313; Loss self: 0.0000; time: 0.12s
Val loss: 0.5700 score: 0.8980 time: 0.08s
Test loss: 0.5628 score: 0.8542 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1177;  Loss pred: 0.1177; Loss self: 0.0000; time: 0.12s
Val loss: 0.5592 score: 0.9184 time: 0.08s
Test loss: 0.5518 score: 0.8542 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1175;  Loss pred: 0.1175; Loss self: 0.0000; time: 0.12s
Val loss: 0.5481 score: 0.9184 time: 0.08s
Test loss: 0.5405 score: 0.8542 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1039;  Loss pred: 0.1039; Loss self: 0.0000; time: 0.12s
Val loss: 0.5366 score: 0.9184 time: 0.08s
Test loss: 0.5289 score: 0.8750 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0984;  Loss pred: 0.0984; Loss self: 0.0000; time: 0.12s
Val loss: 0.5246 score: 0.9388 time: 0.08s
Test loss: 0.5169 score: 0.8750 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0862;  Loss pred: 0.0862; Loss self: 0.0000; time: 0.12s
Val loss: 0.5120 score: 0.9388 time: 0.08s
Test loss: 0.5043 score: 0.8958 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0825;  Loss pred: 0.0825; Loss self: 0.0000; time: 0.22s
Val loss: 0.4989 score: 0.9388 time: 0.08s
Test loss: 0.4911 score: 0.8958 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0831;  Loss pred: 0.0831; Loss self: 0.0000; time: 0.11s
Val loss: 0.4856 score: 0.9388 time: 0.08s
Test loss: 0.4779 score: 0.9167 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0714;  Loss pred: 0.0714; Loss self: 0.0000; time: 0.11s
Val loss: 0.4718 score: 0.9388 time: 0.08s
Test loss: 0.4643 score: 0.9375 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.11s
Val loss: 0.4576 score: 0.9388 time: 0.08s
Test loss: 0.4504 score: 0.9375 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0573;  Loss pred: 0.0573; Loss self: 0.0000; time: 0.12s
Val loss: 0.4427 score: 0.9388 time: 0.08s
Test loss: 0.4359 score: 0.9375 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0534;  Loss pred: 0.0534; Loss self: 0.0000; time: 0.12s
Val loss: 0.4278 score: 0.9592 time: 0.08s
Test loss: 0.4214 score: 0.9375 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0479;  Loss pred: 0.0479; Loss self: 0.0000; time: 0.12s
Val loss: 0.4129 score: 0.9592 time: 0.08s
Test loss: 0.4071 score: 0.9375 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0426;  Loss pred: 0.0426; Loss self: 0.0000; time: 0.12s
Val loss: 0.3979 score: 0.9592 time: 0.09s
Test loss: 0.3927 score: 0.9375 time: 0.17s
Epoch 74/1000, LR 0.000267
Train loss: 0.0427;  Loss pred: 0.0427; Loss self: 0.0000; time: 0.12s
Val loss: 0.3831 score: 0.9592 time: 0.08s
Test loss: 0.3785 score: 0.9375 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0368;  Loss pred: 0.0368; Loss self: 0.0000; time: 0.12s
Val loss: 0.3683 score: 0.9592 time: 0.08s
Test loss: 0.3643 score: 0.9375 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0359;  Loss pred: 0.0359; Loss self: 0.0000; time: 0.12s
Val loss: 0.3542 score: 0.9592 time: 0.08s
Test loss: 0.3505 score: 0.9375 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0305;  Loss pred: 0.0305; Loss self: 0.0000; time: 0.12s
Val loss: 0.3401 score: 0.9592 time: 0.09s
Test loss: 0.3368 score: 0.9375 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0296;  Loss pred: 0.0296; Loss self: 0.0000; time: 0.12s
Val loss: 0.3264 score: 0.9592 time: 0.08s
Test loss: 0.3234 score: 0.9375 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0262;  Loss pred: 0.0262; Loss self: 0.0000; time: 0.11s
Val loss: 0.3132 score: 0.9592 time: 0.08s
Test loss: 0.3104 score: 0.9375 time: 0.11s
Epoch 80/1000, LR 0.000267
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.13s
Val loss: 0.3003 score: 0.9592 time: 0.08s
Test loss: 0.2978 score: 0.9375 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0219;  Loss pred: 0.0219; Loss self: 0.0000; time: 0.12s
Val loss: 0.2877 score: 0.9592 time: 0.08s
Test loss: 0.2852 score: 0.9375 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0196;  Loss pred: 0.0196; Loss self: 0.0000; time: 0.12s
Val loss: 0.2760 score: 0.9592 time: 0.08s
Test loss: 0.2734 score: 0.9375 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0202;  Loss pred: 0.0202; Loss self: 0.0000; time: 0.12s
Val loss: 0.2650 score: 0.9592 time: 0.09s
Test loss: 0.2622 score: 0.9375 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0174;  Loss pred: 0.0174; Loss self: 0.0000; time: 0.12s
Val loss: 0.2547 score: 0.9592 time: 0.09s
Test loss: 0.2516 score: 0.9375 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0149;  Loss pred: 0.0149; Loss self: 0.0000; time: 0.12s
Val loss: 0.2451 score: 0.9592 time: 0.09s
Test loss: 0.2417 score: 0.9375 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.16s
Val loss: 0.2368 score: 0.9592 time: 0.09s
Test loss: 0.2327 score: 0.9375 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0128;  Loss pred: 0.0128; Loss self: 0.0000; time: 0.12s
Val loss: 0.2294 score: 0.9592 time: 0.09s
Test loss: 0.2246 score: 0.9375 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0127;  Loss pred: 0.0127; Loss self: 0.0000; time: 0.12s
Val loss: 0.2225 score: 0.9592 time: 0.09s
Test loss: 0.2169 score: 0.9375 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.12s
Val loss: 0.2164 score: 0.9592 time: 0.09s
Test loss: 0.2101 score: 0.9375 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.2113 score: 0.9592 time: 0.09s
Test loss: 0.2038 score: 0.9375 time: 0.08s
Epoch 91/1000, LR 0.000266
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.12s
Val loss: 0.2071 score: 0.9592 time: 0.09s
Test loss: 0.1985 score: 0.9375 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.12s
Val loss: 0.2039 score: 0.9592 time: 0.08s
Test loss: 0.1938 score: 0.9375 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.14s
Val loss: 0.2014 score: 0.9592 time: 0.11s
Test loss: 0.1897 score: 0.9375 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.11s
Val loss: 0.1992 score: 0.9592 time: 0.08s
Test loss: 0.1861 score: 0.9375 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.11s
Val loss: 0.1978 score: 0.9592 time: 0.08s
Test loss: 0.1831 score: 0.9375 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.11s
Val loss: 0.1969 score: 0.9592 time: 0.08s
Test loss: 0.1804 score: 0.9375 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.11s
Val loss: 0.1961 score: 0.9592 time: 0.08s
Test loss: 0.1782 score: 0.9375 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.11s
Val loss: 0.1962 score: 0.9592 time: 0.08s
Test loss: 0.1764 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.11s
Val loss: 0.1971 score: 0.9592 time: 0.08s
Test loss: 0.1754 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.14s
Val loss: 0.1981 score: 0.9592 time: 0.08s
Test loss: 0.1745 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.11s
Val loss: 0.1997 score: 0.9592 time: 0.08s
Test loss: 0.1741 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.2014 score: 0.9592 time: 0.08s
Test loss: 0.1739 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.11s
Val loss: 0.2032 score: 0.9592 time: 0.08s
Test loss: 0.1737 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.11s
Val loss: 0.2056 score: 0.9592 time: 0.08s
Test loss: 0.1740 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.2077 score: 0.9592 time: 0.08s
Test loss: 0.1741 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.11s
Val loss: 0.2097 score: 0.9592 time: 0.08s
Test loss: 0.1743 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.14s
Val loss: 0.2113 score: 0.9592 time: 0.09s
Test loss: 0.1744 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.2130 score: 0.9592 time: 0.08s
Test loss: 0.1745 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.11s
Val loss: 0.2147 score: 0.9592 time: 0.08s
Test loss: 0.1746 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.11s
Val loss: 0.2166 score: 0.9592 time: 0.08s
Test loss: 0.1749 score: 0.9583 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.11s
Val loss: 0.2182 score: 0.9592 time: 0.08s
Test loss: 0.1752 score: 0.9583 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.11s
Val loss: 0.2200 score: 0.9592 time: 0.08s
Test loss: 0.1756 score: 0.9583 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.2213 score: 0.9592 time: 0.08s
Test loss: 0.1759 score: 0.9583 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.12s
Val loss: 0.2228 score: 0.9592 time: 0.15s
Test loss: 0.1763 score: 0.9583 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.11s
Val loss: 0.2239 score: 0.9592 time: 0.08s
Test loss: 0.1766 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.11s
Val loss: 0.2251 score: 0.9592 time: 0.08s
Test loss: 0.1770 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.11s
Val loss: 0.2263 score: 0.9592 time: 0.08s
Test loss: 0.1774 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 096,   Train_Loss: 0.0067,   Val_Loss: 0.1961,   Val_Precision: 1.0000,   Val_Recall: 0.9200,   Val_accuracy: 0.9583,   Val_Score: 0.9592,   Val_Loss: 0.1961,   Test_Precision: 0.9565,   Test_Recall: 0.9167,   Test_accuracy: 0.9362,   Test_Score: 0.9375,   Test_loss: 0.1782


[0.08130666404031217, 0.0822259800042957, 0.08247798995580524, 0.0813729630317539, 0.08193867199588567, 0.08290606108494103, 0.08303875802084804, 0.08341728907544166, 0.08333099307492375, 0.08419168996624649, 0.08169648505281657, 0.07640662603080273, 0.07613991701509804, 0.0756448470056057, 0.07649089896585792, 0.07687133096624166, 0.07608142006210983, 0.07585918705444783, 0.08265544101595879, 0.08310862397775054, 0.08372052002232522, 0.08507303311489522, 0.08335881703533232, 0.08376629208214581, 0.08380790892988443, 0.08353550604078919, 0.08414001297205687, 0.0840749170165509, 0.08417534292675555, 0.0842644179938361, 0.08388468297198415, 0.08453306695446372, 0.08487929496914148, 0.08464671298861504, 0.08458988706115633, 0.0851032619830221, 0.0838476560311392, 0.0840995559701696, 0.08418219396844506, 0.08409199200104922, 0.08407610596623272, 0.08394573989789933, 0.08432338701095432, 0.08438613102771342, 0.08404462097678334, 0.0839559530140832, 0.0837594949407503, 0.08374761592131108, 0.08348970499355346, 0.0843551509315148, 0.08489478891715407, 0.08390811597928405, 0.08432180399540812, 0.08478476305026561, 0.08488708105869591, 0.08443687902763486, 0.08461920695845038, 0.08442359801847488, 0.08445659396238625, 0.08419876103289425, 0.08351990603841841, 0.08342217595782131, 0.08338164002634585, 0.08394210203550756, 0.0841186559991911, 0.08426265104208142, 0.08399951097089797, 0.08512688498012722, 0.08389519597403705, 0.08457535004708916, 0.08383860206231475, 0.08398901904001832, 0.08387294900603592, 0.08406232495326549, 0.0842521240701899, 0.08420637995004654, 0.08494354202412069, 0.08436930307652801, 0.08391791302710772, 0.0844784100772813, 0.08384254202246666, 0.08445941202808172, 0.08379940991289914, 0.0846183019457385, 0.08398005797062069, 0.08508286403957754, 0.08367936802096665, 0.08438487106468529, 0.08347895496990532, 0.0842649950645864, 0.08450500399339944, 0.08411535201594234, 0.08417397900484502, 0.08378756802994758, 0.08361021894961596, 0.08357543789315969, 0.083963270066306, 0.08367242990061641, 0.08369225403293967, 0.08425147796515375, 0.08407339605037123, 0.08413543202914298, 0.08456295297946781, 0.08554695907514542, 0.08388423197902739, 0.0829955090302974, 0.0898211789317429, 0.08404386800248176, 0.08374615001957864, 0.08343284099828452, 0.08379437506664544, 0.08481201610993594, 0.08338013594038785, 0.11134479509200901, 0.08200447994749993, 0.08183781604748219, 0.08172046800609678, 0.07705881900619715, 0.0731826729606837, 0.07408047397620976, 0.07576771499589086, 0.07651078002527356, 0.07664653903339058, 0.07765694602858275, 0.07641796790994704, 0.07528274809010327, 0.09104827104602009, 0.07516400993335992, 0.0751850779633969, 0.07567787007428706, 0.07508519501425326, 0.07841505494434386, 0.0757587649859488, 0.07662701094523072, 0.0798207629704848, 0.08008845907170326, 0.08024927403312176, 0.08003195596393198, 0.08210436499211937, 0.08015766204334795, 0.18689177895430475, 0.07931856706272811, 0.07953456905670464, 0.08026900002732873, 0.08072435192298144, 0.0818916349671781, 0.0815137029858306, 0.08075263595674187, 0.08125329203903675, 0.08107543794903904, 0.08081398997455835, 0.08072015992365777, 0.08107582398224622, 0.08150352898519486, 0.08103358501102775, 0.08099634700920433, 0.08098581701051444, 0.08130528905894607, 0.0815529900137335, 0.08267519297078252, 0.08256656490266323, 0.21805701893754303, 0.0825463819783181, 0.08271988097112626, 0.0831359950825572, 0.08478934899903834, 0.0830576439620927, 0.08292773808352649, 0.08100929902866483, 0.0822678740369156, 0.08276556804776192, 0.08303715998772532, 0.08243142801802605, 0.08168333605863154, 0.08167215797584504, 0.08130841003730893, 0.08206455502659082, 0.08174591592978686, 0.08317363704554737, 0.08311343693640083, 0.08260678593069315, 0.1704507659887895, 0.08177040901500732, 0.08204918296542019, 0.08312135492451489, 0.08335812401492149, 0.08265293191652745, 0.0831135850166902, 0.08205993799492717, 0.08255413104780018, 0.08226589194964617, 0.08304938697256148, 0.08329488197341561, 0.08098234096542001, 0.08554433204699308, 0.0808718359330669, 0.08076205407269299, 0.08077584998682141, 0.08177072298713028, 0.08172377594746649, 0.0808320640353486, 0.20715023996308446, 0.08063537999987602, 0.08037415600847453, 0.08083680702839047, 0.08239077194593847, 0.08131189097184688, 0.08231400104705244, 0.08147879096213728, 0.08146015799138695, 0.08186333195772022, 0.0826015139464289, 0.0830563580384478, 0.0812774799996987, 0.20376955100800842, 0.08095758594572544, 0.08173770701978356, 0.08197410695720464, 0.08354068209882826, 0.08230075798928738, 0.08267177396919578, 0.08271326404064894, 0.08279418293386698, 0.08368811302352697, 0.08269777405075729, 0.08289013197645545, 0.08294877002481371, 0.08331797609571368, 0.08304104395210743, 0.08294131001457572, 0.08242440002504736, 0.08340093202423304, 0.0750533570535481, 0.07476189197041094, 0.07447419199161232, 0.07449851895216852, 0.07475072203669697, 0.0744565729983151, 0.07418039708863944, 0.07500026607885957, 0.07461674103979021, 0.07409351109527051, 0.07409823301713914, 0.07440263801254332, 0.0742656959919259, 0.07403588201850653, 0.074608059017919, 0.07503011100925505, 0.07454635400790721, 0.07431847101543099, 0.0743594930972904, 0.07426615199074149, 0.07418217498343438, 0.07409517001360655, 0.07525960402563214, 0.0743638890562579, 0.07420777902007103, 0.07451928989030421, 0.07504889089614153, 0.07420429005287588, 0.07412441400811076, 0.0744184929644689, 0.0742613630136475, 0.07472232601139694, 0.07445864006876945, 0.07522288104519248, 0.07427849306259304, 0.0742599560180679, 0.07461285404860973, 0.07504429796244949, 0.0752427929546684, 0.07527909998316318, 0.07552737509831786, 0.07555009599309415, 0.07555668405257165, 0.07562823791522533, 0.07592155004385859, 0.07548616291023791, 0.0753813449991867, 0.07542449305765331, 0.07547296909615397, 0.07540663110557944, 0.07540625100955367, 0.07541852898430079, 0.07566182396840304, 0.07573781709652394, 0.07613841199781746, 0.07569752493873239, 0.07514835707843304, 0.07541516306810081, 0.07522358791902661, 0.07615005597472191, 0.07516645803116262, 0.07642757100984454, 0.07847801293246448, 0.07432719005737454, 0.07963966100942343, 0.07444397802464664, 0.07411433104425669, 0.07420741103123873, 0.0743066620780155, 0.0764934120234102, 0.0764625349547714, 0.0748167090350762, 0.17152472690213472, 0.07734912598971277, 0.0774441680405289, 0.0777566310716793, 0.07773578900378197, 0.07643430202733725, 0.12150779098737985, 0.07766953692771494, 0.07756429607979953, 0.07830585504416376, 0.08162055106367916, 0.07843446591868997, 0.07968762703239918, 0.07949984597507864, 0.07940350903663784, 0.07928691001143306, 0.07893441303167492, 0.08102430403232574, 0.07866291899699718, 0.07978629297576845, 0.07609188999049366, 0.07673444296233356, 0.07668099296279252, 0.07722847699187696, 0.0746148219332099, 0.07164834998548031, 0.07290380005724728, 0.07253942894749343, 0.07171024999115616, 0.07133467099629343, 0.07185839198064059, 0.07506148098036647, 0.07167868805117905, 0.07335335004609078, 0.07849410199560225, 0.07206010702066123, 0.07162854098714888, 0.07181398500688374, 0.07258481602184474, 0.0715856549795717, 0.07224699191283435, 0.0717680340167135, 0.07131212297827005, 0.07138615404255688, 0.07145413104444742]
[0.001659319674292085, 0.0016780812245774635, 0.001683224284812352, 0.001660672714933753, 0.0016722177958344013, 0.001691960430304919, 0.001694668531037715, 0.0017023936546008503, 0.0017006325117331377, 0.0017181977544131937, 0.001667275205159522, 0.0015593188985878108, 0.0015538758574509804, 0.001543772387869504, 0.0015610387544052638, 0.001568802672780442, 0.001552682042083874, 0.0015481466745805679, 0.001686845735019567, 0.001696094366892868, 0.0017085820412719433, 0.001736184349283576, 0.0017012003476598433, 0.0017095161649417511, 0.0017103654883649884, 0.0017048062457303917, 0.0017171431218787115, 0.0017158146329908346, 0.0017178641413623582, 0.0017196819998742062, 0.001711932305550697, 0.0017251646317237494, 0.001732230509574316, 0.001727483938543164, 0.0017263242257378843, 0.0017368012649596346, 0.0017111766536967183, 0.0017163174687789716, 0.0017180039585396952, 0.001716163102062229, 0.0017158388972700555, 0.0017131783652632516, 0.0017208854492031494, 0.0017221659393410903, 0.001715196346464966, 0.0017133867962057798, 0.0017093774477704143, 0.001709135018802267, 0.0017038715304806828, 0.0017215336924798939, 0.001732546712594981, 0.0017124105301894704, 0.001720853142763431, 0.0017303012867401146, 0.001732389409361141, 0.0017232016128088748, 0.0017269225909887832, 0.0017229305718056097, 0.001723603958416046, 0.001718342061895801, 0.0017044878783350696, 0.0017024933868943124, 0.00170166612298665, 0.0017131041231736237, 0.0017167072652896143, 0.0017196459396343147, 0.0017142757340999587, 0.0017372833669413717, 0.0017121468566130011, 0.0017260275519814115, 0.00171099187882275, 0.0017140616130615985, 0.001711692836857876, 0.001715557652107459, 0.0017194311034732632, 0.0017184975500009498, 0.0017335416739616468, 0.0017218225117658777, 0.0017126104699409738, 0.0017240491852506387, 0.001711072286172789, 0.0017236614699608513, 0.0017101920390387578, 0.001726904121341602, 0.0017138787340942997, 0.0017363849803995416, 0.0017077422045095234, 0.0017221402258099038, 0.0017036521422429656, 0.001719693776828294, 0.0017245919182326418, 0.0017166398370600476, 0.001717836306221327, 0.0017099503679581139, 0.001706330998971754, 0.0017056211814930548, 0.001713536123802163, 0.0017076006102166614, 0.0017080051843457076, 0.001719417917656199, 0.001715783592864719, 0.0017170496332478157, 0.001725774550601384, 0.001745856307656029, 0.0017119231016128039, 0.001693785898577498, 0.0018330852843212839, 0.001715180979642485, 0.0017091051024403802, 0.0017027110407813167, 0.0017100892870743967, 0.0017308574716313457, 0.001701635427354854, 0.002272342756979776, 0.0016735608152551006, 0.001670159511173106, 0.0016677646531856485, 0.001572628959310146, 0.0014935239379731367, 0.0015118464076777501, 0.0015462798978753236, 0.0015614444903117052, 0.0015642150823140936, 0.0015848356332363828, 0.0015595503655091232, 0.0015363826140837402, 0.0018581279805310223, 0.0015339593863951005, 0.0015343893461917735, 0.0015444463280466746, 0.0015323509186582298, 0.0016003072437621197, 0.0015460972446112, 0.0015638165499026679, 0.001628995162662955, 0.0016344583484021072, 0.00163774028639024, 0.0016333052237537137, 0.0016755992855534566, 0.0016358706539458766, 0.003814117937842954, 0.0016187462665862879, 0.0016231544705449926, 0.0016381428577005863, 0.0016474357535302335, 0.0016712578564730225, 0.001663544958894502, 0.0016480129787090178, 0.0016582304497762602, 0.0016546007744701846, 0.001649265101521599, 0.001647350202523628, 0.0016546086526989024, 0.0016633373262284665, 0.0016537466328781173, 0.001652986673657231, 0.0016527717757247845, 0.001659291613447879, 0.0016643467349741533, 0.0016872488361384188, 0.0016850319367890455, 0.004450143243623327, 0.0016846200403738388, 0.0016881608361454339, 0.0016966529608685144, 0.0017303948775313947, 0.001695053958410055, 0.001692402818031153, 0.0016532510005849966, 0.0016789362048350122, 0.001689093225464529, 0.0016946359181168433, 0.0016822740411842052, 0.0016670068583394192, 0.001666778734200919, 0.0016593553068838557, 0.0016747868372773637, 0.0016682839985670789, 0.0016974211641948443, 0.0016961925905387924, 0.0016858527740957786, 0.003478587060995704, 0.001668783857449129, 0.0016744731217432692, 0.001696354182132957, 0.0017011862043861527, 0.0016867945289087234, 0.0016961956125855142, 0.0016746926121413708, 0.0016847781846489832, 0.0016788957540744118, 0.001694885448419622, 0.0016998955504778698, 0.0016527008360289798, 0.0017458026948365935, 0.0016504456312870796, 0.0016482051851569998, 0.0016484867344249267, 0.001668790265043475, 0.0016678321621931937, 0.0016496339599050734, 0.004227555917613968, 0.0016456199999974699, 0.0016402888981321333, 0.001649730755681438, 0.0016814443254273158, 0.0016594263463642221, 0.0016798775723888253, 0.0016628324686150467, 0.0016624522039058562, 0.0016706802440351065, 0.0016857451825801814, 0.0016950277150703632, 0.001658724081626504, 0.00415856226546956, 0.001652195631545417, 0.0016681164697915011, 0.0016729409583102987, 0.0017049118795679236, 0.001679607305903824, 0.0016871790605958324, 0.0016880257967479375, 0.001689677202731979, 0.00170792067394953, 0.0016877096745052508, 0.0016916353464582745, 0.001692832041322729, 0.0017003668590961974, 0.00169471518269607, 0.001692679796215831, 0.0016821306127560685, 0.0017020598372292457, 0.001563611605282252, 0.001557539416050228, 0.0015515456664919232, 0.0015520524781701777, 0.0015573067090978536, 0.0015511786041315645, 0.001545424939346655, 0.0015625055433095743, 0.0015545154383289628, 0.0015436148144848023, 0.0015437131878570653, 0.0015500549585946526, 0.0015472019998317894, 0.001542414208718886, 0.0015543345628733125, 0.0015631273126928136, 0.0015530490418314002, 0.0015483014794881456, 0.00154915610619355, 0.0015472114998071145, 0.0015454619788215496, 0.0015436493752834697, 0.0015679084172006696, 0.0015492476886720397, 0.0015459953962514799, 0.0015524852060480043, 0.0015635185603362818, 0.0015459227094349142, 0.0015442586251689743, 0.001550385270093102, 0.0015471117294509895, 0.0015567151252374363, 0.0015512216680993636, 0.0015671433551081766, 0.0015474686054706883, 0.0015470824170430812, 0.0015544344593460362, 0.0015634228742176977, 0.0015675581865555917, 0.0015683145829825662, 0.0015734869812149554, 0.0015739603331894614, 0.001574097584428576, 0.0015755882899005276, 0.0015816989592470538, 0.0015726283939632897, 0.0015704446874830562, 0.0015713436053677772, 0.001572353522836541, 0.0015709714813662383, 0.0015709635626990348, 0.0015712193538395998, 0.00157628799934173, 0.0015778711895109154, 0.001586216916621197, 0.0015770317695569247, 0.001565590772467355, 0.0015711492305854335, 0.0015671580816463877, 0.0015864594994733732, 0.0015659678756492212, 0.0015922410627050947, 0.0016349586027596767, 0.001548483126195303, 0.0016591596043629882, 0.001550916208846805, 0.0015440485634220142, 0.0015459877298174736, 0.0015480554599586565, 0.0015936127504877125, 0.0015929694782244042, 0.0015586814382307541, 0.0035734318104611398, 0.0016114401247856829, 0.0016134201675110187, 0.0016199298139933187, 0.0016194956042454578, 0.0015923812922361928, 0.00253141231223708, 0.001618115352660728, 0.0016159228349958237, 0.001631371980086745, 0.0017004281471599825, 0.0016340513733060409, 0.0016601588965083163, 0.0016562467911474716, 0.0016542397715966217, 0.0016518106252381888, 0.0016444669381598942, 0.0016880063340067863, 0.0016388108124374412, 0.001662214436995176, 0.0015852477081352845, 0.0015986342283819492, 0.0015975206867248442, 0.0016089266039974366, 0.0015544754569418728, 0.0014926739580308397, 0.0015188291678593184, 0.00151123810307278, 0.00149396354148242, 0.0014861389790894464, 0.0014970498329300124, 0.0015637808537576348, 0.0014933060010662302, 0.0015281947926268913, 0.001635293791575047, 0.0015012522295971091, 0.0014922612705656018, 0.0014961246876434113, 0.0015121836671217654, 0.0014913678120744105, 0.0015051456648507155, 0.001495167375348198, 0.0014856692287139595, 0.0014872115425532684, 0.0014886277300926547]
[602.6566281910866, 595.9187108191365, 594.0978923741475, 602.1656109644047, 598.0082274516287, 591.0303705032769, 590.0858968494913, 587.408204499249, 588.0165133270834, 582.0051838803179, 599.7810061023021, 641.3056372917977, 643.5520541778845, 647.7638853095814, 640.5990864595719, 637.4287967190076, 644.046864004357, 645.9336291704565, 592.8224373098351, 589.5898362258778, 585.2806454968684, 575.9757023570929, 587.8202419694961, 584.960833075289, 584.6703566007653, 586.5769218669005, 582.3626390011734, 582.8135398617629, 582.1182105861681, 581.5028592920955, 584.1352469123004, 579.65482343608, 577.2903747352558, 578.8765832713491, 579.2654618935032, 575.7711145052864, 584.3931997550709, 582.642790853503, 582.0708357680392, 582.6951988411528, 582.8052980912288, 583.7103831546094, 581.0962028082967, 580.6641376164978, 583.0236299540915, 583.6393756590493, 585.0083030546157, 585.0912824317315, 586.8987080956085, 580.8773911125061, 577.1850148283828, 583.9721155471723, 581.107112018955, 577.9340324504981, 577.2374239858539, 580.3151485971322, 579.0647509147648, 580.4064402618455, 580.1796840377287, 581.9563067069001, 586.6864837881934, 587.3737940469769, 587.6593454448439, 583.7356798531561, 582.5104956559362, 581.5150531583563, 583.3367293885351, 575.61133608306, 584.0620482627393, 579.3650274307844, 584.4563100369893, 583.4095999698833, 584.2169684110393, 582.9008420507236, 581.587711179583, 581.9036518262405, 576.8537411129605, 580.7799544765004, 583.9039393671729, 580.0298556184301, 584.4288450470626, 580.1603258107942, 584.729654432298, 579.0709441489532, 583.4718525336336, 575.9091510742625, 585.5684759440653, 580.6728075988765, 586.974286125944, 581.4988769944516, 579.8473189093904, 582.5333761988306, 582.1276429997396, 584.8122955721342, 586.0527650277738, 586.2966588657318, 583.5885138978578, 585.6170312993268, 585.4783165562077, 581.5921712407977, 582.8240835024963, 582.3943470454552, 579.4499632941789, 572.7848251970926, 584.1383874415267, 590.3933908292871, 545.5283551470214, 583.0288534382195, 585.1015239332735, 587.2987113192934, 584.7647883408414, 577.748322083096, 587.6699461731781, 440.0744548455021, 597.5283305420664, 598.7452056585951, 599.6049850857969, 635.877899920311, 669.5573968215743, 661.4428522114462, 646.7134452009993, 640.432629020564, 639.2982725371783, 630.9802600525245, 641.2104553439958, 650.8795340647451, 538.1760624013726, 651.9077420622341, 651.7250673578493, 647.4812247213158, 652.5920321669064, 624.880005947562, 646.7898468129487, 639.4611951524878, 613.875364961353, 611.8234832827819, 610.5974239689189, 612.2554348425876, 596.8014003238825, 611.2952742247098, 262.1838171489638, 617.7620425397871, 616.0843087622083, 610.447370508132, 607.003944073166, 598.3517122309139, 601.1259236808023, 606.7913377620101, 603.0524889558787, 604.3753970320771, 606.3306615033616, 607.0354673026222, 604.3725193681645, 601.2009616037714, 604.6875501476536, 604.9655547358414, 605.0442140213057, 602.6668199220737, 600.836339559695, 592.6808059258675, 593.4605618844084, 224.7118677433393, 593.6056653927061, 592.3606202613331, 589.3957238539232, 577.9027740920118, 589.9517210283918, 590.8758773891337, 604.8688309555862, 595.6152456062315, 592.0336337415498, 590.0972529316183, 594.4334725013464, 599.8775559904685, 599.9596584002593, 602.643686889413, 597.0909119548977, 599.4183249727979, 589.1289805346221, 589.5556940750176, 593.1716074888915, 287.4730407678116, 599.2387783092419, 597.2027780051285, 589.4995340787989, 587.8251289727774, 592.8404336519593, 589.5546436862303, 597.1245067602795, 593.5499456911273, 595.6295961635258, 590.0103755875888, 588.2714380415214, 605.0701846335032, 572.8024151627282, 605.8969656699096, 606.7205764218883, 606.6169530620149, 599.2364774335186, 599.5807148154544, 606.1950858828974, 236.5432934508409, 607.6737035290878, 609.6487034319031, 606.1595181857053, 594.7267981923005, 602.6178879171015, 595.2814755291819, 601.383494052704, 601.5210528462384, 598.5585832898535, 593.209466254806, 589.9608549813526, 602.8730221480987, 240.46772325701514, 605.2552015675216, 599.4785244971478, 597.7497263322541, 586.5405784218187, 595.3772625809601, 592.7053170318786, 592.4080081753181, 591.8290182190631, 585.5072868738812, 592.5189711868828, 591.1439496069112, 590.7260588112625, 588.1083806417715, 590.0696531255069, 590.779190627553, 594.4841574231629, 587.5234102391388, 639.5450101686135, 642.0383264109649, 644.5185737014242, 644.3081107534259, 642.1342656253623, 644.6710890264344, 647.0712194037459, 639.9977294684536, 643.2872748275546, 647.8300095440328, 647.7887264720262, 645.1384155479517, 646.3280167093367, 648.3342764526204, 643.3621331506773, 639.743155838849, 643.8946698172333, 645.8690463375331, 645.5127381946755, 646.3240482149122, 647.0557113042166, 647.8155052641821, 637.7923538323696, 645.4745792502454, 646.8324565678944, 644.1285212279691, 639.5830694743527, 646.8628695968462, 647.5599253270022, 645.00096801097, 646.3657284499171, 642.3782898926199, 644.653192103261, 638.103717021454, 646.2166640827155, 646.3779750734205, 643.3207871760052, 639.6222138558501, 637.9348521647596, 637.6271768755952, 635.5311559221532, 635.3400266279948, 635.2846290422438, 634.6835695657103, 632.2315597122453, 635.8781285131389, 636.7623183231592, 636.3980459677674, 635.9892896070791, 636.5487928083346, 636.5520014238421, 636.4483721234039, 634.4018354625599, 633.7652950682019, 630.4308001771293, 634.1026346482261, 638.7365188822685, 636.4767779744163, 638.09772077967, 630.3344020644404, 638.5827037386821, 628.0456040375427, 611.6362813786732, 645.7932818790528, 602.7147703996424, 644.7801591702735, 647.6480233132947, 646.8356641601965, 645.9716889126871, 627.5050194559236, 627.758418268406, 641.5679146953154, 279.8430341031058, 620.5629266759119, 619.8013512764466, 617.3106954151808, 617.476205170629, 627.9902965926537, 395.03639733673884, 618.0029120641259, 618.8414312510068, 612.9809830047632, 588.0871836132435, 611.9758633884213, 602.3519809478614, 603.7747546711837, 604.5072891911132, 605.396275287793, 608.0997901477837, 592.4148386495211, 610.198561304753, 601.6070957774398, 630.8162408109032, 625.5339603307167, 625.9699848082402, 621.5323915431964, 643.3038202914473, 669.9386658552123, 658.4018934857755, 661.7090966451373, 669.3603774344632, 672.8845781386459, 667.9804359236387, 639.4757920184811, 669.6551137449347, 654.366841730333, 611.5109133000753, 666.1105844075049, 670.1239385653805, 668.3934890314046, 661.2953318715332, 670.5254008459892, 664.3875229838188, 668.8214419921501, 673.0973359834817, 672.3992998892304, 671.7596211497138]
Elapsed: 0.0820848706143676~0.01566864682906967
Time per graph: 0.0016860941614330798~0.0003171135028958607
Speed: 603.0427190040836~55.72726489174676
Total Time: 0.0726
best val loss: 0.1961347758769989 test_score: 0.9375

Testing...
Test loss: 0.4214 score: 0.9375 time: 0.07s
test Score 0.9375
Epoch Time List: [0.2585912949871272, 0.2636762351030484, 0.2666517689358443, 0.264044001000002, 0.3631483339704573, 0.26449008693452924, 0.2647828150074929, 0.2655341239878908, 0.2674151589162648, 0.2688815090805292, 0.2620687480084598, 0.3725732129532844, 0.24565964308567345, 0.24647613591514528, 0.24678855703677982, 0.25021466612815857, 0.24890182993840426, 0.24454928189516068, 0.39920764905400574, 0.26504675892647356, 0.26737631496507674, 0.27127470390405506, 0.27326649299357086, 0.269692077068612, 0.26884203602094203, 0.27114358998369426, 0.27154727512970567, 0.2695925988955423, 0.2714511880185455, 0.27188421797472984, 0.27032638480886817, 0.2709738939302042, 0.271332020056434, 0.2727815790567547, 0.27097001613583416, 0.2725289069348946, 0.27177899691741914, 0.2716720289317891, 0.2706974019529298, 0.27008703991305083, 0.27067692298442125, 0.2702614008449018, 0.27056273189373314, 0.2702282859245315, 0.2698757549514994, 0.27011089003644884, 0.2692750310525298, 0.2701240157475695, 0.27032909099943936, 0.2719096989603713, 0.2726719449274242, 0.272472096956335, 0.2717965330230072, 0.27414073911495507, 0.2734424890950322, 0.27214644209016114, 0.2721663569100201, 0.2741073650540784, 0.272680839872919, 0.2713122410932556, 0.2710627330234274, 0.27020718390122056, 0.2697495670290664, 0.27015921007841825, 0.2707666299538687, 0.27203503903001547, 0.27100660908035934, 0.27275092201307416, 0.27016831189393997, 0.271871647099033, 0.2714761398965493, 0.27298268605954945, 0.271074972813949, 0.27249525988008827, 0.27246175601612777, 0.2738945399178192, 0.27317001495976, 0.2723112179664895, 0.2727937310701236, 0.27301768213510513, 0.27363113407045603, 0.2725254959659651, 0.27281185414176434, 0.2738700301852077, 0.2730553769506514, 0.27499344607349485, 0.27269184798933566, 0.2734788110246882, 0.272584684076719, 0.27262844901997596, 0.2737057479098439, 0.27339794486761093, 0.274374911095947, 0.27194561203941703, 0.2715846858918667, 0.2713403159286827, 0.27350104483775795, 0.2709582820534706, 0.27125576813705266, 0.27207500592339784, 0.27266525488812476, 0.2723695560125634, 0.2721400238806382, 0.2756269659148529, 0.27280901290941983, 0.26776835694909096, 0.3082755560753867, 0.27095189702231437, 0.2708449469646439, 0.26939893001690507, 0.27183159708511084, 0.27456782502122223, 0.2704115549568087, 0.293164843111299, 0.32335987500846386, 0.26450769300572574, 0.26424814597703516, 0.2517891810275614, 0.24412179505452514, 0.33753902395255864, 0.24861660099122673, 0.2504335909616202, 0.25275876896921545, 0.25495653797406703, 0.25933399400673807, 0.2512899430003017, 0.33314073004294187, 0.2495840861229226, 0.24811906507238746, 0.2498384079663083, 0.2502687310334295, 0.25674802309367806, 0.25754052808042616, 0.25200502504594624, 0.38911498500965536, 0.26417364715598524, 0.2646574820391834, 0.2647921380121261, 0.2701308389659971, 0.2657114041503519, 0.37184626411180943, 0.2638373050140217, 0.26251801394391805, 0.264382730005309, 0.26472981891129166, 0.27677399304229766, 0.2710685059428215, 0.3946397420950234, 0.2671588659286499, 0.2649727939860895, 0.26706937595736235, 0.2667823350057006, 0.27301390399225056, 0.27047251584008336, 0.3439732809783891, 0.26749226299580187, 0.26833605696447194, 0.2684848109493032, 0.2699328640010208, 0.2748599109472707, 0.27406537206843495, 0.40815815108362585, 0.2744708020472899, 0.27400260511785746, 0.2754145299550146, 0.27746250992640853, 0.2758809400256723, 0.27378813503310084, 0.3436944881686941, 0.27133779297582805, 0.2738103929441422, 0.27502222394105047, 0.27459802699740976, 0.27116278395988047, 0.26964506588410586, 0.36357297596987337, 0.270231349975802, 0.2703728540800512, 0.2738108990015462, 0.2757712979800999, 0.27329661196563393, 0.36031927505973727, 0.2711006229510531, 0.272979406057857, 0.27396285615395755, 0.2750202401075512, 0.27532128512393683, 0.27286286908201873, 0.29941478301770985, 0.2733034690609202, 0.2715137619525194, 0.27383136097341776, 0.27557066490408033, 0.27060815901495516, 0.27062051894608885, 0.3374436520971358, 0.2647254371549934, 0.26362215890549123, 0.268643865827471, 0.27280109701678157, 0.26762076292652637, 0.39429188787471503, 0.2648369229864329, 0.26465360703878105, 0.2661936179501936, 0.26948151097167283, 0.27094204898457974, 0.26785846904385835, 0.3691446949960664, 0.26836267893668264, 0.26738440501503646, 0.27151821996085346, 0.27461161999963224, 0.2721155198523775, 0.39079070498701185, 0.26664362591691315, 0.26914786791894585, 0.2686893721111119, 0.27496757090557367, 0.27452910610008985, 0.27517029899172485, 0.27391040802467614, 0.27521514904219657, 0.2745974430581555, 0.27465988497715443, 0.27369704097509384, 0.27322545903734863, 0.2747643761103973, 0.2748836660757661, 0.2754033539677039, 0.2739604930393398, 0.2753625169862062, 0.2695456959772855, 0.2659867109032348, 0.2665393720380962, 0.26583360985387117, 0.267647240892984, 0.26669514598324895, 0.26711352192796767, 0.26675924111623317, 0.26639833580702543, 0.2661770331906155, 0.26351608021650463, 0.2647676238557324, 0.26571444794535637, 0.26536116609349847, 0.2650821980787441, 0.26447794295381755, 0.26565500895958394, 0.26573471596930176, 0.26466122700367123, 0.2655334719456732, 0.26566758705303073, 0.2646072640782222, 0.2658912979532033, 0.26608943892642856, 0.2631865058792755, 0.2651519108330831, 0.26709142106119543, 0.2659170209662989, 0.2643577739363536, 0.26452302001416683, 0.26500650495290756, 0.26555127394385636, 0.26685653894674033, 0.26597305899485946, 0.26548088213894516, 0.26411255402490497, 0.2656904039904475, 0.2672748928889632, 0.26851958001498133, 0.2691674300003797, 0.2688588179880753, 0.27024486917071044, 0.26929587009362876, 0.2698816228657961, 0.26896465907339007, 0.2689315639436245, 0.2683150420198217, 0.2690095031866804, 0.27113062306307256, 0.2698400740046054, 0.26916702406015247, 0.2699485789053142, 0.2702694630715996, 0.27064982906449586, 0.27092246105894446, 0.26921352418139577, 0.26830064901150763, 0.26878068689256907, 0.26864409702830017, 0.268636601860635, 0.269293372053653, 0.2705453980015591, 0.27483465208206326, 0.26778999785892665, 0.26893610798288137, 0.37227682408411056, 0.262818418093957, 0.26277357805520296, 0.2645024760859087, 0.2706603010883555, 0.2720781429670751, 0.2665356050711125, 0.3712562269065529, 0.27318669203668833, 0.27176464395597577, 0.27349716890603304, 0.2751416841056198, 0.2734148429008201, 0.31306074594613165, 0.2860529498429969, 0.2720564929768443, 0.2749894040171057, 0.27976415515877306, 0.28116665896959603, 0.2776565089588985, 0.32400359492748976, 0.2790706818923354, 0.2781199589371681, 0.27689580782316625, 0.2796455620555207, 0.27728116093203425, 0.2752348491922021, 0.3222892569610849, 0.2678102048812434, 0.2687904859194532, 0.27094216586556286, 0.2666928948601708, 0.25494416302535683, 0.2544615870574489, 0.29203417093958706, 0.2534750100458041, 0.252233530045487, 0.2576620531035587, 0.2596319280564785, 0.25797293393407017, 0.25588211708236486, 0.30201544892042875, 0.2569459098158404, 0.25256707100197673, 0.2549210391007364, 0.2566871579037979, 0.2588152709649876, 0.25532774382736534, 0.3365137140499428, 0.2554860070813447, 0.25412925996351987, 0.2552677068160847]
Total Epoch List: [118, 114, 117]
Total Time List: [0.07761115906760097, 0.08418258605524898, 0.07262141001410782]
T-times Epoch Time: 0.2728676178119987 ~ 0.0015765983705573906
T-times Total Epoch: 100.44444444444444 ~ 12.311793001572934
T-times Total Time: 0.07913380235226618 ~ 0.0008590753568113296
T-times Inference Elapsed: 0.07955616184924591 ~ 0.00179565749545674
T-times Time Per Graph: 0.0016342625853155808 ~ 3.742697884968946e-05
T-times Speed: 625.1336845581305 ~ 16.336695485859074
T-times cross validation test micro f1 score:0.7867174233086144 ~ 0.0879244157095113
T-times cross validation test precision:0.8046606855302506 ~ 0.12575982669224253
T-times cross validation test recall:0.7940740740740742 ~ 0.19567406622249128
T-times cross validation test f1_score:0.7867174233086144 ~ 0.1571873556732874
