Namespace(seed=15, model='I2BGNNT', dataset='ico_wallets/Times', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/ico_wallets/Times/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 338], edge_attr=[338, 2], x=[122, 14887], y=[1, 1], num_nodes=122)
Data(edge_index=[2, 338], edge_attr=[338, 2], x=[122, 14887], y=[1, 1], num_nodes=122)
Data(edge_index=[2, 298], edge_attr=[298, 2], x=[109, 14887], y=[1, 1], num_nodes=122)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c933c16c0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.29s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6916;  Loss pred: 0.6916; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4898 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6914;  Loss pred: 0.6914; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6906;  Loss pred: 0.6906; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6879;  Loss pred: 0.6879; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6883;  Loss pred: 0.6883; Loss self: 0.0000; time: 0.21s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4898 time: 0.06s
Epoch 7/1000, LR 0.000150
Train loss: 0.6876;  Loss pred: 0.6876; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6846;  Loss pred: 0.6846; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6805;  Loss pred: 0.6805; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.06s
Epoch 10/1000, LR 0.000240
Train loss: 0.6777;  Loss pred: 0.6777; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.06s
Epoch 11/1000, LR 0.000270
Train loss: 0.6753;  Loss pred: 0.6753; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.06s
Epoch 12/1000, LR 0.000270
Train loss: 0.6715;  Loss pred: 0.6715; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.06s
Epoch 13/1000, LR 0.000270
Train loss: 0.6665;  Loss pred: 0.6665; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6614;  Loss pred: 0.6614; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6605;  Loss pred: 0.6605; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6544;  Loss pred: 0.6544; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6481;  Loss pred: 0.6481; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6449;  Loss pred: 0.6449; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6357;  Loss pred: 0.6357; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6291;  Loss pred: 0.6291; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6210;  Loss pred: 0.6210; Loss self: 0.0000; time: 0.26s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6133;  Loss pred: 0.6133; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4898 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6089;  Loss pred: 0.6089; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4898 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5984;  Loss pred: 0.5984; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4898 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5897;  Loss pred: 0.5897; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5821;  Loss pred: 0.5821; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5694;  Loss pred: 0.5694; Loss self: 0.0000; time: 0.28s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6906 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4898 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5590;  Loss pred: 0.5590; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5499;  Loss pred: 0.5499; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5373;  Loss pred: 0.5373; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5223;  Loss pred: 0.5223; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5160;  Loss pred: 0.5160; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6876 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4995;  Loss pred: 0.4995; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6867 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4863;  Loss pred: 0.4863; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6858 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.4898 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4691;  Loss pred: 0.4691; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.4898 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4528;  Loss pred: 0.4528; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6836 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.4898 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4380;  Loss pred: 0.4380; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6825 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.4898 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4200;  Loss pred: 0.4200; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6812 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.4898 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4056;  Loss pred: 0.4056; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6799 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6887 score: 0.4898 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3866;  Loss pred: 0.3866; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6784 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.4898 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3751;  Loss pred: 0.3751; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6768 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.4898 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3558;  Loss pred: 0.3558; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6749 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.4898 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3534;  Loss pred: 0.3534; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6729 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6854 score: 0.4898 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3270;  Loss pred: 0.3270; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6705 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6842 score: 0.4898 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3136;  Loss pred: 0.3136; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6676 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6826 score: 0.4898 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2955;  Loss pred: 0.2955; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6644 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6809 score: 0.4898 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2797;  Loss pred: 0.2797; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6610 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6791 score: 0.4898 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2597;  Loss pred: 0.2597; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6570 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6769 score: 0.4898 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2457;  Loss pred: 0.2457; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6528 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6747 score: 0.4898 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2286;  Loss pred: 0.2286; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6483 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6723 score: 0.4898 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2176;  Loss pred: 0.2176; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6438 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6701 score: 0.4898 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2035;  Loss pred: 0.2035; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6390 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6677 score: 0.4898 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1917;  Loss pred: 0.1917; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6339 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6653 score: 0.4898 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1725;  Loss pred: 0.1725; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6282 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6627 score: 0.4898 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1588;  Loss pred: 0.1588; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6227 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6603 score: 0.4898 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1586;  Loss pred: 0.1586; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6162 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6572 score: 0.4898 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1329;  Loss pred: 0.1329; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6097 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6543 score: 0.4898 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1378;  Loss pred: 0.1378; Loss self: 0.0000; time: 0.13s
Val loss: 0.6033 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6517 score: 0.4898 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1158;  Loss pred: 0.1158; Loss self: 0.0000; time: 0.13s
Val loss: 0.5961 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6484 score: 0.4898 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1118;  Loss pred: 0.1118; Loss self: 0.0000; time: 0.13s
Val loss: 0.5884 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6450 score: 0.4898 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1029;  Loss pred: 0.1029; Loss self: 0.0000; time: 0.13s
Val loss: 0.5802 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6412 score: 0.4898 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0959;  Loss pred: 0.0959; Loss self: 0.0000; time: 0.13s
Val loss: 0.5712 score: 0.5510 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6367 score: 0.4898 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0867;  Loss pred: 0.0867; Loss self: 0.0000; time: 0.13s
Val loss: 0.5617 score: 0.5714 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6319 score: 0.4898 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0766;  Loss pred: 0.0766; Loss self: 0.0000; time: 0.13s
Val loss: 0.5512 score: 0.5714 time: 0.08s
Test loss: 0.6261 score: 0.5102 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0692;  Loss pred: 0.0692; Loss self: 0.0000; time: 0.13s
Val loss: 0.5399 score: 0.6122 time: 0.08s
Test loss: 0.6198 score: 0.5102 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0684;  Loss pred: 0.0684; Loss self: 0.0000; time: 0.13s
Val loss: 0.5286 score: 0.6531 time: 0.08s
Test loss: 0.6134 score: 0.5306 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0601;  Loss pred: 0.0601; Loss self: 0.0000; time: 0.13s
Val loss: 0.5159 score: 0.6531 time: 0.08s
Test loss: 0.6056 score: 0.5510 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0541;  Loss pred: 0.0541; Loss self: 0.0000; time: 0.13s
Val loss: 0.5028 score: 0.6735 time: 0.08s
Test loss: 0.5975 score: 0.5510 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0515;  Loss pred: 0.0515; Loss self: 0.0000; time: 0.13s
Val loss: 0.4893 score: 0.6735 time: 0.08s
Test loss: 0.5887 score: 0.5714 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0465;  Loss pred: 0.0465; Loss self: 0.0000; time: 0.13s
Val loss: 0.4747 score: 0.7347 time: 0.08s
Test loss: 0.5788 score: 0.6122 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0410;  Loss pred: 0.0410; Loss self: 0.0000; time: 0.13s
Val loss: 0.4593 score: 0.7551 time: 0.08s
Test loss: 0.5679 score: 0.6122 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0408;  Loss pred: 0.0408; Loss self: 0.0000; time: 0.13s
Val loss: 0.4436 score: 0.7959 time: 0.08s
Test loss: 0.5567 score: 0.6531 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0368;  Loss pred: 0.0368; Loss self: 0.0000; time: 0.13s
Val loss: 0.4277 score: 0.7959 time: 0.08s
Test loss: 0.5449 score: 0.6531 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0330;  Loss pred: 0.0330; Loss self: 0.0000; time: 0.13s
Val loss: 0.4108 score: 0.8163 time: 0.08s
Test loss: 0.5320 score: 0.6735 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0304;  Loss pred: 0.0304; Loss self: 0.0000; time: 0.13s
Val loss: 0.3935 score: 0.8367 time: 0.08s
Test loss: 0.5182 score: 0.6735 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0296;  Loss pred: 0.0296; Loss self: 0.0000; time: 0.13s
Val loss: 0.3761 score: 0.8571 time: 0.08s
Test loss: 0.5037 score: 0.7143 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0262;  Loss pred: 0.0262; Loss self: 0.0000; time: 0.13s
Val loss: 0.3594 score: 0.8776 time: 0.08s
Test loss: 0.4895 score: 0.7143 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0234;  Loss pred: 0.0234; Loss self: 0.0000; time: 0.13s
Val loss: 0.3433 score: 0.8980 time: 0.08s
Test loss: 0.4757 score: 0.7347 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.13s
Val loss: 0.3278 score: 0.9184 time: 0.08s
Test loss: 0.4622 score: 0.7551 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0199;  Loss pred: 0.0199; Loss self: 0.0000; time: 0.13s
Val loss: 0.3129 score: 0.9184 time: 0.08s
Test loss: 0.4488 score: 0.7959 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0178;  Loss pred: 0.0178; Loss self: 0.0000; time: 0.13s
Val loss: 0.2989 score: 0.9184 time: 0.08s
Test loss: 0.4362 score: 0.8367 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.13s
Val loss: 0.2854 score: 0.9184 time: 0.08s
Test loss: 0.4237 score: 0.8367 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0167;  Loss pred: 0.0167; Loss self: 0.0000; time: 0.13s
Val loss: 0.2728 score: 0.9184 time: 0.08s
Test loss: 0.4116 score: 0.8367 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.13s
Val loss: 0.2613 score: 0.9388 time: 0.08s
Test loss: 0.4002 score: 0.8367 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.13s
Val loss: 0.2510 score: 0.9388 time: 0.08s
Test loss: 0.3896 score: 0.8367 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.14s
Val loss: 0.2413 score: 0.9388 time: 0.08s
Test loss: 0.3791 score: 0.8776 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0123;  Loss pred: 0.0123; Loss self: 0.0000; time: 0.13s
Val loss: 0.2324 score: 0.9388 time: 0.08s
Test loss: 0.3689 score: 0.8980 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.13s
Val loss: 0.2245 score: 0.9388 time: 0.08s
Test loss: 0.3597 score: 0.8980 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.13s
Val loss: 0.2176 score: 0.9388 time: 0.08s
Test loss: 0.3516 score: 0.8980 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.13s
Val loss: 0.2113 score: 0.9388 time: 0.08s
Test loss: 0.3439 score: 0.8980 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.13s
Val loss: 0.2060 score: 0.9388 time: 0.08s
Test loss: 0.3372 score: 0.8980 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.13s
Val loss: 0.2015 score: 0.9184 time: 0.08s
Test loss: 0.3317 score: 0.9184 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.13s
Val loss: 0.1976 score: 0.9184 time: 0.08s
Test loss: 0.3268 score: 0.9184 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.13s
Val loss: 0.1942 score: 0.9184 time: 0.08s
Test loss: 0.3225 score: 0.9184 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.13s
Val loss: 0.1918 score: 0.9184 time: 0.08s
Test loss: 0.3194 score: 0.9184 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.13s
Val loss: 0.1898 score: 0.9184 time: 0.08s
Test loss: 0.3169 score: 0.8776 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.13s
Val loss: 0.1883 score: 0.9184 time: 0.08s
Test loss: 0.3151 score: 0.8776 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.13s
Val loss: 0.1872 score: 0.9184 time: 0.08s
Test loss: 0.3139 score: 0.8776 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.13s
Val loss: 0.1867 score: 0.9184 time: 0.08s
Test loss: 0.3135 score: 0.8776 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.13s
Val loss: 0.1865 score: 0.9184 time: 0.08s
Test loss: 0.3135 score: 0.8776 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.13s
Val loss: 0.1865 score: 0.9184 time: 0.08s
Test loss: 0.3140 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.13s
Val loss: 0.1868 score: 0.9184 time: 0.08s
Test loss: 0.3146 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.13s
Val loss: 0.1873 score: 0.9184 time: 0.08s
Test loss: 0.3157 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.13s
Val loss: 0.1878 score: 0.9184 time: 0.08s
Test loss: 0.3170 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.13s
Val loss: 0.1884 score: 0.9184 time: 0.08s
Test loss: 0.3185 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.13s
Val loss: 0.1892 score: 0.9184 time: 0.08s
Test loss: 0.3203 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.14s
Val loss: 0.1900 score: 0.9184 time: 0.08s
Test loss: 0.3222 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.13s
Val loss: 0.1909 score: 0.9184 time: 0.08s
Test loss: 0.3244 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.13s
Val loss: 0.1917 score: 0.9184 time: 0.08s
Test loss: 0.3265 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.13s
Val loss: 0.1926 score: 0.9184 time: 0.08s
Test loss: 0.3286 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.13s
Val loss: 0.1935 score: 0.9184 time: 0.08s
Test loss: 0.3307 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.13s
Val loss: 0.1947 score: 0.9184 time: 0.08s
Test loss: 0.3330 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.13s
Val loss: 0.1955 score: 0.9184 time: 0.08s
Test loss: 0.3352 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.13s
Val loss: 0.1964 score: 0.9184 time: 0.08s
Test loss: 0.3371 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.13s
Val loss: 0.1973 score: 0.9184 time: 0.08s
Test loss: 0.3389 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.13s
Val loss: 0.1984 score: 0.9184 time: 0.08s
Test loss: 0.3409 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.13s
Val loss: 0.1993 score: 0.9184 time: 0.08s
Test loss: 0.3429 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.14s
Val loss: 0.2002 score: 0.9184 time: 0.08s
Test loss: 0.3446 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.14s
Val loss: 0.2011 score: 0.9184 time: 0.08s
Test loss: 0.3463 score: 0.8571 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.13s
Val loss: 0.2021 score: 0.9184 time: 0.08s
Test loss: 0.3480 score: 0.8571 time: 0.21s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 099,   Train_Loss: 0.0059,   Val_Loss: 0.1865,   Val_Precision: 0.9545,   Val_Recall: 0.8750,   Val_accuracy: 0.9130,   Val_Score: 0.9184,   Val_Loss: 0.1865,   Test_Precision: 0.9130,   Test_Recall: 0.8400,   Test_accuracy: 0.8750,   Test_Score: 0.8776,   Test_loss: 0.3135


[0.07366148196160793, 0.07384558802004904, 0.07436171697918326, 0.07458233996294439, 0.07112412608694285, 0.06843863998074085, 0.07374879403505474, 0.07190705800894648, 0.06876892794389278, 0.06975735304877162, 0.06896481104195118, 0.06878241896629333, 0.07004087907262146, 0.07161875697784126, 0.0752331850817427, 0.07440769008826464, 0.0742156800115481, 0.07703078689519316, 0.0724963879911229, 0.07348259899299592, 0.07190671400167048, 0.07225505798123777, 0.07271916000172496, 0.07245512504596263, 0.07267285499256104, 0.07476193201728165, 0.07299624104052782, 0.07255698589142412, 0.07359132298734039, 0.07332269102334976, 0.07353684189729393, 0.07300648104865104, 0.07288098998833448, 0.07327174802776426, 0.07329829293303192, 0.07331471401266754, 0.0731162279844284, 0.07328014995437115, 0.0730300199938938, 0.0726756319636479, 0.07317272806540132, 0.0731148871127516, 0.07307401299476624, 0.07329615205526352, 0.07342953910119832, 0.0725485619623214, 0.07275002798996866, 0.07312426203861833, 0.0729310349561274, 0.07317116693593562, 0.07325680798385292, 0.07350077095907182, 0.07359340798575431, 0.07292862609028816, 0.07328087801579386, 0.07403383799828589, 0.073703832924366, 0.07375404005870223, 0.07385501696262509, 0.07376169902272522, 0.07366216997615993, 0.07355374505277723, 0.0740089729661122, 0.07334079197607934, 0.07389209698885679, 0.0735879959538579, 0.0737681380705908, 0.0734347349498421, 0.074687265092507, 0.0739350279327482, 0.07456575497053564, 0.07444732706062496, 0.0745117359329015, 0.07435939298011363, 0.0737658980069682, 0.07424685300793499, 0.07628422102425247, 0.07581822399515659, 0.075761315994896, 0.07572142698336393, 0.07574198103975505, 0.07530167303048074, 0.07591303903609514, 0.07576766598504037, 0.07579073100350797, 0.07602635899093002, 0.07587363803759217, 0.07517860201187432, 0.07515778997913003, 0.07619248703122139, 0.07581047806888819, 0.0755351580446586, 0.07606923603452742, 0.07652921008411795, 0.07647006306797266, 0.07637524697929621, 0.07643036008812487, 0.07579917006660253, 0.07564960094168782, 0.07645101600792259, 0.07614853698760271, 0.07647880795411766, 0.07598572794813663, 0.07579457492101938, 0.07590426097158343, 0.07626006589271128, 0.07677606004290283, 0.07576896692626178, 0.07623567199334502, 0.07576995599083602, 0.07599820895120502, 0.07575053500477225, 0.07573499891441315, 0.07599760498851538, 0.07566699094604701, 0.0762189719825983, 0.07654026604723185, 0.07653353700879961, 0.07566340698394924, 0.21378896699752659]
[0.0015032955502368966, 0.0015070528167356945, 0.0015175860607996583, 0.0015220885706723345, 0.001451512777284548, 0.0013967069383824663, 0.0015050774292868314, 0.001467490979774418, 0.0014034475090590362, 0.0014236194499749311, 0.001407445123305126, 0.0014037228360468028, 0.0014294056953596218, 0.0014616072852620665, 0.001535371124117198, 0.001518524287515605, 0.0015146057145213898, 0.0015720568754121053, 0.0014795181222678143, 0.0014996448774080798, 0.0014674839592177648, 0.0014745930200252607, 0.0014840644898311216, 0.001478676021346176, 0.0014831194896441028, 0.0015257537146384011, 0.001489719204908731, 0.0014807548141106963, 0.0015018637344355182, 0.0014963814494561177, 0.001500751875454978, 0.0014899281846663477, 0.001487367142619071, 0.0014953417964849848, 0.0014958835292455492, 0.0014962186533197456, 0.0014921679180495593, 0.0014955132643749214, 0.0014904085713039552, 0.0014831761625234265, 0.0014933209809265574, 0.0014921405533214612, 0.0014913063876482906, 0.0014958398378625208, 0.001498562022473435, 0.0014805828971902327, 0.0014846944487748705, 0.0014923318783391494, 0.0014883884684923961, 0.0014932891211415433, 0.0014950368976296515, 0.0015000157338586084, 0.0015019062854235573, 0.0014883393079650645, 0.0014955281227713032, 0.0015108946530262427, 0.0015041598555993062, 0.0015051844909939232, 0.001507245244135206, 0.0015053407963821475, 0.0015033095913502027, 0.0015010968378117802, 0.0015103872033900448, 0.0014967508566546806, 0.0015080019793644243, 0.0015017958357930183, 0.0015054722055222612, 0.0014986680602008591, 0.0015242298998470818, 0.0015088781210764938, 0.0015217501014395027, 0.0015193332053188766, 0.0015206476721000305, 0.001517538632247217, 0.0015054264899381266, 0.0015152418981211222, 0.0015568208372296424, 0.0015473106937787058, 0.0015461493060182855, 0.0015453352445584474, 0.0015457547150970418, 0.00153676883735675, 0.0015492456946141866, 0.0015462788976538851, 0.0015467496123164892, 0.001551558346753674, 0.0015484415926039219, 0.0015342571839158023, 0.001533832448553674, 0.0015549487149228854, 0.0015471526136507793, 0.0015415338376460939, 0.0015524333884597433, 0.0015618206139615908, 0.001560613531999442, 0.0015586785097815553, 0.0015598032671045891, 0.001546921838093929, 0.0015438694069732208, 0.001560224816488216, 0.0015540517752571982, 0.0015607919990636256, 0.0015507291417987067, 0.0015468280596126402, 0.0015490665504404781, 0.0015563278753614547, 0.0015668583682225067, 0.0015463054474747302, 0.0015558300406805106, 0.0015463256324660412, 0.0015509838561470412, 0.0015459292858116785, 0.0015456122227431256, 0.0015509715303778648, 0.0015442243050213676, 0.0015554892241346594, 0.0015620462458618746, 0.0015619089185469309, 0.0015441511629377396, 0.004363040142806665]
[665.2051885887743, 663.5467509134944, 658.9412131744754, 656.9919906554989, 688.9364087244026, 715.969809069686, 664.417644262888, 681.4351936621237, 712.5311018368375, 702.4349098472976, 710.5072755175589, 712.3913455851609, 699.5914478628208, 684.178308416614, 651.3083281900174, 658.5340835318866, 660.2378364299229, 636.1093009041775, 675.8957426403091, 666.8245363051257, 681.4384537007444, 678.1532167993508, 673.825165181194, 676.2806629471188, 674.2545067895812, 655.4137737996574, 671.267442015199, 675.3312502992432, 665.8393681606901, 668.2788004111285, 666.3326672151139, 671.1732889487814, 672.3289572197506, 668.7434286600183, 668.5012438798301, 668.3515125153954, 670.1658626377109, 668.6667539642112, 670.9569572087888, 674.2287431984029, 669.6483962741435, 670.1781529722714, 670.5530186703927, 668.520769863269, 667.3063810528582, 675.4096659482857, 673.5392597616114, 670.0922325085778, 671.8676079322962, 669.6626834296839, 668.8798126557801, 666.6596739139671, 665.8205040522797, 671.8898000263478, 668.6601106149311, 661.8595134988747, 664.8229550053825, 664.370385147715, 663.4620370447798, 664.301400987301, 665.1989754830518, 666.1795393945052, 662.0818805638136, 668.113865145903, 663.1291030675362, 665.8694718459872, 664.2434156750782, 667.2591660263814, 656.0690090781744, 662.7440520421624, 657.1381194941587, 658.1834692345321, 657.6145272487672, 658.9618074626344, 664.2635868863316, 659.9606315268773, 642.3346708151059, 646.2826140998794, 646.7680683279195, 647.1087768956777, 646.9331713713844, 650.7159539491997, 645.4754100504588, 646.7138635321643, 646.5170522993377, 644.513306310588, 645.8106038848773, 651.781207533768, 651.9616930408201, 643.108026909809, 646.3486479464516, 648.7045406197437, 644.1500211433589, 640.2783975705629, 640.7736313287058, 641.569120074766, 641.1064914976532, 646.4450726432113, 647.7231788409584, 640.9332741231608, 643.4792044393105, 640.7003627645038, 644.8579400784909, 646.484264224184, 645.5500570428361, 642.5381282641048, 638.2197780482427, 646.7027595570454, 642.743727690594, 646.694317810166, 644.7520366099768, 646.8601178448841, 646.9928131295555, 644.7571605368984, 647.5743172467182, 642.8845565010674, 640.1859116842217, 640.2421985849957, 647.6049910149374, 229.1979828901409]
Elapsed: 0.0753152700587331~0.01282065098854945
Time per graph: 0.0015370463277292468~0.0002616459385418256
Speed: 657.6092906165005~42.56492059717974
Total Time: 0.2144
best val loss: 0.18649834394454956 test_score: 0.8776

Testing...
Test loss: 0.4002 score: 0.8367 time: 0.07s
test Score 0.8367
Epoch Time List: [0.4362340150400996, 0.27332188410218805, 0.2754631119314581, 0.2767267640447244, 0.27000524080358446, 0.3509583150735125, 0.26423860900104046, 0.2653178567998111, 0.25897041196003556, 0.2613543859915808, 0.2623669638996944, 0.2603344878880307, 0.34591204510070384, 0.2664010749431327, 0.2729101988952607, 0.2752308549825102, 0.27135353710036725, 0.2803317798534408, 0.27279081905726343, 0.27219412405975163, 0.40059225587174296, 0.2700551589950919, 0.2711160039762035, 0.27246459701564163, 0.27166289591696113, 0.2720634260913357, 0.43137029802892357, 0.2718472609994933, 0.2729932959191501, 0.27241942996624857, 0.27461262594442815, 0.27323674806393683, 0.2739993418799713, 0.27397362189367414, 0.2745911639649421, 0.27392575901467353, 0.273690520087257, 0.2740890569984913, 0.27359618805348873, 0.27268360601738095, 0.2738693669671193, 0.27410243113990873, 0.2729180359747261, 0.27302778989542276, 0.2737003939691931, 0.2729207960655913, 0.2730551370186731, 0.2737112520262599, 0.27370598702691495, 0.2738218141021207, 0.27383755694609135, 0.27483153296634555, 0.27891952998470515, 0.2763802050612867, 0.2739112579729408, 0.2807045991066843, 0.2778661079937592, 0.2748151159612462, 0.2811055020429194, 0.2785247249994427, 0.27619306405540556, 0.27610946202185005, 0.276167243020609, 0.27553066005930305, 0.27625084097962826, 0.27730222907848656, 0.2768276580609381, 0.2756754959700629, 0.2765720580937341, 0.27856375207193196, 0.2786641720449552, 0.277697431971319, 0.27982409903779626, 0.2788999939803034, 0.2780092101311311, 0.2787600759183988, 0.2805068960878998, 0.28266721800900996, 0.2819869730155915, 0.28276852786075324, 0.28308314899913967, 0.28281617688480765, 0.28303670103196055, 0.2845591650111601, 0.28335911000613123, 0.28529614803846925, 0.28355773293878883, 0.2815737910568714, 0.2811447230633348, 0.2824122039601207, 0.28090374276507646, 0.2810714670922607, 0.2832761589670554, 0.2850963060045615, 0.28447463805787265, 0.2843315440695733, 0.28471980488393456, 0.28295483998954296, 0.2840897769201547, 0.2845272879349068, 0.28407755389343947, 0.28327555395662785, 0.2841170758474618, 0.28393305593635887, 0.2840399370761588, 0.2836927139433101, 0.28580557194072753, 0.2834120460320264, 0.28321719903033227, 0.28362643206492066, 0.284523592912592, 0.28340650792233646, 0.28302497405093163, 0.2835472479928285, 0.2838265469763428, 0.2836810040753335, 0.28997285396326333, 0.2878603491699323, 0.2847708601038903, 0.4199028149014339]
Total Epoch List: [120]
Total Time List: [0.21436113491654396]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c93540880>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6969;  Loss pred: 0.6969; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6978;  Loss pred: 0.6978; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6968;  Loss pred: 0.6968; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.08s
Epoch 4/1000, LR 0.000060
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6935;  Loss pred: 0.6935; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 6/1000, LR 0.000120
Train loss: 0.6923;  Loss pred: 0.6923; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 7/1000, LR 0.000150
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 8/1000, LR 0.000180
Train loss: 0.6892;  Loss pred: 0.6892; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6844;  Loss pred: 0.6844; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6809;  Loss pred: 0.6809; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6800;  Loss pred: 0.6800; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6737;  Loss pred: 0.6737; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6732;  Loss pred: 0.6732; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6680;  Loss pred: 0.6680; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.08s
Epoch 15/1000, LR 0.000270
Train loss: 0.6618;  Loss pred: 0.6618; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.08s
Epoch 16/1000, LR 0.000270
Train loss: 0.6612;  Loss pred: 0.6612; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6542;  Loss pred: 0.6542; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6451;  Loss pred: 0.6451; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4898 time: 0.08s
Epoch 19/1000, LR 0.000270
Train loss: 0.6409;  Loss pred: 0.6409; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
Test loss: 0.6928 score: 0.5306 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6360;  Loss pred: 0.6360; Loss self: 0.0000; time: 0.13s
Val loss: 0.6928 score: 0.6735 time: 0.07s
Test loss: 0.6926 score: 0.7347 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.6288;  Loss pred: 0.6288; Loss self: 0.0000; time: 0.14s
Val loss: 0.6927 score: 0.5918 time: 0.07s
Test loss: 0.6924 score: 0.6939 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.6206;  Loss pred: 0.6206; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5102 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.6106;  Loss pred: 0.6106; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5102 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.6026;  Loss pred: 0.6026; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5102 time: 0.08s
Epoch 25/1000, LR 0.000270
Train loss: 0.5937;  Loss pred: 0.5937; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5102 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.5823;  Loss pred: 0.5823; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5102 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5696;  Loss pred: 0.5696; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5102 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5591;  Loss pred: 0.5591; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.5102 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5418;  Loss pred: 0.5418; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.5102 time: 0.09s
Epoch 30/1000, LR 0.000270
Train loss: 0.5294;  Loss pred: 0.5294; Loss self: 0.0000; time: 0.24s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.4898 time: 0.07s
Test loss: 0.6892 score: 0.5510 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.5193;  Loss pred: 0.5193; Loss self: 0.0000; time: 0.13s
Val loss: 0.6902 score: 0.5306 time: 0.07s
Test loss: 0.6885 score: 0.6327 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.5058;  Loss pred: 0.5058; Loss self: 0.0000; time: 0.13s
Val loss: 0.6896 score: 0.6531 time: 0.07s
Test loss: 0.6876 score: 0.8571 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.4905;  Loss pred: 0.4905; Loss self: 0.0000; time: 0.13s
Val loss: 0.6889 score: 0.8367 time: 0.07s
Test loss: 0.6867 score: 0.9388 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4807;  Loss pred: 0.4807; Loss self: 0.0000; time: 0.13s
Val loss: 0.6881 score: 0.8571 time: 0.07s
Test loss: 0.6856 score: 0.9388 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4613;  Loss pred: 0.4613; Loss self: 0.0000; time: 0.13s
Val loss: 0.6872 score: 0.8163 time: 0.07s
Test loss: 0.6843 score: 0.8980 time: 0.08s
Epoch 36/1000, LR 0.000270
Train loss: 0.4499;  Loss pred: 0.4499; Loss self: 0.0000; time: 0.13s
Val loss: 0.6861 score: 0.7755 time: 0.07s
Test loss: 0.6827 score: 0.8776 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4333;  Loss pred: 0.4333; Loss self: 0.0000; time: 0.25s
Val loss: 0.6848 score: 0.7755 time: 0.07s
Test loss: 0.6809 score: 0.8367 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4109;  Loss pred: 0.4109; Loss self: 0.0000; time: 0.13s
Val loss: 0.6834 score: 0.7347 time: 0.07s
Test loss: 0.6790 score: 0.8163 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.3989;  Loss pred: 0.3989; Loss self: 0.0000; time: 0.13s
Val loss: 0.6820 score: 0.7347 time: 0.07s
Test loss: 0.6769 score: 0.7551 time: 0.08s
Epoch 40/1000, LR 0.000269
Train loss: 0.3844;  Loss pred: 0.3844; Loss self: 0.0000; time: 0.13s
Val loss: 0.6804 score: 0.7143 time: 0.07s
Test loss: 0.6747 score: 0.7755 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.3690;  Loss pred: 0.3690; Loss self: 0.0000; time: 0.14s
Val loss: 0.6787 score: 0.7347 time: 0.07s
Test loss: 0.6722 score: 0.7755 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3525;  Loss pred: 0.3525; Loss self: 0.0000; time: 0.14s
Val loss: 0.6767 score: 0.7347 time: 0.07s
Test loss: 0.6694 score: 0.7551 time: 0.08s
Epoch 43/1000, LR 0.000269
Train loss: 0.3380;  Loss pred: 0.3380; Loss self: 0.0000; time: 0.15s
Val loss: 0.6745 score: 0.7143 time: 0.08s
Test loss: 0.6663 score: 0.7551 time: 0.08s
Epoch 44/1000, LR 0.000269
Train loss: 0.3202;  Loss pred: 0.3202; Loss self: 0.0000; time: 0.13s
Val loss: 0.6720 score: 0.7143 time: 0.07s
Test loss: 0.6626 score: 0.7551 time: 0.08s
Epoch 45/1000, LR 0.000269
Train loss: 0.3100;  Loss pred: 0.3100; Loss self: 0.0000; time: 0.13s
Val loss: 0.6692 score: 0.7143 time: 0.07s
Test loss: 0.6586 score: 0.7551 time: 0.08s
Epoch 46/1000, LR 0.000269
Train loss: 0.2940;  Loss pred: 0.2940; Loss self: 0.0000; time: 0.13s
Val loss: 0.6661 score: 0.7143 time: 0.07s
Test loss: 0.6541 score: 0.7755 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2788;  Loss pred: 0.2788; Loss self: 0.0000; time: 0.13s
Val loss: 0.6628 score: 0.7143 time: 0.07s
Test loss: 0.6492 score: 0.7755 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.2646;  Loss pred: 0.2646; Loss self: 0.0000; time: 0.14s
Val loss: 0.6590 score: 0.7143 time: 0.07s
Test loss: 0.6437 score: 0.7755 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2518;  Loss pred: 0.2518; Loss self: 0.0000; time: 0.13s
Val loss: 0.6549 score: 0.7347 time: 0.07s
Test loss: 0.6377 score: 0.7551 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2405;  Loss pred: 0.2405; Loss self: 0.0000; time: 0.14s
Val loss: 0.6503 score: 0.7347 time: 0.16s
Test loss: 0.6311 score: 0.7959 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2278;  Loss pred: 0.2278; Loss self: 0.0000; time: 0.13s
Val loss: 0.6452 score: 0.7347 time: 0.07s
Test loss: 0.6238 score: 0.8163 time: 0.08s
Epoch 52/1000, LR 0.000269
Train loss: 0.2138;  Loss pred: 0.2138; Loss self: 0.0000; time: 0.13s
Val loss: 0.6396 score: 0.7347 time: 0.07s
Test loss: 0.6159 score: 0.8367 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.1992;  Loss pred: 0.1992; Loss self: 0.0000; time: 0.13s
Val loss: 0.6336 score: 0.7755 time: 0.07s
Test loss: 0.6073 score: 0.8367 time: 0.08s
Epoch 54/1000, LR 0.000269
Train loss: 0.1901;  Loss pred: 0.1901; Loss self: 0.0000; time: 0.13s
Val loss: 0.6271 score: 0.7959 time: 0.07s
Test loss: 0.5981 score: 0.8367 time: 0.08s
Epoch 55/1000, LR 0.000269
Train loss: 0.1782;  Loss pred: 0.1782; Loss self: 0.0000; time: 0.13s
Val loss: 0.6200 score: 0.7959 time: 0.07s
Test loss: 0.5881 score: 0.8367 time: 0.08s
Epoch 56/1000, LR 0.000269
Train loss: 0.1686;  Loss pred: 0.1686; Loss self: 0.0000; time: 0.13s
Val loss: 0.6124 score: 0.7959 time: 0.07s
Test loss: 0.5774 score: 0.8367 time: 0.08s
Epoch 57/1000, LR 0.000269
Train loss: 0.1582;  Loss pred: 0.1582; Loss self: 0.0000; time: 0.25s
Val loss: 0.6042 score: 0.7959 time: 0.07s
Test loss: 0.5659 score: 0.8776 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1458;  Loss pred: 0.1458; Loss self: 0.0000; time: 0.13s
Val loss: 0.5956 score: 0.8163 time: 0.07s
Test loss: 0.5539 score: 0.8776 time: 0.08s
Epoch 59/1000, LR 0.000268
Train loss: 0.1385;  Loss pred: 0.1385; Loss self: 0.0000; time: 0.13s
Val loss: 0.5865 score: 0.8163 time: 0.07s
Test loss: 0.5410 score: 0.8980 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1251;  Loss pred: 0.1251; Loss self: 0.0000; time: 0.14s
Val loss: 0.5769 score: 0.8163 time: 0.07s
Test loss: 0.5277 score: 0.9184 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.1186;  Loss pred: 0.1186; Loss self: 0.0000; time: 0.14s
Val loss: 0.5667 score: 0.8163 time: 0.07s
Test loss: 0.5136 score: 0.9184 time: 0.08s
Epoch 62/1000, LR 0.000268
Train loss: 0.1077;  Loss pred: 0.1077; Loss self: 0.0000; time: 0.14s
Val loss: 0.5559 score: 0.8163 time: 0.07s
Test loss: 0.4989 score: 0.9184 time: 0.08s
Epoch 63/1000, LR 0.000268
Train loss: 0.1050;  Loss pred: 0.1050; Loss self: 0.0000; time: 0.15s
Val loss: 0.5447 score: 0.8163 time: 0.13s
Test loss: 0.4839 score: 0.9184 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.0907;  Loss pred: 0.0907; Loss self: 0.0000; time: 0.13s
Val loss: 0.5331 score: 0.7959 time: 0.07s
Test loss: 0.4684 score: 0.9388 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.0852;  Loss pred: 0.0852; Loss self: 0.0000; time: 0.13s
Val loss: 0.5212 score: 0.8163 time: 0.07s
Test loss: 0.4527 score: 0.9388 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0804;  Loss pred: 0.0804; Loss self: 0.0000; time: 0.13s
Val loss: 0.5090 score: 0.8163 time: 0.07s
Test loss: 0.4366 score: 0.9388 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0725;  Loss pred: 0.0725; Loss self: 0.0000; time: 0.14s
Val loss: 0.4965 score: 0.8367 time: 0.07s
Test loss: 0.4201 score: 0.9388 time: 0.09s
Epoch 68/1000, LR 0.000268
Train loss: 0.0662;  Loss pred: 0.0662; Loss self: 0.0000; time: 0.14s
Val loss: 0.4839 score: 0.8367 time: 0.07s
Test loss: 0.4037 score: 0.9592 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0592;  Loss pred: 0.0592; Loss self: 0.0000; time: 0.14s
Val loss: 0.4713 score: 0.8367 time: 0.07s
Test loss: 0.3870 score: 0.9592 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0564;  Loss pred: 0.0564; Loss self: 0.0000; time: 0.15s
Val loss: 0.4588 score: 0.8367 time: 0.12s
Test loss: 0.3704 score: 0.9592 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0517;  Loss pred: 0.0517; Loss self: 0.0000; time: 0.13s
Val loss: 0.4467 score: 0.8367 time: 0.08s
Test loss: 0.3542 score: 0.9592 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0492;  Loss pred: 0.0492; Loss self: 0.0000; time: 0.14s
Val loss: 0.4348 score: 0.8367 time: 0.07s
Test loss: 0.3379 score: 0.9592 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0432;  Loss pred: 0.0432; Loss self: 0.0000; time: 0.14s
Val loss: 0.4232 score: 0.8571 time: 0.07s
Test loss: 0.3219 score: 0.9388 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0426;  Loss pred: 0.0426; Loss self: 0.0000; time: 0.14s
Val loss: 0.4122 score: 0.8571 time: 0.08s
Test loss: 0.3063 score: 0.9388 time: 0.09s
Epoch 75/1000, LR 0.000267
Train loss: 0.0368;  Loss pred: 0.0368; Loss self: 0.0000; time: 0.14s
Val loss: 0.4016 score: 0.8571 time: 0.07s
Test loss: 0.2912 score: 0.9388 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0340;  Loss pred: 0.0340; Loss self: 0.0000; time: 0.13s
Val loss: 0.3917 score: 0.8776 time: 0.07s
Test loss: 0.2764 score: 0.9592 time: 0.09s
Epoch 77/1000, LR 0.000267
Train loss: 0.0307;  Loss pred: 0.0307; Loss self: 0.0000; time: 0.25s
Val loss: 0.3825 score: 0.8776 time: 0.07s
Test loss: 0.2624 score: 0.9592 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0277;  Loss pred: 0.0277; Loss self: 0.0000; time: 0.13s
Val loss: 0.3740 score: 0.8776 time: 0.07s
Test loss: 0.2490 score: 0.9592 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0261;  Loss pred: 0.0261; Loss self: 0.0000; time: 0.13s
Val loss: 0.3663 score: 0.8776 time: 0.07s
Test loss: 0.2362 score: 0.9592 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.13s
Val loss: 0.3596 score: 0.8776 time: 0.07s
Test loss: 0.2242 score: 0.9592 time: 0.08s
Epoch 81/1000, LR 0.000267
Train loss: 0.0219;  Loss pred: 0.0219; Loss self: 0.0000; time: 0.13s
Val loss: 0.3539 score: 0.8776 time: 0.07s
Test loss: 0.2133 score: 0.9592 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0204;  Loss pred: 0.0204; Loss self: 0.0000; time: 0.13s
Val loss: 0.3492 score: 0.8776 time: 0.07s
Test loss: 0.2030 score: 0.9592 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.13s
Val loss: 0.3457 score: 0.8776 time: 0.07s
Test loss: 0.1935 score: 0.9592 time: 0.21s
Epoch 84/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.13s
Val loss: 0.3430 score: 0.8776 time: 0.07s
Test loss: 0.1850 score: 0.9592 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.13s
Val loss: 0.3415 score: 0.8776 time: 0.07s
Test loss: 0.1775 score: 0.9592 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.13s
Val loss: 0.3414 score: 0.8776 time: 0.07s
Test loss: 0.1711 score: 0.9388 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0147;  Loss pred: 0.0147; Loss self: 0.0000; time: 0.13s
Val loss: 0.3418 score: 0.8776 time: 0.07s
Test loss: 0.1655 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.13s
Val loss: 0.3436 score: 0.8571 time: 0.07s
Test loss: 0.1609 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.13s
Val loss: 0.3463 score: 0.8571 time: 0.08s
Test loss: 0.1570 score: 0.9388 time: 0.13s
     INFO: Early stopping counter 3 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.13s
Val loss: 0.3495 score: 0.8571 time: 0.07s
Test loss: 0.1539 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.13s
Val loss: 0.3537 score: 0.8776 time: 0.07s
Test loss: 0.1515 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.13s
Val loss: 0.3579 score: 0.8776 time: 0.07s
Test loss: 0.1493 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.13s
Val loss: 0.3630 score: 0.8571 time: 0.07s
Test loss: 0.1480 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.13s
Val loss: 0.3685 score: 0.8571 time: 0.07s
Test loss: 0.1472 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.15s
Val loss: 0.3745 score: 0.8571 time: 0.13s
Test loss: 0.1470 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.13s
Val loss: 0.3809 score: 0.8571 time: 0.07s
Test loss: 0.1472 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.13s
Val loss: 0.3868 score: 0.8571 time: 0.07s
Test loss: 0.1475 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.13s
Val loss: 0.3937 score: 0.8571 time: 0.07s
Test loss: 0.1484 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.13s
Val loss: 0.4005 score: 0.8571 time: 0.07s
Test loss: 0.1495 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.13s
Val loss: 0.4078 score: 0.8571 time: 0.07s
Test loss: 0.1509 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.13s
Val loss: 0.4147 score: 0.8571 time: 0.07s
Test loss: 0.1523 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.13s
Val loss: 0.4219 score: 0.8776 time: 0.19s
Test loss: 0.1541 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.13s
Val loss: 0.4297 score: 0.8776 time: 0.07s
Test loss: 0.1561 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.13s
Val loss: 0.4371 score: 0.8776 time: 0.07s
Test loss: 0.1582 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.13s
Val loss: 0.4439 score: 0.8776 time: 0.07s
Test loss: 0.1601 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.13s
Val loss: 0.4509 score: 0.8776 time: 0.07s
Test loss: 0.1621 score: 0.9388 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 085,   Train_Loss: 0.0142,   Val_Loss: 0.3414,   Val_Precision: 0.9130,   Val_Recall: 0.8400,   Val_accuracy: 0.8750,   Val_Score: 0.8776,   Val_Loss: 0.3414,   Test_Precision: 1.0000,   Test_Recall: 0.8750,   Test_accuracy: 0.9333,   Test_Score: 0.9388,   Test_loss: 0.1711


[0.07366148196160793, 0.07384558802004904, 0.07436171697918326, 0.07458233996294439, 0.07112412608694285, 0.06843863998074085, 0.07374879403505474, 0.07190705800894648, 0.06876892794389278, 0.06975735304877162, 0.06896481104195118, 0.06878241896629333, 0.07004087907262146, 0.07161875697784126, 0.0752331850817427, 0.07440769008826464, 0.0742156800115481, 0.07703078689519316, 0.0724963879911229, 0.07348259899299592, 0.07190671400167048, 0.07225505798123777, 0.07271916000172496, 0.07245512504596263, 0.07267285499256104, 0.07476193201728165, 0.07299624104052782, 0.07255698589142412, 0.07359132298734039, 0.07332269102334976, 0.07353684189729393, 0.07300648104865104, 0.07288098998833448, 0.07327174802776426, 0.07329829293303192, 0.07331471401266754, 0.0731162279844284, 0.07328014995437115, 0.0730300199938938, 0.0726756319636479, 0.07317272806540132, 0.0731148871127516, 0.07307401299476624, 0.07329615205526352, 0.07342953910119832, 0.0725485619623214, 0.07275002798996866, 0.07312426203861833, 0.0729310349561274, 0.07317116693593562, 0.07325680798385292, 0.07350077095907182, 0.07359340798575431, 0.07292862609028816, 0.07328087801579386, 0.07403383799828589, 0.073703832924366, 0.07375404005870223, 0.07385501696262509, 0.07376169902272522, 0.07366216997615993, 0.07355374505277723, 0.0740089729661122, 0.07334079197607934, 0.07389209698885679, 0.0735879959538579, 0.0737681380705908, 0.0734347349498421, 0.074687265092507, 0.0739350279327482, 0.07456575497053564, 0.07444732706062496, 0.0745117359329015, 0.07435939298011363, 0.0737658980069682, 0.07424685300793499, 0.07628422102425247, 0.07581822399515659, 0.075761315994896, 0.07572142698336393, 0.07574198103975505, 0.07530167303048074, 0.07591303903609514, 0.07576766598504037, 0.07579073100350797, 0.07602635899093002, 0.07587363803759217, 0.07517860201187432, 0.07515778997913003, 0.07619248703122139, 0.07581047806888819, 0.0755351580446586, 0.07606923603452742, 0.07652921008411795, 0.07647006306797266, 0.07637524697929621, 0.07643036008812487, 0.07579917006660253, 0.07564960094168782, 0.07645101600792259, 0.07614853698760271, 0.07647880795411766, 0.07598572794813663, 0.07579457492101938, 0.07590426097158343, 0.07626006589271128, 0.07677606004290283, 0.07576896692626178, 0.07623567199334502, 0.07576995599083602, 0.07599820895120502, 0.07575053500477225, 0.07573499891441315, 0.07599760498851538, 0.07566699094604701, 0.0762189719825983, 0.07654026604723185, 0.07653353700879961, 0.07566340698394924, 0.21378896699752659, 0.08562509494367987, 0.08539587096311152, 0.08585883805062622, 0.08546410594135523, 0.08160008501727134, 0.0831144810654223, 0.08247925993055105, 0.08121886407025158, 0.08515426400117576, 0.08488957001827657, 0.08537214796524495, 0.08559306594543159, 0.08532646798994392, 0.08709583501331508, 0.08597366593312472, 0.08612448605708778, 0.08691724704112858, 0.08725487801712006, 0.08722428092733026, 0.08688382990658283, 0.08639772492460907, 0.08742806001100689, 0.08605919708497822, 0.08594034402631223, 0.0858055519638583, 0.08639246504753828, 0.08754934999160469, 0.08653756603598595, 0.09354004997294396, 0.08617725607473403, 0.08653532003518194, 0.08679400500841439, 0.08676997595466673, 0.0878182000014931, 0.08762839902192354, 0.0900284870294854, 0.08653482899535447, 0.08643339900299907, 0.08678092702757567, 0.08668766706250608, 0.08761576400138438, 0.08745984605047852, 0.08066660701297224, 0.0834010411053896, 0.08289269788656384, 0.08320492098573595, 0.08284455700777471, 0.08323349594138563, 0.08282940299250185, 0.08253738202620298, 0.08231669501401484, 0.08273347106296569, 0.08271288895048201, 0.08467472402844578, 0.08194378903135657, 0.0824882680317387, 0.08762456104159355, 0.08593188610393554, 0.08764642104506493, 0.08963798196054995, 0.0887218409916386, 0.08741247898433357, 0.08833463699556887, 0.08736712799873203, 0.08750453789252788, 0.08770055999048054, 0.08996506105177104, 0.0879662330262363, 0.08768020907882601, 0.0887081609107554, 0.0894701030338183, 0.08933479897677898, 0.08953859901521355, 0.09062910603825003, 0.08917668997310102, 0.092785167042166, 0.08703346201218665, 0.08682011696510017, 0.08691258390899748, 0.08721788902767003, 0.08781009609811008, 0.08723508403636515, 0.21382508997339755, 0.0877846609801054, 0.08597861102316529, 0.08677321998402476, 0.0868111300515011, 0.08599907904863358, 0.1341204340569675, 0.08444743393920362, 0.08466750907246023, 0.08522279397584498, 0.08565074496436864, 0.08584124699700624, 0.08462300198152661, 0.08496286801528186, 0.08493750507477671, 0.08495350310113281, 0.08543269999790937, 0.0857780349906534, 0.08541724400129169, 0.08434078900609165, 0.08574556896928698, 0.08581087097991258, 0.08602260099723935, 0.08713911194354296]
[0.0015032955502368966, 0.0015070528167356945, 0.0015175860607996583, 0.0015220885706723345, 0.001451512777284548, 0.0013967069383824663, 0.0015050774292868314, 0.001467490979774418, 0.0014034475090590362, 0.0014236194499749311, 0.001407445123305126, 0.0014037228360468028, 0.0014294056953596218, 0.0014616072852620665, 0.001535371124117198, 0.001518524287515605, 0.0015146057145213898, 0.0015720568754121053, 0.0014795181222678143, 0.0014996448774080798, 0.0014674839592177648, 0.0014745930200252607, 0.0014840644898311216, 0.001478676021346176, 0.0014831194896441028, 0.0015257537146384011, 0.001489719204908731, 0.0014807548141106963, 0.0015018637344355182, 0.0014963814494561177, 0.001500751875454978, 0.0014899281846663477, 0.001487367142619071, 0.0014953417964849848, 0.0014958835292455492, 0.0014962186533197456, 0.0014921679180495593, 0.0014955132643749214, 0.0014904085713039552, 0.0014831761625234265, 0.0014933209809265574, 0.0014921405533214612, 0.0014913063876482906, 0.0014958398378625208, 0.001498562022473435, 0.0014805828971902327, 0.0014846944487748705, 0.0014923318783391494, 0.0014883884684923961, 0.0014932891211415433, 0.0014950368976296515, 0.0015000157338586084, 0.0015019062854235573, 0.0014883393079650645, 0.0014955281227713032, 0.0015108946530262427, 0.0015041598555993062, 0.0015051844909939232, 0.001507245244135206, 0.0015053407963821475, 0.0015033095913502027, 0.0015010968378117802, 0.0015103872033900448, 0.0014967508566546806, 0.0015080019793644243, 0.0015017958357930183, 0.0015054722055222612, 0.0014986680602008591, 0.0015242298998470818, 0.0015088781210764938, 0.0015217501014395027, 0.0015193332053188766, 0.0015206476721000305, 0.001517538632247217, 0.0015054264899381266, 0.0015152418981211222, 0.0015568208372296424, 0.0015473106937787058, 0.0015461493060182855, 0.0015453352445584474, 0.0015457547150970418, 0.00153676883735675, 0.0015492456946141866, 0.0015462788976538851, 0.0015467496123164892, 0.001551558346753674, 0.0015484415926039219, 0.0015342571839158023, 0.001533832448553674, 0.0015549487149228854, 0.0015471526136507793, 0.0015415338376460939, 0.0015524333884597433, 0.0015618206139615908, 0.001560613531999442, 0.0015586785097815553, 0.0015598032671045891, 0.001546921838093929, 0.0015438694069732208, 0.001560224816488216, 0.0015540517752571982, 0.0015607919990636256, 0.0015507291417987067, 0.0015468280596126402, 0.0015490665504404781, 0.0015563278753614547, 0.0015668583682225067, 0.0015463054474747302, 0.0015558300406805106, 0.0015463256324660412, 0.0015509838561470412, 0.0015459292858116785, 0.0015456122227431256, 0.0015509715303778648, 0.0015442243050213676, 0.0015554892241346594, 0.0015620462458618746, 0.0015619089185469309, 0.0015441511629377396, 0.004363040142806665, 0.0017474509172179565, 0.0017427728767981942, 0.0017522211847066575, 0.0017441654273745964, 0.0016653078574953334, 0.0016962138992943326, 0.0016832502026643073, 0.0016575278381683997, 0.0017378421224729748, 0.0017324402044546238, 0.0017422887339845908, 0.0017467972641924815, 0.0017413564895906923, 0.0017774660206798995, 0.0017545646108800964, 0.0017576425725936281, 0.0017738213681862975, 0.0017807117962677563, 0.0017800873658638827, 0.0017731393858486293, 0.00176321887601243, 0.00178424612267361, 0.0017563101445913923, 0.0017538845719655557, 0.0017511337135481288, 0.0017631115315824139, 0.0017867214284000956, 0.0017660727762446112, 0.001908980611692734, 0.001758719511729266, 0.001766026939493509, 0.0017713062246615182, 0.0017708158358095251, 0.0017922081632957775, 0.001788334673916807, 0.0018373160618262328, 0.0017660169182725403, 0.0017639469184285524, 0.001771039327093381, 0.0017691360625001241, 0.0017880768163547832, 0.0017848948173567044, 0.0016462572859790251, 0.001702062063375298, 0.0016916877119706906, 0.001698059611953795, 0.0016907052450566267, 0.0016986427743139925, 0.0016903959794388134, 0.0016844363678816933, 0.0016799325513064253, 0.0016884381849584834, 0.0016880181418465717, 0.001728055592417261, 0.001672322225129726, 0.001683434041464055, 0.0017882563477876236, 0.0017537119613048068, 0.0017887024703074474, 0.0018293465706234683, 0.0018106498161558897, 0.00178392814253742, 0.00180274769378712, 0.001783002612219021, 0.0017858068957658751, 0.0017898073467445008, 0.0018360216541177764, 0.0017952292454333938, 0.0017893920220168574, 0.0018103706308317427, 0.0018259204700779245, 0.001823159162791408, 0.0018273183472492561, 0.0018495735926173475, 0.0018199324484306331, 0.0018935748375952244, 0.0017761931022895233, 0.0017718391217367382, 0.0017737262022244384, 0.0017799569189320414, 0.0017920427775124507, 0.00178030783747684, 0.004363777346395869, 0.0017915236934715388, 0.001754665531085006, 0.0017708820404903013, 0.001771655715336757, 0.001755083245890481, 0.002737151715448316, 0.0017234170191674208, 0.0017279083484175559, 0.0017392406933845915, 0.0017479743870279314, 0.0017518621836123721, 0.0017270000404393186, 0.0017339360819445277, 0.0017334184709138104, 0.0017337449612476084, 0.0017435244897532525, 0.0017505721426663958, 0.0017432090612508509, 0.0017212405919610541, 0.001749909570801775, 0.0017512422648961752, 0.001755563285657946, 0.0017783492233376115]
[665.2051885887743, 663.5467509134944, 658.9412131744754, 656.9919906554989, 688.9364087244026, 715.969809069686, 664.417644262888, 681.4351936621237, 712.5311018368375, 702.4349098472976, 710.5072755175589, 712.3913455851609, 699.5914478628208, 684.178308416614, 651.3083281900174, 658.5340835318866, 660.2378364299229, 636.1093009041775, 675.8957426403091, 666.8245363051257, 681.4384537007444, 678.1532167993508, 673.825165181194, 676.2806629471188, 674.2545067895812, 655.4137737996574, 671.267442015199, 675.3312502992432, 665.8393681606901, 668.2788004111285, 666.3326672151139, 671.1732889487814, 672.3289572197506, 668.7434286600183, 668.5012438798301, 668.3515125153954, 670.1658626377109, 668.6667539642112, 670.9569572087888, 674.2287431984029, 669.6483962741435, 670.1781529722714, 670.5530186703927, 668.520769863269, 667.3063810528582, 675.4096659482857, 673.5392597616114, 670.0922325085778, 671.8676079322962, 669.6626834296839, 668.8798126557801, 666.6596739139671, 665.8205040522797, 671.8898000263478, 668.6601106149311, 661.8595134988747, 664.8229550053825, 664.370385147715, 663.4620370447798, 664.301400987301, 665.1989754830518, 666.1795393945052, 662.0818805638136, 668.113865145903, 663.1291030675362, 665.8694718459872, 664.2434156750782, 667.2591660263814, 656.0690090781744, 662.7440520421624, 657.1381194941587, 658.1834692345321, 657.6145272487672, 658.9618074626344, 664.2635868863316, 659.9606315268773, 642.3346708151059, 646.2826140998794, 646.7680683279195, 647.1087768956777, 646.9331713713844, 650.7159539491997, 645.4754100504588, 646.7138635321643, 646.5170522993377, 644.513306310588, 645.8106038848773, 651.781207533768, 651.9616930408201, 643.108026909809, 646.3486479464516, 648.7045406197437, 644.1500211433589, 640.2783975705629, 640.7736313287058, 641.569120074766, 641.1064914976532, 646.4450726432113, 647.7231788409584, 640.9332741231608, 643.4792044393105, 640.7003627645038, 644.8579400784909, 646.484264224184, 645.5500570428361, 642.5381282641048, 638.2197780482427, 646.7027595570454, 642.743727690594, 646.694317810166, 644.7520366099768, 646.8601178448841, 646.9928131295555, 644.7571605368984, 647.5743172467182, 642.8845565010674, 640.1859116842217, 640.2421985849957, 647.6049910149374, 229.1979828901409, 572.2621391804573, 573.7982345910676, 570.7042060260285, 573.3401111529021, 600.4895704413634, 589.5482877578264, 594.0887447493932, 603.3081176512965, 575.4262640250573, 577.2204994023458, 573.9576802020716, 572.4762801608149, 574.2649514775984, 562.5986591954593, 569.941963834775, 568.9438885884354, 563.7546248653455, 561.5731878094635, 561.770180035347, 563.9714553638418, 567.1445636185161, 560.460794781802, 569.3755189421007, 570.1629491382737, 571.058618918261, 567.1790933739103, 559.6843380870187, 566.2280815666082, 523.8397885630062, 568.5954999252536, 566.2427778631717, 564.5551210046087, 564.7114622412736, 557.9708989613417, 559.17945034852, 544.272170029381, 566.2459909943373, 566.9104832762599, 564.6402000802511, 565.2476489495165, 559.2600893056845, 560.2571032622108, 607.4384657349002, 587.5226418106847, 591.125650983818, 588.9074758979725, 591.4691534339606, 588.7052976184804, 591.5773654004935, 593.6703927008984, 595.2619938356065, 592.2633170160083, 592.41069465407, 578.6850865145879, 597.9708844223652, 594.02386750497, 559.2039425651527, 570.2190679340376, 559.0644708105742, 546.6432747399992, 552.2879085051661, 560.5606953302627, 554.7087944953913, 560.8516741068922, 559.9709589939355, 558.7193514536134, 544.655885597661, 557.0319236630895, 558.8490323505977, 552.3730792851891, 547.6689792285001, 548.4984637703914, 547.2500188625286, 540.6651587109283, 549.4709437497647, 528.1016520424225, 563.0018485664617, 564.3853258075769, 563.7848720653138, 561.8113502432358, 558.0223935212687, 561.7006109557213, 229.15926286338146, 558.1840774108001, 569.9091834223501, 564.6903504217207, 564.4437524420028, 569.773543415388, 365.3432852684275, 580.242616196919, 578.7343992612889, 574.9635480607249, 572.0907625541888, 570.8211578253156, 579.038782040571, 576.7225276715777, 576.8947411024342, 576.786103118879, 573.5508769030955, 571.2418103928258, 573.6546592308575, 580.9763055033893, 571.4581008559312, 571.0232216553353, 569.617745010669, 562.3192491535475]
Elapsed: 0.08118692131669764~0.014478780307259242
Time per graph: 0.001656875945238727~0.0002954853123930458
Speed: 613.6369495149928~62.732328264050246
Total Time: 0.0879
best val loss: 0.34138232469558716 test_score: 0.9388

Testing...
Test loss: 0.2764 score: 0.9592 time: 0.08s
test Score 0.9592
Epoch Time List: [0.4362340150400996, 0.27332188410218805, 0.2754631119314581, 0.2767267640447244, 0.27000524080358446, 0.3509583150735125, 0.26423860900104046, 0.2653178567998111, 0.25897041196003556, 0.2613543859915808, 0.2623669638996944, 0.2603344878880307, 0.34591204510070384, 0.2664010749431327, 0.2729101988952607, 0.2752308549825102, 0.27135353710036725, 0.2803317798534408, 0.27279081905726343, 0.27219412405975163, 0.40059225587174296, 0.2700551589950919, 0.2711160039762035, 0.27246459701564163, 0.27166289591696113, 0.2720634260913357, 0.43137029802892357, 0.2718472609994933, 0.2729932959191501, 0.27241942996624857, 0.27461262594442815, 0.27323674806393683, 0.2739993418799713, 0.27397362189367414, 0.2745911639649421, 0.27392575901467353, 0.273690520087257, 0.2740890569984913, 0.27359618805348873, 0.27268360601738095, 0.2738693669671193, 0.27410243113990873, 0.2729180359747261, 0.27302778989542276, 0.2737003939691931, 0.2729207960655913, 0.2730551370186731, 0.2737112520262599, 0.27370598702691495, 0.2738218141021207, 0.27383755694609135, 0.27483153296634555, 0.27891952998470515, 0.2763802050612867, 0.2739112579729408, 0.2807045991066843, 0.2778661079937592, 0.2748151159612462, 0.2811055020429194, 0.2785247249994427, 0.27619306405540556, 0.27610946202185005, 0.276167243020609, 0.27553066005930305, 0.27625084097962826, 0.27730222907848656, 0.2768276580609381, 0.2756754959700629, 0.2765720580937341, 0.27856375207193196, 0.2786641720449552, 0.277697431971319, 0.27982409903779626, 0.2788999939803034, 0.2780092101311311, 0.2787600759183988, 0.2805068960878998, 0.28266721800900996, 0.2819869730155915, 0.28276852786075324, 0.28308314899913967, 0.28281617688480765, 0.28303670103196055, 0.2845591650111601, 0.28335911000613123, 0.28529614803846925, 0.28355773293878883, 0.2815737910568714, 0.2811447230633348, 0.2824122039601207, 0.28090374276507646, 0.2810714670922607, 0.2832761589670554, 0.2850963060045615, 0.28447463805787265, 0.2843315440695733, 0.28471980488393456, 0.28295483998954296, 0.2840897769201547, 0.2845272879349068, 0.28407755389343947, 0.28327555395662785, 0.2841170758474618, 0.28393305593635887, 0.2840399370761588, 0.2836927139433101, 0.28580557194072753, 0.2834120460320264, 0.28321719903033227, 0.28362643206492066, 0.284523592912592, 0.28340650792233646, 0.28302497405093163, 0.2835472479928285, 0.2838265469763428, 0.2836810040753335, 0.28997285396326333, 0.2878603491699323, 0.2847708601038903, 0.4199028149014339, 0.28223508514929563, 0.38909436005633324, 0.2819783821469173, 0.281402779975906, 0.2738869530148804, 0.2703647289890796, 0.27280729194171727, 0.2689992181258276, 0.3581756768980995, 0.27892380103003234, 0.2798323311144486, 0.2803439620183781, 0.28086093498859555, 0.28787129011470824, 0.2826779260067269, 0.3673561931354925, 0.2870910168858245, 0.2866373060969636, 0.288051248062402, 0.28662641905248165, 0.2879971219226718, 0.28351188194938004, 0.2992157060652971, 0.2829372889827937, 0.2834109980612993, 0.2856704560108483, 0.2871288739843294, 0.2894508169265464, 0.28966729692183435, 0.3904477428877726, 0.28588769398629665, 0.28686583903618157, 0.2863853119779378, 0.28997053508646786, 0.2892727970611304, 0.28787038300652057, 0.40466256195213646, 0.28723207802977413, 0.2879065761808306, 0.2871641309466213, 0.2936547910794616, 0.29141865903511643, 0.3054548348300159, 0.2754905440378934, 0.27754123497288674, 0.2764850460225716, 0.27641998406033963, 0.28281831892672926, 0.2775753140449524, 0.37372740695718676, 0.2747213899856433, 0.2741026140283793, 0.27678584412205964, 0.27948934119194746, 0.2783803130732849, 0.2743931240402162, 0.4053120029857382, 0.2875145429279655, 0.29067847377154976, 0.2926332870265469, 0.2971520130522549, 0.29054477298632264, 0.36095732590183616, 0.28993665101006627, 0.2895308380248025, 0.28990496217738837, 0.2931743520312011, 0.2938270688755438, 0.29172181198373437, 0.3618606640957296, 0.29052550601772964, 0.2945062699727714, 0.2966483480995521, 0.29979541315697134, 0.2961245710030198, 0.2949548600008711, 0.4008086788235232, 0.28713884006720036, 0.2870375260245055, 0.28831470501609147, 0.2906756380107254, 0.28717859904281795, 0.4143905509263277, 0.28485152893699706, 0.28451232600491494, 0.2859699021792039, 0.28864738205447793, 0.2859041409101337, 0.34072851086966693, 0.27979920303914696, 0.27854675403796136, 0.27957427699584514, 0.28617280907928944, 0.2816587599227205, 0.3572894729441032, 0.280296646989882, 0.28000266500748694, 0.2806593800196424, 0.28178505902178586, 0.28629310603719205, 0.2820771150290966, 0.4066343830199912, 0.28639007010497153, 0.28369936894159764, 0.28703689004760236, 0.28939254803117365]
Total Epoch List: [120, 106]
Total Time List: [0.21436113491654396, 0.08790170098654926]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c933c0550>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6918;  Loss pred: 0.6918; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6880;  Loss pred: 0.6880; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6867;  Loss pred: 0.6867; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6836;  Loss pred: 0.6836; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6835;  Loss pred: 0.6835; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6956 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6784;  Loss pred: 0.6784; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6763;  Loss pred: 0.6763; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6709;  Loss pred: 0.6709; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6679;  Loss pred: 0.6679; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6962 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6623;  Loss pred: 0.6623; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6606;  Loss pred: 0.6606; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6966 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6544;  Loss pred: 0.6544; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6507;  Loss pred: 0.6507; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6971 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6445;  Loss pred: 0.6445; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6974 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6396;  Loss pred: 0.6396; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6977 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6338;  Loss pred: 0.6338; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6981 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6249;  Loss pred: 0.6249; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6985 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6184;  Loss pred: 0.6184; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6989 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6909,   Val_Loss: 0.6950,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.4898,   Val_Loss: 0.6950,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.5000,   Test_loss: 0.6941


[0.07366148196160793, 0.07384558802004904, 0.07436171697918326, 0.07458233996294439, 0.07112412608694285, 0.06843863998074085, 0.07374879403505474, 0.07190705800894648, 0.06876892794389278, 0.06975735304877162, 0.06896481104195118, 0.06878241896629333, 0.07004087907262146, 0.07161875697784126, 0.0752331850817427, 0.07440769008826464, 0.0742156800115481, 0.07703078689519316, 0.0724963879911229, 0.07348259899299592, 0.07190671400167048, 0.07225505798123777, 0.07271916000172496, 0.07245512504596263, 0.07267285499256104, 0.07476193201728165, 0.07299624104052782, 0.07255698589142412, 0.07359132298734039, 0.07332269102334976, 0.07353684189729393, 0.07300648104865104, 0.07288098998833448, 0.07327174802776426, 0.07329829293303192, 0.07331471401266754, 0.0731162279844284, 0.07328014995437115, 0.0730300199938938, 0.0726756319636479, 0.07317272806540132, 0.0731148871127516, 0.07307401299476624, 0.07329615205526352, 0.07342953910119832, 0.0725485619623214, 0.07275002798996866, 0.07312426203861833, 0.0729310349561274, 0.07317116693593562, 0.07325680798385292, 0.07350077095907182, 0.07359340798575431, 0.07292862609028816, 0.07328087801579386, 0.07403383799828589, 0.073703832924366, 0.07375404005870223, 0.07385501696262509, 0.07376169902272522, 0.07366216997615993, 0.07355374505277723, 0.0740089729661122, 0.07334079197607934, 0.07389209698885679, 0.0735879959538579, 0.0737681380705908, 0.0734347349498421, 0.074687265092507, 0.0739350279327482, 0.07456575497053564, 0.07444732706062496, 0.0745117359329015, 0.07435939298011363, 0.0737658980069682, 0.07424685300793499, 0.07628422102425247, 0.07581822399515659, 0.075761315994896, 0.07572142698336393, 0.07574198103975505, 0.07530167303048074, 0.07591303903609514, 0.07576766598504037, 0.07579073100350797, 0.07602635899093002, 0.07587363803759217, 0.07517860201187432, 0.07515778997913003, 0.07619248703122139, 0.07581047806888819, 0.0755351580446586, 0.07606923603452742, 0.07652921008411795, 0.07647006306797266, 0.07637524697929621, 0.07643036008812487, 0.07579917006660253, 0.07564960094168782, 0.07645101600792259, 0.07614853698760271, 0.07647880795411766, 0.07598572794813663, 0.07579457492101938, 0.07590426097158343, 0.07626006589271128, 0.07677606004290283, 0.07576896692626178, 0.07623567199334502, 0.07576995599083602, 0.07599820895120502, 0.07575053500477225, 0.07573499891441315, 0.07599760498851538, 0.07566699094604701, 0.0762189719825983, 0.07654026604723185, 0.07653353700879961, 0.07566340698394924, 0.21378896699752659, 0.08562509494367987, 0.08539587096311152, 0.08585883805062622, 0.08546410594135523, 0.08160008501727134, 0.0831144810654223, 0.08247925993055105, 0.08121886407025158, 0.08515426400117576, 0.08488957001827657, 0.08537214796524495, 0.08559306594543159, 0.08532646798994392, 0.08709583501331508, 0.08597366593312472, 0.08612448605708778, 0.08691724704112858, 0.08725487801712006, 0.08722428092733026, 0.08688382990658283, 0.08639772492460907, 0.08742806001100689, 0.08605919708497822, 0.08594034402631223, 0.0858055519638583, 0.08639246504753828, 0.08754934999160469, 0.08653756603598595, 0.09354004997294396, 0.08617725607473403, 0.08653532003518194, 0.08679400500841439, 0.08676997595466673, 0.0878182000014931, 0.08762839902192354, 0.0900284870294854, 0.08653482899535447, 0.08643339900299907, 0.08678092702757567, 0.08668766706250608, 0.08761576400138438, 0.08745984605047852, 0.08066660701297224, 0.0834010411053896, 0.08289269788656384, 0.08320492098573595, 0.08284455700777471, 0.08323349594138563, 0.08282940299250185, 0.08253738202620298, 0.08231669501401484, 0.08273347106296569, 0.08271288895048201, 0.08467472402844578, 0.08194378903135657, 0.0824882680317387, 0.08762456104159355, 0.08593188610393554, 0.08764642104506493, 0.08963798196054995, 0.0887218409916386, 0.08741247898433357, 0.08833463699556887, 0.08736712799873203, 0.08750453789252788, 0.08770055999048054, 0.08996506105177104, 0.0879662330262363, 0.08768020907882601, 0.0887081609107554, 0.0894701030338183, 0.08933479897677898, 0.08953859901521355, 0.09062910603825003, 0.08917668997310102, 0.092785167042166, 0.08703346201218665, 0.08682011696510017, 0.08691258390899748, 0.08721788902767003, 0.08781009609811008, 0.08723508403636515, 0.21382508997339755, 0.0877846609801054, 0.08597861102316529, 0.08677321998402476, 0.0868111300515011, 0.08599907904863358, 0.1341204340569675, 0.08444743393920362, 0.08466750907246023, 0.08522279397584498, 0.08565074496436864, 0.08584124699700624, 0.08462300198152661, 0.08496286801528186, 0.08493750507477671, 0.08495350310113281, 0.08543269999790937, 0.0857780349906534, 0.08541724400129169, 0.08434078900609165, 0.08574556896928698, 0.08581087097991258, 0.08602260099723935, 0.08713911194354296, 0.0777172779198736, 0.07762634905520827, 0.07783273106906563, 0.07765467697754502, 0.0776018489850685, 0.0779194220667705, 0.07771450793370605, 0.07786130998283625, 0.07797686906997114, 0.07782921299804002, 0.07595243898686022, 0.07839954295195639, 0.07817889703437686, 0.07830839999951422, 0.07812315598130226, 0.07839824305847287, 0.07842207700014114, 0.07779968099202961, 0.07752656901720911, 0.07827322091907263, 0.07816646806895733]
[0.0015032955502368966, 0.0015070528167356945, 0.0015175860607996583, 0.0015220885706723345, 0.001451512777284548, 0.0013967069383824663, 0.0015050774292868314, 0.001467490979774418, 0.0014034475090590362, 0.0014236194499749311, 0.001407445123305126, 0.0014037228360468028, 0.0014294056953596218, 0.0014616072852620665, 0.001535371124117198, 0.001518524287515605, 0.0015146057145213898, 0.0015720568754121053, 0.0014795181222678143, 0.0014996448774080798, 0.0014674839592177648, 0.0014745930200252607, 0.0014840644898311216, 0.001478676021346176, 0.0014831194896441028, 0.0015257537146384011, 0.001489719204908731, 0.0014807548141106963, 0.0015018637344355182, 0.0014963814494561177, 0.001500751875454978, 0.0014899281846663477, 0.001487367142619071, 0.0014953417964849848, 0.0014958835292455492, 0.0014962186533197456, 0.0014921679180495593, 0.0014955132643749214, 0.0014904085713039552, 0.0014831761625234265, 0.0014933209809265574, 0.0014921405533214612, 0.0014913063876482906, 0.0014958398378625208, 0.001498562022473435, 0.0014805828971902327, 0.0014846944487748705, 0.0014923318783391494, 0.0014883884684923961, 0.0014932891211415433, 0.0014950368976296515, 0.0015000157338586084, 0.0015019062854235573, 0.0014883393079650645, 0.0014955281227713032, 0.0015108946530262427, 0.0015041598555993062, 0.0015051844909939232, 0.001507245244135206, 0.0015053407963821475, 0.0015033095913502027, 0.0015010968378117802, 0.0015103872033900448, 0.0014967508566546806, 0.0015080019793644243, 0.0015017958357930183, 0.0015054722055222612, 0.0014986680602008591, 0.0015242298998470818, 0.0015088781210764938, 0.0015217501014395027, 0.0015193332053188766, 0.0015206476721000305, 0.001517538632247217, 0.0015054264899381266, 0.0015152418981211222, 0.0015568208372296424, 0.0015473106937787058, 0.0015461493060182855, 0.0015453352445584474, 0.0015457547150970418, 0.00153676883735675, 0.0015492456946141866, 0.0015462788976538851, 0.0015467496123164892, 0.001551558346753674, 0.0015484415926039219, 0.0015342571839158023, 0.001533832448553674, 0.0015549487149228854, 0.0015471526136507793, 0.0015415338376460939, 0.0015524333884597433, 0.0015618206139615908, 0.001560613531999442, 0.0015586785097815553, 0.0015598032671045891, 0.001546921838093929, 0.0015438694069732208, 0.001560224816488216, 0.0015540517752571982, 0.0015607919990636256, 0.0015507291417987067, 0.0015468280596126402, 0.0015490665504404781, 0.0015563278753614547, 0.0015668583682225067, 0.0015463054474747302, 0.0015558300406805106, 0.0015463256324660412, 0.0015509838561470412, 0.0015459292858116785, 0.0015456122227431256, 0.0015509715303778648, 0.0015442243050213676, 0.0015554892241346594, 0.0015620462458618746, 0.0015619089185469309, 0.0015441511629377396, 0.004363040142806665, 0.0017474509172179565, 0.0017427728767981942, 0.0017522211847066575, 0.0017441654273745964, 0.0016653078574953334, 0.0016962138992943326, 0.0016832502026643073, 0.0016575278381683997, 0.0017378421224729748, 0.0017324402044546238, 0.0017422887339845908, 0.0017467972641924815, 0.0017413564895906923, 0.0017774660206798995, 0.0017545646108800964, 0.0017576425725936281, 0.0017738213681862975, 0.0017807117962677563, 0.0017800873658638827, 0.0017731393858486293, 0.00176321887601243, 0.00178424612267361, 0.0017563101445913923, 0.0017538845719655557, 0.0017511337135481288, 0.0017631115315824139, 0.0017867214284000956, 0.0017660727762446112, 0.001908980611692734, 0.001758719511729266, 0.001766026939493509, 0.0017713062246615182, 0.0017708158358095251, 0.0017922081632957775, 0.001788334673916807, 0.0018373160618262328, 0.0017660169182725403, 0.0017639469184285524, 0.001771039327093381, 0.0017691360625001241, 0.0017880768163547832, 0.0017848948173567044, 0.0016462572859790251, 0.001702062063375298, 0.0016916877119706906, 0.001698059611953795, 0.0016907052450566267, 0.0016986427743139925, 0.0016903959794388134, 0.0016844363678816933, 0.0016799325513064253, 0.0016884381849584834, 0.0016880181418465717, 0.001728055592417261, 0.001672322225129726, 0.001683434041464055, 0.0017882563477876236, 0.0017537119613048068, 0.0017887024703074474, 0.0018293465706234683, 0.0018106498161558897, 0.00178392814253742, 0.00180274769378712, 0.001783002612219021, 0.0017858068957658751, 0.0017898073467445008, 0.0018360216541177764, 0.0017952292454333938, 0.0017893920220168574, 0.0018103706308317427, 0.0018259204700779245, 0.001823159162791408, 0.0018273183472492561, 0.0018495735926173475, 0.0018199324484306331, 0.0018935748375952244, 0.0017761931022895233, 0.0017718391217367382, 0.0017737262022244384, 0.0017799569189320414, 0.0017920427775124507, 0.00178030783747684, 0.004363777346395869, 0.0017915236934715388, 0.001754665531085006, 0.0017708820404903013, 0.001771655715336757, 0.001755083245890481, 0.002737151715448316, 0.0017234170191674208, 0.0017279083484175559, 0.0017392406933845915, 0.0017479743870279314, 0.0017518621836123721, 0.0017270000404393186, 0.0017339360819445277, 0.0017334184709138104, 0.0017337449612476084, 0.0017435244897532525, 0.0017505721426663958, 0.0017432090612508509, 0.0017212405919610541, 0.001749909570801775, 0.0017512422648961752, 0.001755563285657946, 0.0017783492233376115, 0.0016191099566640332, 0.001617215605316839, 0.001621515230605534, 0.0016178057703655213, 0.001616705187188927, 0.0016233212930577186, 0.0016190522486188759, 0.0016221106246424217, 0.001624518105624399, 0.001621441937459167, 0.0015823424788929212, 0.0016333238114990916, 0.001628727021549518, 0.0016314249999898796, 0.0016275657496104639, 0.0016332967303848516, 0.001633793270836274, 0.00162082668733395, 0.0016151368545251898, 0.0016306921024806798, 0.0016284680847699444]
[665.2051885887743, 663.5467509134944, 658.9412131744754, 656.9919906554989, 688.9364087244026, 715.969809069686, 664.417644262888, 681.4351936621237, 712.5311018368375, 702.4349098472976, 710.5072755175589, 712.3913455851609, 699.5914478628208, 684.178308416614, 651.3083281900174, 658.5340835318866, 660.2378364299229, 636.1093009041775, 675.8957426403091, 666.8245363051257, 681.4384537007444, 678.1532167993508, 673.825165181194, 676.2806629471188, 674.2545067895812, 655.4137737996574, 671.267442015199, 675.3312502992432, 665.8393681606901, 668.2788004111285, 666.3326672151139, 671.1732889487814, 672.3289572197506, 668.7434286600183, 668.5012438798301, 668.3515125153954, 670.1658626377109, 668.6667539642112, 670.9569572087888, 674.2287431984029, 669.6483962741435, 670.1781529722714, 670.5530186703927, 668.520769863269, 667.3063810528582, 675.4096659482857, 673.5392597616114, 670.0922325085778, 671.8676079322962, 669.6626834296839, 668.8798126557801, 666.6596739139671, 665.8205040522797, 671.8898000263478, 668.6601106149311, 661.8595134988747, 664.8229550053825, 664.370385147715, 663.4620370447798, 664.301400987301, 665.1989754830518, 666.1795393945052, 662.0818805638136, 668.113865145903, 663.1291030675362, 665.8694718459872, 664.2434156750782, 667.2591660263814, 656.0690090781744, 662.7440520421624, 657.1381194941587, 658.1834692345321, 657.6145272487672, 658.9618074626344, 664.2635868863316, 659.9606315268773, 642.3346708151059, 646.2826140998794, 646.7680683279195, 647.1087768956777, 646.9331713713844, 650.7159539491997, 645.4754100504588, 646.7138635321643, 646.5170522993377, 644.513306310588, 645.8106038848773, 651.781207533768, 651.9616930408201, 643.108026909809, 646.3486479464516, 648.7045406197437, 644.1500211433589, 640.2783975705629, 640.7736313287058, 641.569120074766, 641.1064914976532, 646.4450726432113, 647.7231788409584, 640.9332741231608, 643.4792044393105, 640.7003627645038, 644.8579400784909, 646.484264224184, 645.5500570428361, 642.5381282641048, 638.2197780482427, 646.7027595570454, 642.743727690594, 646.694317810166, 644.7520366099768, 646.8601178448841, 646.9928131295555, 644.7571605368984, 647.5743172467182, 642.8845565010674, 640.1859116842217, 640.2421985849957, 647.6049910149374, 229.1979828901409, 572.2621391804573, 573.7982345910676, 570.7042060260285, 573.3401111529021, 600.4895704413634, 589.5482877578264, 594.0887447493932, 603.3081176512965, 575.4262640250573, 577.2204994023458, 573.9576802020716, 572.4762801608149, 574.2649514775984, 562.5986591954593, 569.941963834775, 568.9438885884354, 563.7546248653455, 561.5731878094635, 561.770180035347, 563.9714553638418, 567.1445636185161, 560.460794781802, 569.3755189421007, 570.1629491382737, 571.058618918261, 567.1790933739103, 559.6843380870187, 566.2280815666082, 523.8397885630062, 568.5954999252536, 566.2427778631717, 564.5551210046087, 564.7114622412736, 557.9708989613417, 559.17945034852, 544.272170029381, 566.2459909943373, 566.9104832762599, 564.6402000802511, 565.2476489495165, 559.2600893056845, 560.2571032622108, 607.4384657349002, 587.5226418106847, 591.125650983818, 588.9074758979725, 591.4691534339606, 588.7052976184804, 591.5773654004935, 593.6703927008984, 595.2619938356065, 592.2633170160083, 592.41069465407, 578.6850865145879, 597.9708844223652, 594.02386750497, 559.2039425651527, 570.2190679340376, 559.0644708105742, 546.6432747399992, 552.2879085051661, 560.5606953302627, 554.7087944953913, 560.8516741068922, 559.9709589939355, 558.7193514536134, 544.655885597661, 557.0319236630895, 558.8490323505977, 552.3730792851891, 547.6689792285001, 548.4984637703914, 547.2500188625286, 540.6651587109283, 549.4709437497647, 528.1016520424225, 563.0018485664617, 564.3853258075769, 563.7848720653138, 561.8113502432358, 558.0223935212687, 561.7006109557213, 229.15926286338146, 558.1840774108001, 569.9091834223501, 564.6903504217207, 564.4437524420028, 569.773543415388, 365.3432852684275, 580.242616196919, 578.7343992612889, 574.9635480607249, 572.0907625541888, 570.8211578253156, 579.038782040571, 576.7225276715777, 576.8947411024342, 576.786103118879, 573.5508769030955, 571.2418103928258, 573.6546592308575, 580.9763055033893, 571.4581008559312, 571.0232216553353, 569.617745010669, 562.3192491535475, 617.6232786934191, 618.3467415923702, 616.7071274603834, 618.1211727128798, 618.5419629529157, 616.0209961371116, 617.6452927032125, 616.4807657433598, 615.5671620635096, 616.7350041328157, 631.9744387445413, 612.2484671806649, 613.9764286888496, 612.9610616523612, 614.4145022954291, 612.2586186555161, 612.0725417654216, 616.9691107720286, 619.1425805177204, 613.2365505902411, 614.0740548447845]
Elapsed: 0.08090496808761799~0.013881271598939376
Time per graph: 0.0016539366695359047~0.0002828267565401262
Speed: 613.8747710537971~60.02342025114748
Total Time: 0.0790
best val loss: 0.6949630379676819 test_score: 0.5000

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.07s
test Score 0.5000
Epoch Time List: [0.4362340150400996, 0.27332188410218805, 0.2754631119314581, 0.2767267640447244, 0.27000524080358446, 0.3509583150735125, 0.26423860900104046, 0.2653178567998111, 0.25897041196003556, 0.2613543859915808, 0.2623669638996944, 0.2603344878880307, 0.34591204510070384, 0.2664010749431327, 0.2729101988952607, 0.2752308549825102, 0.27135353710036725, 0.2803317798534408, 0.27279081905726343, 0.27219412405975163, 0.40059225587174296, 0.2700551589950919, 0.2711160039762035, 0.27246459701564163, 0.27166289591696113, 0.2720634260913357, 0.43137029802892357, 0.2718472609994933, 0.2729932959191501, 0.27241942996624857, 0.27461262594442815, 0.27323674806393683, 0.2739993418799713, 0.27397362189367414, 0.2745911639649421, 0.27392575901467353, 0.273690520087257, 0.2740890569984913, 0.27359618805348873, 0.27268360601738095, 0.2738693669671193, 0.27410243113990873, 0.2729180359747261, 0.27302778989542276, 0.2737003939691931, 0.2729207960655913, 0.2730551370186731, 0.2737112520262599, 0.27370598702691495, 0.2738218141021207, 0.27383755694609135, 0.27483153296634555, 0.27891952998470515, 0.2763802050612867, 0.2739112579729408, 0.2807045991066843, 0.2778661079937592, 0.2748151159612462, 0.2811055020429194, 0.2785247249994427, 0.27619306405540556, 0.27610946202185005, 0.276167243020609, 0.27553066005930305, 0.27625084097962826, 0.27730222907848656, 0.2768276580609381, 0.2756754959700629, 0.2765720580937341, 0.27856375207193196, 0.2786641720449552, 0.277697431971319, 0.27982409903779626, 0.2788999939803034, 0.2780092101311311, 0.2787600759183988, 0.2805068960878998, 0.28266721800900996, 0.2819869730155915, 0.28276852786075324, 0.28308314899913967, 0.28281617688480765, 0.28303670103196055, 0.2845591650111601, 0.28335911000613123, 0.28529614803846925, 0.28355773293878883, 0.2815737910568714, 0.2811447230633348, 0.2824122039601207, 0.28090374276507646, 0.2810714670922607, 0.2832761589670554, 0.2850963060045615, 0.28447463805787265, 0.2843315440695733, 0.28471980488393456, 0.28295483998954296, 0.2840897769201547, 0.2845272879349068, 0.28407755389343947, 0.28327555395662785, 0.2841170758474618, 0.28393305593635887, 0.2840399370761588, 0.2836927139433101, 0.28580557194072753, 0.2834120460320264, 0.28321719903033227, 0.28362643206492066, 0.284523592912592, 0.28340650792233646, 0.28302497405093163, 0.2835472479928285, 0.2838265469763428, 0.2836810040753335, 0.28997285396326333, 0.2878603491699323, 0.2847708601038903, 0.4199028149014339, 0.28223508514929563, 0.38909436005633324, 0.2819783821469173, 0.281402779975906, 0.2738869530148804, 0.2703647289890796, 0.27280729194171727, 0.2689992181258276, 0.3581756768980995, 0.27892380103003234, 0.2798323311144486, 0.2803439620183781, 0.28086093498859555, 0.28787129011470824, 0.2826779260067269, 0.3673561931354925, 0.2870910168858245, 0.2866373060969636, 0.288051248062402, 0.28662641905248165, 0.2879971219226718, 0.28351188194938004, 0.2992157060652971, 0.2829372889827937, 0.2834109980612993, 0.2856704560108483, 0.2871288739843294, 0.2894508169265464, 0.28966729692183435, 0.3904477428877726, 0.28588769398629665, 0.28686583903618157, 0.2863853119779378, 0.28997053508646786, 0.2892727970611304, 0.28787038300652057, 0.40466256195213646, 0.28723207802977413, 0.2879065761808306, 0.2871641309466213, 0.2936547910794616, 0.29141865903511643, 0.3054548348300159, 0.2754905440378934, 0.27754123497288674, 0.2764850460225716, 0.27641998406033963, 0.28281831892672926, 0.2775753140449524, 0.37372740695718676, 0.2747213899856433, 0.2741026140283793, 0.27678584412205964, 0.27948934119194746, 0.2783803130732849, 0.2743931240402162, 0.4053120029857382, 0.2875145429279655, 0.29067847377154976, 0.2926332870265469, 0.2971520130522549, 0.29054477298632264, 0.36095732590183616, 0.28993665101006627, 0.2895308380248025, 0.28990496217738837, 0.2931743520312011, 0.2938270688755438, 0.29172181198373437, 0.3618606640957296, 0.29052550601772964, 0.2945062699727714, 0.2966483480995521, 0.29979541315697134, 0.2961245710030198, 0.2949548600008711, 0.4008086788235232, 0.28713884006720036, 0.2870375260245055, 0.28831470501609147, 0.2906756380107254, 0.28717859904281795, 0.4143905509263277, 0.28485152893699706, 0.28451232600491494, 0.2859699021792039, 0.28864738205447793, 0.2859041409101337, 0.34072851086966693, 0.27979920303914696, 0.27854675403796136, 0.27957427699584514, 0.28617280907928944, 0.2816587599227205, 0.3572894729441032, 0.280296646989882, 0.28000266500748694, 0.2806593800196424, 0.28178505902178586, 0.28629310603719205, 0.2820771150290966, 0.4066343830199912, 0.28639007010497153, 0.28369936894159764, 0.28703689004760236, 0.28939254803117365, 0.2702452080557123, 0.27158828696701676, 0.27082082198467106, 0.27184284711256623, 0.2705943059409037, 0.2715787768829614, 0.2718348269117996, 0.2744027351727709, 0.2724900239845738, 0.2723515840480104, 0.2678671039175242, 0.271308591007255, 0.2727220399538055, 0.2729905139422044, 0.27432691387366503, 0.27385482902172953, 0.2738774510798976, 0.27416826295666397, 0.2743250181665644, 0.27505045488942415, 0.2753841968951747]
Total Epoch List: [120, 106, 21]
Total Time List: [0.21436113491654396, 0.08790170098654926, 0.07896992808673531]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c93510b80>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6871;  Loss pred: 0.6871; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6868;  Loss pred: 0.6868; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 3/1000, LR 0.000030
Train loss: 0.6855;  Loss pred: 0.6855; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.08s
Epoch 4/1000, LR 0.000060
Train loss: 0.6853;  Loss pred: 0.6853; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.08s
Epoch 5/1000, LR 0.000090
Train loss: 0.6826;  Loss pred: 0.6826; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6835;  Loss pred: 0.6835; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4898 time: 0.08s
Epoch 7/1000, LR 0.000150
Train loss: 0.6812;  Loss pred: 0.6812; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4898 time: 0.08s
Epoch 8/1000, LR 0.000180
Train loss: 0.6772;  Loss pred: 0.6772; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6734;  Loss pred: 0.6734; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6709;  Loss pred: 0.6709; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6671;  Loss pred: 0.6671; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4898 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6623;  Loss pred: 0.6623; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4898 time: 0.08s
Epoch 13/1000, LR 0.000270
Train loss: 0.6594;  Loss pred: 0.6594; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6555;  Loss pred: 0.6555; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6500;  Loss pred: 0.6500; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6447;  Loss pred: 0.6447; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6393;  Loss pred: 0.6393; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6337;  Loss pred: 0.6337; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6260;  Loss pred: 0.6260; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6204;  Loss pred: 0.6204; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6162;  Loss pred: 0.6162; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 22/1000, LR 0.000270
Train loss: 0.6071;  Loss pred: 0.6071; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.6016;  Loss pred: 0.6016; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.5933;  Loss pred: 0.5933; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 25/1000, LR 0.000270
Train loss: 0.5838;  Loss pred: 0.5838; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.5745;  Loss pred: 0.5745; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5680;  Loss pred: 0.5680; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5544;  Loss pred: 0.5544; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5460;  Loss pred: 0.5460; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.5361;  Loss pred: 0.5361; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.5285;  Loss pred: 0.5285; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.5120;  Loss pred: 0.5120; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 011,   Train_Loss: 0.6623,   Val_Loss: 0.6929,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.5102,   Val_Loss: 0.6929,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.4898,   Test_loss: 0.6942


[0.08338175003882498, 0.0837053059367463, 0.08345696690957993, 0.08375546603929251, 0.08363855502102524, 0.08358361397404224, 0.08351182099431753, 0.08354522997979075, 0.08341239707078785, 0.08330009295605123, 0.08440965402405709, 0.08316197001840919, 0.08322190504986793, 0.08317383797839284, 0.0835430269362405, 0.08329569699708372, 0.08345999696757644, 0.08318039996083826, 0.08311299700289965, 0.08290131401736289, 0.08276570599991828, 0.0826319910120219, 0.08316313801333308, 0.08273941499646753, 0.08275314199272543, 0.08309270511381328, 0.08325715002138168, 0.08277140697464347, 0.08309285703580827, 0.08317698596511036, 0.08248421596363187, 0.08318277297075838]
[0.0017016683681392853, 0.0017082715497295164, 0.0017032034063179577, 0.001709295225291684, 0.0017069092861433722, 0.0017057880402865763, 0.0017043228774350516, 0.0017050046934651173, 0.0017022938177711805, 0.00170000189706227, 0.001722646000490961, 0.0016971830616001875, 0.0016984062255075087, 0.00169742526486516, 0.0017049597333926633, 0.0016999121836139535, 0.0017032652442362539, 0.0016975591828742502, 0.0016961836123040744, 0.001691863551374753, 0.001689096040814659, 0.001686367163510651, 0.0016972068982312875, 0.001688559489723827, 0.0016888396325046007, 0.0016957694921186383, 0.0016991255106404424, 0.0016892123872376218, 0.0016957725925675156, 0.001697489509492048, 0.0016833513461965688, 0.0016976076116481302]
[587.6585700969837, 585.3870247726936, 587.1289338023539, 585.0364437947542, 585.8542150528817, 586.2393078052053, 586.7432827663301, 586.5086494088639, 587.4426550578111, 588.2346376954488, 580.5023201023287, 589.211631099565, 588.787290685528, 589.1275573062935, 586.5241157397431, 588.2656819801333, 587.107617785274, 589.0810818782963, 589.5588147096956, 591.0642138885448, 592.0326469522097, 592.9906734653305, 589.2033558443178, 592.2207692922653, 592.1225323904612, 589.7027895876538, 588.5380413263734, 591.991870030805, 589.7017114104502, 589.1052606853735, 594.0530491506956, 589.0642767730909]
Elapsed: 0.08324573387290002~0.0003796404770737259
Time per graph: 0.0016988925280183678~7.747764838239294e-06
Speed: 588.6309694480549~2.67901448744962
Total Time: 0.0835
best val loss: 0.6929283738136292 test_score: 0.4898

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.08s
test Score 0.4898
Epoch Time List: [0.27803983993362635, 0.2771797371096909, 0.2764886349905282, 0.27680959494318813, 0.2769861171254888, 0.2763110240921378, 0.27664082613773644, 0.27724980702623725, 0.2763609972316772, 0.2771250510122627, 0.27757431799545884, 0.27554093196522444, 0.27525735611561686, 0.2750848879804835, 0.27563684002961963, 0.2750759822083637, 0.27522060612682253, 0.2752099201316014, 0.27474271692335606, 0.27388660598080605, 0.2730623910902068, 0.27348504203837365, 0.27248769998550415, 0.2722432679729536, 0.2719748611561954, 0.2740685979370028, 0.27317881386261433, 0.27461145096458495, 0.27454475103877485, 0.2750811430159956, 0.2734542629914358, 0.2738510499475524]
Total Epoch List: [32]
Total Time List: [0.08353830000851303]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c93541300>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6904;  Loss pred: 0.6904; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6916;  Loss pred: 0.6916; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4898 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6916;  Loss pred: 0.6916; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6892;  Loss pred: 0.6892; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6900;  Loss pred: 0.6900; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6872;  Loss pred: 0.6872; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6863;  Loss pred: 0.6863; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6841;  Loss pred: 0.6841; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6824;  Loss pred: 0.6824; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6781;  Loss pred: 0.6781; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6759;  Loss pred: 0.6759; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6693;  Loss pred: 0.6693; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6682;  Loss pred: 0.6682; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6648;  Loss pred: 0.6648; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6585;  Loss pred: 0.6585; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.4898 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5102 time: 0.17s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6560;  Loss pred: 0.6560; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6523;  Loss pred: 0.6523; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6457;  Loss pred: 0.6457; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6414;  Loss pred: 0.6414; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6343;  Loss pred: 0.6343; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6266;  Loss pred: 0.6266; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6904,   Val_Loss: 0.6937,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.4898,   Val_Loss: 0.6937,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.5102,   Test_loss: 0.6929


[0.08338175003882498, 0.0837053059367463, 0.08345696690957993, 0.08375546603929251, 0.08363855502102524, 0.08358361397404224, 0.08351182099431753, 0.08354522997979075, 0.08341239707078785, 0.08330009295605123, 0.08440965402405709, 0.08316197001840919, 0.08322190504986793, 0.08317383797839284, 0.0835430269362405, 0.08329569699708372, 0.08345999696757644, 0.08318039996083826, 0.08311299700289965, 0.08290131401736289, 0.08276570599991828, 0.0826319910120219, 0.08316313801333308, 0.08273941499646753, 0.08275314199272543, 0.08309270511381328, 0.08325715002138168, 0.08277140697464347, 0.08309285703580827, 0.08317698596511036, 0.08248421596363187, 0.08318277297075838, 0.08182475611101836, 0.08055347797926515, 0.0779830829706043, 0.07789569604210556, 0.0786398199852556, 0.0799470969941467, 0.08837878401391208, 0.07883082295302302, 0.08005769201554358, 0.07961835607420653, 0.0838694479316473, 0.08036628901027143, 0.0814876580843702, 0.0802931470097974, 0.17482580605428666, 0.07409817399457097, 0.0740797040052712, 0.07416185596957803, 0.07445754099171609, 0.07544486597180367, 0.07407329801935703]
[0.0017016683681392853, 0.0017082715497295164, 0.0017032034063179577, 0.001709295225291684, 0.0017069092861433722, 0.0017057880402865763, 0.0017043228774350516, 0.0017050046934651173, 0.0017022938177711805, 0.00170000189706227, 0.001722646000490961, 0.0016971830616001875, 0.0016984062255075087, 0.00169742526486516, 0.0017049597333926633, 0.0016999121836139535, 0.0017032652442362539, 0.0016975591828742502, 0.0016961836123040744, 0.001691863551374753, 0.001689096040814659, 0.001686367163510651, 0.0016972068982312875, 0.001688559489723827, 0.0016888396325046007, 0.0016957694921186383, 0.0016991255106404424, 0.0016892123872376218, 0.0016957725925675156, 0.001697489509492048, 0.0016833513461965688, 0.0016976076116481302, 0.0016698929818575175, 0.0016439485301890848, 0.0015914914891960062, 0.0015897080824919501, 0.0016048942854133795, 0.0016315734080438102, 0.0018036486533451446, 0.001608792305163735, 0.0016338304492968078, 0.0016248644096776843, 0.001711621386360149, 0.0016401283471483964, 0.0016630134302932694, 0.0016386356532611713, 0.0035678735929446257, 0.0015122076325422647, 0.0015118306939851266, 0.0015135072646852658, 0.001519541652892165, 0.0015396911422817074, 0.001511699959578715]
[587.6585700969837, 585.3870247726936, 587.1289338023539, 585.0364437947542, 585.8542150528817, 586.2393078052053, 586.7432827663301, 586.5086494088639, 587.4426550578111, 588.2346376954488, 580.5023201023287, 589.211631099565, 588.787290685528, 589.1275573062935, 586.5241157397431, 588.2656819801333, 587.107617785274, 589.0810818782963, 589.5588147096956, 591.0642138885448, 592.0326469522097, 592.9906734653305, 589.2033558443178, 592.2207692922653, 592.1225323904612, 589.7027895876538, 588.5380413263734, 591.991870030805, 589.7017114104502, 589.1052606853735, 594.0530491506956, 589.0642767730909, 598.8407705550345, 608.2915502743759, 628.3414060261061, 629.0463079438132, 623.0940000776598, 612.9053066628237, 554.4317060561356, 621.5842758510862, 612.0586138117299, 615.4359674838128, 584.2413561602847, 609.7083815048052, 601.318054192534, 610.2637874440394, 280.27898801613185, 661.2848516832565, 661.4497271278699, 660.7170136100735, 658.0931809909165, 649.4809072669435, 661.5069304352453]
Elapsed: 0.0832971859644255~0.013068139876697377
Time per graph: 0.0016999425707025615~0.0002666967321774975
Speed: 595.8219642549516~49.95838195609187
Total Time: 0.0745
best val loss: 0.6937288641929626 test_score: 0.5102

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
test Score 0.5102
Epoch Time List: [0.27803983993362635, 0.2771797371096909, 0.2764886349905282, 0.27680959494318813, 0.2769861171254888, 0.2763110240921378, 0.27664082613773644, 0.27724980702623725, 0.2763609972316772, 0.2771250510122627, 0.27757431799545884, 0.27554093196522444, 0.27525735611561686, 0.2750848879804835, 0.27563684002961963, 0.2750759822083637, 0.27522060612682253, 0.2752099201316014, 0.27474271692335606, 0.27388660598080605, 0.2730623910902068, 0.27348504203837365, 0.27248769998550415, 0.2722432679729536, 0.2719748611561954, 0.2740685979370028, 0.27317881386261433, 0.27461145096458495, 0.27454475103877485, 0.2750811430159956, 0.2734542629914358, 0.2738510499475524, 0.279137795092538, 0.3659026899840683, 0.26811780396383256, 0.2673270530067384, 0.26971528492867947, 0.26937374204862863, 0.2809436620445922, 0.2759793180739507, 0.3336809719912708, 0.2767015630379319, 0.2817945539718494, 0.27746995887719095, 0.28081414895132184, 0.27929254504851997, 0.38066146906930953, 0.2616617369931191, 0.25766832509543747, 0.2574729659827426, 0.25833420106209815, 0.2606858661165461, 0.26021196914371103]
Total Epoch List: [32, 21]
Total Time List: [0.08353830000851303, 0.07450327009428293]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c933c06a0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6997 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.5000 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6956;  Loss pred: 0.6956; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6996 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.5000 time: 0.08s
Epoch 3/1000, LR 0.000030
Train loss: 0.6964;  Loss pred: 0.6964; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6995 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.5000 time: 0.08s
Epoch 4/1000, LR 0.000060
Train loss: 0.6945;  Loss pred: 0.6945; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6993 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.5000 time: 0.08s
Epoch 5/1000, LR 0.000090
Train loss: 0.6944;  Loss pred: 0.6944; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6990 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.08s
Epoch 6/1000, LR 0.000120
Train loss: 0.6903;  Loss pred: 0.6903; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6987 score: 0.4898 time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.08s
Epoch 7/1000, LR 0.000150
Train loss: 0.6903;  Loss pred: 0.6903; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6984 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.5000 time: 0.08s
Epoch 8/1000, LR 0.000180
Train loss: 0.6861;  Loss pred: 0.6861; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6980 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.5000 time: 0.08s
Epoch 9/1000, LR 0.000210
Train loss: 0.6836;  Loss pred: 0.6836; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6976 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.5000 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6777;  Loss pred: 0.6777; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.08s
Epoch 11/1000, LR 0.000270
Train loss: 0.6752;  Loss pred: 0.6752; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.5000 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6698;  Loss pred: 0.6698; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.4898 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.16s
Epoch 13/1000, LR 0.000270
Train loss: 0.6634;  Loss pred: 0.6634; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.08s
Epoch 14/1000, LR 0.000270
Train loss: 0.6561;  Loss pred: 0.6561; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.09s
Epoch 15/1000, LR 0.000270
Train loss: 0.6538;  Loss pred: 0.6538; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6481;  Loss pred: 0.6481; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.08s
Epoch 17/1000, LR 0.000270
Train loss: 0.6391;  Loss pred: 0.6391; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.08s
Epoch 18/1000, LR 0.000270
Train loss: 0.6348;  Loss pred: 0.6348; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.22s
Epoch 19/1000, LR 0.000270
Train loss: 0.6239;  Loss pred: 0.6239; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6137;  Loss pred: 0.6137; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6090;  Loss pred: 0.6090; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.5980;  Loss pred: 0.5980; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5893;  Loss pred: 0.5893; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5749;  Loss pred: 0.5749; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.20s
Epoch 25/1000, LR 0.000270
Train loss: 0.5685;  Loss pred: 0.5685; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5000 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.5517;  Loss pred: 0.5517; Loss self: 0.0000; time: 0.13s
Val loss: 0.6908 score: 0.7959 time: 0.08s
Test loss: 0.6915 score: 0.7292 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5469;  Loss pred: 0.5469; Loss self: 0.0000; time: 0.13s
Val loss: 0.6903 score: 0.6327 time: 0.08s
Test loss: 0.6912 score: 0.5625 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5305;  Loss pred: 0.5305; Loss self: 0.0000; time: 0.13s
Val loss: 0.6898 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5000 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5230;  Loss pred: 0.5230; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.5000 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.5097;  Loss pred: 0.5097; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5000 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.4913;  Loss pred: 0.4913; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6882 score: 0.5102 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.5000 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.4841;  Loss pred: 0.4841; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6876 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6900 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4715;  Loss pred: 0.4715; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6869 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.5000 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4611;  Loss pred: 0.4611; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5000 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4459;  Loss pred: 0.4459; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6855 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.5000 time: 0.08s
Epoch 36/1000, LR 0.000270
Train loss: 0.4252;  Loss pred: 0.4252; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5000 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4178;  Loss pred: 0.4178; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6839 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.5000 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4025;  Loss pred: 0.4025; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6830 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.5000 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3867;  Loss pred: 0.3867; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6820 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6881 score: 0.5000 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3706;  Loss pred: 0.3706; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6811 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6878 score: 0.5000 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3577;  Loss pred: 0.3577; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6801 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.5000 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3522;  Loss pred: 0.3522; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6874 score: 0.5000 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3384;  Loss pred: 0.3384; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6780 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.5000 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3200;  Loss pred: 0.3200; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6769 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6868 score: 0.5000 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3119;  Loss pred: 0.3119; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6756 score: 0.5102 time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.5000 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2868;  Loss pred: 0.2868; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6745 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6862 score: 0.5000 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2726;  Loss pred: 0.2726; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6734 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6861 score: 0.5000 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.2619;  Loss pred: 0.2619; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6721 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6859 score: 0.5000 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2429;  Loss pred: 0.2429; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6704 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6854 score: 0.5000 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2350;  Loss pred: 0.2350; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6683 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6846 score: 0.5000 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2263;  Loss pred: 0.2263; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6659 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6836 score: 0.5000 time: 0.13s
Epoch 52/1000, LR 0.000269
Train loss: 0.2066;  Loss pred: 0.2066; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6629 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6820 score: 0.5000 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.1916;  Loss pred: 0.1916; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6592 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6799 score: 0.5000 time: 0.08s
Epoch 54/1000, LR 0.000269
Train loss: 0.1789;  Loss pred: 0.1789; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6548 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6773 score: 0.5000 time: 0.08s
Epoch 55/1000, LR 0.000269
Train loss: 0.1666;  Loss pred: 0.1666; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6496 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6742 score: 0.5000 time: 0.08s
Epoch 56/1000, LR 0.000269
Train loss: 0.1563;  Loss pred: 0.1563; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6437 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6707 score: 0.5000 time: 0.08s
Epoch 57/1000, LR 0.000269
Train loss: 0.1481;  Loss pred: 0.1481; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6368 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6665 score: 0.5000 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1332;  Loss pred: 0.1332; Loss self: 0.0000; time: 0.15s
Val loss: 0.6290 score: 0.5306 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6615 score: 0.5000 time: 0.08s
Epoch 59/1000, LR 0.000268
Train loss: 0.1247;  Loss pred: 0.1247; Loss self: 0.0000; time: 0.13s
Val loss: 0.6202 score: 0.5510 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6557 score: 0.5000 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1202;  Loss pred: 0.1202; Loss self: 0.0000; time: 0.13s
Val loss: 0.6105 score: 0.5714 time: 0.08s
Test loss: 0.6489 score: 0.5208 time: 0.08s
Epoch 61/1000, LR 0.000268
Train loss: 0.1085;  Loss pred: 0.1085; Loss self: 0.0000; time: 0.13s
Val loss: 0.5996 score: 0.5918 time: 0.08s
Test loss: 0.6412 score: 0.5208 time: 0.08s
Epoch 62/1000, LR 0.000268
Train loss: 0.1018;  Loss pred: 0.1018; Loss self: 0.0000; time: 0.13s
Val loss: 0.5876 score: 0.5918 time: 0.08s
Test loss: 0.6323 score: 0.5208 time: 0.08s
Epoch 63/1000, LR 0.000268
Train loss: 0.0936;  Loss pred: 0.0936; Loss self: 0.0000; time: 0.13s
Val loss: 0.5746 score: 0.6327 time: 0.08s
Test loss: 0.6224 score: 0.5208 time: 0.08s
Epoch 64/1000, LR 0.000268
Train loss: 0.0846;  Loss pred: 0.0846; Loss self: 0.0000; time: 0.13s
Val loss: 0.5605 score: 0.6327 time: 0.08s
Test loss: 0.6113 score: 0.5208 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.0770;  Loss pred: 0.0770; Loss self: 0.0000; time: 0.17s
Val loss: 0.5460 score: 0.6531 time: 0.08s
Test loss: 0.5999 score: 0.5208 time: 0.08s
Epoch 66/1000, LR 0.000268
Train loss: 0.0722;  Loss pred: 0.0722; Loss self: 0.0000; time: 0.13s
Val loss: 0.5303 score: 0.6531 time: 0.08s
Test loss: 0.5871 score: 0.5208 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0645;  Loss pred: 0.0645; Loss self: 0.0000; time: 0.13s
Val loss: 0.5140 score: 0.6939 time: 0.08s
Test loss: 0.5735 score: 0.6042 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0582;  Loss pred: 0.0582; Loss self: 0.0000; time: 0.13s
Val loss: 0.4970 score: 0.6939 time: 0.08s
Test loss: 0.5592 score: 0.6458 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0540;  Loss pred: 0.0540; Loss self: 0.0000; time: 0.13s
Val loss: 0.4793 score: 0.7551 time: 0.08s
Test loss: 0.5439 score: 0.6667 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0502;  Loss pred: 0.0502; Loss self: 0.0000; time: 0.13s
Val loss: 0.4608 score: 0.7755 time: 0.08s
Test loss: 0.5273 score: 0.7083 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0449;  Loss pred: 0.0449; Loss self: 0.0000; time: 0.13s
Val loss: 0.4421 score: 0.7959 time: 0.21s
Test loss: 0.5102 score: 0.7083 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0412;  Loss pred: 0.0412; Loss self: 0.0000; time: 0.13s
Val loss: 0.4238 score: 0.8571 time: 0.08s
Test loss: 0.4930 score: 0.7500 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0387;  Loss pred: 0.0387; Loss self: 0.0000; time: 0.13s
Val loss: 0.4055 score: 0.8571 time: 0.08s
Test loss: 0.4751 score: 0.7917 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0342;  Loss pred: 0.0342; Loss self: 0.0000; time: 0.13s
Val loss: 0.3877 score: 0.8571 time: 0.08s
Test loss: 0.4571 score: 0.7917 time: 0.08s
Epoch 75/1000, LR 0.000267
Train loss: 0.0298;  Loss pred: 0.0298; Loss self: 0.0000; time: 0.13s
Val loss: 0.3708 score: 0.8571 time: 0.08s
Test loss: 0.4398 score: 0.7917 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0280;  Loss pred: 0.0280; Loss self: 0.0000; time: 0.13s
Val loss: 0.3548 score: 0.8776 time: 0.08s
Test loss: 0.4232 score: 0.7917 time: 0.08s
Epoch 77/1000, LR 0.000267
Train loss: 0.0271;  Loss pred: 0.0271; Loss self: 0.0000; time: 0.15s
Val loss: 0.3393 score: 0.8776 time: 0.15s
Test loss: 0.4070 score: 0.8125 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0251;  Loss pred: 0.0251; Loss self: 0.0000; time: 0.13s
Val loss: 0.3248 score: 0.8776 time: 0.08s
Test loss: 0.3911 score: 0.8125 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0226;  Loss pred: 0.0226; Loss self: 0.0000; time: 0.13s
Val loss: 0.3109 score: 0.8776 time: 0.08s
Test loss: 0.3756 score: 0.8333 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0203;  Loss pred: 0.0203; Loss self: 0.0000; time: 0.13s
Val loss: 0.2978 score: 0.8980 time: 0.08s
Test loss: 0.3604 score: 0.8333 time: 0.08s
Epoch 81/1000, LR 0.000267
Train loss: 0.0203;  Loss pred: 0.0203; Loss self: 0.0000; time: 0.13s
Val loss: 0.2855 score: 0.8980 time: 0.08s
Test loss: 0.3455 score: 0.8333 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0181;  Loss pred: 0.0181; Loss self: 0.0000; time: 0.13s
Val loss: 0.2742 score: 0.8980 time: 0.08s
Test loss: 0.3314 score: 0.8750 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0164;  Loss pred: 0.0164; Loss self: 0.0000; time: 0.24s
Val loss: 0.2637 score: 0.8980 time: 0.08s
Test loss: 0.3177 score: 0.8750 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0147;  Loss pred: 0.0147; Loss self: 0.0000; time: 0.13s
Val loss: 0.2543 score: 0.8980 time: 0.08s
Test loss: 0.3051 score: 0.8750 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.13s
Val loss: 0.2458 score: 0.9184 time: 0.08s
Test loss: 0.2932 score: 0.8750 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.13s
Val loss: 0.2382 score: 0.9184 time: 0.08s
Test loss: 0.2820 score: 0.8750 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.13s
Val loss: 0.2314 score: 0.9184 time: 0.08s
Test loss: 0.2715 score: 0.9167 time: 0.08s
Epoch 88/1000, LR 0.000266
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.13s
Val loss: 0.2253 score: 0.9184 time: 0.08s
Test loss: 0.2618 score: 0.9167 time: 0.08s
Epoch 89/1000, LR 0.000266
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.13s
Val loss: 0.2202 score: 0.9184 time: 0.08s
Test loss: 0.2530 score: 0.9167 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.13s
Val loss: 0.2158 score: 0.9184 time: 0.08s
Test loss: 0.2448 score: 0.9167 time: 0.08s
Epoch 91/1000, LR 0.000266
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.13s
Val loss: 0.2123 score: 0.9388 time: 0.08s
Test loss: 0.2376 score: 0.9167 time: 0.08s
Epoch 92/1000, LR 0.000266
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.13s
Val loss: 0.2095 score: 0.9388 time: 0.08s
Test loss: 0.2312 score: 0.9167 time: 0.08s
Epoch 93/1000, LR 0.000265
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.13s
Val loss: 0.2073 score: 0.9388 time: 0.08s
Test loss: 0.2256 score: 0.9167 time: 0.08s
Epoch 94/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.13s
Val loss: 0.2058 score: 0.9388 time: 0.08s
Test loss: 0.2206 score: 0.9167 time: 0.08s
Epoch 95/1000, LR 0.000265
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.13s
Val loss: 0.2049 score: 0.9388 time: 0.08s
Test loss: 0.2162 score: 0.9167 time: 0.08s
Epoch 96/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.13s
Val loss: 0.2043 score: 0.9388 time: 0.08s
Test loss: 0.2121 score: 0.9167 time: 0.08s
Epoch 97/1000, LR 0.000265
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.13s
Val loss: 0.2041 score: 0.9388 time: 0.08s
Test loss: 0.2086 score: 0.9167 time: 0.08s
Epoch 98/1000, LR 0.000265
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.13s
Val loss: 0.2045 score: 0.9388 time: 0.08s
Test loss: 0.2060 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.13s
Val loss: 0.2052 score: 0.9388 time: 0.08s
Test loss: 0.2038 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.13s
Val loss: 0.2060 score: 0.9388 time: 0.08s
Test loss: 0.2020 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.13s
Val loss: 0.2072 score: 0.9388 time: 0.08s
Test loss: 0.2007 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.13s
Val loss: 0.2086 score: 0.9388 time: 0.08s
Test loss: 0.1996 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.13s
Val loss: 0.2101 score: 0.9388 time: 0.08s
Test loss: 0.1987 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.13s
Val loss: 0.2118 score: 0.9388 time: 0.08s
Test loss: 0.1982 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.13s
Val loss: 0.2134 score: 0.9388 time: 0.08s
Test loss: 0.1979 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.13s
Val loss: 0.2151 score: 0.9388 time: 0.08s
Test loss: 0.1978 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.13s
Val loss: 0.2170 score: 0.9388 time: 0.08s
Test loss: 0.1982 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.13s
Val loss: 0.2188 score: 0.9388 time: 0.08s
Test loss: 0.1987 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.13s
Val loss: 0.2207 score: 0.9388 time: 0.08s
Test loss: 0.1992 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.13s
Val loss: 0.2226 score: 0.9388 time: 0.08s
Test loss: 0.1998 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.13s
Val loss: 0.2246 score: 0.9388 time: 0.08s
Test loss: 0.2005 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.13s
Val loss: 0.2264 score: 0.9388 time: 0.08s
Test loss: 0.2012 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.13s
Val loss: 0.2284 score: 0.9388 time: 0.08s
Test loss: 0.2021 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.14s
Val loss: 0.2303 score: 0.9388 time: 0.08s
Test loss: 0.2028 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.13s
Val loss: 0.2321 score: 0.9388 time: 0.08s
Test loss: 0.2033 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.13s
Val loss: 0.2338 score: 0.9388 time: 0.08s
Test loss: 0.2037 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.14s
Val loss: 0.2355 score: 0.9388 time: 0.08s
Test loss: 0.2045 score: 0.9167 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 096,   Train_Loss: 0.0066,   Val_Loss: 0.2041,   Val_Precision: 0.9231,   Val_Recall: 0.9600,   Val_accuracy: 0.9412,   Val_Score: 0.9388,   Val_Loss: 0.2041,   Test_Precision: 0.8846,   Test_Recall: 0.9583,   Test_accuracy: 0.9200,   Test_Score: 0.9167,   Test_loss: 0.2086


[0.08338175003882498, 0.0837053059367463, 0.08345696690957993, 0.08375546603929251, 0.08363855502102524, 0.08358361397404224, 0.08351182099431753, 0.08354522997979075, 0.08341239707078785, 0.08330009295605123, 0.08440965402405709, 0.08316197001840919, 0.08322190504986793, 0.08317383797839284, 0.0835430269362405, 0.08329569699708372, 0.08345999696757644, 0.08318039996083826, 0.08311299700289965, 0.08290131401736289, 0.08276570599991828, 0.0826319910120219, 0.08316313801333308, 0.08273941499646753, 0.08275314199272543, 0.08309270511381328, 0.08325715002138168, 0.08277140697464347, 0.08309285703580827, 0.08317698596511036, 0.08248421596363187, 0.08318277297075838, 0.08182475611101836, 0.08055347797926515, 0.0779830829706043, 0.07789569604210556, 0.0786398199852556, 0.0799470969941467, 0.08837878401391208, 0.07883082295302302, 0.08005769201554358, 0.07961835607420653, 0.0838694479316473, 0.08036628901027143, 0.0814876580843702, 0.0802931470097974, 0.17482580605428666, 0.07409817399457097, 0.0740797040052712, 0.07416185596957803, 0.07445754099171609, 0.07544486597180367, 0.07407329801935703, 0.08519660402089357, 0.0850595060037449, 0.08587061404250562, 0.08513119304552674, 0.08333336398936808, 0.08052650198806077, 0.08008012897334993, 0.08128373301587999, 0.08084201801102608, 0.08152855501975864, 0.08070194604806602, 0.16983788704965264, 0.08054817700758576, 0.09584844997152686, 0.07978332391940057, 0.08338191895745695, 0.08298413804732263, 0.22106208896730095, 0.0765483760042116, 0.07638504507485777, 0.07676951703615487, 0.07734155503567308, 0.07637038896791637, 0.20143040001858026, 0.08113497996237129, 0.08154241798911244, 0.08151632908266038, 0.08317620807792991, 0.08248719910625368, 0.08348042401485145, 0.08013316302094609, 0.07586030999664217, 0.07588021806441247, 0.07657470891717821, 0.08271628699731082, 0.08040756802074611, 0.08044536306988448, 0.07545316405594349, 0.0755244439933449, 0.07575962296687067, 0.07599395199213177, 0.07666508306283504, 0.07663253298960626, 0.07545877306256443, 0.07980900502298027, 0.08018203394021839, 0.0799619669560343, 0.08059609099291265, 0.08165256003849208, 0.08014168497174978, 0.13719026395119727, 0.08124951203353703, 0.08183840801939368, 0.08174000994767994, 0.08422572200652212, 0.08242990798316896, 0.08208055910654366, 0.08173490897752345, 0.08178919402416795, 0.08200308296363801, 0.08276356395799667, 0.08375004003755748, 0.08132428792305291, 0.08460516494233161, 0.08092124294489622, 0.08132856094744056, 0.08133397693745792, 0.08107613795436919, 0.08342410693876445, 0.08263396704569459, 0.08258927497081459, 0.08257835695985705, 0.08239440305624157, 0.0827248829882592, 0.08359587995801121, 0.08258523291442543, 0.08137747889850289, 0.08204894990194589, 0.08201855805236846, 0.08306447695940733, 0.08299439901020378, 0.08385848696343601, 0.0818444910692051, 0.08175202901475132, 0.08189450902864337, 0.08212196500971913, 0.08434279100038111, 0.0828225240111351, 0.08271392795722932, 0.08278710802551359, 0.08295666403137147, 0.08300885802600533, 0.0834763569291681, 0.08315766602754593, 0.08324454503599554, 0.08339552592951804, 0.08283221302554011, 0.08335669501684606, 0.08362430997658521, 0.08323176705744117, 0.08311537397094071, 0.08337391703389585, 0.08356096898205578, 0.0832217619754374, 0.08353369997348636, 0.08334729599300772, 0.08335480489768088, 0.08361875801347196, 0.08362346491776407, 0.0834725929889828, 0.0835559229599312, 0.08333483093883842, 0.08524647599551827, 0.08516539400443435, 0.08553455001674592, 0.08548850903753191, 0.08546435902826488]
[0.0017016683681392853, 0.0017082715497295164, 0.0017032034063179577, 0.001709295225291684, 0.0017069092861433722, 0.0017057880402865763, 0.0017043228774350516, 0.0017050046934651173, 0.0017022938177711805, 0.00170000189706227, 0.001722646000490961, 0.0016971830616001875, 0.0016984062255075087, 0.00169742526486516, 0.0017049597333926633, 0.0016999121836139535, 0.0017032652442362539, 0.0016975591828742502, 0.0016961836123040744, 0.001691863551374753, 0.001689096040814659, 0.001686367163510651, 0.0016972068982312875, 0.001688559489723827, 0.0016888396325046007, 0.0016957694921186383, 0.0016991255106404424, 0.0016892123872376218, 0.0016957725925675156, 0.001697489509492048, 0.0016833513461965688, 0.0016976076116481302, 0.0016698929818575175, 0.0016439485301890848, 0.0015914914891960062, 0.0015897080824919501, 0.0016048942854133795, 0.0016315734080438102, 0.0018036486533451446, 0.001608792305163735, 0.0016338304492968078, 0.0016248644096776843, 0.001711621386360149, 0.0016401283471483964, 0.0016630134302932694, 0.0016386356532611713, 0.0035678735929446257, 0.0015122076325422647, 0.0015118306939851266, 0.0015135072646852658, 0.001519541652892165, 0.0015396911422817074, 0.001511699959578715, 0.0017749292504352827, 0.0017720730417446855, 0.0017889711258855339, 0.001773566521781807, 0.0017361117497785017, 0.0016776354580845994, 0.0016683360202781234, 0.0016934111044974998, 0.0016842087085630435, 0.0016985115629116383, 0.001681290542668042, 0.0035382893135344298, 0.00167808702099137, 0.001996842707740143, 0.0016621525816541787, 0.0017371233116136864, 0.0017288362093192215, 0.00460546018681877, 0.001594757833421075, 0.0015913551057262036, 0.0015993649382532265, 0.0016112823965765226, 0.0015910497701649244, 0.004196466667053755, 0.0016903120825494018, 0.0016988003747731757, 0.0016982568558887579, 0.0017328376682902065, 0.0017184833147136185, 0.0017391755003094052, 0.00166944089626971, 0.0015804231249300453, 0.0015808378763419266, 0.0015953064357745461, 0.001723255979110642, 0.0016751576670988773, 0.0016759450639559266, 0.001571940917832156, 0.0015734259165280189, 0.0015783254784764722, 0.0015832073331694119, 0.00159718923047573, 0.0015965111039501305, 0.001572057772136759, 0.0016626876046454224, 0.0016704590404212165, 0.001665874311584048, 0.0016790852290190135, 0.0017010950008019183, 0.0016696184369114537, 0.0028581304989832765, 0.0016926981673653547, 0.0017049668337373685, 0.0017029168739099987, 0.0017547025418025441, 0.0017172897496493533, 0.001710011648052993, 0.0017028106036984052, 0.0017039415421701658, 0.0017083975617424585, 0.0017242409157915972, 0.0017447925007824476, 0.0016942559983969356, 0.001762607602965242, 0.0016858592280186713, 0.0016943450197383452, 0.0016944578528637066, 0.0016890862073826913, 0.0017380022278909262, 0.0017215409801186372, 0.001720609895225304, 0.0017203824366636884, 0.0017165500636716995, 0.0017234350622554, 0.0017415808324585669, 0.0017205256857171964, 0.00169536414371881, 0.001709353122957206, 0.001708719959424343, 0.0017305099366543193, 0.0017290499793792453, 0.00174705181173825, 0.001705093563941773, 0.0017031672711406525, 0.0017061356047634035, 0.0017108742710358154, 0.0017571414791746065, 0.0017254692502319813, 0.0017232068324422773, 0.0017247314171981998, 0.0017282638339869056, 0.001729351208875111, 0.001739090769357669, 0.0017324513755738735, 0.0017342613549165737, 0.0017374067901982926, 0.0017256711046987523, 0.0017365978128509596, 0.0017421731245121919, 0.0017339951470300246, 0.0017315702910612647, 0.0017369566048728302, 0.0017408535204594955, 0.0017337867078216125, 0.0017402854161142993, 0.0017364019998543274, 0.0017365584353683516, 0.0017420574586139992, 0.0017421555191200848, 0.0017390123539371416, 0.0017407483949985665, 0.0017361423112258005, 0.0017759682499066305, 0.0017742790417590488, 0.0017819697920155402, 0.0017810106049485814, 0.0017805074797555183]
[587.6585700969837, 585.3870247726936, 587.1289338023539, 585.0364437947542, 585.8542150528817, 586.2393078052053, 586.7432827663301, 586.5086494088639, 587.4426550578111, 588.2346376954488, 580.5023201023287, 589.211631099565, 588.787290685528, 589.1275573062935, 586.5241157397431, 588.2656819801333, 587.107617785274, 589.0810818782963, 589.5588147096956, 591.0642138885448, 592.0326469522097, 592.9906734653305, 589.2033558443178, 592.2207692922653, 592.1225323904612, 589.7027895876538, 588.5380413263734, 591.991870030805, 589.7017114104502, 589.1052606853735, 594.0530491506956, 589.0642767730909, 598.8407705550345, 608.2915502743759, 628.3414060261061, 629.0463079438132, 623.0940000776598, 612.9053066628237, 554.4317060561356, 621.5842758510862, 612.0586138117299, 615.4359674838128, 584.2413561602847, 609.7083815048052, 601.318054192534, 610.2637874440394, 280.27898801613185, 661.2848516832565, 661.4497271278699, 660.7170136100735, 658.0931809909165, 649.4809072669435, 661.5069304352453, 563.4027383090117, 564.3108249169318, 558.9805142914221, 563.8356316036873, 575.9997881055658, 596.0770530814402, 599.3996340337319, 590.524059600246, 593.7506408295405, 588.750775582458, 594.7811961239601, 282.6224515261842, 595.9166524088995, 500.7905710969669, 601.6294839820285, 575.6643718464974, 578.4237943476314, 217.13356742548498, 627.0544524335709, 628.3952565971484, 625.2481694966797, 620.623673494287, 628.5158508249194, 238.29570906661758, 591.6067277302761, 588.6506824755794, 588.8390772764845, 577.0881013838425, 581.9084721032906, 574.9851005962863, 599.0029369919322, 632.7419437400748, 632.5759364483405, 626.8388176560477, 580.296840470614, 596.95873387957, 596.6782691788146, 636.1562248656822, 635.5558208972672, 633.5828785867926, 631.6292118216171, 626.0998890545646, 626.3658282900591, 636.1089380581659, 601.4358904258842, 598.6378449290465, 600.285383504785, 595.5623828483315, 587.8566450013591, 598.9392413813132, 349.87905568193275, 590.7727787975789, 586.5216731565109, 587.2277239839314, 569.897162725219, 582.3129149895561, 584.7913381985397, 587.2643721081243, 586.8745935534765, 585.3438464171435, 579.9653579969137, 573.1340543655207, 590.2295762542237, 567.3412495882214, 593.1693366683193, 590.1985654341099, 590.1592643983189, 592.036093616288, 575.3732555415103, 580.874932138465, 581.1892647920962, 581.2661061218951, 582.5638419546009, 580.2365414867065, 574.1909771643003, 581.2177105528957, 589.8437829447561, 585.0166279685881, 585.2334049734479, 577.8643501656799, 578.3522812677832, 572.3928696797137, 586.4780802340468, 587.1413905988669, 586.1198823868832, 584.4964863458783, 569.1061373553919, 579.5524897737556, 580.3133908091078, 579.8004199543631, 578.615359723819, 578.2515401544541, 575.0131146802354, 577.2167773936804, 576.6143592861785, 575.570445356593, 579.4846986063247, 575.8385692990754, 573.9957676594281, 576.7028827691896, 577.5104858071389, 575.71962200703, 574.4308686787454, 576.7722151108387, 574.6183877313614, 575.903506264041, 575.8516267768922, 574.0338787651766, 574.0015681866753, 575.0390431304239, 574.4655591084567, 575.9896487367741, 563.0731292930343, 563.6092049019436, 561.1767407509898, 561.4789699856225, 561.6376293669432]
Elapsed: 0.0846684235463138~0.01769449240364438
Time per graph: 0.0017528841968904546~0.00036858966244521083
Speed: 582.4319856929948~58.83102975018112
Total Time: 0.0862
best val loss: 0.20410723984241486 test_score: 0.9167

Testing...
Test loss: 0.2376 score: 0.9167 time: 0.08s
test Score 0.9167
Epoch Time List: [0.27803983993362635, 0.2771797371096909, 0.2764886349905282, 0.27680959494318813, 0.2769861171254888, 0.2763110240921378, 0.27664082613773644, 0.27724980702623725, 0.2763609972316772, 0.2771250510122627, 0.27757431799545884, 0.27554093196522444, 0.27525735611561686, 0.2750848879804835, 0.27563684002961963, 0.2750759822083637, 0.27522060612682253, 0.2752099201316014, 0.27474271692335606, 0.27388660598080605, 0.2730623910902068, 0.27348504203837365, 0.27248769998550415, 0.2722432679729536, 0.2719748611561954, 0.2740685979370028, 0.27317881386261433, 0.27461145096458495, 0.27454475103877485, 0.2750811430159956, 0.2734542629914358, 0.2738510499475524, 0.279137795092538, 0.3659026899840683, 0.26811780396383256, 0.2673270530067384, 0.26971528492867947, 0.26937374204862863, 0.2809436620445922, 0.2759793180739507, 0.3336809719912708, 0.2767015630379319, 0.2817945539718494, 0.27746995887719095, 0.28081414895132184, 0.27929254504851997, 0.38066146906930953, 0.2616617369931191, 0.25766832509543747, 0.2574729659827426, 0.25833420106209815, 0.2606858661165461, 0.26021196914371103, 0.2946409509750083, 0.29399309190921485, 0.29488354292698205, 0.29661697696428746, 0.29198374890256673, 0.3612742959521711, 0.27981338603422046, 0.2813683321001008, 0.28070045192725956, 0.284444835036993, 0.28209932800382376, 0.39344110898673534, 0.2896585271228105, 0.31134034297429025, 0.30284521693829447, 0.2869992470368743, 0.29164815496187657, 0.42806392605416477, 0.27419311297126114, 0.2682321460451931, 0.2685614739311859, 0.2731827381066978, 0.2714562240289524, 0.3947432478889823, 0.28288534795865417, 0.28337850712705404, 0.28424544900190085, 0.2869505858980119, 0.2904945670161396, 0.29039760294836015, 0.34204363415483385, 0.26952980493661016, 0.26746483403258026, 0.26728956995066255, 0.27343411615584046, 0.2834485680796206, 0.2816846870118752, 0.37005843699444085, 0.2682135431095958, 0.26708662300370634, 0.2678288290044293, 0.2692478880053386, 0.2752399449236691, 0.26744614099152386, 0.39175251114647835, 0.27887503313831985, 0.2795190780889243, 0.2814441000809893, 0.2837665998376906, 0.2819792799418792, 0.3344070150051266, 0.30703021690715104, 0.2866590799530968, 0.2865746719762683, 0.2850727359764278, 0.29181602608878165, 0.28851966198999435, 0.3456520010950044, 0.2893673370126635, 0.28909524402115494, 0.2898034381214529, 0.2925498818513006, 0.2895359519170597, 0.29160910402424634, 0.3303079861216247, 0.28412424796260893, 0.284766590106301, 0.28642099106218666, 0.2905016168951988, 0.2914045099169016, 0.41856674500741065, 0.29100222303532064, 0.29112220800016075, 0.2923187150154263, 0.2935544950887561, 0.2901556681608781, 0.3679866030579433, 0.2883916209684685, 0.28768168308306485, 0.2868948200484738, 0.2934182321187109, 0.29007603018544614, 0.3957409670110792, 0.2875966608989984, 0.28755163808818907, 0.28938856394961476, 0.2939214288489893, 0.2918609210755676, 0.29214267805218697, 0.2927189798792824, 0.2912951122270897, 0.29273951810318977, 0.29322442202828825, 0.29273373482283205, 0.2922086479375139, 0.2926015449920669, 0.2923754380317405, 0.29367255803663284, 0.2936691539362073, 0.29293786897324026, 0.29187470709439367, 0.2923568479018286, 0.29262397915590554, 0.2922930819913745, 0.2929096430307254, 0.2932632981101051, 0.29212128196377307, 0.29258669703267515, 0.29292052797973156, 0.29342031793203205, 0.2921550020109862, 0.2935210280120373, 0.2952392428414896, 0.2982125331182033, 0.2967949900776148, 0.2981480360031128, 0.29915000195614994]
Total Epoch List: [32, 21, 117]
Total Time List: [0.08353830000851303, 0.07450327009428293, 0.08617691299878061]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c93384640>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6918;  Loss pred: 0.6918; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6935;  Loss pred: 0.6935; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6896;  Loss pred: 0.6896; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6912;  Loss pred: 0.6912; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6883;  Loss pred: 0.6883; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6866;  Loss pred: 0.6866; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6845;  Loss pred: 0.6845; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6797;  Loss pred: 0.6797; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6778;  Loss pred: 0.6778; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6731;  Loss pred: 0.6731; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6711;  Loss pred: 0.6711; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6981 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6666;  Loss pred: 0.6666; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6622;  Loss pred: 0.6622; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6984 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6561;  Loss pred: 0.6561; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6986 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6531;  Loss pred: 0.6531; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6988 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6460;  Loss pred: 0.6460; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6991 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6423;  Loss pred: 0.6423; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6993 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6378;  Loss pred: 0.6378; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6996 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6289;  Loss pred: 0.6289; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6998 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6211;  Loss pred: 0.6211; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6956 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7002 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6918,   Val_Loss: 0.6946,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.5102,   Val_Loss: 0.6946,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.4898,   Test_loss: 0.6977


[0.08658879797440022, 0.08560835907701403, 0.08604988898150623, 0.0861111149424687, 0.08603387605398893, 0.08599471393972635, 0.08574975200463086, 0.08564695401582867, 0.08560035494156182, 0.08647597092203796, 0.08732317690737545, 0.08592898899223655, 0.08598317299038172, 0.08542188908904791, 0.08469003601931036, 0.08490876201540232, 0.08466155105270445, 0.08502368803601712, 0.08468084002379328, 0.0853470970178023, 0.08471374702639878]
[0.0017671183260081678, 0.0017471093689186536, 0.0017561201832960456, 0.001757369692703443, 0.001755793388856917, 0.0017549941620352318, 0.0017499949388700177, 0.0017478970207311974, 0.0017469460192155472, 0.0017648157331028155, 0.0017821056511709277, 0.0017536528365762563, 0.0017547586324567698, 0.0017433038589601613, 0.001728368082026742, 0.0017328318778653533, 0.0017277867561776418, 0.0017351773068574922, 0.0017281804086488424, 0.0017417774901592306, 0.0017288519801305874]
[565.8930617617158, 572.3740126349013, 569.4371088675204, 569.0322327464597, 569.5430945044366, 569.8024652345965, 571.4302240472227, 572.116084723155, 572.4275329635213, 566.6313945659626, 561.1339593379062, 570.2382929749938, 569.8789460291406, 573.623464928527, 578.5804600298836, 577.090029779394, 578.7751274423968, 576.3099805696852, 578.6432915194532, 574.1261473694792, 578.4185178909682]
Elapsed: 0.08564489200112543~0.0006902089013075053
Time per graph: 0.0017478549387984783~1.408589594505115e-05
Speed: 572.1669252343486~4.599602258402462
Total Time: 0.0851
best val loss: 0.6945539712905884 test_score: 0.4898

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
test Score 0.4898
Epoch Time List: [0.2837958049494773, 0.2810814700787887, 0.2821239938493818, 0.28369553585071117, 0.28261684300377965, 0.2839909391477704, 0.28272307000588626, 0.28338566003367305, 0.2823107799049467, 0.2830013009952381, 0.2939212329220027, 0.2865681261755526, 0.28280604910105467, 0.2761254410725087, 0.2803084159968421, 0.2796346000395715, 0.2798533720197156, 0.2783971820026636, 0.28061681089457124, 0.28048126690555364, 0.2807834621053189]
Total Epoch List: [21]
Total Time List: [0.08505547500681132]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c9337de40>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6937;  Loss pred: 0.6937; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6944;  Loss pred: 0.6944; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
Epoch 3/1000, LR 0.000030
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.09s
     INFO: Early stopping counter 1 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6943;  Loss pred: 0.6943; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.09s
Epoch 5/1000, LR 0.000090
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6907;  Loss pred: 0.6907; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6914;  Loss pred: 0.6914; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 9/1000, LR 0.000210
Train loss: 0.6852;  Loss pred: 0.6852; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6821;  Loss pred: 0.6821; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 11/1000, LR 0.000270
Train loss: 0.6798;  Loss pred: 0.6798; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6779;  Loss pred: 0.6779; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 13/1000, LR 0.000270
Train loss: 0.6754;  Loss pred: 0.6754; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 14/1000, LR 0.000270
Train loss: 0.6713;  Loss pred: 0.6713; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
Epoch 15/1000, LR 0.000270
Train loss: 0.6686;  Loss pred: 0.6686; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5102 time: 0.09s
Epoch 16/1000, LR 0.000270
Train loss: 0.6656;  Loss pred: 0.6656; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5102 time: 0.09s
Epoch 17/1000, LR 0.000270
Train loss: 0.6610;  Loss pred: 0.6610; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5102 time: 0.08s
Epoch 18/1000, LR 0.000270
Train loss: 0.6565;  Loss pred: 0.6565; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4898 time: 0.21s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5102 time: 0.09s
Epoch 19/1000, LR 0.000270
Train loss: 0.6527;  Loss pred: 0.6527; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5102 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6513;  Loss pred: 0.6513; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5102 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.6383;  Loss pred: 0.6383; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5102 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.6344;  Loss pred: 0.6344; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5102 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.6276;  Loss pred: 0.6276; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5102 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.6188;  Loss pred: 0.6188; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5102 time: 0.08s
Epoch 25/1000, LR 0.000270
Train loss: 0.6137;  Loss pred: 0.6137; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5102 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.6042;  Loss pred: 0.6042; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5102 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5932;  Loss pred: 0.5932; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5102 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5905;  Loss pred: 0.5905; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5102 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5755;  Loss pred: 0.5755; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5102 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.5674;  Loss pred: 0.5674; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6906 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5102 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.5570;  Loss pred: 0.5570; Loss self: 0.0000; time: 0.26s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6900 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5102 time: 0.09s
Epoch 32/1000, LR 0.000270
Train loss: 0.5405;  Loss pred: 0.5405; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.5102 time: 0.09s
Epoch 33/1000, LR 0.000270
Train loss: 0.5250;  Loss pred: 0.5250; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6887 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.5102 time: 0.09s
Epoch 34/1000, LR 0.000270
Train loss: 0.5224;  Loss pred: 0.5224; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5102 time: 0.09s
Epoch 35/1000, LR 0.000270
Train loss: 0.4984;  Loss pred: 0.4984; Loss self: 0.0000; time: 0.14s
Val loss: 0.6870 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6869 score: 0.5102 time: 0.09s
Epoch 36/1000, LR 0.000270
Train loss: 0.4874;  Loss pred: 0.4874; Loss self: 0.0000; time: 0.13s
Val loss: 0.6860 score: 0.5102 time: 0.09s
Test loss: 0.6859 score: 0.5714 time: 0.22s
Epoch 37/1000, LR 0.000270
Train loss: 0.4675;  Loss pred: 0.4675; Loss self: 0.0000; time: 0.14s
Val loss: 0.6848 score: 0.5714 time: 0.09s
Test loss: 0.6849 score: 0.6327 time: 0.09s
Epoch 38/1000, LR 0.000270
Train loss: 0.4528;  Loss pred: 0.4528; Loss self: 0.0000; time: 0.14s
Val loss: 0.6834 score: 0.6735 time: 0.09s
Test loss: 0.6836 score: 0.6531 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.4297;  Loss pred: 0.4297; Loss self: 0.0000; time: 0.13s
Val loss: 0.6818 score: 0.7959 time: 0.08s
Test loss: 0.6821 score: 0.7551 time: 0.08s
Epoch 40/1000, LR 0.000269
Train loss: 0.4230;  Loss pred: 0.4230; Loss self: 0.0000; time: 0.13s
Val loss: 0.6798 score: 0.8163 time: 0.08s
Test loss: 0.6803 score: 0.8163 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.4039;  Loss pred: 0.4039; Loss self: 0.0000; time: 0.13s
Val loss: 0.6775 score: 0.8980 time: 0.08s
Test loss: 0.6783 score: 0.8367 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3879;  Loss pred: 0.3879; Loss self: 0.0000; time: 0.13s
Val loss: 0.6751 score: 0.8980 time: 0.08s
Test loss: 0.6760 score: 0.8571 time: 0.19s
Epoch 43/1000, LR 0.000269
Train loss: 0.3759;  Loss pred: 0.3759; Loss self: 0.0000; time: 0.13s
Val loss: 0.6723 score: 0.8980 time: 0.08s
Test loss: 0.6734 score: 0.9184 time: 0.08s
Epoch 44/1000, LR 0.000269
Train loss: 0.3561;  Loss pred: 0.3561; Loss self: 0.0000; time: 0.13s
Val loss: 0.6694 score: 0.8980 time: 0.08s
Test loss: 0.6707 score: 0.9184 time: 0.08s
Epoch 45/1000, LR 0.000269
Train loss: 0.3348;  Loss pred: 0.3348; Loss self: 0.0000; time: 0.13s
Val loss: 0.6662 score: 0.8980 time: 0.08s
Test loss: 0.6676 score: 0.9184 time: 0.08s
Epoch 46/1000, LR 0.000269
Train loss: 0.3245;  Loss pred: 0.3245; Loss self: 0.0000; time: 0.13s
Val loss: 0.6627 score: 0.8980 time: 0.08s
Test loss: 0.6643 score: 0.9184 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.3033;  Loss pred: 0.3033; Loss self: 0.0000; time: 0.13s
Val loss: 0.6589 score: 0.8980 time: 0.08s
Test loss: 0.6608 score: 0.9184 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.2898;  Loss pred: 0.2898; Loss self: 0.0000; time: 0.13s
Val loss: 0.6548 score: 0.8980 time: 0.08s
Test loss: 0.6569 score: 0.9184 time: 0.20s
Epoch 49/1000, LR 0.000269
Train loss: 0.2776;  Loss pred: 0.2776; Loss self: 0.0000; time: 0.13s
Val loss: 0.6501 score: 0.8980 time: 0.08s
Test loss: 0.6524 score: 0.9184 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2551;  Loss pred: 0.2551; Loss self: 0.0000; time: 0.13s
Val loss: 0.6450 score: 0.8980 time: 0.08s
Test loss: 0.6474 score: 0.9184 time: 0.08s
Epoch 51/1000, LR 0.000269
Train loss: 0.2541;  Loss pred: 0.2541; Loss self: 0.0000; time: 0.13s
Val loss: 0.6394 score: 0.8980 time: 0.08s
Test loss: 0.6418 score: 0.9184 time: 0.08s
Epoch 52/1000, LR 0.000269
Train loss: 0.2279;  Loss pred: 0.2279; Loss self: 0.0000; time: 0.13s
Val loss: 0.6333 score: 0.8980 time: 0.08s
Test loss: 0.6357 score: 0.9184 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.2125;  Loss pred: 0.2125; Loss self: 0.0000; time: 0.13s
Val loss: 0.6268 score: 0.8980 time: 0.08s
Test loss: 0.6291 score: 0.9184 time: 0.08s
Epoch 54/1000, LR 0.000269
Train loss: 0.1998;  Loss pred: 0.1998; Loss self: 0.0000; time: 0.13s
Val loss: 0.6199 score: 0.8980 time: 0.08s
Test loss: 0.6219 score: 0.9184 time: 0.20s
Epoch 55/1000, LR 0.000269
Train loss: 0.1846;  Loss pred: 0.1846; Loss self: 0.0000; time: 0.13s
Val loss: 0.6124 score: 0.8980 time: 0.08s
Test loss: 0.6141 score: 0.9184 time: 0.08s
Epoch 56/1000, LR 0.000269
Train loss: 0.1733;  Loss pred: 0.1733; Loss self: 0.0000; time: 0.13s
Val loss: 0.6045 score: 0.8980 time: 0.08s
Test loss: 0.6059 score: 0.9184 time: 0.08s
Epoch 57/1000, LR 0.000269
Train loss: 0.1664;  Loss pred: 0.1664; Loss self: 0.0000; time: 0.13s
Val loss: 0.5961 score: 0.8980 time: 0.08s
Test loss: 0.5971 score: 0.9184 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1488;  Loss pred: 0.1488; Loss self: 0.0000; time: 0.13s
Val loss: 0.5873 score: 0.8776 time: 0.08s
Test loss: 0.5879 score: 0.9184 time: 0.08s
Epoch 59/1000, LR 0.000268
Train loss: 0.1415;  Loss pred: 0.1415; Loss self: 0.0000; time: 0.13s
Val loss: 0.5781 score: 0.8776 time: 0.08s
Test loss: 0.5780 score: 0.9184 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1286;  Loss pred: 0.1286; Loss self: 0.0000; time: 0.13s
Val loss: 0.5684 score: 0.8776 time: 0.09s
Test loss: 0.5676 score: 0.9184 time: 0.20s
Epoch 61/1000, LR 0.000268
Train loss: 0.1231;  Loss pred: 0.1231; Loss self: 0.0000; time: 0.13s
Val loss: 0.5583 score: 0.8776 time: 0.09s
Test loss: 0.5566 score: 0.9184 time: 0.09s
Epoch 62/1000, LR 0.000268
Train loss: 0.1192;  Loss pred: 0.1192; Loss self: 0.0000; time: 0.14s
Val loss: 0.5482 score: 0.8980 time: 0.09s
Test loss: 0.5453 score: 0.9388 time: 0.08s
Epoch 63/1000, LR 0.000268
Train loss: 0.1079;  Loss pred: 0.1079; Loss self: 0.0000; time: 0.13s
Val loss: 0.5376 score: 0.8980 time: 0.09s
Test loss: 0.5335 score: 0.9388 time: 0.09s
Epoch 64/1000, LR 0.000268
Train loss: 0.0980;  Loss pred: 0.0980; Loss self: 0.0000; time: 0.13s
Val loss: 0.5267 score: 0.8980 time: 0.08s
Test loss: 0.5212 score: 0.9388 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.0907;  Loss pred: 0.0907; Loss self: 0.0000; time: 0.13s
Val loss: 0.5152 score: 0.8980 time: 0.09s
Test loss: 0.5081 score: 0.9388 time: 0.09s
Epoch 66/1000, LR 0.000268
Train loss: 0.0840;  Loss pred: 0.0840; Loss self: 0.0000; time: 0.14s
Val loss: 0.5035 score: 0.8980 time: 0.18s
Test loss: 0.4946 score: 0.9388 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0824;  Loss pred: 0.0824; Loss self: 0.0000; time: 0.13s
Val loss: 0.4919 score: 0.8776 time: 0.08s
Test loss: 0.4810 score: 0.9388 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0723;  Loss pred: 0.0723; Loss self: 0.0000; time: 0.13s
Val loss: 0.4803 score: 0.8776 time: 0.08s
Test loss: 0.4673 score: 0.9388 time: 0.08s
Epoch 69/1000, LR 0.000268
Train loss: 0.0693;  Loss pred: 0.0693; Loss self: 0.0000; time: 0.13s
Val loss: 0.4684 score: 0.8776 time: 0.08s
Test loss: 0.4532 score: 0.9388 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0646;  Loss pred: 0.0646; Loss self: 0.0000; time: 0.14s
Val loss: 0.4565 score: 0.8776 time: 0.09s
Test loss: 0.4390 score: 0.9388 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0604;  Loss pred: 0.0604; Loss self: 0.0000; time: 0.13s
Val loss: 0.4445 score: 0.8776 time: 0.08s
Test loss: 0.4246 score: 0.9388 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.13s
Val loss: 0.4328 score: 0.8776 time: 0.17s
Test loss: 0.4102 score: 0.9592 time: 0.09s
Epoch 73/1000, LR 0.000267
Train loss: 0.0569;  Loss pred: 0.0569; Loss self: 0.0000; time: 0.12s
Val loss: 0.4212 score: 0.8776 time: 0.09s
Test loss: 0.3957 score: 0.9592 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0520;  Loss pred: 0.0520; Loss self: 0.0000; time: 0.13s
Val loss: 0.4096 score: 0.8776 time: 0.08s
Test loss: 0.3810 score: 0.9592 time: 0.08s
Epoch 75/1000, LR 0.000267
Train loss: 0.0484;  Loss pred: 0.0484; Loss self: 0.0000; time: 0.13s
Val loss: 0.3979 score: 0.8980 time: 0.08s
Test loss: 0.3660 score: 0.9592 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0466;  Loss pred: 0.0466; Loss self: 0.0000; time: 0.13s
Val loss: 0.3866 score: 0.8980 time: 0.08s
Test loss: 0.3511 score: 0.9592 time: 0.09s
Epoch 77/1000, LR 0.000267
Train loss: 0.0413;  Loss pred: 0.0413; Loss self: 0.0000; time: 0.13s
Val loss: 0.3761 score: 0.8980 time: 0.09s
Test loss: 0.3367 score: 0.9592 time: 0.09s
Epoch 78/1000, LR 0.000267
Train loss: 0.0347;  Loss pred: 0.0347; Loss self: 0.0000; time: 0.14s
Val loss: 0.3658 score: 0.8980 time: 0.15s
Test loss: 0.3223 score: 0.9796 time: 0.09s
Epoch 79/1000, LR 0.000267
Train loss: 0.0320;  Loss pred: 0.0320; Loss self: 0.0000; time: 0.12s
Val loss: 0.3559 score: 0.8980 time: 0.08s
Test loss: 0.3083 score: 0.9796 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0308;  Loss pred: 0.0308; Loss self: 0.0000; time: 0.12s
Val loss: 0.3462 score: 0.8980 time: 0.08s
Test loss: 0.2943 score: 0.9592 time: 0.08s
Epoch 81/1000, LR 0.000267
Train loss: 0.0317;  Loss pred: 0.0317; Loss self: 0.0000; time: 0.12s
Val loss: 0.3368 score: 0.8980 time: 0.08s
Test loss: 0.2805 score: 0.9592 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0263;  Loss pred: 0.0263; Loss self: 0.0000; time: 0.12s
Val loss: 0.3278 score: 0.8980 time: 0.08s
Test loss: 0.2669 score: 0.9592 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0238;  Loss pred: 0.0238; Loss self: 0.0000; time: 0.12s
Val loss: 0.3194 score: 0.8980 time: 0.07s
Test loss: 0.2538 score: 0.9592 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0249;  Loss pred: 0.0249; Loss self: 0.0000; time: 0.12s
Val loss: 0.3116 score: 0.8980 time: 0.16s
Test loss: 0.2412 score: 0.9592 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.12s
Val loss: 0.3043 score: 0.8980 time: 0.08s
Test loss: 0.2292 score: 0.9592 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.12s
Val loss: 0.2977 score: 0.8776 time: 0.07s
Test loss: 0.2179 score: 0.9592 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0175;  Loss pred: 0.0175; Loss self: 0.0000; time: 0.12s
Val loss: 0.2919 score: 0.8776 time: 0.08s
Test loss: 0.2074 score: 0.9592 time: 0.08s
Epoch 88/1000, LR 0.000266
Train loss: 0.0182;  Loss pred: 0.0182; Loss self: 0.0000; time: 0.12s
Val loss: 0.2869 score: 0.8776 time: 0.08s
Test loss: 0.1975 score: 0.9592 time: 0.08s
Epoch 89/1000, LR 0.000266
Train loss: 0.0153;  Loss pred: 0.0153; Loss self: 0.0000; time: 0.12s
Val loss: 0.2826 score: 0.8776 time: 0.08s
Test loss: 0.1884 score: 0.9592 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.12s
Val loss: 0.2790 score: 0.8776 time: 0.08s
Test loss: 0.1798 score: 0.9592 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0199;  Loss pred: 0.0199; Loss self: 0.0000; time: 0.12s
Val loss: 0.2760 score: 0.8776 time: 0.08s
Test loss: 0.1714 score: 0.9592 time: 0.18s
Epoch 92/1000, LR 0.000266
Train loss: 0.0125;  Loss pred: 0.0125; Loss self: 0.0000; time: 0.12s
Val loss: 0.2739 score: 0.8776 time: 0.08s
Test loss: 0.1641 score: 0.9592 time: 0.08s
Epoch 93/1000, LR 0.000265
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.12s
Val loss: 0.2719 score: 0.8776 time: 0.08s
Test loss: 0.1567 score: 0.9592 time: 0.08s
Epoch 94/1000, LR 0.000265
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.12s
Val loss: 0.2706 score: 0.8776 time: 0.08s
Test loss: 0.1501 score: 0.9592 time: 0.08s
Epoch 95/1000, LR 0.000265
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.12s
Val loss: 0.2699 score: 0.8776 time: 0.08s
Test loss: 0.1442 score: 0.9592 time: 0.08s
Epoch 96/1000, LR 0.000265
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.12s
Val loss: 0.2699 score: 0.8776 time: 0.08s
Test loss: 0.1388 score: 0.9592 time: 0.08s
Epoch 97/1000, LR 0.000265
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.12s
Val loss: 0.2700 score: 0.8776 time: 0.08s
Test loss: 0.1338 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.12s
Val loss: 0.2705 score: 0.8776 time: 0.08s
Test loss: 0.1291 score: 0.9592 time: 0.15s
     INFO: Early stopping counter 2 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.12s
Val loss: 0.2713 score: 0.8776 time: 0.08s
Test loss: 0.1248 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.2719 score: 0.8980 time: 0.08s
Test loss: 0.1203 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.12s
Val loss: 0.2729 score: 0.8980 time: 0.08s
Test loss: 0.1164 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.12s
Val loss: 0.2746 score: 0.8980 time: 0.08s
Test loss: 0.1132 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.13s
Val loss: 0.2766 score: 0.8980 time: 0.08s
Test loss: 0.1107 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.12s
Val loss: 0.2788 score: 0.8980 time: 0.08s
Test loss: 0.1085 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.2810 score: 0.8980 time: 0.21s
Test loss: 0.1063 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.12s
Val loss: 0.2834 score: 0.8980 time: 0.08s
Test loss: 0.1045 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.13s
Val loss: 0.2860 score: 0.8980 time: 0.08s
Test loss: 0.1030 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.13s
Val loss: 0.2883 score: 0.8980 time: 0.08s
Test loss: 0.1013 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.13s
Val loss: 0.2907 score: 0.8980 time: 0.08s
Test loss: 0.0999 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.13s
Val loss: 0.2928 score: 0.8980 time: 0.08s
Test loss: 0.0982 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.13s
Val loss: 0.2944 score: 0.8980 time: 0.08s
Test loss: 0.0964 score: 0.9592 time: 0.20s
     INFO: Early stopping counter 15 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.12s
Val loss: 0.2963 score: 0.8980 time: 0.08s
Test loss: 0.0949 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.12s
Val loss: 0.2983 score: 0.8980 time: 0.08s
Test loss: 0.0937 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.12s
Val loss: 0.3006 score: 0.8980 time: 0.08s
Test loss: 0.0929 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.12s
Val loss: 0.3025 score: 0.8980 time: 0.08s
Test loss: 0.0921 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.12s
Val loss: 0.3048 score: 0.8980 time: 0.08s
Test loss: 0.0917 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 095,   Train_Loss: 0.0097,   Val_Loss: 0.2699,   Val_Precision: 0.9130,   Val_Recall: 0.8400,   Val_accuracy: 0.8750,   Val_Score: 0.8776,   Val_Loss: 0.2699,   Test_Precision: 1.0000,   Test_Recall: 0.9167,   Test_accuracy: 0.9565,   Test_Score: 0.9592,   Test_loss: 0.1388


[0.08658879797440022, 0.08560835907701403, 0.08604988898150623, 0.0861111149424687, 0.08603387605398893, 0.08599471393972635, 0.08574975200463086, 0.08564695401582867, 0.08560035494156182, 0.08647597092203796, 0.08732317690737545, 0.08592898899223655, 0.08598317299038172, 0.08542188908904791, 0.08469003601931036, 0.08490876201540232, 0.08466155105270445, 0.08502368803601712, 0.08468084002379328, 0.0853470970178023, 0.08471374702639878, 0.08708954299800098, 0.08677158900536597, 0.09217875299509615, 0.09850691503379494, 0.08677908801473677, 0.08698908996302634, 0.0870973359560594, 0.08714025688823313, 0.0870103680063039, 0.08612568804528564, 0.08555057202465832, 0.09050444001331925, 0.09005968505516648, 0.08995733107440174, 0.09416762797627598, 0.09129530901554972, 0.08821869094390422, 0.09706173103768378, 0.08572351292241365, 0.08608829299919307, 0.087068474967964, 0.08991049195174128, 0.08633504202589393, 0.08955462207086384, 0.08571578201372176, 0.08625667402520776, 0.08629016391932964, 0.09013961302116513, 0.0858304820721969, 0.08853500697296113, 0.09188860096037388, 0.09323775605298579, 0.09266915498301387, 0.09498228691518307, 0.09379286994226277, 0.22528715000953525, 0.09828993701376021, 0.08510666596703231, 0.08588808798231184, 0.08766449498943985, 0.08561693993397057, 0.19382417702581733, 0.08505779108963907, 0.08573354000691324, 0.08562552195508033, 0.08699332503601909, 0.08645381405949593, 0.20439515903126448, 0.0854403639677912, 0.08462043094914407, 0.08486135199200362, 0.08700362301897258, 0.08512384304776788, 0.20838255190756172, 0.08504921395797282, 0.08478686702437699, 0.08534339303150773, 0.08720687089953572, 0.0857107889605686, 0.2066203170688823, 0.09145812003407627, 0.08898391702678055, 0.09212973504327238, 0.08691967197228223, 0.0900667340029031, 0.08595400804188102, 0.08409703895449638, 0.08524887193925679, 0.08558173500932753, 0.08984738204162568, 0.08766871795523912, 0.09688407799694687, 0.08799603290390223, 0.0874552329769358, 0.08712072600610554, 0.09787169902119786, 0.09198639797978103, 0.09333691804204136, 0.08002554601989686, 0.0811932769138366, 0.08286011195741594, 0.08090337098110467, 0.07975220400840044, 0.07983894797507674, 0.0804538440424949, 0.08074911800213158, 0.08159708394668996, 0.08027460693847388, 0.08152031397912651, 0.07981405209284276, 0.18579440307803452, 0.08504250494297594, 0.08454033802263439, 0.08451892400626093, 0.08424082398414612, 0.08522331097628921, 0.08486933005042374, 0.15130590798798949, 0.08344309800304472, 0.08291569096036255, 0.08363104297313839, 0.08323090593330562, 0.08505538094323128, 0.08378126297611743, 0.08627755800262094, 0.08769372501410544, 0.08793538995087147, 0.08777338801883161, 0.08895277697592974, 0.0870746630243957, 0.20553521194960922, 0.08602184092160314, 0.08536988904234022, 0.08590867999009788, 0.08675707899965346, 0.08597368304617703]
[0.0017671183260081678, 0.0017471093689186536, 0.0017561201832960456, 0.001757369692703443, 0.001755793388856917, 0.0017549941620352318, 0.0017499949388700177, 0.0017478970207311974, 0.0017469460192155472, 0.0017648157331028155, 0.0017821056511709277, 0.0017536528365762563, 0.0017547586324567698, 0.0017433038589601613, 0.001728368082026742, 0.0017328318778653533, 0.0017277867561776418, 0.0017351773068574922, 0.0017281804086488424, 0.0017417774901592306, 0.0017288519801305874, 0.0017773376122041016, 0.0017708487552115504, 0.001881199040716248, 0.002010345204771325, 0.001771001796219118, 0.0017752875502658437, 0.0017774966521644775, 0.001778372589555778, 0.0017757217960470185, 0.0017576671029650131, 0.0017459300413195575, 0.0018470293880269236, 0.0018379527562278875, 0.0018358638994775865, 0.0019217883260464485, 0.0018631695717459126, 0.00180038144783478, 0.001980851653830281, 0.0017494594473961968, 0.0017569039387590423, 0.0017769076524074285, 0.0018349079990151282, 0.0017619396331815087, 0.0018276453483849764, 0.0017493016737494239, 0.0017603402862287297, 0.001761023753455707, 0.0018395839392074517, 0.0017516424912693246, 0.0018068368769992068, 0.001875277570619875, 0.001902811348020118, 0.0018912072445513035, 0.0019384140186772055, 0.001914140202903322, 0.0045976969389701075, 0.0020059170819134737, 0.0017368707340210676, 0.0017528181220879968, 0.0017890713263150988, 0.001747284488448379, 0.003955595449506476, 0.0017358732875436544, 0.0017496640817737396, 0.0017474596317363332, 0.0017753739803269201, 0.0017643635522346108, 0.004171329776148255, 0.0017436808973018611, 0.0017269475703906951, 0.0017318643263674208, 0.0017755841432443382, 0.0017372212866891403, 0.004252705140970647, 0.0017356982440402617, 0.0017303442249872855, 0.0017417018986021985, 0.0017797320591741983, 0.0017491997747054817, 0.004216741164671067, 0.0018664922455933933, 0.0018159983066689906, 0.0018801986743524975, 0.0017738708565771884, 0.0018380966123041449, 0.0017541634294261433, 0.001716266101112171, 0.0017397728967195262, 0.0017465660205985211, 0.00183362004166583, 0.0017891575092905943, 0.001977226081570344, 0.0017958374062020863, 0.0017848006729986898, 0.001777974000124603, 0.001997381612677507, 0.0018772734281587967, 0.0019048350620824769, 0.0016331744085693238, 0.0016570056513027878, 0.0016910226930084886, 0.0016510892036960137, 0.0016275960001714376, 0.0016293662852056477, 0.001641915184540712, 0.001647941183716971, 0.001665246611156938, 0.0016382572844586506, 0.001663679877125031, 0.0016288582059763828, 0.003791722511796623, 0.001735561325366856, 0.0017253130208700895, 0.001724876000127774, 0.0017192004894723697, 0.0017392512444140656, 0.0017320271438861989, 0.0030878756732242753, 0.001702920367409076, 0.001692156958374746, 0.0017067559790436406, 0.0016985899170062371, 0.001735824100882271, 0.0017098216933901518, 0.001760766489849407, 0.0017896678574307232, 0.0017945997949157441, 0.00179129363303738, 0.0018153627954271374, 0.0017770339392733816, 0.004194596162236923, 0.0017555477739102682, 0.0017422426335171473, 0.0017532383671448547, 0.0017705526326459889, 0.001754564960126062]
[565.8930617617158, 572.3740126349013, 569.4371088675204, 569.0322327464597, 569.5430945044366, 569.8024652345965, 571.4302240472227, 572.116084723155, 572.4275329635213, 566.6313945659626, 561.1339593379062, 570.2382929749938, 569.8789460291406, 573.623464928527, 578.5804600298836, 577.090029779394, 578.7751274423968, 576.3099805696852, 578.6432915194532, 574.1261473694792, 578.4185178909682, 562.6393056296636, 564.7009644708688, 531.5758611163548, 497.42700787238624, 564.6521658729446, 563.2890287831135, 562.5889639692366, 562.3118607837918, 563.1512786665832, 568.9359482879878, 572.7606354972902, 541.4099020201531, 544.0836259863092, 544.7026875383083, 520.3486702706875, 536.7198000463984, 555.4378496860458, 504.83336198667183, 571.6051329388328, 569.1830827736275, 562.7754479222139, 544.9864519293293, 567.5563346028573, 547.1521052394895, 571.6566873549128, 568.0719846174475, 567.8515113936832, 543.6011799661777, 570.8927506521903, 553.4533929043995, 533.2543915989188, 525.5381733141877, 528.7627799021328, 515.8856623841436, 522.4277712171888, 217.50019918102777, 498.52509309412, 575.7480855727691, 570.509847769475, 558.949207497318, 572.3166471236854, 252.80643907221756, 576.0789149621911, 571.5382800715894, 572.2592853297373, 563.2616063325759, 566.7766139996912, 239.73170515503702, 573.4994295959663, 579.0563750431436, 577.4124362833296, 563.1949371730732, 575.6319057693776, 235.14444732271227, 576.1370119683106, 577.9196910992366, 574.1510650028855, 561.882332143864, 571.6899890227651, 237.14996034811315, 535.7643474602709, 550.6613064162257, 531.8586879359331, 563.7388969395281, 544.041044037642, 570.0723109517451, 582.6602292919391, 574.7876644621697, 572.5520754476349, 545.3692571398311, 558.9222831457151, 505.7590577632802, 556.8432846684282, 560.2866556072472, 562.4379208750627, 500.65545494808646, 532.6874524510721, 524.9798367879378, 612.3044757210037, 603.4982434814087, 591.3581196364112, 605.6607951656817, 614.4030827641923, 613.7355418973743, 609.0448577462464, 606.8177735230064, 600.511655931397, 610.404732813651, 601.077174611307, 613.9269804645594, 263.7323793839999, 576.1824634970038, 579.6049690135021, 579.7518197980161, 581.6657255064558, 574.9600600900469, 577.3581571916196, 323.8472353894441, 587.2265193007582, 590.9617279005033, 585.9068386333338, 588.7236171532791, 576.0952388503696, 584.8563062837554, 567.934479537674, 558.7628988518666, 557.2273009464762, 558.2557664230433, 550.8540786001454, 562.7354536677526, 238.4019727579003, 569.6227780646619, 573.9728673619086, 570.3730985698757, 564.7954099537598, 569.9418503878888]
Elapsed: 0.09328181092987639~0.026701825507720784
Time per graph: 0.0019037104271403345~0.0005449352144432812
Speed: 547.0888533449131~77.47711163573085
Total Time: 0.0866
best val loss: 0.2698821723461151 test_score: 0.9592

Testing...
Test loss: 0.6783 score: 0.8367 time: 0.08s
test Score 0.8367
Epoch Time List: [0.2837958049494773, 0.2810814700787887, 0.2821239938493818, 0.28369553585071117, 0.28261684300377965, 0.2839909391477704, 0.28272307000588626, 0.28338566003367305, 0.2823107799049467, 0.2830013009952381, 0.2939212329220027, 0.2865681261755526, 0.28280604910105467, 0.2761254410725087, 0.2803084159968421, 0.2796346000395715, 0.2798533720197156, 0.2783971820026636, 0.28061681089457124, 0.28048126690555364, 0.2807834621053189, 0.2989050062606111, 0.2911948439432308, 0.2978786489693448, 0.31020626181270927, 0.2978935450082645, 0.29239408508874476, 0.29211291996762156, 0.29357861005701125, 0.2921533160842955, 0.2920098799513653, 0.2872731500538066, 0.3588575239991769, 0.30390383198391646, 0.29976118891499937, 0.31684042792767286, 0.306452963151969, 0.29811059194616973, 0.44217156805098057, 0.28959127294365317, 0.29082705616019666, 0.2917197790229693, 0.2992113899672404, 0.2940560029819608, 0.2919142978498712, 0.4077908571343869, 0.2881688369670883, 0.2880157040199265, 0.2924670201027766, 0.2960165840340778, 0.28936176002025604, 0.4280837581027299, 0.30703556293156, 0.30764980101957917, 0.3109228400280699, 0.313343288959004, 0.43950305494945496, 0.324140515178442, 0.31050930789206177, 0.28652057505678385, 0.2947513780090958, 0.28945214999839664, 0.39613810693845153, 0.28515510505530983, 0.28599544102326035, 0.28619896387681365, 0.2949497369118035, 0.29211604699958116, 0.40906830702442676, 0.2855011710198596, 0.2853786618215963, 0.28654489608015865, 0.29018943198025227, 0.28979159018490463, 0.4108151928521693, 0.2855122579494491, 0.2852310910820961, 0.2868860069429502, 0.29317300603725016, 0.2922157250577584, 0.4182195569155738, 0.3065870830323547, 0.3145516930380836, 0.3092727040639147, 0.2986249360255897, 0.3058613509638235, 0.3989885929040611, 0.2876761599909514, 0.2866518300725147, 0.2887753170216456, 0.30589356808923185, 0.29180083400569856, 0.38855106907431036, 0.2933226421009749, 0.2927909739082679, 0.28969690680969507, 0.3028415320441127, 0.302497168071568, 0.37354701990261674, 0.2702474407851696, 0.27059820014983416, 0.2701004878617823, 0.27271264896262437, 0.2672009001253173, 0.3556393050821498, 0.26886895298957825, 0.2693987750681117, 0.26797564094886184, 0.2676319960737601, 0.27564726502168924, 0.26916727994102985, 0.38158922095317394, 0.27887041692156345, 0.27769399993121624, 0.28006350400391966, 0.27908950205892324, 0.28575454803649336, 0.28309486096259207, 0.3518232599599287, 0.2778768389252946, 0.2783445359673351, 0.27892814902588725, 0.27861371694598347, 0.28695395891554654, 0.2797230409923941, 0.41310951102059335, 0.2895585709484294, 0.2927948320284486, 0.29337165609467775, 0.29583380196709186, 0.29522484506014735, 0.4102987120859325, 0.2816529518458992, 0.28180642100051045, 0.28255552100017667, 0.2861807148437947, 0.28728566400241107]
Total Epoch List: [21, 116]
Total Time List: [0.08505547500681132, 0.08659059298224747]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x784c93513550>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6945;  Loss pred: 0.6945; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6958;  Loss pred: 0.6958; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6961;  Loss pred: 0.6961; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6966 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6932;  Loss pred: 0.6932; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6962 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6881;  Loss pred: 0.6881; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6835;  Loss pred: 0.6835; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6818;  Loss pred: 0.6818; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6779;  Loss pred: 0.6779; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6721;  Loss pred: 0.6721; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6703;  Loss pred: 0.6703; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6643;  Loss pred: 0.6643; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.4898 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.08s
Epoch 14/1000, LR 0.000270
Train loss: 0.6597;  Loss pred: 0.6597; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.09s
Epoch 15/1000, LR 0.000270
Train loss: 0.6545;  Loss pred: 0.6545; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.08s
Epoch 16/1000, LR 0.000270
Train loss: 0.6477;  Loss pred: 0.6477; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6420;  Loss pred: 0.6420; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6346;  Loss pred: 0.6346; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.08s
Epoch 19/1000, LR 0.000270
Train loss: 0.6341;  Loss pred: 0.6341; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.09s
Epoch 20/1000, LR 0.000270
Train loss: 0.6272;  Loss pred: 0.6272; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6107;  Loss pred: 0.6107; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6050;  Loss pred: 0.6050; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5961;  Loss pred: 0.5961; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5864;  Loss pred: 0.5864; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5801;  Loss pred: 0.5801; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5676;  Loss pred: 0.5676; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.5000 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5553;  Loss pred: 0.5553; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5427;  Loss pred: 0.5427; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5324;  Loss pred: 0.5324; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5188;  Loss pred: 0.5188; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5089;  Loss pred: 0.5089; Loss self: 0.0000; time: 0.12s
Val loss: 0.6860 score: 0.5102 time: 0.08s
Test loss: 0.6853 score: 0.5417 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4828;  Loss pred: 0.4828; Loss self: 0.0000; time: 0.12s
Val loss: 0.6849 score: 0.5306 time: 0.09s
Test loss: 0.6841 score: 0.6458 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4778;  Loss pred: 0.4778; Loss self: 0.0000; time: 0.12s
Val loss: 0.6836 score: 0.6327 time: 0.09s
Test loss: 0.6828 score: 0.7292 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4625;  Loss pred: 0.4625; Loss self: 0.0000; time: 0.12s
Val loss: 0.6822 score: 0.7347 time: 0.09s
Test loss: 0.6813 score: 0.7708 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4439;  Loss pred: 0.4439; Loss self: 0.0000; time: 0.12s
Val loss: 0.6806 score: 0.7551 time: 0.09s
Test loss: 0.6797 score: 0.8333 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4320;  Loss pred: 0.4320; Loss self: 0.0000; time: 0.12s
Val loss: 0.6789 score: 0.7959 time: 0.09s
Test loss: 0.6778 score: 0.8542 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4076;  Loss pred: 0.4076; Loss self: 0.0000; time: 0.12s
Val loss: 0.6770 score: 0.8571 time: 0.09s
Test loss: 0.6758 score: 0.8958 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3980;  Loss pred: 0.3980; Loss self: 0.0000; time: 0.12s
Val loss: 0.6749 score: 0.8571 time: 0.09s
Test loss: 0.6736 score: 0.9167 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3761;  Loss pred: 0.3761; Loss self: 0.0000; time: 0.12s
Val loss: 0.6726 score: 0.8980 time: 0.08s
Test loss: 0.6712 score: 0.9167 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3614;  Loss pred: 0.3614; Loss self: 0.0000; time: 0.12s
Val loss: 0.6701 score: 0.8980 time: 0.09s
Test loss: 0.6684 score: 0.9375 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3470;  Loss pred: 0.3470; Loss self: 0.0000; time: 0.12s
Val loss: 0.6674 score: 0.8980 time: 0.09s
Test loss: 0.6655 score: 0.9375 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3321;  Loss pred: 0.3321; Loss self: 0.0000; time: 0.12s
Val loss: 0.6644 score: 0.8980 time: 0.09s
Test loss: 0.6622 score: 0.9167 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3208;  Loss pred: 0.3208; Loss self: 0.0000; time: 0.12s
Val loss: 0.6611 score: 0.8980 time: 0.08s
Test loss: 0.6587 score: 0.9167 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3017;  Loss pred: 0.3017; Loss self: 0.0000; time: 0.12s
Val loss: 0.6576 score: 0.8980 time: 0.09s
Test loss: 0.6548 score: 0.9167 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2889;  Loss pred: 0.2889; Loss self: 0.0000; time: 0.12s
Val loss: 0.6537 score: 0.8980 time: 0.09s
Test loss: 0.6506 score: 0.9167 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2748;  Loss pred: 0.2748; Loss self: 0.0000; time: 0.12s
Val loss: 0.6495 score: 0.8980 time: 0.09s
Test loss: 0.6459 score: 0.9167 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2576;  Loss pred: 0.2576; Loss self: 0.0000; time: 0.12s
Val loss: 0.6448 score: 0.8980 time: 0.09s
Test loss: 0.6408 score: 0.9167 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2498;  Loss pred: 0.2498; Loss self: 0.0000; time: 0.12s
Val loss: 0.6398 score: 0.8980 time: 0.09s
Test loss: 0.6354 score: 0.9167 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2328;  Loss pred: 0.2328; Loss self: 0.0000; time: 0.12s
Val loss: 0.6346 score: 0.8980 time: 0.09s
Test loss: 0.6297 score: 0.9167 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2181;  Loss pred: 0.2181; Loss self: 0.0000; time: 0.12s
Val loss: 0.6290 score: 0.8980 time: 0.09s
Test loss: 0.6235 score: 0.9167 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2083;  Loss pred: 0.2083; Loss self: 0.0000; time: 0.12s
Val loss: 0.6232 score: 0.8776 time: 0.08s
Test loss: 0.6170 score: 0.9167 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1918;  Loss pred: 0.1918; Loss self: 0.0000; time: 0.12s
Val loss: 0.6170 score: 0.8776 time: 0.09s
Test loss: 0.6100 score: 0.9167 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1829;  Loss pred: 0.1829; Loss self: 0.0000; time: 0.12s
Val loss: 0.6103 score: 0.8776 time: 0.09s
Test loss: 0.6026 score: 0.9167 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1657;  Loss pred: 0.1657; Loss self: 0.0000; time: 0.12s
Val loss: 0.6033 score: 0.8776 time: 0.09s
Test loss: 0.5947 score: 0.9167 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1631;  Loss pred: 0.1631; Loss self: 0.0000; time: 0.12s
Val loss: 0.5958 score: 0.8776 time: 0.09s
Test loss: 0.5864 score: 0.9167 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1460;  Loss pred: 0.1460; Loss self: 0.0000; time: 0.12s
Val loss: 0.5880 score: 0.8776 time: 0.09s
Test loss: 0.5777 score: 0.9167 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1383;  Loss pred: 0.1383; Loss self: 0.0000; time: 0.12s
Val loss: 0.5796 score: 0.8776 time: 0.09s
Test loss: 0.5683 score: 0.9583 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1293;  Loss pred: 0.1293; Loss self: 0.0000; time: 0.12s
Val loss: 0.5705 score: 0.8980 time: 0.09s
Test loss: 0.5583 score: 0.9583 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1175;  Loss pred: 0.1175; Loss self: 0.0000; time: 0.12s
Val loss: 0.5609 score: 0.8980 time: 0.09s
Test loss: 0.5476 score: 0.9583 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1092;  Loss pred: 0.1092; Loss self: 0.0000; time: 0.12s
Val loss: 0.5509 score: 0.8980 time: 0.09s
Test loss: 0.5364 score: 0.9583 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1015;  Loss pred: 0.1015; Loss self: 0.0000; time: 0.12s
Val loss: 0.5405 score: 0.8980 time: 0.09s
Test loss: 0.5248 score: 0.9583 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0929;  Loss pred: 0.0929; Loss self: 0.0000; time: 0.12s
Val loss: 0.5294 score: 0.8980 time: 0.09s
Test loss: 0.5123 score: 0.9583 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0921;  Loss pred: 0.0921; Loss self: 0.0000; time: 0.12s
Val loss: 0.5180 score: 0.8980 time: 0.08s
Test loss: 0.4995 score: 0.9583 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0812;  Loss pred: 0.0812; Loss self: 0.0000; time: 0.12s
Val loss: 0.5062 score: 0.8980 time: 0.08s
Test loss: 0.4862 score: 0.9583 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0743;  Loss pred: 0.0743; Loss self: 0.0000; time: 0.12s
Val loss: 0.4937 score: 0.8980 time: 0.08s
Test loss: 0.4724 score: 0.9375 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0682;  Loss pred: 0.0682; Loss self: 0.0000; time: 0.12s
Val loss: 0.4806 score: 0.8980 time: 0.08s
Test loss: 0.4581 score: 0.9375 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0621;  Loss pred: 0.0621; Loss self: 0.0000; time: 0.12s
Val loss: 0.4673 score: 0.8980 time: 0.08s
Test loss: 0.4436 score: 0.9375 time: 0.08s
Epoch 68/1000, LR 0.000268
Train loss: 0.0542;  Loss pred: 0.0542; Loss self: 0.0000; time: 0.12s
Val loss: 0.4538 score: 0.8980 time: 0.09s
Test loss: 0.4290 score: 0.9375 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0505;  Loss pred: 0.0505; Loss self: 0.0000; time: 0.12s
Val loss: 0.4400 score: 0.8980 time: 0.08s
Test loss: 0.4141 score: 0.9167 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0478;  Loss pred: 0.0478; Loss self: 0.0000; time: 0.12s
Val loss: 0.4261 score: 0.8980 time: 0.08s
Test loss: 0.3991 score: 0.9167 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0433;  Loss pred: 0.0433; Loss self: 0.0000; time: 0.12s
Val loss: 0.4126 score: 0.8980 time: 0.09s
Test loss: 0.3846 score: 0.9167 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0390;  Loss pred: 0.0390; Loss self: 0.0000; time: 0.12s
Val loss: 0.3993 score: 0.8980 time: 0.08s
Test loss: 0.3703 score: 0.9167 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0379;  Loss pred: 0.0379; Loss self: 0.0000; time: 0.12s
Val loss: 0.3860 score: 0.8980 time: 0.08s
Test loss: 0.3560 score: 0.9167 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0328;  Loss pred: 0.0328; Loss self: 0.0000; time: 0.12s
Val loss: 0.3734 score: 0.8980 time: 0.08s
Test loss: 0.3423 score: 0.9167 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0310;  Loss pred: 0.0310; Loss self: 0.0000; time: 0.12s
Val loss: 0.3612 score: 0.8980 time: 0.08s
Test loss: 0.3289 score: 0.9167 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0279;  Loss pred: 0.0279; Loss self: 0.0000; time: 0.12s
Val loss: 0.3498 score: 0.8980 time: 0.08s
Test loss: 0.3161 score: 0.9167 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0253;  Loss pred: 0.0253; Loss self: 0.0000; time: 0.12s
Val loss: 0.3391 score: 0.8980 time: 0.08s
Test loss: 0.3039 score: 0.9167 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.12s
Val loss: 0.3291 score: 0.8980 time: 0.08s
Test loss: 0.2923 score: 0.9167 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0216;  Loss pred: 0.0216; Loss self: 0.0000; time: 0.12s
Val loss: 0.3200 score: 0.8980 time: 0.09s
Test loss: 0.2815 score: 0.9167 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0205;  Loss pred: 0.0205; Loss self: 0.0000; time: 0.12s
Val loss: 0.3113 score: 0.8980 time: 0.08s
Test loss: 0.2711 score: 0.9167 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0186;  Loss pred: 0.0186; Loss self: 0.0000; time: 0.12s
Val loss: 0.3037 score: 0.8980 time: 0.08s
Test loss: 0.2616 score: 0.9167 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0167;  Loss pred: 0.0167; Loss self: 0.0000; time: 0.12s
Val loss: 0.2967 score: 0.8980 time: 0.08s
Test loss: 0.2531 score: 0.9167 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0165;  Loss pred: 0.0165; Loss self: 0.0000; time: 0.23s
Val loss: 0.2906 score: 0.8980 time: 0.08s
Test loss: 0.2452 score: 0.9167 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.12s
Val loss: 0.2853 score: 0.8980 time: 0.09s
Test loss: 0.2380 score: 0.9167 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.13s
Val loss: 0.2803 score: 0.8980 time: 0.09s
Test loss: 0.2316 score: 0.9167 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.12s
Val loss: 0.2756 score: 0.8980 time: 0.08s
Test loss: 0.2258 score: 0.9167 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.12s
Val loss: 0.2720 score: 0.8980 time: 0.09s
Test loss: 0.2207 score: 0.8958 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.12s
Val loss: 0.2692 score: 0.8980 time: 0.08s
Test loss: 0.2163 score: 0.8958 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.12s
Val loss: 0.2667 score: 0.8980 time: 0.09s
Test loss: 0.2125 score: 0.8958 time: 0.17s
Epoch 90/1000, LR 0.000266
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.12s
Val loss: 0.2648 score: 0.8980 time: 0.08s
Test loss: 0.2094 score: 0.8958 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.12s
Val loss: 0.2631 score: 0.8980 time: 0.08s
Test loss: 0.2069 score: 0.8958 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.12s
Val loss: 0.2619 score: 0.8980 time: 0.08s
Test loss: 0.2048 score: 0.8958 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.12s
Val loss: 0.2615 score: 0.8980 time: 0.08s
Test loss: 0.2034 score: 0.8958 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.12s
Val loss: 0.2618 score: 0.9184 time: 0.08s
Test loss: 0.2024 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.12s
Val loss: 0.2629 score: 0.9184 time: 0.08s
Test loss: 0.2018 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.2644 score: 0.9184 time: 0.08s
Test loss: 0.2016 score: 0.8958 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.23s
Val loss: 0.2666 score: 0.9184 time: 0.08s
Test loss: 0.2017 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.12s
Val loss: 0.2685 score: 0.9184 time: 0.08s
Test loss: 0.2020 score: 0.8958 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.12s
Val loss: 0.2702 score: 0.9184 time: 0.09s
Test loss: 0.2025 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.2722 score: 0.9184 time: 0.08s
Test loss: 0.2032 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.12s
Val loss: 0.2743 score: 0.9184 time: 0.08s
Test loss: 0.2041 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.12s
Val loss: 0.2769 score: 0.9184 time: 0.08s
Test loss: 0.2051 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.13s
Val loss: 0.2797 score: 0.9184 time: 0.17s
Test loss: 0.2064 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.12s
Val loss: 0.2820 score: 0.9184 time: 0.08s
Test loss: 0.2077 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.12s
Val loss: 0.2844 score: 0.9184 time: 0.08s
Test loss: 0.2092 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.12s
Val loss: 0.2866 score: 0.9184 time: 0.08s
Test loss: 0.2107 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.12s
Val loss: 0.2889 score: 0.9184 time: 0.08s
Test loss: 0.2122 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.12s
Val loss: 0.2915 score: 0.9184 time: 0.08s
Test loss: 0.2138 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.12s
Val loss: 0.2935 score: 0.9184 time: 0.08s
Test loss: 0.2154 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.13s
Val loss: 0.2957 score: 0.9184 time: 0.16s
Test loss: 0.2169 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.12s
Val loss: 0.2979 score: 0.9184 time: 0.08s
Test loss: 0.2183 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.2999 score: 0.9184 time: 0.08s
Test loss: 0.2197 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.3016 score: 0.9184 time: 0.08s
Test loss: 0.2212 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 092,   Train_Loss: 0.0082,   Val_Loss: 0.2615,   Val_Precision: 1.0000,   Val_Recall: 0.8000,   Val_accuracy: 0.8889,   Val_Score: 0.8980,   Val_Loss: 0.2615,   Test_Precision: 0.8800,   Test_Recall: 0.9167,   Test_accuracy: 0.8980,   Test_Score: 0.8958,   Test_loss: 0.2034


[0.08658879797440022, 0.08560835907701403, 0.08604988898150623, 0.0861111149424687, 0.08603387605398893, 0.08599471393972635, 0.08574975200463086, 0.08564695401582867, 0.08560035494156182, 0.08647597092203796, 0.08732317690737545, 0.08592898899223655, 0.08598317299038172, 0.08542188908904791, 0.08469003601931036, 0.08490876201540232, 0.08466155105270445, 0.08502368803601712, 0.08468084002379328, 0.0853470970178023, 0.08471374702639878, 0.08708954299800098, 0.08677158900536597, 0.09217875299509615, 0.09850691503379494, 0.08677908801473677, 0.08698908996302634, 0.0870973359560594, 0.08714025688823313, 0.0870103680063039, 0.08612568804528564, 0.08555057202465832, 0.09050444001331925, 0.09005968505516648, 0.08995733107440174, 0.09416762797627598, 0.09129530901554972, 0.08821869094390422, 0.09706173103768378, 0.08572351292241365, 0.08608829299919307, 0.087068474967964, 0.08991049195174128, 0.08633504202589393, 0.08955462207086384, 0.08571578201372176, 0.08625667402520776, 0.08629016391932964, 0.09013961302116513, 0.0858304820721969, 0.08853500697296113, 0.09188860096037388, 0.09323775605298579, 0.09266915498301387, 0.09498228691518307, 0.09379286994226277, 0.22528715000953525, 0.09828993701376021, 0.08510666596703231, 0.08588808798231184, 0.08766449498943985, 0.08561693993397057, 0.19382417702581733, 0.08505779108963907, 0.08573354000691324, 0.08562552195508033, 0.08699332503601909, 0.08645381405949593, 0.20439515903126448, 0.0854403639677912, 0.08462043094914407, 0.08486135199200362, 0.08700362301897258, 0.08512384304776788, 0.20838255190756172, 0.08504921395797282, 0.08478686702437699, 0.08534339303150773, 0.08720687089953572, 0.0857107889605686, 0.2066203170688823, 0.09145812003407627, 0.08898391702678055, 0.09212973504327238, 0.08691967197228223, 0.0900667340029031, 0.08595400804188102, 0.08409703895449638, 0.08524887193925679, 0.08558173500932753, 0.08984738204162568, 0.08766871795523912, 0.09688407799694687, 0.08799603290390223, 0.0874552329769358, 0.08712072600610554, 0.09787169902119786, 0.09198639797978103, 0.09333691804204136, 0.08002554601989686, 0.0811932769138366, 0.08286011195741594, 0.08090337098110467, 0.07975220400840044, 0.07983894797507674, 0.0804538440424949, 0.08074911800213158, 0.08159708394668996, 0.08027460693847388, 0.08152031397912651, 0.07981405209284276, 0.18579440307803452, 0.08504250494297594, 0.08454033802263439, 0.08451892400626093, 0.08424082398414612, 0.08522331097628921, 0.08486933005042374, 0.15130590798798949, 0.08344309800304472, 0.08291569096036255, 0.08363104297313839, 0.08323090593330562, 0.08505538094323128, 0.08378126297611743, 0.08627755800262094, 0.08769372501410544, 0.08793538995087147, 0.08777338801883161, 0.08895277697592974, 0.0870746630243957, 0.20553521194960922, 0.08602184092160314, 0.08536988904234022, 0.08590867999009788, 0.08675707899965346, 0.08597368304617703, 0.07878015108872205, 0.07815905497409403, 0.07830086105968803, 0.07825859903823584, 0.07829330698587, 0.07819552102591842, 0.07858408393803984, 0.07874346699099988, 0.07884864590596408, 0.07889440399594605, 0.0785855510039255, 0.07873015606310219, 0.08147580700460821, 0.09195123298559338, 0.0823499649995938, 0.07868824107572436, 0.07907108997460455, 0.08111567189916968, 0.09056892897933722, 0.0790261480724439, 0.07888753502629697, 0.07850377098657191, 0.07815235701855272, 0.07918326300568879, 0.0782567219575867, 0.07848919194657356, 0.07814425905235112, 0.07817126798909158, 0.0786406520055607, 0.07886607805266976, 0.0781962750479579, 0.07876605598721653, 0.07811783091165125, 0.07922606903593987, 0.07876861898694187, 0.07860970904584974, 0.07855199195910245, 0.07822146301623434, 0.07866673194803298, 0.07865020004101098, 0.0785316179972142, 0.07851297699380666, 0.07834081293549389, 0.07874586095567793, 0.0786217579152435, 0.0787768509471789, 0.07821822504047304, 0.07857611402869225, 0.07821343396790326, 0.07846404297742993, 0.07847267901524901, 0.07911910396069288, 0.07848831196315587, 0.07903938600793481, 0.07904997898731381, 0.07867872400674969, 0.07865005801431835, 0.07862424792256206, 0.0787606609519571, 0.07882034697104245, 0.07846159103792161, 0.07820221106521785, 0.07789146492723376, 0.07835094700567424, 0.07820255402475595, 0.0782226239098236, 0.08270764001645148, 0.07979296194389462, 0.07849644694942981, 0.08469070203136653, 0.0783286519581452, 0.07832047599367797, 0.07810980593785644, 0.0785334319807589, 0.0782076739706099, 0.07821205607615411, 0.07810848404187709, 0.07811849506106228, 0.07814423006493598, 0.07785184099338949, 0.07688458892516792, 0.08135332190431654, 0.08774984406773001, 0.08371556305792183, 0.07889669702854007, 0.07726277294568717, 0.07783547800499946, 0.07734045793768018, 0.17937843594700098, 0.07715937402099371, 0.0771907779853791, 0.07729405700229108, 0.07716930599417537, 0.07783983601257205, 0.07590785599313676, 0.0825172949116677, 0.07607767195440829, 0.0853258540155366, 0.07771605800371617, 0.07710692589171231, 0.07846892694942653, 0.07815846905577928, 0.07718833803664893, 0.07722098904196173, 0.07752233603969216, 0.07740785006899387, 0.0785646919393912, 0.07831814198289067, 0.07715307001490146, 0.07702964905183762, 0.07709586108103395, 0.07777334190905094, 0.07736501295585185]
[0.0017671183260081678, 0.0017471093689186536, 0.0017561201832960456, 0.001757369692703443, 0.001755793388856917, 0.0017549941620352318, 0.0017499949388700177, 0.0017478970207311974, 0.0017469460192155472, 0.0017648157331028155, 0.0017821056511709277, 0.0017536528365762563, 0.0017547586324567698, 0.0017433038589601613, 0.001728368082026742, 0.0017328318778653533, 0.0017277867561776418, 0.0017351773068574922, 0.0017281804086488424, 0.0017417774901592306, 0.0017288519801305874, 0.0017773376122041016, 0.0017708487552115504, 0.001881199040716248, 0.002010345204771325, 0.001771001796219118, 0.0017752875502658437, 0.0017774966521644775, 0.001778372589555778, 0.0017757217960470185, 0.0017576671029650131, 0.0017459300413195575, 0.0018470293880269236, 0.0018379527562278875, 0.0018358638994775865, 0.0019217883260464485, 0.0018631695717459126, 0.00180038144783478, 0.001980851653830281, 0.0017494594473961968, 0.0017569039387590423, 0.0017769076524074285, 0.0018349079990151282, 0.0017619396331815087, 0.0018276453483849764, 0.0017493016737494239, 0.0017603402862287297, 0.001761023753455707, 0.0018395839392074517, 0.0017516424912693246, 0.0018068368769992068, 0.001875277570619875, 0.001902811348020118, 0.0018912072445513035, 0.0019384140186772055, 0.001914140202903322, 0.0045976969389701075, 0.0020059170819134737, 0.0017368707340210676, 0.0017528181220879968, 0.0017890713263150988, 0.001747284488448379, 0.003955595449506476, 0.0017358732875436544, 0.0017496640817737396, 0.0017474596317363332, 0.0017753739803269201, 0.0017643635522346108, 0.004171329776148255, 0.0017436808973018611, 0.0017269475703906951, 0.0017318643263674208, 0.0017755841432443382, 0.0017372212866891403, 0.004252705140970647, 0.0017356982440402617, 0.0017303442249872855, 0.0017417018986021985, 0.0017797320591741983, 0.0017491997747054817, 0.004216741164671067, 0.0018664922455933933, 0.0018159983066689906, 0.0018801986743524975, 0.0017738708565771884, 0.0018380966123041449, 0.0017541634294261433, 0.001716266101112171, 0.0017397728967195262, 0.0017465660205985211, 0.00183362004166583, 0.0017891575092905943, 0.001977226081570344, 0.0017958374062020863, 0.0017848006729986898, 0.001777974000124603, 0.001997381612677507, 0.0018772734281587967, 0.0019048350620824769, 0.0016331744085693238, 0.0016570056513027878, 0.0016910226930084886, 0.0016510892036960137, 0.0016275960001714376, 0.0016293662852056477, 0.001641915184540712, 0.001647941183716971, 0.001665246611156938, 0.0016382572844586506, 0.001663679877125031, 0.0016288582059763828, 0.003791722511796623, 0.001735561325366856, 0.0017253130208700895, 0.001724876000127774, 0.0017192004894723697, 0.0017392512444140656, 0.0017320271438861989, 0.0030878756732242753, 0.001702920367409076, 0.001692156958374746, 0.0017067559790436406, 0.0016985899170062371, 0.001735824100882271, 0.0017098216933901518, 0.001760766489849407, 0.0017896678574307232, 0.0017945997949157441, 0.00179129363303738, 0.0018153627954271374, 0.0017770339392733816, 0.004194596162236923, 0.0017555477739102682, 0.0017422426335171473, 0.0017532383671448547, 0.0017705526326459889, 0.001754564960126062, 0.0016412531476817094, 0.0016283136452936258, 0.0016312679387435007, 0.0016303874799632467, 0.001631110562205625, 0.0016290733547066338, 0.00163716841537583, 0.0016404888956458308, 0.0016426801230409183, 0.0016436334165822093, 0.001637198979248448, 0.0016402115846479621, 0.0016974126459293377, 0.001915650687199862, 0.0017156242708248708, 0.0016393383557442576, 0.001647314374470928, 0.0016899098312327017, 0.0018868526870695252, 0.0016463780848425813, 0.0016434903130478535, 0.0016354952288869147, 0.0016281741045531817, 0.0016496513126185164, 0.0016303483741163898, 0.0016351914988869491, 0.0016280053969239816, 0.0016285680831060745, 0.0016383469167825144, 0.0016430432927639533, 0.0016290890634991229, 0.0016409594997336778, 0.0016274548106594011, 0.001650543104915414, 0.001641012895561289, 0.0016377022717885363, 0.0016364998324813012, 0.0016296138128382154, 0.0016388902489173536, 0.0016385458341877286, 0.0016360753749419625, 0.0016356870207043055, 0.001632100269489456, 0.0016405387699099567, 0.0016379532899009064, 0.0016411843947328937, 0.001629546355009855, 0.0016370023755977552, 0.0016294465409979846, 0.0016346675620297901, 0.0016348474794843544, 0.0016483146658477683, 0.0016351731658990805, 0.0016466538751653086, 0.0016468745622357044, 0.0016391400834739518, 0.001638542875298299, 0.0016380051650533762, 0.001640847103165773, 0.0016420905618967179, 0.0016346164799567002, 0.0016292127305253719, 0.0016227388526507032, 0.0016323113959515467, 0.001629219875515749, 0.001629637998121325, 0.0017230758336760725, 0.001662353373831138, 0.0016353426447797876, 0.0017643896256534692, 0.0016318469157946918, 0.0016316765832016245, 0.0016272876237053424, 0.0016361131662658106, 0.001629326541054373, 0.0016294178349198774, 0.0016272600842057727, 0.001627468647105464, 0.0016280047930194996, 0.0016219133540289477, 0.0016017622692743316, 0.0016948608730065946, 0.001828121751411042, 0.0017440742303733714, 0.001643681188094585, 0.0016096411030351494, 0.0016215724584374887, 0.0016112595403683372, 0.0037370507488958538, 0.0016074869587707024, 0.0016081412080287312, 0.0016102928542143975, 0.0016076938748786536, 0.0016216632502619177, 0.0015814136665236826, 0.0017191103106597438, 0.0015849514990501727, 0.0017776219586570126, 0.0016190845417440869, 0.001606394289410673, 0.0016347693114463862, 0.0016283014386620682, 0.0016080903757635194, 0.0016087706050408694, 0.0016150486674935867, 0.0016126635431040388, 0.0016367644154039833, 0.0016316279579768889, 0.001607355625310447, 0.0016047843552466172, 0.0016061637725215405, 0.0016202779564385612, 0.0016117711032469135]
[565.8930617617158, 572.3740126349013, 569.4371088675204, 569.0322327464597, 569.5430945044366, 569.8024652345965, 571.4302240472227, 572.116084723155, 572.4275329635213, 566.6313945659626, 561.1339593379062, 570.2382929749938, 569.8789460291406, 573.623464928527, 578.5804600298836, 577.090029779394, 578.7751274423968, 576.3099805696852, 578.6432915194532, 574.1261473694792, 578.4185178909682, 562.6393056296636, 564.7009644708688, 531.5758611163548, 497.42700787238624, 564.6521658729446, 563.2890287831135, 562.5889639692366, 562.3118607837918, 563.1512786665832, 568.9359482879878, 572.7606354972902, 541.4099020201531, 544.0836259863092, 544.7026875383083, 520.3486702706875, 536.7198000463984, 555.4378496860458, 504.83336198667183, 571.6051329388328, 569.1830827736275, 562.7754479222139, 544.9864519293293, 567.5563346028573, 547.1521052394895, 571.6566873549128, 568.0719846174475, 567.8515113936832, 543.6011799661777, 570.8927506521903, 553.4533929043995, 533.2543915989188, 525.5381733141877, 528.7627799021328, 515.8856623841436, 522.4277712171888, 217.50019918102777, 498.52509309412, 575.7480855727691, 570.509847769475, 558.949207497318, 572.3166471236854, 252.80643907221756, 576.0789149621911, 571.5382800715894, 572.2592853297373, 563.2616063325759, 566.7766139996912, 239.73170515503702, 573.4994295959663, 579.0563750431436, 577.4124362833296, 563.1949371730732, 575.6319057693776, 235.14444732271227, 576.1370119683106, 577.9196910992366, 574.1510650028855, 561.882332143864, 571.6899890227651, 237.14996034811315, 535.7643474602709, 550.6613064162257, 531.8586879359331, 563.7388969395281, 544.041044037642, 570.0723109517451, 582.6602292919391, 574.7876644621697, 572.5520754476349, 545.3692571398311, 558.9222831457151, 505.7590577632802, 556.8432846684282, 560.2866556072472, 562.4379208750627, 500.65545494808646, 532.6874524510721, 524.9798367879378, 612.3044757210037, 603.4982434814087, 591.3581196364112, 605.6607951656817, 614.4030827641923, 613.7355418973743, 609.0448577462464, 606.8177735230064, 600.511655931397, 610.404732813651, 601.077174611307, 613.9269804645594, 263.7323793839999, 576.1824634970038, 579.6049690135021, 579.7518197980161, 581.6657255064558, 574.9600600900469, 577.3581571916196, 323.8472353894441, 587.2265193007582, 590.9617279005033, 585.9068386333338, 588.7236171532791, 576.0952388503696, 584.8563062837554, 567.934479537674, 558.7628988518666, 557.2273009464762, 558.2557664230433, 550.8540786001454, 562.7354536677526, 238.4019727579003, 569.6227780646619, 573.9728673619086, 570.3730985698757, 564.7954099537598, 569.9418503878888, 609.2905298689069, 614.1322974786439, 613.0200785839384, 613.3511280536469, 613.0792253884845, 613.8459002541857, 610.8107086652042, 609.5743791099044, 608.7612469242075, 608.4081705271068, 610.7993058113483, 609.6774400082228, 589.1319370090456, 522.015838629597, 582.8782076621012, 610.0021978354805, 607.0486699426589, 591.747548607698, 529.9830807423032, 607.3938964606755, 608.4611464155815, 611.435595981885, 614.1849309625453, 606.1887093052925, 613.3658400107133, 611.549167593328, 614.2485779773457, 614.0363490930986, 610.3713381802316, 608.6266895121091, 613.8399811316016, 609.3995617577988, 614.456385179031, 605.8611841289945, 609.3797329106069, 610.6115972519834, 611.0602519792352, 613.642319500441, 610.1689851779869, 610.2972398667914, 611.2187832638662, 611.3639023493706, 612.7074535149817, 609.5558473481772, 610.5180203646091, 609.3160544356456, 613.6677222624651, 610.872662683124, 613.7053133314405, 611.7451787923691, 611.6778553039143, 606.68027817715, 611.5560240680453, 607.2921669100675, 607.210787591774, 610.0759844031301, 610.2983419447896, 610.4986854344954, 609.4413050860419, 608.9798109824936, 611.7642959445076, 613.7933869922132, 616.2421010420285, 612.6282046919458, 613.7906951837535, 613.6332125004556, 580.3575097832831, 601.5568144186773, 611.492645404999, 566.7682384097188, 612.8025798994821, 612.8665510648142, 614.519514210398, 611.2046651897277, 613.7505127442888, 613.7161252130105, 614.5299142442103, 614.4511611812313, 614.2488058313858, 616.5557472696856, 624.3123709319509, 590.0189307137949, 547.0095190477039, 573.3700908968307, 608.390487914044, 621.2565012873948, 616.6853628998964, 620.6324772304516, 267.59069308744586, 622.0890281839254, 621.8359401571494, 621.0050534490281, 622.0089630406028, 616.6508366262159, 632.3456165635865, 581.6962377569764, 630.9341330629225, 562.5493064653052, 617.6329735832043, 622.5121731270989, 611.7071032580342, 614.1369013477463, 621.8555965955591, 621.5926601758091, 619.1763877629223, 620.092147724261, 610.9614741063281, 612.8848155065534, 622.1398576975512, 623.1366829634402, 622.6015161767003, 617.1780564107913, 620.4354935918007]
Elapsed: 0.0871917894310318~0.02186788772031902
Time per graph: 0.0017947615857699768~0.00044224149781778603
Speed: 573.5791621141753~68.74261344389265
Total Time: 0.0782
best val loss: 0.26154661178588867 test_score: 0.8958

Testing...
Test loss: 0.2024 score: 0.8958 time: 0.07s
test Score 0.8958
Epoch Time List: [0.2837958049494773, 0.2810814700787887, 0.2821239938493818, 0.28369553585071117, 0.28261684300377965, 0.2839909391477704, 0.28272307000588626, 0.28338566003367305, 0.2823107799049467, 0.2830013009952381, 0.2939212329220027, 0.2865681261755526, 0.28280604910105467, 0.2761254410725087, 0.2803084159968421, 0.2796346000395715, 0.2798533720197156, 0.2783971820026636, 0.28061681089457124, 0.28048126690555364, 0.2807834621053189, 0.2989050062606111, 0.2911948439432308, 0.2978786489693448, 0.31020626181270927, 0.2978935450082645, 0.29239408508874476, 0.29211291996762156, 0.29357861005701125, 0.2921533160842955, 0.2920098799513653, 0.2872731500538066, 0.3588575239991769, 0.30390383198391646, 0.29976118891499937, 0.31684042792767286, 0.306452963151969, 0.29811059194616973, 0.44217156805098057, 0.28959127294365317, 0.29082705616019666, 0.2917197790229693, 0.2992113899672404, 0.2940560029819608, 0.2919142978498712, 0.4077908571343869, 0.2881688369670883, 0.2880157040199265, 0.2924670201027766, 0.2960165840340778, 0.28936176002025604, 0.4280837581027299, 0.30703556293156, 0.30764980101957917, 0.3109228400280699, 0.313343288959004, 0.43950305494945496, 0.324140515178442, 0.31050930789206177, 0.28652057505678385, 0.2947513780090958, 0.28945214999839664, 0.39613810693845153, 0.28515510505530983, 0.28599544102326035, 0.28619896387681365, 0.2949497369118035, 0.29211604699958116, 0.40906830702442676, 0.2855011710198596, 0.2853786618215963, 0.28654489608015865, 0.29018943198025227, 0.28979159018490463, 0.4108151928521693, 0.2855122579494491, 0.2852310910820961, 0.2868860069429502, 0.29317300603725016, 0.2922157250577584, 0.4182195569155738, 0.3065870830323547, 0.3145516930380836, 0.3092727040639147, 0.2986249360255897, 0.3058613509638235, 0.3989885929040611, 0.2876761599909514, 0.2866518300725147, 0.2887753170216456, 0.30589356808923185, 0.29180083400569856, 0.38855106907431036, 0.2933226421009749, 0.2927909739082679, 0.28969690680969507, 0.3028415320441127, 0.302497168071568, 0.37354701990261674, 0.2702474407851696, 0.27059820014983416, 0.2701004878617823, 0.27271264896262437, 0.2672009001253173, 0.3556393050821498, 0.26886895298957825, 0.2693987750681117, 0.26797564094886184, 0.2676319960737601, 0.27564726502168924, 0.26916727994102985, 0.38158922095317394, 0.27887041692156345, 0.27769399993121624, 0.28006350400391966, 0.27908950205892324, 0.28575454803649336, 0.28309486096259207, 0.3518232599599287, 0.2778768389252946, 0.2783445359673351, 0.27892814902588725, 0.27861371694598347, 0.28695395891554654, 0.2797230409923941, 0.41310951102059335, 0.2895585709484294, 0.2927948320284486, 0.29337165609467775, 0.29583380196709186, 0.29522484506014735, 0.4102987120859325, 0.2816529518458992, 0.28180642100051045, 0.28255552100017667, 0.2861807148437947, 0.28728566400241107, 0.285534015041776, 0.27671739808283746, 0.27785459312144667, 0.27735239500179887, 0.2772178630111739, 0.2777661168947816, 0.2775441789999604, 0.27856064890511334, 0.27874222793616354, 0.2784961920697242, 0.27916366094723344, 0.27824266685638577, 0.3017488120822236, 0.30423743289429694, 0.297133443178609, 0.2804287989856675, 0.28255567396990955, 0.28555284324102104, 0.29949278198182583, 0.28291002893820405, 0.2780341380275786, 0.277045646100305, 0.2769927189219743, 0.2778759930515662, 0.27739916695281863, 0.2780540769454092, 0.2774348108796403, 0.277267180965282, 0.2788728311425075, 0.277694956981577, 0.2769237101310864, 0.2778868689201772, 0.2779690580209717, 0.27955847105477005, 0.2783899682108313, 0.2792333351681009, 0.27857156400568783, 0.2789808032102883, 0.27844168606679887, 0.2792418400058523, 0.27817634493112564, 0.27805184200406075, 0.27861877402756363, 0.2793685499345884, 0.27829138981178403, 0.2787019570823759, 0.2790691088885069, 0.27986872394103557, 0.27905664208810776, 0.278825797024183, 0.27824787492863834, 0.2867396930232644, 0.2791360249975696, 0.28098830091767013, 0.27911001292522997, 0.27971430984325707, 0.2791375470114872, 0.27926925104111433, 0.28027706395369023, 0.2783835690934211, 0.27877754089422524, 0.27913016197271645, 0.27666140883229673, 0.2755471771815792, 0.27650719811208546, 0.27633388189133257, 0.2814149910118431, 0.2841310849180445, 0.27764987491536885, 0.2832577698864043, 0.27984556287992746, 0.27692217484582216, 0.2770611820742488, 0.27704469696618617, 0.2766389111056924, 0.27605129894800484, 0.2771678570425138, 0.2762991999043152, 0.276880145072937, 0.2764046990778297, 0.27375010901596397, 0.2733212038874626, 0.4004315680358559, 0.29094373900443316, 0.28953097201883793, 0.2726292188744992, 0.2782069491222501, 0.2748128151288256, 0.3816625609761104, 0.27244674088433385, 0.2723076519323513, 0.27143047098070383, 0.27373606991022825, 0.2774353239219636, 0.27052770694717765, 0.27447712689172477, 0.3790723291458562, 0.28536443191114813, 0.27803721907548606, 0.2707495040958747, 0.27855686203110963, 0.27582011080812663, 0.3716895590769127, 0.2729518929263577, 0.27368277008645236, 0.27228048886172473, 0.2722364799119532, 0.280266682151705, 0.27283558098133653, 0.36328405793756247, 0.27249526197556406, 0.27197814593091607, 0.27360287902411073]
Total Epoch List: [21, 116, 113]
Total Time List: [0.08505547500681132, 0.08659059298224747, 0.07824832305777818]
T-times Epoch Time: 0.29129477485120875 ~ 0.002068404004798627
T-times Total Epoch: 74.1111111111111 ~ 12.341838908943874
T-times Total Time: 0.09726062645980467 ~ 0.021097919067019882
T-times Inference Elapsed: 0.08425506035498787 ~ 0.0025831740807203615
T-times Time Per Graph: 0.0017338608173987785 ~ 5.904422626893949e-05
T-times Speed: 589.9619729536557 ~ 17.290836803791343
T-times cross validation test micro f1 score:0.5092015840152486 ~ 0.06515401508281664
T-times cross validation test precision:0.5197398736529171 ~ 0.15906931278259312
T-times cross validation test recall:0.5007407407407407 ~ 0.12920326708317284
T-times cross validation test f1_score:0.5092015840152486 ~ 0.14335143323313418
