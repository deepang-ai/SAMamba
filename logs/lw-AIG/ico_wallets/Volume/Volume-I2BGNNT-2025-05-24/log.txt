Namespace(seed=15, model='I2BGNNT', dataset='ico_wallets/Volume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/ico_wallets/Volume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 334], edge_attr=[334, 2], x=[97, 14887], y=[1, 1], num_nodes=97)
Data(edge_index=[2, 334], edge_attr=[334, 2], x=[97, 14887], y=[1, 1], num_nodes=97)
Data(edge_index=[2, 276], edge_attr=[276, 2], x=[88, 14887], y=[1, 1], num_nodes=97)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d080cd900>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.28s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4898 time: 0.06s
Epoch 2/1000, LR 0.000000
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4898 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6875;  Loss pred: 0.6875; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6832;  Loss pred: 0.6832; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6834;  Loss pred: 0.6834; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6794;  Loss pred: 0.6794; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6744;  Loss pred: 0.6744; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6678;  Loss pred: 0.6678; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6645;  Loss pred: 0.6645; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.06s
Epoch 13/1000, LR 0.000270
Train loss: 0.6606;  Loss pred: 0.6606; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6541;  Loss pred: 0.6541; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6529;  Loss pred: 0.6529; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.19s
Epoch 16/1000, LR 0.000270
Train loss: 0.6462;  Loss pred: 0.6462; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6398;  Loss pred: 0.6398; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5102 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6354;  Loss pred: 0.6354; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5102 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6235;  Loss pred: 0.6235; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5102 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6224;  Loss pred: 0.6224; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5102 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6138;  Loss pred: 0.6138; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5102 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6046;  Loss pred: 0.6046; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4898 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5102 time: 0.06s
Epoch 23/1000, LR 0.000270
Train loss: 0.5939;  Loss pred: 0.5939; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5102 time: 0.06s
Epoch 24/1000, LR 0.000270
Train loss: 0.5891;  Loss pred: 0.5891; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5102 time: 0.06s
Epoch 25/1000, LR 0.000270
Train loss: 0.5743;  Loss pred: 0.5743; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5102 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.5643;  Loss pred: 0.5643; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.5102 time: 0.06s
     INFO: Early stopping counter 2 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5584;  Loss pred: 0.5584; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5102 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5392;  Loss pred: 0.5392; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5102 time: 0.06s
Epoch 29/1000, LR 0.000270
Train loss: 0.5265;  Loss pred: 0.5265; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.5102 time: 0.20s
Epoch 30/1000, LR 0.000270
Train loss: 0.5163;  Loss pred: 0.5163; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6900 score: 0.5102 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5016;  Loss pred: 0.5016; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5102 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4832;  Loss pred: 0.4832; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5102 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4780;  Loss pred: 0.4780; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.5102 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4605;  Loss pred: 0.4605; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.5102 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4496;  Loss pred: 0.4496; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6885 score: 0.5102 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4220;  Loss pred: 0.4220; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.5102 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4084;  Loss pred: 0.4084; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.4898 time: 0.22s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.5102 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3931;  Loss pred: 0.3931; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6887 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.5102 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3725;  Loss pred: 0.3725; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.5102 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3641;  Loss pred: 0.3641; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6857 score: 0.5102 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3463;  Loss pred: 0.3463; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6859 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6849 score: 0.5102 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3233;  Loss pred: 0.3233; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6846 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6840 score: 0.5102 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3111;  Loss pred: 0.3111; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6830 score: 0.4898 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6828 score: 0.5102 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.2934;  Loss pred: 0.2934; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6811 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6814 score: 0.5102 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2746;  Loss pred: 0.2746; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6788 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6798 score: 0.5102 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2549;  Loss pred: 0.2549; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6763 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6780 score: 0.5102 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2413;  Loss pred: 0.2413; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6734 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6759 score: 0.5102 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2304;  Loss pred: 0.2304; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6701 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6735 score: 0.5102 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2138;  Loss pred: 0.2138; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6662 score: 0.4898 time: 0.21s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6707 score: 0.5102 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2068;  Loss pred: 0.2068; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6617 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6674 score: 0.5102 time: 0.06s
Epoch 51/1000, LR 0.000269
Train loss: 0.1869;  Loss pred: 0.1869; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6567 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6637 score: 0.5102 time: 0.06s
Epoch 52/1000, LR 0.000269
Train loss: 0.1745;  Loss pred: 0.1745; Loss self: 0.0000; time: 0.12s
Val loss: 0.6512 score: 0.5102 time: 0.07s
Test loss: 0.6597 score: 0.5306 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1626;  Loss pred: 0.1626; Loss self: 0.0000; time: 0.12s
Val loss: 0.6452 score: 0.5102 time: 0.07s
Test loss: 0.6551 score: 0.5306 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1450;  Loss pred: 0.1450; Loss self: 0.0000; time: 0.13s
Val loss: 0.6384 score: 0.5510 time: 0.07s
Test loss: 0.6502 score: 0.5510 time: 0.06s
Epoch 55/1000, LR 0.000269
Train loss: 0.1344;  Loss pred: 0.1344; Loss self: 0.0000; time: 0.12s
Val loss: 0.6308 score: 0.5510 time: 0.07s
Test loss: 0.6446 score: 0.5510 time: 0.06s
Epoch 56/1000, LR 0.000269
Train loss: 0.1269;  Loss pred: 0.1269; Loss self: 0.0000; time: 0.12s
Val loss: 0.6225 score: 0.5510 time: 0.07s
Test loss: 0.6383 score: 0.5510 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1182;  Loss pred: 0.1182; Loss self: 0.0000; time: 0.12s
Val loss: 0.6133 score: 0.5714 time: 0.07s
Test loss: 0.6315 score: 0.5510 time: 0.06s
Epoch 58/1000, LR 0.000269
Train loss: 0.1044;  Loss pred: 0.1044; Loss self: 0.0000; time: 0.12s
Val loss: 0.6031 score: 0.5714 time: 0.07s
Test loss: 0.6238 score: 0.5714 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.0985;  Loss pred: 0.0985; Loss self: 0.0000; time: 0.12s
Val loss: 0.5918 score: 0.5714 time: 0.07s
Test loss: 0.6153 score: 0.5918 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.0862;  Loss pred: 0.0862; Loss self: 0.0000; time: 0.12s
Val loss: 0.5792 score: 0.5918 time: 0.07s
Test loss: 0.6058 score: 0.5918 time: 0.06s
Epoch 61/1000, LR 0.000268
Train loss: 0.0858;  Loss pred: 0.0858; Loss self: 0.0000; time: 0.12s
Val loss: 0.5655 score: 0.5918 time: 0.07s
Test loss: 0.5956 score: 0.5918 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0746;  Loss pred: 0.0746; Loss self: 0.0000; time: 0.12s
Val loss: 0.5507 score: 0.6531 time: 0.07s
Test loss: 0.5846 score: 0.6122 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0678;  Loss pred: 0.0678; Loss self: 0.0000; time: 0.12s
Val loss: 0.5347 score: 0.6531 time: 0.07s
Test loss: 0.5728 score: 0.6327 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0618;  Loss pred: 0.0618; Loss self: 0.0000; time: 0.12s
Val loss: 0.5176 score: 0.6531 time: 0.07s
Test loss: 0.5602 score: 0.6735 time: 0.06s
Epoch 65/1000, LR 0.000268
Train loss: 0.0561;  Loss pred: 0.0561; Loss self: 0.0000; time: 0.12s
Val loss: 0.4997 score: 0.6735 time: 0.07s
Test loss: 0.5470 score: 0.6735 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0482;  Loss pred: 0.0482; Loss self: 0.0000; time: 0.12s
Val loss: 0.4814 score: 0.7143 time: 0.07s
Test loss: 0.5336 score: 0.7143 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0445;  Loss pred: 0.0445; Loss self: 0.0000; time: 0.12s
Val loss: 0.4625 score: 0.7347 time: 0.07s
Test loss: 0.5198 score: 0.7551 time: 0.06s
Epoch 68/1000, LR 0.000268
Train loss: 0.0415;  Loss pred: 0.0415; Loss self: 0.0000; time: 0.12s
Val loss: 0.4438 score: 0.8163 time: 0.07s
Test loss: 0.5061 score: 0.7347 time: 0.06s
Epoch 69/1000, LR 0.000268
Train loss: 0.0390;  Loss pred: 0.0390; Loss self: 0.0000; time: 0.12s
Val loss: 0.4252 score: 0.8367 time: 0.07s
Test loss: 0.4927 score: 0.7755 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0348;  Loss pred: 0.0348; Loss self: 0.0000; time: 0.12s
Val loss: 0.4059 score: 0.8367 time: 0.07s
Test loss: 0.4791 score: 0.7959 time: 0.06s
Epoch 71/1000, LR 0.000268
Train loss: 0.0299;  Loss pred: 0.0299; Loss self: 0.0000; time: 0.12s
Val loss: 0.3867 score: 0.8980 time: 0.07s
Test loss: 0.4655 score: 0.8367 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.0291;  Loss pred: 0.0291; Loss self: 0.0000; time: 0.12s
Val loss: 0.3675 score: 0.9184 time: 0.07s
Test loss: 0.4523 score: 0.8367 time: 0.06s
Epoch 73/1000, LR 0.000267
Train loss: 0.0262;  Loss pred: 0.0262; Loss self: 0.0000; time: 0.12s
Val loss: 0.3486 score: 0.9592 time: 0.07s
Test loss: 0.4395 score: 0.8163 time: 0.06s
Epoch 74/1000, LR 0.000267
Train loss: 0.0238;  Loss pred: 0.0238; Loss self: 0.0000; time: 0.12s
Val loss: 0.3298 score: 0.9796 time: 0.07s
Test loss: 0.4269 score: 0.8163 time: 0.06s
Epoch 75/1000, LR 0.000267
Train loss: 0.0226;  Loss pred: 0.0226; Loss self: 0.0000; time: 0.12s
Val loss: 0.3114 score: 0.9796 time: 0.07s
Test loss: 0.4148 score: 0.8367 time: 0.06s
Epoch 76/1000, LR 0.000267
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.12s
Val loss: 0.2934 score: 0.9796 time: 0.07s
Test loss: 0.4031 score: 0.8367 time: 0.06s
Epoch 77/1000, LR 0.000267
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.12s
Val loss: 0.2757 score: 0.9796 time: 0.07s
Test loss: 0.3919 score: 0.8571 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.12s
Val loss: 0.2585 score: 0.9796 time: 0.07s
Test loss: 0.3815 score: 0.8571 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.12s
Val loss: 0.2421 score: 0.9796 time: 0.07s
Test loss: 0.3715 score: 0.8571 time: 0.06s
Epoch 80/1000, LR 0.000267
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.12s
Val loss: 0.2266 score: 0.9796 time: 0.07s
Test loss: 0.3628 score: 0.8571 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.12s
Val loss: 0.2120 score: 0.9796 time: 0.07s
Test loss: 0.3549 score: 0.8571 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.12s
Val loss: 0.1984 score: 0.9796 time: 0.07s
Test loss: 0.3480 score: 0.8571 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.13s
Val loss: 0.1856 score: 0.9796 time: 0.08s
Test loss: 0.3420 score: 0.8571 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.13s
Val loss: 0.1739 score: 0.9796 time: 0.09s
Test loss: 0.3370 score: 0.8571 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.1629 score: 0.9796 time: 0.08s
Test loss: 0.3329 score: 0.8571 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.12s
Val loss: 0.1530 score: 0.9796 time: 0.08s
Test loss: 0.3296 score: 0.8571 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.12s
Val loss: 0.1440 score: 0.9796 time: 0.07s
Test loss: 0.3272 score: 0.8571 time: 0.06s
Epoch 88/1000, LR 0.000266
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.12s
Val loss: 0.1360 score: 0.9796 time: 0.07s
Test loss: 0.3256 score: 0.8571 time: 0.06s
Epoch 89/1000, LR 0.000266
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.12s
Val loss: 0.1288 score: 0.9796 time: 0.07s
Test loss: 0.3249 score: 0.8571 time: 0.06s
Epoch 90/1000, LR 0.000266
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.12s
Val loss: 0.1224 score: 0.9796 time: 0.07s
Test loss: 0.3249 score: 0.8571 time: 0.06s
Epoch 91/1000, LR 0.000266
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.12s
Val loss: 0.1167 score: 0.9796 time: 0.07s
Test loss: 0.3256 score: 0.8571 time: 0.06s
Epoch 92/1000, LR 0.000266
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.12s
Val loss: 0.1117 score: 0.9796 time: 0.07s
Test loss: 0.3268 score: 0.8571 time: 0.06s
Epoch 93/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.12s
Val loss: 0.1072 score: 0.9592 time: 0.07s
Test loss: 0.3287 score: 0.8571 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.1032 score: 0.9388 time: 0.08s
Test loss: 0.3312 score: 0.8571 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.13s
Val loss: 0.0997 score: 0.9388 time: 0.07s
Test loss: 0.3340 score: 0.8571 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.13s
Val loss: 0.0966 score: 0.9388 time: 0.07s
Test loss: 0.3372 score: 0.8571 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.13s
Val loss: 0.0939 score: 0.9388 time: 0.08s
Test loss: 0.3409 score: 0.8571 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.13s
Val loss: 0.0916 score: 0.9388 time: 0.08s
Test loss: 0.3448 score: 0.8571 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.13s
Val loss: 0.0896 score: 0.9388 time: 0.07s
Test loss: 0.3488 score: 0.8571 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.13s
Val loss: 0.0879 score: 0.9388 time: 0.07s
Test loss: 0.3530 score: 0.8571 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.13s
Val loss: 0.0864 score: 0.9388 time: 0.08s
Test loss: 0.3574 score: 0.8571 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.14s
Val loss: 0.0850 score: 0.9388 time: 0.08s
Test loss: 0.3620 score: 0.8571 time: 0.08s
Epoch 103/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.14s
Val loss: 0.0839 score: 0.9388 time: 0.08s
Test loss: 0.3665 score: 0.8571 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.14s
Val loss: 0.0831 score: 0.9388 time: 0.08s
Test loss: 0.3710 score: 0.8571 time: 0.07s
Epoch 105/1000, LR 0.000264
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.14s
Val loss: 0.0824 score: 0.9388 time: 0.08s
Test loss: 0.3753 score: 0.8571 time: 0.07s
Epoch 106/1000, LR 0.000264
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.14s
Val loss: 0.0818 score: 0.9388 time: 0.08s
Test loss: 0.3796 score: 0.8571 time: 0.08s
Epoch 107/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.14s
Val loss: 0.0814 score: 0.9388 time: 0.08s
Test loss: 0.3836 score: 0.8571 time: 0.07s
Epoch 108/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.14s
Val loss: 0.0809 score: 0.9388 time: 0.08s
Test loss: 0.3877 score: 0.8776 time: 0.07s
Epoch 109/1000, LR 0.000264
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.14s
Val loss: 0.0805 score: 0.9388 time: 0.08s
Test loss: 0.3918 score: 0.8776 time: 0.08s
Epoch 110/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.14s
Val loss: 0.0804 score: 0.9388 time: 0.08s
Test loss: 0.3957 score: 0.8776 time: 0.08s
Epoch 111/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.14s
Val loss: 0.0804 score: 0.9388 time: 0.08s
Test loss: 0.3994 score: 0.8776 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.14s
Val loss: 0.0805 score: 0.9388 time: 0.08s
Test loss: 0.4031 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.0806 score: 0.9388 time: 0.07s
Test loss: 0.4063 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.12s
Val loss: 0.0805 score: 0.9388 time: 0.07s
Test loss: 0.4095 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.13s
Val loss: 0.0805 score: 0.9388 time: 0.07s
Test loss: 0.4126 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.12s
Val loss: 0.0804 score: 0.9388 time: 0.07s
Test loss: 0.4158 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.0805 score: 0.9388 time: 0.07s
Test loss: 0.4187 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.12s
Val loss: 0.0806 score: 0.9388 time: 0.07s
Test loss: 0.4212 score: 0.8776 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.13s
Val loss: 0.0806 score: 0.9388 time: 0.07s
Test loss: 0.4237 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.12s
Val loss: 0.0805 score: 0.9388 time: 0.07s
Test loss: 0.4261 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.12s
Val loss: 0.0803 score: 0.9388 time: 0.07s
Test loss: 0.4288 score: 0.8980 time: 0.07s
Epoch 122/1000, LR 0.000262
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.12s
Val loss: 0.0802 score: 0.9388 time: 0.07s
Test loss: 0.4310 score: 0.8980 time: 0.07s
Epoch 123/1000, LR 0.000262
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.12s
Val loss: 0.0801 score: 0.9388 time: 0.07s
Test loss: 0.4329 score: 0.8980 time: 0.06s
Epoch 124/1000, LR 0.000261
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.12s
Val loss: 0.0800 score: 0.9388 time: 0.07s
Test loss: 0.4351 score: 0.8980 time: 0.07s
Epoch 125/1000, LR 0.000261
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.0799 score: 0.9388 time: 0.07s
Test loss: 0.4372 score: 0.8980 time: 0.07s
Epoch 126/1000, LR 0.000261
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.0798 score: 0.9388 time: 0.07s
Test loss: 0.4390 score: 0.8980 time: 0.07s
Epoch 127/1000, LR 0.000261
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.12s
Val loss: 0.0797 score: 0.9388 time: 0.07s
Test loss: 0.4406 score: 0.8980 time: 0.07s
Epoch 128/1000, LR 0.000261
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.13s
Val loss: 0.0796 score: 0.9388 time: 0.07s
Test loss: 0.4422 score: 0.8980 time: 0.07s
Epoch 129/1000, LR 0.000261
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.13s
Val loss: 0.0795 score: 0.9388 time: 0.07s
Test loss: 0.4435 score: 0.8980 time: 0.07s
Epoch 130/1000, LR 0.000260
Train loss: 0.0025;  Loss pred: 0.0025; Loss self: 0.0000; time: 0.13s
Val loss: 0.0795 score: 0.9388 time: 0.07s
Test loss: 0.4450 score: 0.8980 time: 0.07s
Epoch 131/1000, LR 0.000260
Train loss: 0.0022;  Loss pred: 0.0022; Loss self: 0.0000; time: 0.13s
Val loss: 0.0795 score: 0.9388 time: 0.07s
Test loss: 0.4463 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 132/1000, LR 0.000260
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.13s
Val loss: 0.0796 score: 0.9388 time: 0.07s
Test loss: 0.4476 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 133/1000, LR 0.000260
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.12s
Val loss: 0.0797 score: 0.9388 time: 0.07s
Test loss: 0.4491 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 134/1000, LR 0.000260
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.12s
Val loss: 0.0799 score: 0.9388 time: 0.07s
Test loss: 0.4505 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 135/1000, LR 0.000260
Train loss: 0.0020;  Loss pred: 0.0020; Loss self: 0.0000; time: 0.12s
Val loss: 0.0801 score: 0.9388 time: 0.07s
Test loss: 0.4514 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 136/1000, LR 0.000260
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.13s
Val loss: 0.0803 score: 0.9388 time: 0.07s
Test loss: 0.4522 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 137/1000, LR 0.000259
Train loss: 0.0021;  Loss pred: 0.0021; Loss self: 0.0000; time: 0.13s
Val loss: 0.0806 score: 0.9388 time: 0.07s
Test loss: 0.4533 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 138/1000, LR 0.000259
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.13s
Val loss: 0.0808 score: 0.9388 time: 0.07s
Test loss: 0.4545 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 139/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.13s
Val loss: 0.0809 score: 0.9388 time: 0.07s
Test loss: 0.4553 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 140/1000, LR 0.000259
Train loss: 0.0017;  Loss pred: 0.0017; Loss self: 0.0000; time: 0.13s
Val loss: 0.0808 score: 0.9388 time: 0.07s
Test loss: 0.4563 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 141/1000, LR 0.000259
Train loss: 0.0018;  Loss pred: 0.0018; Loss self: 0.0000; time: 0.12s
Val loss: 0.0809 score: 0.9388 time: 0.08s
Test loss: 0.4574 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 142/1000, LR 0.000259
Train loss: 0.0016;  Loss pred: 0.0016; Loss self: 0.0000; time: 0.13s
Val loss: 0.0809 score: 0.9388 time: 0.07s
Test loss: 0.4582 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 143/1000, LR 0.000258
Train loss: 0.0019;  Loss pred: 0.0019; Loss self: 0.0000; time: 0.12s
Val loss: 0.0810 score: 0.9388 time: 0.07s
Test loss: 0.4593 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 144/1000, LR 0.000258
Train loss: 0.0018;  Loss pred: 0.0018; Loss self: 0.0000; time: 0.25s
Val loss: 0.0811 score: 0.9388 time: 0.07s
Test loss: 0.4602 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 145/1000, LR 0.000258
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.12s
Val loss: 0.0812 score: 0.9388 time: 0.07s
Test loss: 0.4611 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 146/1000, LR 0.000258
Train loss: 0.0016;  Loss pred: 0.0016; Loss self: 0.0000; time: 0.12s
Val loss: 0.0812 score: 0.9388 time: 0.07s
Test loss: 0.4621 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 147/1000, LR 0.000258
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.12s
Val loss: 0.0810 score: 0.9388 time: 0.07s
Test loss: 0.4631 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 148/1000, LR 0.000257
Train loss: 0.0013;  Loss pred: 0.0013; Loss self: 0.0000; time: 0.13s
Val loss: 0.0809 score: 0.9388 time: 0.08s
Test loss: 0.4642 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 149/1000, LR 0.000257
Train loss: 0.0014;  Loss pred: 0.0014; Loss self: 0.0000; time: 0.13s
Val loss: 0.0807 score: 0.9388 time: 0.07s
Test loss: 0.4653 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 150/1000, LR 0.000257
Train loss: 0.0015;  Loss pred: 0.0015; Loss self: 0.0000; time: 0.13s
Val loss: 0.0808 score: 0.9388 time: 0.07s
Test loss: 0.4660 score: 0.8980 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 129,   Train_Loss: 0.0025,   Val_Loss: 0.0795,   Val_Precision: 0.9565,   Val_Recall: 0.9167,   Val_accuracy: 0.9362,   Val_Score: 0.9388,   Val_Loss: 0.0795,   Test_Precision: 0.8846,   Test_Recall: 0.9200,   Test_accuracy: 0.9020,   Test_Score: 0.8980,   Test_loss: 0.4450


[0.06632305192761123, 0.07275906705763191, 0.07755232497584075, 0.07238274300470948, 0.07310916495043784, 0.07323813799303025, 0.07302752591203898, 0.07294250000268221, 0.07271825708448887, 0.07775088504422456, 0.07468694297131151, 0.06940282706636935, 0.07082904793787748, 0.07043946604244411, 0.19234758196398616, 0.07019173307344317, 0.07020904694218189, 0.07051032199524343, 0.07121239101979882, 0.07162261405028403, 0.07076394592877477, 0.06712763500399888, 0.06728304398711771, 0.0671779370168224, 0.06765816593542695, 0.06772508495487273, 0.06754313700366765, 0.0659570029238239, 0.20257570396643132, 0.0712679181015119, 0.07123174401931465, 0.07090553699526936, 0.0713410199386999, 0.0727489140117541, 0.0763387760380283, 0.07093409704975784, 0.07062539795879275, 0.07040945102926344, 0.07088812999427319, 0.07180396607145667, 0.07222436496522278, 0.07142476306762546, 0.07100091909524053, 0.07095331698656082, 0.0713082819711417, 0.07671771897003055, 0.07395412400364876, 0.07232438598293811, 0.08641207404434681, 0.0697208009660244, 0.06939286703709513, 0.07063184701837599, 0.07195793592836708, 0.0694445560220629, 0.06955418200232089, 0.07072335400152951, 0.0697105269646272, 0.07047944609075785, 0.07058175897691399, 0.06955186708364636, 0.07022563996724784, 0.07007635897025466, 0.0699755649548024, 0.06998322799336165, 0.07435644802171737, 0.07019258197396994, 0.06964382389560342, 0.06969787494745106, 0.0704094129614532, 0.0699743670411408, 0.06984404602553695, 0.06974442198406905, 0.06943598797079176, 0.06951213895808905, 0.06964036193676293, 0.06948556296993047, 0.07018207397777587, 0.07003150507807732, 0.06983198807574809, 0.07044983399100602, 0.07006003893911839, 0.07608484395314008, 0.07059146696701646, 0.07460321392863989, 0.08071495697367936, 0.07635015901178122, 0.06907740200404078, 0.06922202999703586, 0.0692986719077453, 0.06924141698982567, 0.06904905301053077, 0.06960208900272846, 0.07063215004745871, 0.07193983590696007, 0.0741564859636128, 0.07545729703269899, 0.07582273799926043, 0.07321844296529889, 0.07107004208955914, 0.07805430504959077, 0.07959886197932065, 0.08255606796592474, 0.08121322293300182, 0.0812627850100398, 0.08124391199089587, 0.08250005193985999, 0.08205985301174223, 0.08176352898590267, 0.08248068497050554, 0.0831730340141803, 0.08308264298830181, 0.07417673105373979, 0.07115710794460028, 0.07069294003304094, 0.07347145106177777, 0.07189359294716269, 0.07028038101270795, 0.07208249100949615, 0.07101235107984394, 0.07053598901256919, 0.07155294402036816, 0.07139669300522655, 0.06995076104067266, 0.07048566499724984, 0.0711956339655444, 0.07065302995033562, 0.07231938501354307, 0.07231123000383377, 0.072308205999434, 0.07207843393553048, 0.07112440292257816, 0.07152770599350333, 0.07040830398909748, 0.07230375299695879, 0.07309212407562882, 0.07317774905823171, 0.07308810204267502, 0.07239336194470525, 0.07341051404364407, 0.07322963606566191, 0.07401779806241393, 0.0717745510628447, 0.0717735510552302, 0.07089083094615489, 0.07144772401079535, 0.0713078030385077, 0.07129679899662733, 0.07518392696511, 0.07375179906375706, 0.07365930906962603]
[0.001353531671992066, 0.0014848789195435084, 0.0015827005097110356, 0.0014771988368308057, 0.0014920237744987315, 0.0014946558774087805, 0.001490357671674265, 0.0014886224490343308, 0.0014840460629487525, 0.0015867527560045828, 0.0015242233259451328, 0.0014163842258442725, 0.0014454907742423974, 0.001437540123315186, 0.003925460856407881, 0.0014324843484376157, 0.0014328376926975896, 0.0014389861631682332, 0.0014533141024448738, 0.0014616860010262047, 0.0014441621618117302, 0.0013699517347754873, 0.0013731233466758716, 0.0013709783064657633, 0.0013807788966413662, 0.00138214459091577, 0.0013784313674217888, 0.0013460612841596712, 0.004134198040131251, 0.0014544473081941204, 0.0014537090616186662, 0.0014470517754136603, 0.001455939182422447, 0.0014846717145255938, 0.0015579342048577204, 0.0014476346336685273, 0.00144133465222026, 0.0014369275720257843, 0.001446696530495371, 0.0014653870626827892, 0.001473966631943322, 0.0014576482258699074, 0.0014489983488824598, 0.0014480268772767515, 0.0014552710606355447, 0.001565667734082256, 0.0015092678368091583, 0.0014760078772028185, 0.0017635117151907512, 0.0014228734891025387, 0.001416180959940717, 0.0014414662656811426, 0.0014685293046605525, 0.0014172358371849572, 0.0014194731020881813, 0.0014433337551332554, 0.0014226638156046368, 0.0014383560426685276, 0.0014404440607533467, 0.0014194258588499256, 0.001433176325862201, 0.0014301297749031562, 0.0014280727541796407, 0.0014282291427216663, 0.0015174785310554566, 0.0014325016729381619, 0.0014213025284817023, 0.0014224056111724706, 0.001436926795131698, 0.001428048306962057, 0.0014253886943987133, 0.0014233555506952867, 0.00141706097899575, 0.0014186150807773276, 0.0014212318762604678, 0.0014180727136720503, 0.0014322872240362422, 0.0014292143893485166, 0.0014251426137907772, 0.0014377517141021636, 0.0014297967130432324, 0.001552751917411022, 0.0014406421830003358, 0.0015225145699722426, 0.0016472440198710074, 0.0015581665104445145, 0.0014097428980416485, 0.0014126944897354258, 0.0014142586103621491, 0.0014130901426495034, 0.0014091643471536891, 0.0014204507959740503, 0.001441472449948137, 0.0014681599164685728, 0.0015133976727267917, 0.0015399448374020202, 0.0015474028163114373, 0.0014942539380673244, 0.0014504090222359008, 0.0015929450010120564, 0.0016244665710065439, 0.001684817713590301, 0.0016574127129184045, 0.0016584241838783634, 0.0016580390202223646, 0.0016836745293848977, 0.0016746908777906578, 0.0016686434486918912, 0.001683279285112358, 0.0016974088574322511, 0.0016955641426184044, 0.0015138108378314242, 0.001452185876420414, 0.0014427130618987947, 0.0014994173686077095, 0.0014672161825951568, 0.0014342934900552643, 0.0014710712450917583, 0.0014492316546906925, 0.0014395099798483507, 0.0014602641636809828, 0.001457075367453603, 0.0014275665518504624, 0.0014384829591275478, 0.001452972121745804, 0.0014418985704150126, 0.0014759058166029198, 0.0014757393878333423, 0.0014756776734578367, 0.0014709884476638874, 0.001451518426991391, 0.0014597491019082312, 0.0014369041630428057, 0.001475586795856302, 0.0014916760015434452, 0.001493423450167994, 0.0014915939192382656, 0.0014774155498919438, 0.001498173755992736, 0.0014944823686869778, 0.0015105673073962027, 0.0014647867563845856, 0.0014647663480659224, 0.0014467516519623448, 0.001458116816546844, 0.0014552612865001572, 0.0014550367142168842, 0.0015343658564308164, 0.0015051387564032053, 0.0015032512055025721]
[738.8079796671811, 673.4555840468305, 631.831476558112, 676.9569370535168, 670.2306069727109, 669.0503246363679, 670.9798721514964, 671.7620042937683, 673.8335318332585, 630.2179064859376, 656.0718386722792, 706.0231127637164, 691.806559972072, 695.632757500951, 254.74715876165484, 698.0879065734167, 697.9157549361433, 694.9337148581665, 688.082499383805, 684.1414635550527, 692.4430139794551, 729.9527236000644, 728.2666938996064, 729.4061439804208, 724.2289134288043, 723.5133043044565, 725.4623071081116, 742.9082254782234, 241.88488076595678, 687.5463926167432, 687.8955537957002, 691.060276481217, 686.841876414207, 673.5495734284506, 641.8756304867995, 690.7820362558246, 693.8014002921392, 695.9293004519338, 691.2299704331112, 682.4135584827862, 678.4414099534736, 686.0365774487268, 690.1319113104926, 690.5949162219016, 687.1572087493314, 638.7051212920139, 662.572921526086, 677.5031593294063, 567.0503866722737, 702.8031709486264, 706.1244489841617, 693.7380525707033, 680.9533843324617, 705.5988663018084, 704.4867553523233, 692.8404441754882, 702.9067507245179, 695.2381540697934, 694.2303607937429, 704.510203026905, 697.7508502998741, 699.237242345868, 700.24443577768, 700.1677602617581, 658.9879062766489, 698.0794639834029, 703.5799767894903, 703.0343469860984, 695.92967671561, 700.2564234870591, 701.5630220231545, 702.5651458003699, 705.6859336488716, 704.912850251142, 703.6149531286835, 705.1824566954218, 698.1839837836159, 699.6850909511436, 701.684161517051, 695.5303827437775, 699.4001251209781, 644.0178812770994, 694.134887760514, 656.8081644159447, 607.0745972890575, 641.7799338497651, 709.3492021766203, 707.8671342359971, 707.0842579094711, 707.668937612875, 709.6404347866572, 704.0018583074303, 693.7350762659246, 681.1247118129627, 660.7648591121671, 649.3739098389136, 646.2441385389953, 669.2302924718439, 689.4606863782702, 627.7680644119309, 615.5866903314515, 593.5360199110366, 603.3500239292727, 602.9820414590292, 603.1221146206119, 593.9390200107935, 597.1251251569804, 599.289201527106, 594.078480525738, 589.1332519100591, 589.7742083975264, 660.5845162480985, 688.6170814888821, 693.1385224196086, 666.9257145717568, 681.5628207093773, 697.2073755709993, 679.776729601988, 690.0208098293496, 694.6808386179773, 684.8076018514588, 686.3062970775549, 700.4927361906628, 695.1768136387994, 688.2444508284577, 693.5300585756016, 677.5500094590668, 677.6264211990605, 677.6547602409546, 679.8149921490711, 688.9337271954116, 685.0492311951195, 695.9406380188835, 677.6964952574594, 670.3868661594706, 669.6024492500843, 670.4237575000874, 676.857638376108, 667.4793200721696, 669.1280010740976, 662.0029409505238, 682.6932286500316, 682.7027404885428, 691.2036344618098, 685.8161079084391, 687.1618239807357, 687.2678814418853, 651.7350446823433, 664.3905724610245, 665.2248116213394]
Elapsed: 0.07399947066558525~0.01483624722116357
Time per graph: 0.0015101932788894948~0.00030278055553395044
Speed: 673.3794788398582~59.10909691937106
Total Time: 0.0745
best val loss: 0.0794835016131401 test_score: 0.8980

Testing...
Test loss: 0.4269 score: 0.8163 time: 0.07s
test Score 0.8163
Epoch Time List: [0.41281948308460414, 0.38811845995951444, 0.2691194099606946, 0.2578462631208822, 0.2592018611030653, 0.25946645881049335, 0.2621396060567349, 0.25859534507617354, 0.35423957009334117, 0.26995226298458874, 0.2633811328560114, 0.2621803539805114, 0.25076676497701555, 0.2594373810570687, 0.38312739494722337, 0.2512215368915349, 0.25148590689059347, 0.251044855103828, 0.25236836611293256, 0.2573338628280908, 0.25583059806376696, 0.3745249940548092, 0.25318286602851003, 0.24462226394098252, 0.24492181988898665, 0.24584747676271945, 0.24591726588550955, 0.2429841220146045, 0.3777448032051325, 0.2519837359432131, 0.25330595893319696, 0.2514737988822162, 0.2529685531044379, 0.25327281386125833, 0.25934564997442067, 0.2745620650239289, 0.39732213714160025, 0.24983132106717676, 0.2511101209092885, 0.2522898759925738, 0.2571489429101348, 0.25520558294374496, 0.350181742105633, 0.2520269110100344, 0.2535983950365335, 0.2597151710651815, 0.27975436905398965, 0.2681678170338273, 0.4114964120090008, 0.26715149416122586, 0.25708114507142454, 0.2572442159289494, 0.2575485990382731, 0.2619460889836773, 0.25812800403218716, 0.26142691797576845, 0.2597676559817046, 0.2590520289959386, 0.2633909899741411, 0.25920631911139935, 0.26055669598281384, 0.2605808759108186, 0.2590580808464438, 0.25863800512161106, 0.2643516168463975, 0.2602966690901667, 0.2591591428499669, 0.2591684340732172, 0.2596386701334268, 0.2589373431401327, 0.2581608289619908, 0.25869054184295237, 0.2589627970010042, 0.2594492509961128, 0.258067018003203, 0.25833792972844094, 0.2588292360305786, 0.2592153260484338, 0.26088436401914805, 0.26149500685278326, 0.2601877710549161, 0.26483053795527667, 0.2779159920755774, 0.29623423994053155, 0.2828466729260981, 0.27197478082962334, 0.2567343859700486, 0.2579446348827332, 0.2564589697867632, 0.2565314080566168, 0.25783187802881, 0.2575269879307598, 0.2594300889177248, 0.2642907170811668, 0.26776262803468853, 0.2742969299433753, 0.27712828398216516, 0.27221162407658994, 0.2652925349539146, 0.2713342810748145, 0.28651070303749293, 0.29528340185061097, 0.2939221929991618, 0.29208509519230574, 0.29305398603901267, 0.29404220287688076, 0.2944203879451379, 0.29530825500842184, 0.29817844391800463, 0.2997472679708153, 0.30171862593851984, 0.29459100286476314, 0.2630853889277205, 0.2621434339089319, 0.26786335196811706, 0.2634581960737705, 0.2618913418846205, 0.26424422510899603, 0.26616798900067806, 0.26314077188726515, 0.2625994828995317, 0.2624753098934889, 0.2610034290701151, 0.25835143006406724, 0.26074008480645716, 0.26271010108757764, 0.2632876959396526, 0.2700118670472875, 0.26631086703855544, 0.2653937239665538, 0.2646518930559978, 0.2661338800098747, 0.2630532290786505, 0.2638908149674535, 0.264156905002892, 0.2686837799847126, 0.26723822695203125, 0.2667768821120262, 0.26894412806723267, 0.26925829192623496, 0.2693120810436085, 0.26585454086307436, 0.26084702415391803, 0.3843881539069116, 0.2602784769842401, 0.2610177960013971, 0.2621824690140784, 0.27297636307775974, 0.26947351987473667, 0.26671765896026045]
Total Epoch List: [150]
Total Time List: [0.07448487903457135]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d08248640>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6945;  Loss pred: 0.6945; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6980;  Loss pred: 0.6980; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6966;  Loss pred: 0.6966; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6971;  Loss pred: 0.6971; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6933;  Loss pred: 0.6933; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6899;  Loss pred: 0.6899; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.09s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6861;  Loss pred: 0.6861; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6858;  Loss pred: 0.6858; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6795;  Loss pred: 0.6795; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.4898 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6743;  Loss pred: 0.6743; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.4898 time: 0.08s
Epoch 11/1000, LR 0.000270
Train loss: 0.6727;  Loss pred: 0.6727; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.4898 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6661;  Loss pred: 0.6661; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6602;  Loss pred: 0.6602; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.4898 time: 0.21s
Epoch 14/1000, LR 0.000270
Train loss: 0.6540;  Loss pred: 0.6540; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5102 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4898 time: 0.08s
Epoch 15/1000, LR 0.000270
Train loss: 0.6496;  Loss pred: 0.6496; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4898 time: 0.08s
Epoch 16/1000, LR 0.000270
Train loss: 0.6450;  Loss pred: 0.6450; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.4898 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6369;  Loss pred: 0.6369; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4898 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6324;  Loss pred: 0.6324; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4898 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6278;  Loss pred: 0.6278; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6179;  Loss pred: 0.6179; Loss self: 0.0000; time: 0.24s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4898 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6119;  Loss pred: 0.6119; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4898 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6069;  Loss pred: 0.6069; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4898 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6019;  Loss pred: 0.6019; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4898 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.5926;  Loss pred: 0.5926; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4898 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5803;  Loss pred: 0.5803; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5709;  Loss pred: 0.5709; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4898 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5633;  Loss pred: 0.5633; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5102 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4898 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5535;  Loss pred: 0.5535; Loss self: 0.0000; time: 0.24s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4898 time: 0.09s
Epoch 29/1000, LR 0.000270
Train loss: 0.5384;  Loss pred: 0.5384; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.4898 time: 0.09s
Epoch 30/1000, LR 0.000270
Train loss: 0.5250;  Loss pred: 0.5250; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.4898 time: 0.10s
Epoch 31/1000, LR 0.000270
Train loss: 0.5202;  Loss pred: 0.5202; Loss self: 0.0000; time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.4898 time: 0.09s
Epoch 32/1000, LR 0.000270
Train loss: 0.5092;  Loss pred: 0.5092; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.4898 time: 0.09s
Epoch 33/1000, LR 0.000270
Train loss: 0.4937;  Loss pred: 0.4937; Loss self: 0.0000; time: 0.27s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6887 score: 0.4898 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.4788;  Loss pred: 0.4788; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6872 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.4898 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4664;  Loss pred: 0.4664; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6862 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6863 score: 0.4898 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4531;  Loss pred: 0.4531; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6850 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6847 score: 0.4898 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4371;  Loss pred: 0.4371; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6837 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6830 score: 0.4898 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4283;  Loss pred: 0.4283; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6822 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6811 score: 0.4898 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4111;  Loss pred: 0.4111; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6806 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6789 score: 0.4898 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3975;  Loss pred: 0.3975; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6787 score: 0.5102 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6764 score: 0.4898 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3792;  Loss pred: 0.3792; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6766 score: 0.5102 time: 0.07s
Test loss: 0.6735 score: 0.5306 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3625;  Loss pred: 0.3625; Loss self: 0.0000; time: 0.12s
Val loss: 0.6742 score: 0.5306 time: 0.07s
Test loss: 0.6703 score: 0.5306 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3500;  Loss pred: 0.3500; Loss self: 0.0000; time: 0.12s
Val loss: 0.6715 score: 0.5510 time: 0.07s
Test loss: 0.6668 score: 0.5510 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3311;  Loss pred: 0.3311; Loss self: 0.0000; time: 0.12s
Val loss: 0.6685 score: 0.5918 time: 0.07s
Test loss: 0.6627 score: 0.5714 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3156;  Loss pred: 0.3156; Loss self: 0.0000; time: 0.12s
Val loss: 0.6652 score: 0.5918 time: 0.07s
Test loss: 0.6583 score: 0.6122 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3035;  Loss pred: 0.3035; Loss self: 0.0000; time: 0.13s
Val loss: 0.6615 score: 0.5918 time: 0.07s
Test loss: 0.6534 score: 0.6122 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.2837;  Loss pred: 0.2837; Loss self: 0.0000; time: 0.13s
Val loss: 0.6574 score: 0.5918 time: 0.07s
Test loss: 0.6480 score: 0.6531 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2707;  Loss pred: 0.2707; Loss self: 0.0000; time: 0.13s
Val loss: 0.6529 score: 0.6122 time: 0.18s
Test loss: 0.6420 score: 0.6531 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2563;  Loss pred: 0.2563; Loss self: 0.0000; time: 0.12s
Val loss: 0.6479 score: 0.6327 time: 0.07s
Test loss: 0.6353 score: 0.6735 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2360;  Loss pred: 0.2360; Loss self: 0.0000; time: 0.12s
Val loss: 0.6424 score: 0.6531 time: 0.07s
Test loss: 0.6280 score: 0.7347 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2231;  Loss pred: 0.2231; Loss self: 0.0000; time: 0.12s
Val loss: 0.6364 score: 0.7755 time: 0.07s
Test loss: 0.6199 score: 0.7347 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2082;  Loss pred: 0.2082; Loss self: 0.0000; time: 0.13s
Val loss: 0.6300 score: 0.7959 time: 0.07s
Test loss: 0.6112 score: 0.7755 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.1976;  Loss pred: 0.1976; Loss self: 0.0000; time: 0.13s
Val loss: 0.6231 score: 0.8163 time: 0.07s
Test loss: 0.6018 score: 0.8571 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1842;  Loss pred: 0.1842; Loss self: 0.0000; time: 0.13s
Val loss: 0.6158 score: 0.7959 time: 0.19s
Test loss: 0.5919 score: 0.8776 time: 0.08s
Epoch 55/1000, LR 0.000269
Train loss: 0.1733;  Loss pred: 0.1733; Loss self: 0.0000; time: 0.13s
Val loss: 0.6080 score: 0.8163 time: 0.07s
Test loss: 0.5811 score: 0.9388 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1596;  Loss pred: 0.1596; Loss self: 0.0000; time: 0.12s
Val loss: 0.5997 score: 0.8367 time: 0.07s
Test loss: 0.5697 score: 0.9592 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1486;  Loss pred: 0.1486; Loss self: 0.0000; time: 0.12s
Val loss: 0.5910 score: 0.8571 time: 0.07s
Test loss: 0.5576 score: 0.9592 time: 0.08s
Epoch 58/1000, LR 0.000269
Train loss: 0.1347;  Loss pred: 0.1347; Loss self: 0.0000; time: 0.12s
Val loss: 0.5819 score: 0.8571 time: 0.07s
Test loss: 0.5450 score: 0.9592 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1266;  Loss pred: 0.1266; Loss self: 0.0000; time: 0.13s
Val loss: 0.5724 score: 0.8571 time: 0.07s
Test loss: 0.5317 score: 0.9592 time: 0.08s
Epoch 60/1000, LR 0.000268
Train loss: 0.1170;  Loss pred: 0.1170; Loss self: 0.0000; time: 0.12s
Val loss: 0.5624 score: 0.8980 time: 0.07s
Test loss: 0.5177 score: 0.9592 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1075;  Loss pred: 0.1075; Loss self: 0.0000; time: 0.12s
Val loss: 0.5521 score: 0.8980 time: 0.19s
Test loss: 0.5033 score: 1.0000 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0972;  Loss pred: 0.0972; Loss self: 0.0000; time: 0.12s
Val loss: 0.5415 score: 0.8980 time: 0.07s
Test loss: 0.4884 score: 1.0000 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0937;  Loss pred: 0.0937; Loss self: 0.0000; time: 0.12s
Val loss: 0.5307 score: 0.8980 time: 0.07s
Test loss: 0.4729 score: 1.0000 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0825;  Loss pred: 0.0825; Loss self: 0.0000; time: 0.12s
Val loss: 0.5198 score: 0.8980 time: 0.07s
Test loss: 0.4572 score: 1.0000 time: 0.08s
Epoch 65/1000, LR 0.000268
Train loss: 0.0756;  Loss pred: 0.0756; Loss self: 0.0000; time: 0.12s
Val loss: 0.5084 score: 0.9184 time: 0.07s
Test loss: 0.4406 score: 0.9796 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0694;  Loss pred: 0.0694; Loss self: 0.0000; time: 0.13s
Val loss: 0.4973 score: 0.9184 time: 0.07s
Test loss: 0.4239 score: 0.9796 time: 0.08s
Epoch 67/1000, LR 0.000268
Train loss: 0.0613;  Loss pred: 0.0613; Loss self: 0.0000; time: 0.13s
Val loss: 0.4862 score: 0.9184 time: 0.07s
Test loss: 0.4069 score: 0.9796 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0553;  Loss pred: 0.0553; Loss self: 0.0000; time: 0.13s
Val loss: 0.4754 score: 0.9184 time: 0.07s
Test loss: 0.3898 score: 0.9796 time: 0.16s
Epoch 69/1000, LR 0.000268
Train loss: 0.0508;  Loss pred: 0.0508; Loss self: 0.0000; time: 0.13s
Val loss: 0.4649 score: 0.9184 time: 0.07s
Test loss: 0.3725 score: 0.9796 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0462;  Loss pred: 0.0462; Loss self: 0.0000; time: 0.13s
Val loss: 0.4548 score: 0.9184 time: 0.07s
Test loss: 0.3553 score: 0.9796 time: 0.08s
Epoch 71/1000, LR 0.000268
Train loss: 0.0447;  Loss pred: 0.0447; Loss self: 0.0000; time: 0.13s
Val loss: 0.4453 score: 0.8980 time: 0.07s
Test loss: 0.3385 score: 0.9796 time: 0.08s
Epoch 72/1000, LR 0.000267
Train loss: 0.0408;  Loss pred: 0.0408; Loss self: 0.0000; time: 0.13s
Val loss: 0.4363 score: 0.8776 time: 0.07s
Test loss: 0.3221 score: 0.9796 time: 0.08s
Epoch 73/1000, LR 0.000267
Train loss: 0.0398;  Loss pred: 0.0398; Loss self: 0.0000; time: 0.13s
Val loss: 0.4274 score: 0.8776 time: 0.07s
Test loss: 0.3061 score: 0.9796 time: 0.08s
Epoch 74/1000, LR 0.000267
Train loss: 0.0331;  Loss pred: 0.0331; Loss self: 0.0000; time: 0.13s
Val loss: 0.4189 score: 0.8776 time: 0.07s
Test loss: 0.2905 score: 0.9796 time: 0.11s
Epoch 75/1000, LR 0.000267
Train loss: 0.0297;  Loss pred: 0.0297; Loss self: 0.0000; time: 0.18s
Val loss: 0.4112 score: 0.8571 time: 0.07s
Test loss: 0.2754 score: 0.9796 time: 0.08s
Epoch 76/1000, LR 0.000267
Train loss: 0.0287;  Loss pred: 0.0287; Loss self: 0.0000; time: 0.12s
Val loss: 0.4043 score: 0.8367 time: 0.07s
Test loss: 0.2611 score: 0.9796 time: 0.08s
Epoch 77/1000, LR 0.000267
Train loss: 0.0236;  Loss pred: 0.0236; Loss self: 0.0000; time: 0.12s
Val loss: 0.3981 score: 0.8367 time: 0.07s
Test loss: 0.2471 score: 0.9796 time: 0.08s
Epoch 78/1000, LR 0.000267
Train loss: 0.0235;  Loss pred: 0.0235; Loss self: 0.0000; time: 0.12s
Val loss: 0.3927 score: 0.8367 time: 0.07s
Test loss: 0.2337 score: 0.9592 time: 0.08s
Epoch 79/1000, LR 0.000267
Train loss: 0.0217;  Loss pred: 0.0217; Loss self: 0.0000; time: 0.13s
Val loss: 0.3879 score: 0.8367 time: 0.07s
Test loss: 0.2208 score: 0.9592 time: 0.08s
Epoch 80/1000, LR 0.000267
Train loss: 0.0184;  Loss pred: 0.0184; Loss self: 0.0000; time: 0.12s
Val loss: 0.3843 score: 0.8367 time: 0.07s
Test loss: 0.2086 score: 0.9592 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.12s
Val loss: 0.3813 score: 0.8367 time: 0.09s
Test loss: 0.1971 score: 0.9592 time: 0.13s
Epoch 82/1000, LR 0.000267
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.13s
Val loss: 0.3790 score: 0.8367 time: 0.07s
Test loss: 0.1860 score: 0.9592 time: 0.08s
Epoch 83/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.12s
Val loss: 0.3777 score: 0.8367 time: 0.07s
Test loss: 0.1756 score: 0.9592 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0135;  Loss pred: 0.0135; Loss self: 0.0000; time: 0.12s
Val loss: 0.3770 score: 0.8367 time: 0.07s
Test loss: 0.1658 score: 0.9592 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0125;  Loss pred: 0.0125; Loss self: 0.0000; time: 0.13s
Val loss: 0.3771 score: 0.8367 time: 0.07s
Test loss: 0.1567 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 86/1000, LR 0.000266
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.14s
Val loss: 0.3782 score: 0.8367 time: 0.07s
Test loss: 0.1482 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 87/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.13s
Val loss: 0.3795 score: 0.8367 time: 0.07s
Test loss: 0.1403 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0110;  Loss pred: 0.0110; Loss self: 0.0000; time: 0.14s
Val loss: 0.3815 score: 0.8367 time: 0.17s
Test loss: 0.1330 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.12s
Val loss: 0.3841 score: 0.8367 time: 0.08s
Test loss: 0.1262 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.13s
Val loss: 0.3879 score: 0.8367 time: 0.07s
Test loss: 0.1202 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.13s
Val loss: 0.3919 score: 0.8367 time: 0.07s
Test loss: 0.1146 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.13s
Val loss: 0.3964 score: 0.8367 time: 0.08s
Test loss: 0.1095 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.13s
Val loss: 0.4013 score: 0.8367 time: 0.07s
Test loss: 0.1051 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.14s
Val loss: 0.4067 score: 0.8367 time: 0.08s
Test loss: 0.1010 score: 0.9592 time: 0.22s
     INFO: Early stopping counter 10 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.14s
Val loss: 0.4120 score: 0.8367 time: 0.08s
Test loss: 0.0974 score: 0.9592 time: 0.09s
     INFO: Early stopping counter 11 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.13s
Val loss: 0.4172 score: 0.8367 time: 0.07s
Test loss: 0.0939 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.13s
Val loss: 0.4226 score: 0.8367 time: 0.07s
Test loss: 0.0910 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.13s
Val loss: 0.4285 score: 0.8367 time: 0.07s
Test loss: 0.0884 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.12s
Val loss: 0.4339 score: 0.8367 time: 0.07s
Test loss: 0.0860 score: 0.9592 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.12s
Val loss: 0.4401 score: 0.8367 time: 0.07s
Test loss: 0.0842 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.28s
Val loss: 0.4467 score: 0.8367 time: 0.07s
Test loss: 0.0826 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.13s
Val loss: 0.4531 score: 0.8367 time: 0.07s
Test loss: 0.0812 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.12s
Val loss: 0.4596 score: 0.8367 time: 0.07s
Test loss: 0.0800 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.12s
Val loss: 0.4659 score: 0.8367 time: 0.07s
Test loss: 0.0789 score: 0.9592 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 083,   Train_Loss: 0.0135,   Val_Loss: 0.3770,   Val_Precision: 1.0000,   Val_Recall: 0.6800,   Val_accuracy: 0.8095,   Val_Score: 0.8367,   Val_Loss: 0.3770,   Test_Precision: 1.0000,   Test_Recall: 0.9167,   Test_accuracy: 0.9565,   Test_Score: 0.9592,   Test_loss: 0.1658


[0.06632305192761123, 0.07275906705763191, 0.07755232497584075, 0.07238274300470948, 0.07310916495043784, 0.07323813799303025, 0.07302752591203898, 0.07294250000268221, 0.07271825708448887, 0.07775088504422456, 0.07468694297131151, 0.06940282706636935, 0.07082904793787748, 0.07043946604244411, 0.19234758196398616, 0.07019173307344317, 0.07020904694218189, 0.07051032199524343, 0.07121239101979882, 0.07162261405028403, 0.07076394592877477, 0.06712763500399888, 0.06728304398711771, 0.0671779370168224, 0.06765816593542695, 0.06772508495487273, 0.06754313700366765, 0.0659570029238239, 0.20257570396643132, 0.0712679181015119, 0.07123174401931465, 0.07090553699526936, 0.0713410199386999, 0.0727489140117541, 0.0763387760380283, 0.07093409704975784, 0.07062539795879275, 0.07040945102926344, 0.07088812999427319, 0.07180396607145667, 0.07222436496522278, 0.07142476306762546, 0.07100091909524053, 0.07095331698656082, 0.0713082819711417, 0.07671771897003055, 0.07395412400364876, 0.07232438598293811, 0.08641207404434681, 0.0697208009660244, 0.06939286703709513, 0.07063184701837599, 0.07195793592836708, 0.0694445560220629, 0.06955418200232089, 0.07072335400152951, 0.0697105269646272, 0.07047944609075785, 0.07058175897691399, 0.06955186708364636, 0.07022563996724784, 0.07007635897025466, 0.0699755649548024, 0.06998322799336165, 0.07435644802171737, 0.07019258197396994, 0.06964382389560342, 0.06969787494745106, 0.0704094129614532, 0.0699743670411408, 0.06984404602553695, 0.06974442198406905, 0.06943598797079176, 0.06951213895808905, 0.06964036193676293, 0.06948556296993047, 0.07018207397777587, 0.07003150507807732, 0.06983198807574809, 0.07044983399100602, 0.07006003893911839, 0.07608484395314008, 0.07059146696701646, 0.07460321392863989, 0.08071495697367936, 0.07635015901178122, 0.06907740200404078, 0.06922202999703586, 0.0692986719077453, 0.06924141698982567, 0.06904905301053077, 0.06960208900272846, 0.07063215004745871, 0.07193983590696007, 0.0741564859636128, 0.07545729703269899, 0.07582273799926043, 0.07321844296529889, 0.07107004208955914, 0.07805430504959077, 0.07959886197932065, 0.08255606796592474, 0.08121322293300182, 0.0812627850100398, 0.08124391199089587, 0.08250005193985999, 0.08205985301174223, 0.08176352898590267, 0.08248068497050554, 0.0831730340141803, 0.08308264298830181, 0.07417673105373979, 0.07115710794460028, 0.07069294003304094, 0.07347145106177777, 0.07189359294716269, 0.07028038101270795, 0.07208249100949615, 0.07101235107984394, 0.07053598901256919, 0.07155294402036816, 0.07139669300522655, 0.06995076104067266, 0.07048566499724984, 0.0711956339655444, 0.07065302995033562, 0.07231938501354307, 0.07231123000383377, 0.072308205999434, 0.07207843393553048, 0.07112440292257816, 0.07152770599350333, 0.07040830398909748, 0.07230375299695879, 0.07309212407562882, 0.07317774905823171, 0.07308810204267502, 0.07239336194470525, 0.07341051404364407, 0.07322963606566191, 0.07401779806241393, 0.0717745510628447, 0.0717735510552302, 0.07089083094615489, 0.07144772401079535, 0.0713078030385077, 0.07129679899662733, 0.07518392696511, 0.07375179906375706, 0.07365930906962603, 0.07825947203673422, 0.09066086390521377, 0.0877621800173074, 0.08683861594181508, 0.07987320504616946, 0.09963619196787477, 0.08156681596301496, 0.07642738509457558, 0.08029586402699351, 0.08092844998463988, 0.08335009193979204, 0.07679609907791018, 0.21232727100141346, 0.08871484699193388, 0.08049315598327667, 0.07918403996154666, 0.07840350503101945, 0.07955480902455747, 0.08160649100318551, 0.07634575106203556, 0.07980679301545024, 0.0790697030024603, 0.08058050798717886, 0.07796399190556258, 0.07776730298064649, 0.07639403501525521, 0.07983413501642644, 0.0948510350426659, 0.10065252997446805, 0.1024332590168342, 0.0978159629739821, 0.09536798403132707, 0.09198389598168433, 0.09176382201258093, 0.07869177602697164, 0.07943619298748672, 0.08299350796733052, 0.07966549694538116, 0.08003878896124661, 0.07898476393893361, 0.0790595900034532, 0.07978112797718495, 0.07857277593575418, 0.07935075392015278, 0.07971862598787993, 0.08105668099597096, 0.07914406294003129, 0.08270924701355398, 0.08009253698401153, 0.07833021797705442, 0.07999360398389399, 0.08025067893322557, 0.07883075997233391, 0.08124123991001397, 0.07941512006800622, 0.07942843995988369, 0.08091909904032946, 0.07947951299138367, 0.08021878194995224, 0.07896876998711377, 0.07945540500804782, 0.0774443669943139, 0.07885204395279288, 0.08025511296000332, 0.07852007797919214, 0.08018402301240712, 0.07991601096000522, 0.16577494400553405, 0.08341967407613993, 0.08285489701665938, 0.08416747092269361, 0.08726413396652788, 0.08464200794696808, 0.11505392892286181, 0.08029421197716147, 0.08225264400243759, 0.08102610195055604, 0.08203664794564247, 0.08056334499269724, 0.07925657695159316, 0.13469268602784723, 0.08032684295903891, 0.08167860994581133, 0.08227765199262649, 0.08408421406056732, 0.08379087608773261, 0.0820220080204308, 0.08150319301057607, 0.08357071003410965, 0.0834547959966585, 0.08327243709936738, 0.08822541800327599, 0.08617323997896165, 0.22471190604846925, 0.09176072000991553, 0.08169727004133165, 0.0808317851042375, 0.08071213203947991, 0.08091370901092887, 0.08008942706510425, 0.07840342202689499, 0.07945831003598869, 0.07810998905915767, 0.07854565908201039]
[0.001353531671992066, 0.0014848789195435084, 0.0015827005097110356, 0.0014771988368308057, 0.0014920237744987315, 0.0014946558774087805, 0.001490357671674265, 0.0014886224490343308, 0.0014840460629487525, 0.0015867527560045828, 0.0015242233259451328, 0.0014163842258442725, 0.0014454907742423974, 0.001437540123315186, 0.003925460856407881, 0.0014324843484376157, 0.0014328376926975896, 0.0014389861631682332, 0.0014533141024448738, 0.0014616860010262047, 0.0014441621618117302, 0.0013699517347754873, 0.0013731233466758716, 0.0013709783064657633, 0.0013807788966413662, 0.00138214459091577, 0.0013784313674217888, 0.0013460612841596712, 0.004134198040131251, 0.0014544473081941204, 0.0014537090616186662, 0.0014470517754136603, 0.001455939182422447, 0.0014846717145255938, 0.0015579342048577204, 0.0014476346336685273, 0.00144133465222026, 0.0014369275720257843, 0.001446696530495371, 0.0014653870626827892, 0.001473966631943322, 0.0014576482258699074, 0.0014489983488824598, 0.0014480268772767515, 0.0014552710606355447, 0.001565667734082256, 0.0015092678368091583, 0.0014760078772028185, 0.0017635117151907512, 0.0014228734891025387, 0.001416180959940717, 0.0014414662656811426, 0.0014685293046605525, 0.0014172358371849572, 0.0014194731020881813, 0.0014433337551332554, 0.0014226638156046368, 0.0014383560426685276, 0.0014404440607533467, 0.0014194258588499256, 0.001433176325862201, 0.0014301297749031562, 0.0014280727541796407, 0.0014282291427216663, 0.0015174785310554566, 0.0014325016729381619, 0.0014213025284817023, 0.0014224056111724706, 0.001436926795131698, 0.001428048306962057, 0.0014253886943987133, 0.0014233555506952867, 0.00141706097899575, 0.0014186150807773276, 0.0014212318762604678, 0.0014180727136720503, 0.0014322872240362422, 0.0014292143893485166, 0.0014251426137907772, 0.0014377517141021636, 0.0014297967130432324, 0.001552751917411022, 0.0014406421830003358, 0.0015225145699722426, 0.0016472440198710074, 0.0015581665104445145, 0.0014097428980416485, 0.0014126944897354258, 0.0014142586103621491, 0.0014130901426495034, 0.0014091643471536891, 0.0014204507959740503, 0.001441472449948137, 0.0014681599164685728, 0.0015133976727267917, 0.0015399448374020202, 0.0015474028163114373, 0.0014942539380673244, 0.0014504090222359008, 0.0015929450010120564, 0.0016244665710065439, 0.001684817713590301, 0.0016574127129184045, 0.0016584241838783634, 0.0016580390202223646, 0.0016836745293848977, 0.0016746908777906578, 0.0016686434486918912, 0.001683279285112358, 0.0016974088574322511, 0.0016955641426184044, 0.0015138108378314242, 0.001452185876420414, 0.0014427130618987947, 0.0014994173686077095, 0.0014672161825951568, 0.0014342934900552643, 0.0014710712450917583, 0.0014492316546906925, 0.0014395099798483507, 0.0014602641636809828, 0.001457075367453603, 0.0014275665518504624, 0.0014384829591275478, 0.001452972121745804, 0.0014418985704150126, 0.0014759058166029198, 0.0014757393878333423, 0.0014756776734578367, 0.0014709884476638874, 0.001451518426991391, 0.0014597491019082312, 0.0014369041630428057, 0.001475586795856302, 0.0014916760015434452, 0.001493423450167994, 0.0014915939192382656, 0.0014774155498919438, 0.001498173755992736, 0.0014944823686869778, 0.0015105673073962027, 0.0014647867563845856, 0.0014647663480659224, 0.0014467516519623448, 0.001458116816546844, 0.0014552612865001572, 0.0014550367142168842, 0.0015343658564308164, 0.0015051387564032053, 0.0015032512055025721, 0.001597132082382331, 0.0018502217123513014, 0.001791064898312396, 0.001772216651873777, 0.0016300654091054992, 0.0020333916728137707, 0.001664628897204387, 0.0015597425529505222, 0.0016386911025917043, 0.0016516010200946915, 0.0017010222844855518, 0.001567267328120616, 0.004333209612273744, 0.0018105070814680383, 0.0016427174690464626, 0.0016160008155417685, 0.001600071531245295, 0.0016235675311134178, 0.001665438591901745, 0.00155807655228644, 0.0016287100615398008, 0.0016136674082134754, 0.0016445001630036502, 0.001591101875623726, 0.001587087815931561, 0.001559061939086841, 0.0016292680615597234, 0.001935735409033998, 0.0020541332647850625, 0.0020904746738129427, 0.001996244142326165, 0.00194628538839443, 0.0018772223669731496, 0.0018727310614812436, 0.0016059546127953396, 0.0016211467956629942, 0.0016937450605577656, 0.001625826468273085, 0.0016334446726785023, 0.0016119339579374206, 0.0016134610204786366, 0.0016281862852486726, 0.0016035260395051874, 0.001619403141227608, 0.0016269107344465293, 0.0016542179795096116, 0.0016151849579598223, 0.0016879438166031424, 0.0016345415711022761, 0.001598575877082743, 0.0016325225302835508, 0.00163776895782093, 0.0016087910198435492, 0.0016579844879594688, 0.0016207167360817595, 0.0016209885706098713, 0.0016514101844965195, 0.001622030877375177, 0.0016371179989786173, 0.001611607550757424, 0.0016215388777152616, 0.0015804972855982427, 0.0016092253867916915, 0.001637859448163333, 0.0016024505710039213, 0.0016364086329062678, 0.0016309389991837802, 0.0033831621225619193, 0.0017024423280844884, 0.0016909162656461097, 0.001717703488218237, 0.0017809006931944465, 0.0017273879172850627, 0.00234803936577269, 0.0016386573872890096, 0.0016786253878048488, 0.0016535939173582866, 0.0016742173050131118, 0.0016441498978101478, 0.0016174811622774114, 0.002748830327098923, 0.0016393233256946718, 0.001666910407057374, 0.001679135754951561, 0.0017160043685830065, 0.0017100178793414819, 0.0016739185310292001, 0.0016633304696035932, 0.0017055246945736663, 0.0017031591019726225, 0.0016994374918238241, 0.0018005187347607345, 0.001758637550591054, 0.00458595726629529, 0.0018726677553043986, 0.001667291225333299, 0.0016496282674334183, 0.0016471863681526513, 0.0016513001838965075, 0.0016344781033694744, 0.0016000698372835712, 0.0016215981639997692, 0.0015940814093705646, 0.0016029726343267426]
[738.8079796671811, 673.4555840468305, 631.831476558112, 676.9569370535168, 670.2306069727109, 669.0503246363679, 670.9798721514964, 671.7620042937683, 673.8335318332585, 630.2179064859376, 656.0718386722792, 706.0231127637164, 691.806559972072, 695.632757500951, 254.74715876165484, 698.0879065734167, 697.9157549361433, 694.9337148581665, 688.082499383805, 684.1414635550527, 692.4430139794551, 729.9527236000644, 728.2666938996064, 729.4061439804208, 724.2289134288043, 723.5133043044565, 725.4623071081116, 742.9082254782234, 241.88488076595678, 687.5463926167432, 687.8955537957002, 691.060276481217, 686.841876414207, 673.5495734284506, 641.8756304867995, 690.7820362558246, 693.8014002921392, 695.9293004519338, 691.2299704331112, 682.4135584827862, 678.4414099534736, 686.0365774487268, 690.1319113104926, 690.5949162219016, 687.1572087493314, 638.7051212920139, 662.572921526086, 677.5031593294063, 567.0503866722737, 702.8031709486264, 706.1244489841617, 693.7380525707033, 680.9533843324617, 705.5988663018084, 704.4867553523233, 692.8404441754882, 702.9067507245179, 695.2381540697934, 694.2303607937429, 704.510203026905, 697.7508502998741, 699.237242345868, 700.24443577768, 700.1677602617581, 658.9879062766489, 698.0794639834029, 703.5799767894903, 703.0343469860984, 695.92967671561, 700.2564234870591, 701.5630220231545, 702.5651458003699, 705.6859336488716, 704.912850251142, 703.6149531286835, 705.1824566954218, 698.1839837836159, 699.6850909511436, 701.684161517051, 695.5303827437775, 699.4001251209781, 644.0178812770994, 694.134887760514, 656.8081644159447, 607.0745972890575, 641.7799338497651, 709.3492021766203, 707.8671342359971, 707.0842579094711, 707.668937612875, 709.6404347866572, 704.0018583074303, 693.7350762659246, 681.1247118129627, 660.7648591121671, 649.3739098389136, 646.2441385389953, 669.2302924718439, 689.4606863782702, 627.7680644119309, 615.5866903314515, 593.5360199110366, 603.3500239292727, 602.9820414590292, 603.1221146206119, 593.9390200107935, 597.1251251569804, 599.289201527106, 594.078480525738, 589.1332519100591, 589.7742083975264, 660.5845162480985, 688.6170814888821, 693.1385224196086, 666.9257145717568, 681.5628207093773, 697.2073755709993, 679.776729601988, 690.0208098293496, 694.6808386179773, 684.8076018514588, 686.3062970775549, 700.4927361906628, 695.1768136387994, 688.2444508284577, 693.5300585756016, 677.5500094590668, 677.6264211990605, 677.6547602409546, 679.8149921490711, 688.9337271954116, 685.0492311951195, 695.9406380188835, 677.6964952574594, 670.3868661594706, 669.6024492500843, 670.4237575000874, 676.857638376108, 667.4793200721696, 669.1280010740976, 662.0029409505238, 682.6932286500316, 682.7027404885428, 691.2036344618098, 685.8161079084391, 687.1618239807357, 687.2678814418853, 651.7350446823433, 664.3905724610245, 665.2248116213394, 626.1222919699725, 540.4757674847402, 558.3270605896163, 564.265096450083, 613.4723149230873, 491.78916849611073, 600.7344950453648, 641.1314470508787, 610.2431375983126, 605.4731062969838, 587.8817750482526, 638.0532421352437, 230.77581965283116, 552.3314491480234, 608.7474071731053, 618.8115688943803, 624.9720593564498, 615.9275674318366, 600.4424329197941, 641.8169880886302, 613.9828221203403, 619.7063873943644, 608.0875043353707, 628.495268166277, 630.084857285, 641.4113351941043, 613.7725421577862, 516.5995287026527, 486.82333183705913, 478.3602559394033, 500.9407310444148, 513.799263953238, 532.7019417589878, 533.9795022190993, 622.6826038747078, 616.8472853138718, 590.4076258505462, 615.0717924171678, 612.2031659390168, 620.3728106079285, 619.7856578545343, 614.1803361568484, 623.6256695329861, 617.5114611930036, 614.6618734679364, 604.5152527579511, 619.1241412148385, 592.436780278874, 611.7923322841131, 625.5567936036354, 612.5489734137459, 610.5867346090814, 621.5847724568026, 603.1419517264181, 617.0109666526905, 616.9074959139076, 605.5430742695094, 616.5110750654959, 610.82951908408, 620.4984579093214, 616.6981339411325, 632.7122539925682, 621.4169924286973, 610.5530002109659, 624.0442095967483, 611.0943073088024, 613.1437169020179, 295.5814601171829, 587.391410271827, 591.3953400985788, 582.1726548609934, 561.5136227535937, 578.9087616009848, 425.88723791303266, 610.255693323665, 595.7255307020631, 604.7433952814478, 597.2940292790538, 608.2170496327041, 618.2452218435739, 363.79109694099816, 610.007790608509, 599.9122662898945, 595.544462114588, 582.7490991912518, 584.7892072246018, 597.4006389577128, 601.203439890283, 586.3298275197194, 587.144206810618, 588.429998050006, 555.3954983605805, 568.6219992652344, 218.056981766827, 533.9975535796268, 599.7752431043326, 606.1971777168044, 607.0958449720039, 605.5834122420671, 611.8160885352341, 624.972721001787, 616.6755872080171, 627.3205333941243, 623.8409680774155]
Elapsed: 0.07911473800983705~0.01898044886724291
Time per graph: 0.0016145864899966746~0.0003873560993314879
Speed: 636.7600218983126~78.51702353395781
Total Time: 0.0794
best val loss: 0.3770391047000885 test_score: 0.9592

Testing...
Test loss: 0.4406 score: 0.9796 time: 0.07s
test Score 0.9796
Epoch Time List: [0.41281948308460414, 0.38811845995951444, 0.2691194099606946, 0.2578462631208822, 0.2592018611030653, 0.25946645881049335, 0.2621396060567349, 0.25859534507617354, 0.35423957009334117, 0.26995226298458874, 0.2633811328560114, 0.2621803539805114, 0.25076676497701555, 0.2594373810570687, 0.38312739494722337, 0.2512215368915349, 0.25148590689059347, 0.251044855103828, 0.25236836611293256, 0.2573338628280908, 0.25583059806376696, 0.3745249940548092, 0.25318286602851003, 0.24462226394098252, 0.24492181988898665, 0.24584747676271945, 0.24591726588550955, 0.2429841220146045, 0.3777448032051325, 0.2519837359432131, 0.25330595893319696, 0.2514737988822162, 0.2529685531044379, 0.25327281386125833, 0.25934564997442067, 0.2745620650239289, 0.39732213714160025, 0.24983132106717676, 0.2511101209092885, 0.2522898759925738, 0.2571489429101348, 0.25520558294374496, 0.350181742105633, 0.2520269110100344, 0.2535983950365335, 0.2597151710651815, 0.27975436905398965, 0.2681678170338273, 0.4114964120090008, 0.26715149416122586, 0.25708114507142454, 0.2572442159289494, 0.2575485990382731, 0.2619460889836773, 0.25812800403218716, 0.26142691797576845, 0.2597676559817046, 0.2590520289959386, 0.2633909899741411, 0.25920631911139935, 0.26055669598281384, 0.2605808759108186, 0.2590580808464438, 0.25863800512161106, 0.2643516168463975, 0.2602966690901667, 0.2591591428499669, 0.2591684340732172, 0.2596386701334268, 0.2589373431401327, 0.2581608289619908, 0.25869054184295237, 0.2589627970010042, 0.2594492509961128, 0.258067018003203, 0.25833792972844094, 0.2588292360305786, 0.2592153260484338, 0.26088436401914805, 0.26149500685278326, 0.2601877710549161, 0.26483053795527667, 0.2779159920755774, 0.29623423994053155, 0.2828466729260981, 0.27197478082962334, 0.2567343859700486, 0.2579446348827332, 0.2564589697867632, 0.2565314080566168, 0.25783187802881, 0.2575269879307598, 0.2594300889177248, 0.2642907170811668, 0.26776262803468853, 0.2742969299433753, 0.27712828398216516, 0.27221162407658994, 0.2652925349539146, 0.2713342810748145, 0.28651070303749293, 0.29528340185061097, 0.2939221929991618, 0.29208509519230574, 0.29305398603901267, 0.29404220287688076, 0.2944203879451379, 0.29530825500842184, 0.29817844391800463, 0.2997472679708153, 0.30171862593851984, 0.29459100286476314, 0.2630853889277205, 0.2621434339089319, 0.26786335196811706, 0.2634581960737705, 0.2618913418846205, 0.26424422510899603, 0.26616798900067806, 0.26314077188726515, 0.2625994828995317, 0.2624753098934889, 0.2610034290701151, 0.25835143006406724, 0.26074008480645716, 0.26271010108757764, 0.2632876959396526, 0.2700118670472875, 0.26631086703855544, 0.2653937239665538, 0.2646518930559978, 0.2661338800098747, 0.2630532290786505, 0.2638908149674535, 0.264156905002892, 0.2686837799847126, 0.26723822695203125, 0.2667768821120262, 0.26894412806723267, 0.26925829192623496, 0.2693120810436085, 0.26585454086307436, 0.26084702415391803, 0.3843881539069116, 0.2602784769842401, 0.2610177960013971, 0.2621824690140784, 0.27297636307775974, 0.26947351987473667, 0.26671765896026045, 0.2602708120830357, 0.27647363604046404, 0.2785297619411722, 0.2759054171619937, 0.2704148478806019, 0.36004015908110887, 0.26491704210639, 0.25314702198375016, 0.27003807108849287, 0.2557560900459066, 0.28335005207918584, 0.25402656791266054, 0.4190228300867602, 0.29116957902442664, 0.26371630106586963, 0.26444421394262463, 0.25964932795614004, 0.2709961460204795, 0.2694806648651138, 0.38096135307569057, 0.26846161007415503, 0.2632771619828418, 0.2626902660122141, 0.2552631559083238, 0.25662601098883897, 0.2535723039181903, 0.2533028300385922, 0.40990922902710736, 0.3082388391485438, 0.31887496914714575, 0.3314981939038262, 0.30967342492658645, 0.4323754619108513, 0.29877107695210725, 0.2848832568852231, 0.26519754994660616, 0.2710543980356306, 0.2665166568476707, 0.26557363104075193, 0.32692306698299944, 0.2633124180138111, 0.26252923801075667, 0.2611608279403299, 0.2633876239415258, 0.26140300394035876, 0.2769293640740216, 0.26610994595102966, 0.38417911995202303, 0.26514460297767073, 0.26382500608451664, 0.26627866306807846, 0.2715572000015527, 0.26587018405552953, 0.39534228609409183, 0.2688587539596483, 0.26445709308609366, 0.2658358790213242, 0.2658020651433617, 0.273973556002602, 0.2666056090965867, 0.3876781560247764, 0.2635641189990565, 0.26100923400372267, 0.2637542790034786, 0.26553075097035617, 0.2762313059065491, 0.2672998448833823, 0.3614353818120435, 0.2752621831605211, 0.27539949386846274, 0.27981386706233025, 0.2868597119813785, 0.2838189689209685, 0.31040545902214944, 0.32638525997754186, 0.27099767210893333, 0.269178589922376, 0.26885251398198307, 0.2714425401063636, 0.2630086148856208, 0.34161457407753915, 0.26986835116986185, 0.26801322598475963, 0.2707035739440471, 0.27434657397679985, 0.28557668707799166, 0.2724715588847175, 0.3830540078924969, 0.28130493697244674, 0.27726410096511245, 0.2760824509896338, 0.29440742800943553, 0.28713617101311684, 0.4397523939842358, 0.31015524291433394, 0.2758844589116052, 0.2732335510663688, 0.27150939393322915, 0.26712020009290427, 0.26395000296179205, 0.418497166945599, 0.2740412378916517, 0.26219537493307143, 0.2622921470319852]
Total Epoch List: [150, 104]
Total Time List: [0.07448487903457135, 0.07944643206428736]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d080cc4f0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6922;  Loss pred: 0.6922; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6965 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.08s
Epoch 2/1000, LR 0.000000
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6930;  Loss pred: 0.6930; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6962 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6872;  Loss pred: 0.6872; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6828;  Loss pred: 0.6828; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6795;  Loss pred: 0.6795; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6956 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6774;  Loss pred: 0.6774; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6745;  Loss pred: 0.6745; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5000 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6665;  Loss pred: 0.6665; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6622;  Loss pred: 0.6622; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6584;  Loss pred: 0.6584; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6550;  Loss pred: 0.6550; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6493;  Loss pred: 0.6493; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6425;  Loss pred: 0.6425; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6359;  Loss pred: 0.6359; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6276;  Loss pred: 0.6276; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6222;  Loss pred: 0.6222; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6135;  Loss pred: 0.6135; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6065;  Loss pred: 0.6065; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5988;  Loss pred: 0.5988; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5872;  Loss pred: 0.5872; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5797;  Loss pred: 0.5797; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5693;  Loss pred: 0.5693; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.5000 time: 0.07s
Epoch 27/1000, LR 0.000270
Train loss: 0.5563;  Loss pred: 0.5563; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5480;  Loss pred: 0.5480; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5390;  Loss pred: 0.5390; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5240;  Loss pred: 0.5240; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5095;  Loss pred: 0.5095; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6882 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.5000 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4984;  Loss pred: 0.4984; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6860 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4843;  Loss pred: 0.4843; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6862 score: 0.4898 time: 0.07s
Test loss: 0.6848 score: 0.5208 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.4632;  Loss pred: 0.4632; Loss self: 0.0000; time: 0.12s
Val loss: 0.6849 score: 0.5714 time: 0.07s
Test loss: 0.6833 score: 0.5833 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4569;  Loss pred: 0.4569; Loss self: 0.0000; time: 0.13s
Val loss: 0.6835 score: 0.6735 time: 0.07s
Test loss: 0.6817 score: 0.6667 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4398;  Loss pred: 0.4398; Loss self: 0.0000; time: 0.13s
Val loss: 0.6819 score: 0.7755 time: 0.07s
Test loss: 0.6800 score: 0.7917 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4192;  Loss pred: 0.4192; Loss self: 0.0000; time: 0.13s
Val loss: 0.6802 score: 0.8163 time: 0.07s
Test loss: 0.6780 score: 0.8750 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4062;  Loss pred: 0.4062; Loss self: 0.0000; time: 0.13s
Val loss: 0.6783 score: 0.8367 time: 0.07s
Test loss: 0.6759 score: 0.8958 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3872;  Loss pred: 0.3872; Loss self: 0.0000; time: 0.12s
Val loss: 0.6760 score: 0.8571 time: 0.07s
Test loss: 0.6732 score: 0.8958 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3728;  Loss pred: 0.3728; Loss self: 0.0000; time: 0.12s
Val loss: 0.6732 score: 0.8980 time: 0.07s
Test loss: 0.6701 score: 0.9167 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3553;  Loss pred: 0.3553; Loss self: 0.0000; time: 0.12s
Val loss: 0.6700 score: 0.8980 time: 0.07s
Test loss: 0.6664 score: 0.9375 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3421;  Loss pred: 0.3421; Loss self: 0.0000; time: 0.12s
Val loss: 0.6665 score: 0.8980 time: 0.07s
Test loss: 0.6625 score: 0.9375 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3264;  Loss pred: 0.3264; Loss self: 0.0000; time: 0.12s
Val loss: 0.6629 score: 0.8980 time: 0.07s
Test loss: 0.6583 score: 0.9375 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3041;  Loss pred: 0.3041; Loss self: 0.0000; time: 0.12s
Val loss: 0.6590 score: 0.8980 time: 0.07s
Test loss: 0.6539 score: 0.9375 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2859;  Loss pred: 0.2859; Loss self: 0.0000; time: 0.12s
Val loss: 0.6548 score: 0.8980 time: 0.07s
Test loss: 0.6490 score: 0.9375 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2724;  Loss pred: 0.2724; Loss self: 0.0000; time: 0.12s
Val loss: 0.6501 score: 0.8980 time: 0.07s
Test loss: 0.6436 score: 0.9375 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2563;  Loss pred: 0.2563; Loss self: 0.0000; time: 0.12s
Val loss: 0.6451 score: 0.8980 time: 0.07s
Test loss: 0.6377 score: 0.9375 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2412;  Loss pred: 0.2412; Loss self: 0.0000; time: 0.12s
Val loss: 0.6396 score: 0.8980 time: 0.07s
Test loss: 0.6314 score: 0.9375 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2270;  Loss pred: 0.2270; Loss self: 0.0000; time: 0.12s
Val loss: 0.6336 score: 0.8980 time: 0.07s
Test loss: 0.6244 score: 0.9167 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2113;  Loss pred: 0.2113; Loss self: 0.0000; time: 0.12s
Val loss: 0.6271 score: 0.8980 time: 0.07s
Test loss: 0.6170 score: 0.9167 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.1940;  Loss pred: 0.1940; Loss self: 0.0000; time: 0.12s
Val loss: 0.6203 score: 0.8980 time: 0.07s
Test loss: 0.6091 score: 0.8958 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1826;  Loss pred: 0.1826; Loss self: 0.0000; time: 0.12s
Val loss: 0.6132 score: 0.8776 time: 0.07s
Test loss: 0.6009 score: 0.8958 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1675;  Loss pred: 0.1675; Loss self: 0.0000; time: 0.12s
Val loss: 0.6057 score: 0.8776 time: 0.07s
Test loss: 0.5923 score: 0.8958 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.1570;  Loss pred: 0.1570; Loss self: 0.0000; time: 0.13s
Val loss: 0.5981 score: 0.8776 time: 0.07s
Test loss: 0.5832 score: 0.8958 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1411;  Loss pred: 0.1411; Loss self: 0.0000; time: 0.12s
Val loss: 0.5902 score: 0.8776 time: 0.07s
Test loss: 0.5738 score: 0.8958 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1308;  Loss pred: 0.1308; Loss self: 0.0000; time: 0.12s
Val loss: 0.5823 score: 0.8980 time: 0.07s
Test loss: 0.5644 score: 0.8958 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1201;  Loss pred: 0.1201; Loss self: 0.0000; time: 0.12s
Val loss: 0.5741 score: 0.8980 time: 0.07s
Test loss: 0.5547 score: 0.8958 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1107;  Loss pred: 0.1107; Loss self: 0.0000; time: 0.13s
Val loss: 0.5657 score: 0.8776 time: 0.07s
Test loss: 0.5447 score: 0.8958 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.0998;  Loss pred: 0.0998; Loss self: 0.0000; time: 0.12s
Val loss: 0.5570 score: 0.8776 time: 0.07s
Test loss: 0.5345 score: 0.8958 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.0939;  Loss pred: 0.0939; Loss self: 0.0000; time: 0.12s
Val loss: 0.5484 score: 0.8776 time: 0.07s
Test loss: 0.5243 score: 0.8958 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.0832;  Loss pred: 0.0832; Loss self: 0.0000; time: 0.12s
Val loss: 0.5398 score: 0.8776 time: 0.07s
Test loss: 0.5140 score: 0.8958 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0762;  Loss pred: 0.0762; Loss self: 0.0000; time: 0.12s
Val loss: 0.5316 score: 0.8776 time: 0.07s
Test loss: 0.5039 score: 0.8958 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0695;  Loss pred: 0.0695; Loss self: 0.0000; time: 0.12s
Val loss: 0.5235 score: 0.8776 time: 0.07s
Test loss: 0.4941 score: 0.8958 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0632;  Loss pred: 0.0632; Loss self: 0.0000; time: 0.13s
Val loss: 0.5155 score: 0.8776 time: 0.07s
Test loss: 0.4843 score: 0.8958 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0556;  Loss pred: 0.0556; Loss self: 0.0000; time: 0.12s
Val loss: 0.5076 score: 0.8776 time: 0.07s
Test loss: 0.4746 score: 0.8958 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0509;  Loss pred: 0.0509; Loss self: 0.0000; time: 0.13s
Val loss: 0.4999 score: 0.8776 time: 0.07s
Test loss: 0.4653 score: 0.8958 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0463;  Loss pred: 0.0463; Loss self: 0.0000; time: 0.12s
Val loss: 0.4924 score: 0.8776 time: 0.07s
Test loss: 0.4563 score: 0.8958 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0423;  Loss pred: 0.0423; Loss self: 0.0000; time: 0.13s
Val loss: 0.4850 score: 0.8776 time: 0.07s
Test loss: 0.4475 score: 0.8750 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0380;  Loss pred: 0.0380; Loss self: 0.0000; time: 0.13s
Val loss: 0.4783 score: 0.8776 time: 0.07s
Test loss: 0.4396 score: 0.8750 time: 0.08s
Epoch 70/1000, LR 0.000268
Train loss: 0.0341;  Loss pred: 0.0341; Loss self: 0.0000; time: 0.13s
Val loss: 0.4717 score: 0.8571 time: 0.07s
Test loss: 0.4316 score: 0.8750 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0336;  Loss pred: 0.0336; Loss self: 0.0000; time: 0.12s
Val loss: 0.4655 score: 0.8571 time: 0.07s
Test loss: 0.4240 score: 0.8750 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0280;  Loss pred: 0.0280; Loss self: 0.0000; time: 0.12s
Val loss: 0.4592 score: 0.8367 time: 0.07s
Test loss: 0.4164 score: 0.8750 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0259;  Loss pred: 0.0259; Loss self: 0.0000; time: 0.12s
Val loss: 0.4534 score: 0.8367 time: 0.07s
Test loss: 0.4092 score: 0.8750 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0238;  Loss pred: 0.0238; Loss self: 0.0000; time: 0.12s
Val loss: 0.4473 score: 0.8571 time: 0.07s
Test loss: 0.4018 score: 0.8750 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0213;  Loss pred: 0.0213; Loss self: 0.0000; time: 0.13s
Val loss: 0.4418 score: 0.8571 time: 0.07s
Test loss: 0.3950 score: 0.8750 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0202;  Loss pred: 0.0202; Loss self: 0.0000; time: 0.13s
Val loss: 0.4364 score: 0.8571 time: 0.07s
Test loss: 0.3884 score: 0.8750 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0185;  Loss pred: 0.0185; Loss self: 0.0000; time: 0.13s
Val loss: 0.4314 score: 0.8571 time: 0.07s
Test loss: 0.3821 score: 0.8750 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0168;  Loss pred: 0.0168; Loss self: 0.0000; time: 0.13s
Val loss: 0.4267 score: 0.8571 time: 0.07s
Test loss: 0.3762 score: 0.8750 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0157;  Loss pred: 0.0157; Loss self: 0.0000; time: 0.12s
Val loss: 0.4222 score: 0.8571 time: 0.07s
Test loss: 0.3704 score: 0.8750 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0141;  Loss pred: 0.0141; Loss self: 0.0000; time: 0.13s
Val loss: 0.4176 score: 0.8571 time: 0.17s
Test loss: 0.3645 score: 0.8750 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0128;  Loss pred: 0.0128; Loss self: 0.0000; time: 0.12s
Val loss: 0.4139 score: 0.8571 time: 0.08s
Test loss: 0.3595 score: 0.8750 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.13s
Val loss: 0.4105 score: 0.8571 time: 0.07s
Test loss: 0.3546 score: 0.8750 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.13s
Val loss: 0.4071 score: 0.8571 time: 0.08s
Test loss: 0.3499 score: 0.8958 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.12s
Val loss: 0.4041 score: 0.8571 time: 0.08s
Test loss: 0.3453 score: 0.8958 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.13s
Val loss: 0.4017 score: 0.8571 time: 0.07s
Test loss: 0.3414 score: 0.8958 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.12s
Val loss: 0.3997 score: 0.8571 time: 0.07s
Test loss: 0.3376 score: 0.8958 time: 0.17s
Epoch 87/1000, LR 0.000266
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.12s
Val loss: 0.3975 score: 0.8571 time: 0.07s
Test loss: 0.3337 score: 0.8958 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.12s
Val loss: 0.3962 score: 0.8571 time: 0.07s
Test loss: 0.3305 score: 0.8958 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.12s
Val loss: 0.3957 score: 0.8571 time: 0.07s
Test loss: 0.3280 score: 0.8958 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.12s
Val loss: 0.3954 score: 0.8571 time: 0.07s
Test loss: 0.3256 score: 0.8958 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.13s
Val loss: 0.3957 score: 0.8571 time: 0.07s
Test loss: 0.3239 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.13s
Val loss: 0.3965 score: 0.8571 time: 0.07s
Test loss: 0.3226 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.3979 score: 0.8776 time: 0.07s
Test loss: 0.3218 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.14s
Val loss: 0.3998 score: 0.8776 time: 0.12s
Test loss: 0.3214 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.12s
Val loss: 0.4019 score: 0.8776 time: 0.07s
Test loss: 0.3210 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.4043 score: 0.8776 time: 0.07s
Test loss: 0.3210 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.12s
Val loss: 0.4070 score: 0.8776 time: 0.07s
Test loss: 0.3211 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.12s
Val loss: 0.4101 score: 0.8776 time: 0.07s
Test loss: 0.3216 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.13s
Val loss: 0.4131 score: 0.8776 time: 0.07s
Test loss: 0.3220 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.4166 score: 0.8776 time: 0.07s
Test loss: 0.3229 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.25s
Val loss: 0.4201 score: 0.8776 time: 0.07s
Test loss: 0.3238 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.12s
Val loss: 0.4237 score: 0.8776 time: 0.07s
Test loss: 0.3248 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.12s
Val loss: 0.4275 score: 0.8776 time: 0.07s
Test loss: 0.3260 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.12s
Val loss: 0.4313 score: 0.8776 time: 0.07s
Test loss: 0.3274 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.12s
Val loss: 0.4353 score: 0.8776 time: 0.07s
Test loss: 0.3290 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.13s
Val loss: 0.4393 score: 0.8776 time: 0.07s
Test loss: 0.3307 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.12s
Val loss: 0.4433 score: 0.8776 time: 0.07s
Test loss: 0.3321 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.13s
Val loss: 0.4474 score: 0.8776 time: 0.14s
Test loss: 0.3340 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.12s
Val loss: 0.4512 score: 0.8776 time: 0.07s
Test loss: 0.3356 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.12s
Val loss: 0.4548 score: 0.8776 time: 0.07s
Test loss: 0.3371 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 089,   Train_Loss: 0.0072,   Val_Loss: 0.3954,   Val_Precision: 0.9500,   Val_Recall: 0.7600,   Val_accuracy: 0.8444,   Val_Score: 0.8571,   Val_Loss: 0.3954,   Test_Precision: 1.0000,   Test_Recall: 0.7917,   Test_accuracy: 0.8837,   Test_Score: 0.8958,   Test_loss: 0.3256


[0.06632305192761123, 0.07275906705763191, 0.07755232497584075, 0.07238274300470948, 0.07310916495043784, 0.07323813799303025, 0.07302752591203898, 0.07294250000268221, 0.07271825708448887, 0.07775088504422456, 0.07468694297131151, 0.06940282706636935, 0.07082904793787748, 0.07043946604244411, 0.19234758196398616, 0.07019173307344317, 0.07020904694218189, 0.07051032199524343, 0.07121239101979882, 0.07162261405028403, 0.07076394592877477, 0.06712763500399888, 0.06728304398711771, 0.0671779370168224, 0.06765816593542695, 0.06772508495487273, 0.06754313700366765, 0.0659570029238239, 0.20257570396643132, 0.0712679181015119, 0.07123174401931465, 0.07090553699526936, 0.0713410199386999, 0.0727489140117541, 0.0763387760380283, 0.07093409704975784, 0.07062539795879275, 0.07040945102926344, 0.07088812999427319, 0.07180396607145667, 0.07222436496522278, 0.07142476306762546, 0.07100091909524053, 0.07095331698656082, 0.0713082819711417, 0.07671771897003055, 0.07395412400364876, 0.07232438598293811, 0.08641207404434681, 0.0697208009660244, 0.06939286703709513, 0.07063184701837599, 0.07195793592836708, 0.0694445560220629, 0.06955418200232089, 0.07072335400152951, 0.0697105269646272, 0.07047944609075785, 0.07058175897691399, 0.06955186708364636, 0.07022563996724784, 0.07007635897025466, 0.0699755649548024, 0.06998322799336165, 0.07435644802171737, 0.07019258197396994, 0.06964382389560342, 0.06969787494745106, 0.0704094129614532, 0.0699743670411408, 0.06984404602553695, 0.06974442198406905, 0.06943598797079176, 0.06951213895808905, 0.06964036193676293, 0.06948556296993047, 0.07018207397777587, 0.07003150507807732, 0.06983198807574809, 0.07044983399100602, 0.07006003893911839, 0.07608484395314008, 0.07059146696701646, 0.07460321392863989, 0.08071495697367936, 0.07635015901178122, 0.06907740200404078, 0.06922202999703586, 0.0692986719077453, 0.06924141698982567, 0.06904905301053077, 0.06960208900272846, 0.07063215004745871, 0.07193983590696007, 0.0741564859636128, 0.07545729703269899, 0.07582273799926043, 0.07321844296529889, 0.07107004208955914, 0.07805430504959077, 0.07959886197932065, 0.08255606796592474, 0.08121322293300182, 0.0812627850100398, 0.08124391199089587, 0.08250005193985999, 0.08205985301174223, 0.08176352898590267, 0.08248068497050554, 0.0831730340141803, 0.08308264298830181, 0.07417673105373979, 0.07115710794460028, 0.07069294003304094, 0.07347145106177777, 0.07189359294716269, 0.07028038101270795, 0.07208249100949615, 0.07101235107984394, 0.07053598901256919, 0.07155294402036816, 0.07139669300522655, 0.06995076104067266, 0.07048566499724984, 0.0711956339655444, 0.07065302995033562, 0.07231938501354307, 0.07231123000383377, 0.072308205999434, 0.07207843393553048, 0.07112440292257816, 0.07152770599350333, 0.07040830398909748, 0.07230375299695879, 0.07309212407562882, 0.07317774905823171, 0.07308810204267502, 0.07239336194470525, 0.07341051404364407, 0.07322963606566191, 0.07401779806241393, 0.0717745510628447, 0.0717735510552302, 0.07089083094615489, 0.07144772401079535, 0.0713078030385077, 0.07129679899662733, 0.07518392696511, 0.07375179906375706, 0.07365930906962603, 0.07825947203673422, 0.09066086390521377, 0.0877621800173074, 0.08683861594181508, 0.07987320504616946, 0.09963619196787477, 0.08156681596301496, 0.07642738509457558, 0.08029586402699351, 0.08092844998463988, 0.08335009193979204, 0.07679609907791018, 0.21232727100141346, 0.08871484699193388, 0.08049315598327667, 0.07918403996154666, 0.07840350503101945, 0.07955480902455747, 0.08160649100318551, 0.07634575106203556, 0.07980679301545024, 0.0790697030024603, 0.08058050798717886, 0.07796399190556258, 0.07776730298064649, 0.07639403501525521, 0.07983413501642644, 0.0948510350426659, 0.10065252997446805, 0.1024332590168342, 0.0978159629739821, 0.09536798403132707, 0.09198389598168433, 0.09176382201258093, 0.07869177602697164, 0.07943619298748672, 0.08299350796733052, 0.07966549694538116, 0.08003878896124661, 0.07898476393893361, 0.0790595900034532, 0.07978112797718495, 0.07857277593575418, 0.07935075392015278, 0.07971862598787993, 0.08105668099597096, 0.07914406294003129, 0.08270924701355398, 0.08009253698401153, 0.07833021797705442, 0.07999360398389399, 0.08025067893322557, 0.07883075997233391, 0.08124123991001397, 0.07941512006800622, 0.07942843995988369, 0.08091909904032946, 0.07947951299138367, 0.08021878194995224, 0.07896876998711377, 0.07945540500804782, 0.0774443669943139, 0.07885204395279288, 0.08025511296000332, 0.07852007797919214, 0.08018402301240712, 0.07991601096000522, 0.16577494400553405, 0.08341967407613993, 0.08285489701665938, 0.08416747092269361, 0.08726413396652788, 0.08464200794696808, 0.11505392892286181, 0.08029421197716147, 0.08225264400243759, 0.08102610195055604, 0.08203664794564247, 0.08056334499269724, 0.07925657695159316, 0.13469268602784723, 0.08032684295903891, 0.08167860994581133, 0.08227765199262649, 0.08408421406056732, 0.08379087608773261, 0.0820220080204308, 0.08150319301057607, 0.08357071003410965, 0.0834547959966585, 0.08327243709936738, 0.08822541800327599, 0.08617323997896165, 0.22471190604846925, 0.09176072000991553, 0.08169727004133165, 0.0808317851042375, 0.08071213203947991, 0.08091370901092887, 0.08008942706510425, 0.07840342202689499, 0.07945831003598869, 0.07810998905915767, 0.07854565908201039, 0.08277090406045318, 0.07851259398739785, 0.07797825196757913, 0.07392711995635182, 0.07507025997620076, 0.07541885296814144, 0.07492980698589236, 0.07461580506060272, 0.07522995898034424, 0.07486004999373108, 0.07457379798870534, 0.07489052799064666, 0.07512536307331175, 0.07516501401551068, 0.07455543894320726, 0.07550156500656158, 0.07537435495760292, 0.0757082310738042, 0.0754166339756921, 0.07680086710024625, 0.07695890998002142, 0.07537961099296808, 0.07768860191572458, 0.07435634103603661, 0.0746856810292229, 0.07539456093218178, 0.07581434410531074, 0.07638640305958688, 0.07650331896729767, 0.07690230291336775, 0.07516731391660869, 0.07528073899447918, 0.07699925301130861, 0.0763868479989469, 0.07568695803638548, 0.07810686097946018, 0.07837743998970836, 0.07519596698693931, 0.07494487601798028, 0.07510368805378675, 0.0759776079794392, 0.07525237300433218, 0.07504300610162318, 0.07498014799784869, 0.07539510098285973, 0.07554726209491491, 0.07543690293096006, 0.07522991194855422, 0.07552468997891992, 0.07504783303011209, 0.07517467206344008, 0.07563188392668962, 0.07581128599122167, 0.0756191989639774, 0.07566151104401797, 0.07583232398610562, 0.07562931207939982, 0.07537657802458853, 0.07553659996483475, 0.07582481601275504, 0.0755255960393697, 0.07531229907181114, 0.07535258610732853, 0.07602615898940712, 0.07574985304381698, 0.0762409329181537, 0.0760217229835689, 0.07546082092449069, 0.08259458595421165, 0.07611395698040724, 0.07583444798365235, 0.07538200600538403, 0.07563733297865838, 0.07616791396867484, 0.07588750892318785, 0.07547806098591536, 0.07704641507007182, 0.07568068406544626, 0.07497129996772856, 0.07431758695747703, 0.07442205003462732, 0.07406533998437226, 0.07758393802214414, 0.07781773107126355, 0.08323311293497682, 0.17155230708885938, 0.07384083699434996, 0.07394129200838506, 0.07324454700574279, 0.0742532069562003, 0.07530239399056882, 0.0742357800481841, 0.07477453991305083, 0.07395042106509209, 0.07349537895061076, 0.07271918503101915, 0.07426078210119158, 0.07718884793575853, 0.07402299391105771, 0.07520097203087062, 0.07351349794771522, 0.07322778494562954, 0.07293658494018018, 0.07351617200765759, 0.07747440808452666, 0.07850746798794717, 0.07385857996996492, 0.07286835997365415, 0.07326941296923906, 0.07311406906228513]
[0.001353531671992066, 0.0014848789195435084, 0.0015827005097110356, 0.0014771988368308057, 0.0014920237744987315, 0.0014946558774087805, 0.001490357671674265, 0.0014886224490343308, 0.0014840460629487525, 0.0015867527560045828, 0.0015242233259451328, 0.0014163842258442725, 0.0014454907742423974, 0.001437540123315186, 0.003925460856407881, 0.0014324843484376157, 0.0014328376926975896, 0.0014389861631682332, 0.0014533141024448738, 0.0014616860010262047, 0.0014441621618117302, 0.0013699517347754873, 0.0013731233466758716, 0.0013709783064657633, 0.0013807788966413662, 0.00138214459091577, 0.0013784313674217888, 0.0013460612841596712, 0.004134198040131251, 0.0014544473081941204, 0.0014537090616186662, 0.0014470517754136603, 0.001455939182422447, 0.0014846717145255938, 0.0015579342048577204, 0.0014476346336685273, 0.00144133465222026, 0.0014369275720257843, 0.001446696530495371, 0.0014653870626827892, 0.001473966631943322, 0.0014576482258699074, 0.0014489983488824598, 0.0014480268772767515, 0.0014552710606355447, 0.001565667734082256, 0.0015092678368091583, 0.0014760078772028185, 0.0017635117151907512, 0.0014228734891025387, 0.001416180959940717, 0.0014414662656811426, 0.0014685293046605525, 0.0014172358371849572, 0.0014194731020881813, 0.0014433337551332554, 0.0014226638156046368, 0.0014383560426685276, 0.0014404440607533467, 0.0014194258588499256, 0.001433176325862201, 0.0014301297749031562, 0.0014280727541796407, 0.0014282291427216663, 0.0015174785310554566, 0.0014325016729381619, 0.0014213025284817023, 0.0014224056111724706, 0.001436926795131698, 0.001428048306962057, 0.0014253886943987133, 0.0014233555506952867, 0.00141706097899575, 0.0014186150807773276, 0.0014212318762604678, 0.0014180727136720503, 0.0014322872240362422, 0.0014292143893485166, 0.0014251426137907772, 0.0014377517141021636, 0.0014297967130432324, 0.001552751917411022, 0.0014406421830003358, 0.0015225145699722426, 0.0016472440198710074, 0.0015581665104445145, 0.0014097428980416485, 0.0014126944897354258, 0.0014142586103621491, 0.0014130901426495034, 0.0014091643471536891, 0.0014204507959740503, 0.001441472449948137, 0.0014681599164685728, 0.0015133976727267917, 0.0015399448374020202, 0.0015474028163114373, 0.0014942539380673244, 0.0014504090222359008, 0.0015929450010120564, 0.0016244665710065439, 0.001684817713590301, 0.0016574127129184045, 0.0016584241838783634, 0.0016580390202223646, 0.0016836745293848977, 0.0016746908777906578, 0.0016686434486918912, 0.001683279285112358, 0.0016974088574322511, 0.0016955641426184044, 0.0015138108378314242, 0.001452185876420414, 0.0014427130618987947, 0.0014994173686077095, 0.0014672161825951568, 0.0014342934900552643, 0.0014710712450917583, 0.0014492316546906925, 0.0014395099798483507, 0.0014602641636809828, 0.001457075367453603, 0.0014275665518504624, 0.0014384829591275478, 0.001452972121745804, 0.0014418985704150126, 0.0014759058166029198, 0.0014757393878333423, 0.0014756776734578367, 0.0014709884476638874, 0.001451518426991391, 0.0014597491019082312, 0.0014369041630428057, 0.001475586795856302, 0.0014916760015434452, 0.001493423450167994, 0.0014915939192382656, 0.0014774155498919438, 0.001498173755992736, 0.0014944823686869778, 0.0015105673073962027, 0.0014647867563845856, 0.0014647663480659224, 0.0014467516519623448, 0.001458116816546844, 0.0014552612865001572, 0.0014550367142168842, 0.0015343658564308164, 0.0015051387564032053, 0.0015032512055025721, 0.001597132082382331, 0.0018502217123513014, 0.001791064898312396, 0.001772216651873777, 0.0016300654091054992, 0.0020333916728137707, 0.001664628897204387, 0.0015597425529505222, 0.0016386911025917043, 0.0016516010200946915, 0.0017010222844855518, 0.001567267328120616, 0.004333209612273744, 0.0018105070814680383, 0.0016427174690464626, 0.0016160008155417685, 0.001600071531245295, 0.0016235675311134178, 0.001665438591901745, 0.00155807655228644, 0.0016287100615398008, 0.0016136674082134754, 0.0016445001630036502, 0.001591101875623726, 0.001587087815931561, 0.001559061939086841, 0.0016292680615597234, 0.001935735409033998, 0.0020541332647850625, 0.0020904746738129427, 0.001996244142326165, 0.00194628538839443, 0.0018772223669731496, 0.0018727310614812436, 0.0016059546127953396, 0.0016211467956629942, 0.0016937450605577656, 0.001625826468273085, 0.0016334446726785023, 0.0016119339579374206, 0.0016134610204786366, 0.0016281862852486726, 0.0016035260395051874, 0.001619403141227608, 0.0016269107344465293, 0.0016542179795096116, 0.0016151849579598223, 0.0016879438166031424, 0.0016345415711022761, 0.001598575877082743, 0.0016325225302835508, 0.00163776895782093, 0.0016087910198435492, 0.0016579844879594688, 0.0016207167360817595, 0.0016209885706098713, 0.0016514101844965195, 0.001622030877375177, 0.0016371179989786173, 0.001611607550757424, 0.0016215388777152616, 0.0015804972855982427, 0.0016092253867916915, 0.001637859448163333, 0.0016024505710039213, 0.0016364086329062678, 0.0016309389991837802, 0.0033831621225619193, 0.0017024423280844884, 0.0016909162656461097, 0.001717703488218237, 0.0017809006931944465, 0.0017273879172850627, 0.00234803936577269, 0.0016386573872890096, 0.0016786253878048488, 0.0016535939173582866, 0.0016742173050131118, 0.0016441498978101478, 0.0016174811622774114, 0.002748830327098923, 0.0016393233256946718, 0.001666910407057374, 0.001679135754951561, 0.0017160043685830065, 0.0017100178793414819, 0.0016739185310292001, 0.0016633304696035932, 0.0017055246945736663, 0.0017031591019726225, 0.0016994374918238241, 0.0018005187347607345, 0.001758637550591054, 0.00458595726629529, 0.0018726677553043986, 0.001667291225333299, 0.0016496282674334183, 0.0016471863681526513, 0.0016513001838965075, 0.0016344781033694744, 0.0016000698372835712, 0.0016215981639997692, 0.0015940814093705646, 0.0016029726343267426, 0.0017243938345927745, 0.0016356790414041218, 0.0016245469159912318, 0.0015401483324239962, 0.0015639637495041825, 0.0015712261035029467, 0.0015610376455394241, 0.0015544959387625568, 0.001567290812090505, 0.0015595843748693976, 0.0015536207914313611, 0.0015602193331384722, 0.0015651117306939948, 0.0015659377919898059, 0.001553238311316818, 0.0015729492709700328, 0.0015702990616167274, 0.0015772548140375875, 0.0015711798744935852, 0.0016000180645884636, 0.0016033106245837796, 0.0015704085623535018, 0.0016185125399109286, 0.0015490904382507626, 0.0015559516881088105, 0.0015707200194204536, 0.0015794655021939736, 0.0015913833970747266, 0.001593819145152035, 0.0016021313106951613, 0.0015659857065960143, 0.0015683487290516496, 0.0016041511044022627, 0.0015913926666447271, 0.0015768116257580307, 0.0016272262704054203, 0.0016328633331189242, 0.0015665826455612357, 0.0015613515837079224, 0.001564660167787224, 0.0015828668329049833, 0.0015677577709235873, 0.0015633959604504828, 0.0015620864166218478, 0.0015707312704762444, 0.0015739012936440606, 0.0015716021443950012, 0.0015672898322615463, 0.0015734310412274983, 0.0015634965214606684, 0.0015661390013216685, 0.0015756642484727006, 0.0015794017914837848, 0.0015753999784161958, 0.0015762814800837077, 0.001579840083043867, 0.0015756106683208297, 0.001570345375512261, 0.0015736791659340572, 0.0015796836669323966, 0.0015734499174868688, 0.0015690062306627321, 0.0015698455439026777, 0.001583878312279315, 0.0015781219384128538, 0.0015883527691282022, 0.0015837858954910189, 0.0015721004359268893, 0.0017207205407127428, 0.0015857074370918174, 0.0015798843329927574, 0.0015704584584455006, 0.0015757777703887161, 0.0015868315410140592, 0.0015809897692330803, 0.0015724596038732368, 0.0016051336472931628, 0.0015766809180301304, 0.0015619020826610115, 0.0015482830616141048, 0.0015504593757214025, 0.0015430279163410887, 0.001616332042128003, 0.001621202730651324, 0.0017340231861453503, 0.0035740063976845704, 0.001538350770715624, 0.0015404435835080221, 0.0015259280626196414, 0.0015469418115875062, 0.001568799874803517, 0.0015465787510038354, 0.0015578029148552257, 0.0015406337721894185, 0.001531153728137724, 0.0015149830214795657, 0.0015470996271081579, 0.0016081009986616361, 0.001542145706480369, 0.0015666869173098046, 0.0015315312072440672, 0.0015255788530339487, 0.0015195121862537537, 0.0015315869168261997, 0.0016140501684276387, 0.0016355722497488994, 0.0015387204160409358, 0.0015180908327844616, 0.0015264461035258137, 0.0015232097721309401]
[738.8079796671811, 673.4555840468305, 631.831476558112, 676.9569370535168, 670.2306069727109, 669.0503246363679, 670.9798721514964, 671.7620042937683, 673.8335318332585, 630.2179064859376, 656.0718386722792, 706.0231127637164, 691.806559972072, 695.632757500951, 254.74715876165484, 698.0879065734167, 697.9157549361433, 694.9337148581665, 688.082499383805, 684.1414635550527, 692.4430139794551, 729.9527236000644, 728.2666938996064, 729.4061439804208, 724.2289134288043, 723.5133043044565, 725.4623071081116, 742.9082254782234, 241.88488076595678, 687.5463926167432, 687.8955537957002, 691.060276481217, 686.841876414207, 673.5495734284506, 641.8756304867995, 690.7820362558246, 693.8014002921392, 695.9293004519338, 691.2299704331112, 682.4135584827862, 678.4414099534736, 686.0365774487268, 690.1319113104926, 690.5949162219016, 687.1572087493314, 638.7051212920139, 662.572921526086, 677.5031593294063, 567.0503866722737, 702.8031709486264, 706.1244489841617, 693.7380525707033, 680.9533843324617, 705.5988663018084, 704.4867553523233, 692.8404441754882, 702.9067507245179, 695.2381540697934, 694.2303607937429, 704.510203026905, 697.7508502998741, 699.237242345868, 700.24443577768, 700.1677602617581, 658.9879062766489, 698.0794639834029, 703.5799767894903, 703.0343469860984, 695.92967671561, 700.2564234870591, 701.5630220231545, 702.5651458003699, 705.6859336488716, 704.912850251142, 703.6149531286835, 705.1824566954218, 698.1839837836159, 699.6850909511436, 701.684161517051, 695.5303827437775, 699.4001251209781, 644.0178812770994, 694.134887760514, 656.8081644159447, 607.0745972890575, 641.7799338497651, 709.3492021766203, 707.8671342359971, 707.0842579094711, 707.668937612875, 709.6404347866572, 704.0018583074303, 693.7350762659246, 681.1247118129627, 660.7648591121671, 649.3739098389136, 646.2441385389953, 669.2302924718439, 689.4606863782702, 627.7680644119309, 615.5866903314515, 593.5360199110366, 603.3500239292727, 602.9820414590292, 603.1221146206119, 593.9390200107935, 597.1251251569804, 599.289201527106, 594.078480525738, 589.1332519100591, 589.7742083975264, 660.5845162480985, 688.6170814888821, 693.1385224196086, 666.9257145717568, 681.5628207093773, 697.2073755709993, 679.776729601988, 690.0208098293496, 694.6808386179773, 684.8076018514588, 686.3062970775549, 700.4927361906628, 695.1768136387994, 688.2444508284577, 693.5300585756016, 677.5500094590668, 677.6264211990605, 677.6547602409546, 679.8149921490711, 688.9337271954116, 685.0492311951195, 695.9406380188835, 677.6964952574594, 670.3868661594706, 669.6024492500843, 670.4237575000874, 676.857638376108, 667.4793200721696, 669.1280010740976, 662.0029409505238, 682.6932286500316, 682.7027404885428, 691.2036344618098, 685.8161079084391, 687.1618239807357, 687.2678814418853, 651.7350446823433, 664.3905724610245, 665.2248116213394, 626.1222919699725, 540.4757674847402, 558.3270605896163, 564.265096450083, 613.4723149230873, 491.78916849611073, 600.7344950453648, 641.1314470508787, 610.2431375983126, 605.4731062969838, 587.8817750482526, 638.0532421352437, 230.77581965283116, 552.3314491480234, 608.7474071731053, 618.8115688943803, 624.9720593564498, 615.9275674318366, 600.4424329197941, 641.8169880886302, 613.9828221203403, 619.7063873943644, 608.0875043353707, 628.495268166277, 630.084857285, 641.4113351941043, 613.7725421577862, 516.5995287026527, 486.82333183705913, 478.3602559394033, 500.9407310444148, 513.799263953238, 532.7019417589878, 533.9795022190993, 622.6826038747078, 616.8472853138718, 590.4076258505462, 615.0717924171678, 612.2031659390168, 620.3728106079285, 619.7856578545343, 614.1803361568484, 623.6256695329861, 617.5114611930036, 614.6618734679364, 604.5152527579511, 619.1241412148385, 592.436780278874, 611.7923322841131, 625.5567936036354, 612.5489734137459, 610.5867346090814, 621.5847724568026, 603.1419517264181, 617.0109666526905, 616.9074959139076, 605.5430742695094, 616.5110750654959, 610.82951908408, 620.4984579093214, 616.6981339411325, 632.7122539925682, 621.4169924286973, 610.5530002109659, 624.0442095967483, 611.0943073088024, 613.1437169020179, 295.5814601171829, 587.391410271827, 591.3953400985788, 582.1726548609934, 561.5136227535937, 578.9087616009848, 425.88723791303266, 610.255693323665, 595.7255307020631, 604.7433952814478, 597.2940292790538, 608.2170496327041, 618.2452218435739, 363.79109694099816, 610.007790608509, 599.9122662898945, 595.544462114588, 582.7490991912518, 584.7892072246018, 597.4006389577128, 601.203439890283, 586.3298275197194, 587.144206810618, 588.429998050006, 555.3954983605805, 568.6219992652344, 218.056981766827, 533.9975535796268, 599.7752431043326, 606.1971777168044, 607.0958449720039, 605.5834122420671, 611.8160885352341, 624.972721001787, 616.6755872080171, 627.3205333941243, 623.8409680774155, 579.913926818322, 611.3668847536045, 615.5562453484706, 649.2881100784157, 639.4010093373496, 636.4456380724358, 640.5995415020534, 643.2953442104464, 638.0436816739623, 641.1964726716, 643.6577094714942, 640.935526666268, 638.9320202440656, 638.5949717257414, 643.8162081852148, 635.748411252515, 636.8213701729105, 634.0129642337988, 636.4643642869439, 624.9929435998008, 623.7094575853638, 636.7769661809181, 617.8512525179649, 645.5401023126853, 642.6934766949321, 636.650700084009, 633.1255722970456, 628.3840850911196, 627.4237594909865, 624.1685642895912, 638.5754325776712, 637.613294464606, 623.3826709065659, 628.3804248692359, 634.1911637791633, 614.5426841903504, 612.4211253429918, 638.3321064058803, 640.4707372987602, 639.1164168346035, 631.7650854839968, 637.8536394757505, 639.633224913704, 640.1694486036117, 636.6461397924553, 635.3638592447533, 636.2933542477168, 638.0440805623258, 635.5537508779913, 639.5920849672042, 638.5129283901988, 634.6529731630994, 633.1511116373624, 634.7594348740151, 634.4044592510821, 632.9754579167954, 634.6745551461179, 636.8025885221529, 635.4535420226206, 633.038133477641, 635.5461263090031, 637.3460987325782, 637.0053435409789, 631.3616344433228, 633.6645956558455, 629.5830620479034, 631.3984755432939, 636.0916752818107, 581.1518932561752, 630.6333543052538, 632.9577293204187, 636.7567347116192, 634.6072516007875, 630.1866166341473, 632.5151619956962, 635.9463845919024, 623.0010826116333, 634.2437385805224, 640.2450006957547, 645.8767293866066, 644.9701395979607, 648.0764148267998, 618.6847590322079, 616.8260027530588, 576.6935574967436, 279.7980441914857, 650.0468027424012, 649.163663444733, 655.3388881801197, 646.436726003144, 637.429933582347, 646.5884775352898, 641.9297270944797, 649.0835252682307, 653.1022859580903, 660.0734040064542, 646.3707847110029, 621.8514887014333, 648.4471576180015, 638.2896218455209, 652.9413147247991, 655.4888972217203, 658.1059428456621, 652.9175647910535, 619.5594285487243, 611.4068028199456, 649.8906426243169, 658.722112276914, 655.1164811454406, 656.5083931946024]
Elapsed: 0.07830938366612747~0.016699032336847185
Time per graph: 0.0016079733680180429~0.00034069770623654943
Speed: 635.3813088634336~68.62120774187251
Total Time: 0.0743
best val loss: 0.3953913450241089 test_score: 0.8958

Testing...
Test loss: 0.6701 score: 0.9167 time: 0.07s
test Score 0.9167
Epoch Time List: [0.41281948308460414, 0.38811845995951444, 0.2691194099606946, 0.2578462631208822, 0.2592018611030653, 0.25946645881049335, 0.2621396060567349, 0.25859534507617354, 0.35423957009334117, 0.26995226298458874, 0.2633811328560114, 0.2621803539805114, 0.25076676497701555, 0.2594373810570687, 0.38312739494722337, 0.2512215368915349, 0.25148590689059347, 0.251044855103828, 0.25236836611293256, 0.2573338628280908, 0.25583059806376696, 0.3745249940548092, 0.25318286602851003, 0.24462226394098252, 0.24492181988898665, 0.24584747676271945, 0.24591726588550955, 0.2429841220146045, 0.3777448032051325, 0.2519837359432131, 0.25330595893319696, 0.2514737988822162, 0.2529685531044379, 0.25327281386125833, 0.25934564997442067, 0.2745620650239289, 0.39732213714160025, 0.24983132106717676, 0.2511101209092885, 0.2522898759925738, 0.2571489429101348, 0.25520558294374496, 0.350181742105633, 0.2520269110100344, 0.2535983950365335, 0.2597151710651815, 0.27975436905398965, 0.2681678170338273, 0.4114964120090008, 0.26715149416122586, 0.25708114507142454, 0.2572442159289494, 0.2575485990382731, 0.2619460889836773, 0.25812800403218716, 0.26142691797576845, 0.2597676559817046, 0.2590520289959386, 0.2633909899741411, 0.25920631911139935, 0.26055669598281384, 0.2605808759108186, 0.2590580808464438, 0.25863800512161106, 0.2643516168463975, 0.2602966690901667, 0.2591591428499669, 0.2591684340732172, 0.2596386701334268, 0.2589373431401327, 0.2581608289619908, 0.25869054184295237, 0.2589627970010042, 0.2594492509961128, 0.258067018003203, 0.25833792972844094, 0.2588292360305786, 0.2592153260484338, 0.26088436401914805, 0.26149500685278326, 0.2601877710549161, 0.26483053795527667, 0.2779159920755774, 0.29623423994053155, 0.2828466729260981, 0.27197478082962334, 0.2567343859700486, 0.2579446348827332, 0.2564589697867632, 0.2565314080566168, 0.25783187802881, 0.2575269879307598, 0.2594300889177248, 0.2642907170811668, 0.26776262803468853, 0.2742969299433753, 0.27712828398216516, 0.27221162407658994, 0.2652925349539146, 0.2713342810748145, 0.28651070303749293, 0.29528340185061097, 0.2939221929991618, 0.29208509519230574, 0.29305398603901267, 0.29404220287688076, 0.2944203879451379, 0.29530825500842184, 0.29817844391800463, 0.2997472679708153, 0.30171862593851984, 0.29459100286476314, 0.2630853889277205, 0.2621434339089319, 0.26786335196811706, 0.2634581960737705, 0.2618913418846205, 0.26424422510899603, 0.26616798900067806, 0.26314077188726515, 0.2625994828995317, 0.2624753098934889, 0.2610034290701151, 0.25835143006406724, 0.26074008480645716, 0.26271010108757764, 0.2632876959396526, 0.2700118670472875, 0.26631086703855544, 0.2653937239665538, 0.2646518930559978, 0.2661338800098747, 0.2630532290786505, 0.2638908149674535, 0.264156905002892, 0.2686837799847126, 0.26723822695203125, 0.2667768821120262, 0.26894412806723267, 0.26925829192623496, 0.2693120810436085, 0.26585454086307436, 0.26084702415391803, 0.3843881539069116, 0.2602784769842401, 0.2610177960013971, 0.2621824690140784, 0.27297636307775974, 0.26947351987473667, 0.26671765896026045, 0.2602708120830357, 0.27647363604046404, 0.2785297619411722, 0.2759054171619937, 0.2704148478806019, 0.36004015908110887, 0.26491704210639, 0.25314702198375016, 0.27003807108849287, 0.2557560900459066, 0.28335005207918584, 0.25402656791266054, 0.4190228300867602, 0.29116957902442664, 0.26371630106586963, 0.26444421394262463, 0.25964932795614004, 0.2709961460204795, 0.2694806648651138, 0.38096135307569057, 0.26846161007415503, 0.2632771619828418, 0.2626902660122141, 0.2552631559083238, 0.25662601098883897, 0.2535723039181903, 0.2533028300385922, 0.40990922902710736, 0.3082388391485438, 0.31887496914714575, 0.3314981939038262, 0.30967342492658645, 0.4323754619108513, 0.29877107695210725, 0.2848832568852231, 0.26519754994660616, 0.2710543980356306, 0.2665166568476707, 0.26557363104075193, 0.32692306698299944, 0.2633124180138111, 0.26252923801075667, 0.2611608279403299, 0.2633876239415258, 0.26140300394035876, 0.2769293640740216, 0.26610994595102966, 0.38417911995202303, 0.26514460297767073, 0.26382500608451664, 0.26627866306807846, 0.2715572000015527, 0.26587018405552953, 0.39534228609409183, 0.2688587539596483, 0.26445709308609366, 0.2658358790213242, 0.2658020651433617, 0.273973556002602, 0.2666056090965867, 0.3876781560247764, 0.2635641189990565, 0.26100923400372267, 0.2637542790034786, 0.26553075097035617, 0.2762313059065491, 0.2672998448833823, 0.3614353818120435, 0.2752621831605211, 0.27539949386846274, 0.27981386706233025, 0.2868597119813785, 0.2838189689209685, 0.31040545902214944, 0.32638525997754186, 0.27099767210893333, 0.269178589922376, 0.26885251398198307, 0.2714425401063636, 0.2630086148856208, 0.34161457407753915, 0.26986835116986185, 0.26801322598475963, 0.2707035739440471, 0.27434657397679985, 0.28557668707799166, 0.2724715588847175, 0.3830540078924969, 0.28130493697244674, 0.27726410096511245, 0.2760824509896338, 0.29440742800943553, 0.28713617101311684, 0.4397523939842358, 0.31015524291433394, 0.2758844589116052, 0.2732335510663688, 0.27150939393322915, 0.26712020009290427, 0.26395000296179205, 0.418497166945599, 0.2740412378916517, 0.26219537493307143, 0.2622921470319852, 0.280470005935058, 0.2702174849109724, 0.27387782000005245, 0.2592301240656525, 0.2598917919676751, 0.2604040040168911, 0.2609957049135119, 0.2604507690994069, 0.26158584002405405, 0.26146499381866306, 0.25986892892979085, 0.26067541807424277, 0.2617526190588251, 0.2609264780767262, 0.2631002828711644, 0.26172143791336566, 0.26310406206175685, 0.2625099529977888, 0.2628538100980222, 0.2664621419971809, 0.26368761295452714, 0.26412050088401884, 0.26573271700181067, 0.26209418196231127, 0.2610239511122927, 0.26270921307150275, 0.2655278081074357, 0.2657848329981789, 0.26613535499200225, 0.268421693937853, 0.26283204299397767, 0.26537979289423674, 0.26759939605835825, 0.2649101660354063, 0.26743187685497105, 0.26940544496756047, 0.2702355240471661, 0.26438732992392033, 0.26180528302211314, 0.2624676408013329, 0.2627750189276412, 0.26402099314145744, 0.2631314561003819, 0.26299398101400584, 0.263195296167396, 0.2639929560245946, 0.26312915002927184, 0.2632703541312367, 0.26329128502402455, 0.2629323840374127, 0.2634335411712527, 0.26445234089624137, 0.26676262298133224, 0.2659091310342774, 0.26401280309073627, 0.26517610996961594, 0.2644369340268895, 0.26621331204660237, 0.26446091302204877, 0.2649350119754672, 0.26401139597874135, 0.2645071758888662, 0.26414844603277743, 0.2661770791746676, 0.26515529211610556, 0.26653206592891365, 0.2652490659384057, 0.26517428806982934, 0.2722522529074922, 0.27043525699991733, 0.2648898810148239, 0.2642067550914362, 0.26529247616417706, 0.2653662689263001, 0.2666048699757084, 0.26574398402590305, 0.2674159100279212, 0.26653571717906743, 0.26026970287784934, 0.36801093886606395, 0.2689656119327992, 0.2631277779582888, 0.2783064260147512, 0.2753123240545392, 0.2789821260375902, 0.3598702960880473, 0.26056665810756385, 0.2564373549539596, 0.25387915899045765, 0.2551104389131069, 0.26938358799088746, 0.26351815508678555, 0.26039429113734514, 0.3270050409482792, 0.2574406609637663, 0.2553590200841427, 0.255538237048313, 0.26207698800135404, 0.2642321779858321, 0.2602710290811956, 0.38503108685836196, 0.25632976193446666, 0.2564393640495837, 0.25503066391684115, 0.2679723290493712, 0.2733381250873208, 0.2608150851447135, 0.33819804701488465, 0.253534741117619, 0.25562204304151237]
Total Epoch List: [150, 104, 110]
Total Time List: [0.07448487903457135, 0.07944643206428736, 0.07425668102223426]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d081a1c30>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.12s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6922;  Loss pred: 0.6922; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6981 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6893;  Loss pred: 0.6893; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6884;  Loss pred: 0.6884; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6841;  Loss pred: 0.6841; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6813;  Loss pred: 0.6813; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6766;  Loss pred: 0.6766; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6752;  Loss pred: 0.6752; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6704;  Loss pred: 0.6704; Loss self: 0.0000; time: 0.22s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6639;  Loss pred: 0.6639; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6595;  Loss pred: 0.6595; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6566;  Loss pred: 0.6566; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6504;  Loss pred: 0.6504; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6444;  Loss pred: 0.6444; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6410;  Loss pred: 0.6410; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6318;  Loss pred: 0.6318; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6269;  Loss pred: 0.6269; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6201;  Loss pred: 0.6201; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6141;  Loss pred: 0.6141; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 22/1000, LR 0.000270
Train loss: 0.6052;  Loss pred: 0.6052; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6981 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.6004;  Loss pred: 0.6004; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.5896;  Loss pred: 0.5896; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6983 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 25/1000, LR 0.000270
Train loss: 0.5837;  Loss pred: 0.5837; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6985 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.5705;  Loss pred: 0.5705; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6987 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5627;  Loss pred: 0.5627; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6988 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5530;  Loss pred: 0.5530; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6989 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5427;  Loss pred: 0.5427; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6991 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.5322;  Loss pred: 0.5322; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6993 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.5227;  Loss pred: 0.5227; Loss self: 0.0000; time: 0.23s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6995 score: 0.4898 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.5128;  Loss pred: 0.5128; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6997 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 33/1000, LR 0.000270
Train loss: 0.4973;  Loss pred: 0.4973; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7000 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 34/1000, LR 0.000270
Train loss: 0.4853;  Loss pred: 0.4853; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7003 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 35/1000, LR 0.000270
Train loss: 0.4712;  Loss pred: 0.4712; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6962 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7005 score: 0.4898 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 014,   Train_Loss: 0.6504,   Val_Loss: 0.6945,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.5102,   Val_Loss: 0.6945,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.4898,   Test_loss: 0.6976


[0.07692270504776388, 0.07690094190184027, 0.121361089986749, 0.07645272894296795, 0.07627751096151769, 0.0776337559800595, 0.07663132704328746, 0.07894080993719399, 0.07557017600629479, 0.07605117000639439, 0.07573828496970236, 0.07558467809576541, 0.07529121998231858, 0.07402989803813398, 0.07729745900724083, 0.07580834708642215, 0.07672818098217249, 0.08082813303917646, 0.07603946700692177, 0.07745800900738686, 0.07941041002050042, 0.08151787798851728, 0.07800891401711851, 0.08020091301295906, 0.08173426298890263, 0.08089256496168673, 0.08147202502004802, 0.08065283601172268, 0.08018246898427606, 0.08813354501035064, 0.08016942301765084, 0.0800207790452987, 0.08000532700680196, 0.07459982798900455, 0.07629724498838186]
[0.0015698511234237527, 0.001569406977588577, 0.0024767569385050815, 0.0015602597743462846, 0.0015566838971738303, 0.0015843623669399899, 0.0015639046335364788, 0.0016110369374937549, 0.0015422484899243834, 0.0015520646940080486, 0.0015456792850959667, 0.001542544450933988, 0.0015365555098432364, 0.0015108142456762036, 0.0015774991634130782, 0.0015471091242126968, 0.0015658812445341324, 0.0016495537354933973, 0.0015518258572841178, 0.0015807756940283033, 0.001620620612663274, 0.001663630163030965, 0.0015920186534105819, 0.0016367533267950829, 0.0016680461834469925, 0.0016508686726874843, 0.0016626943881642453, 0.0016459762451371976, 0.0016363769180464502, 0.0017986437757214417, 0.001636110673829609, 0.0016330771233734427, 0.0016327617756490196, 0.0015224454691633582, 0.0015570866324159565]
[637.0030795143548, 637.1833528716169, 403.75378966479406, 640.918913915459, 642.3911764074302, 631.1687407290434, 639.4251788478217, 620.718232293092, 648.4039417338189, 644.3030395966305, 646.9647420667302, 648.2795354095077, 650.8062960263784, 661.894738457688, 633.9147577336265, 646.366816890752, 638.6180328109821, 606.2245675803283, 644.4022022871306, 632.6008198239006, 617.0475632521009, 601.0951365405047, 628.1333437002762, 610.9656132229126, 599.5037846814978, 605.7417022591377, 601.433436666665, 607.5421823093484, 611.1061510167391, 555.9744589219157, 611.2055962933862, 612.340951745318, 612.4592178197594, 656.8379756481775, 642.2250240812949]
Elapsed: 0.07945269465978656~0.007699874064133693
Time per graph: 0.0016214835644854403~0.00015714028702313657
Speed: 620.8272597948604~42.905789724530514
Total Time: 0.0767
best val loss: 0.6944723129272461 test_score: 0.4898

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4898 time: 0.07s
test Score 0.4898
Epoch Time List: [0.2731443481752649, 0.26727163803298026, 0.34975075197871774, 0.26702513894997537, 0.26408625789918005, 0.2645684687886387, 0.2678214611951262, 0.2806934468680993, 0.2654042668873444, 0.26154610491357744, 0.3622353959362954, 0.25896407198160887, 0.26023257290944457, 0.2578677381388843, 0.2647422271547839, 0.2647106309887022, 0.2611411309335381, 0.3916037258459255, 0.2628089791396633, 0.26124175800941885, 0.26840383606031537, 0.27843115385621786, 0.2649751431308687, 0.36986157100182027, 0.2771551989717409, 0.27500270097516477, 0.2773968109395355, 0.27889837289694697, 0.27538562996778637, 0.27805028192233294, 0.3762972039403394, 0.2732389367884025, 0.2734761780593544, 0.26391982287168503, 0.27540008805226535]
Total Epoch List: [35]
Total Time List: [0.0767092079622671]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d081a1ab0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6971;  Loss pred: 0.6971; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7001 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5102 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6979;  Loss pred: 0.6979; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7000 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5102 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6959;  Loss pred: 0.6959; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6998 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5102 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6956;  Loss pred: 0.6956; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6998 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5102 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6997 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5102 time: 0.08s
Epoch 6/1000, LR 0.000120
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6995 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5102 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6993 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.5102 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6881;  Loss pred: 0.6881; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6991 score: 0.4898 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5102 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6866;  Loss pred: 0.6866; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6989 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.5102 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6987 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5102 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6790;  Loss pred: 0.6790; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6985 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5102 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6739;  Loss pred: 0.6739; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6982 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5102 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6703;  Loss pred: 0.6703; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6980 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5102 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6669;  Loss pred: 0.6669; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6977 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5102 time: 0.09s
Epoch 15/1000, LR 0.000270
Train loss: 0.6631;  Loss pred: 0.6631; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6974 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5102 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6561;  Loss pred: 0.6561; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5102 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6551;  Loss pred: 0.6551; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6970 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5102 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6495;  Loss pred: 0.6495; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5102 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6462;  Loss pred: 0.6462; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5102 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6382;  Loss pred: 0.6382; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6960 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5102 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6335;  Loss pred: 0.6335; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5102 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6261;  Loss pred: 0.6261; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6213;  Loss pred: 0.6213; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5102 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.6119;  Loss pred: 0.6119; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5102 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.6083;  Loss pred: 0.6083; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5102 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.6021;  Loss pred: 0.6021; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5102 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5910;  Loss pred: 0.5910; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5102 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5801;  Loss pred: 0.5801; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5102 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5686;  Loss pred: 0.5686; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5102 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5606;  Loss pred: 0.5606; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6894 score: 0.5102 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5463;  Loss pred: 0.5463; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6887 score: 0.5102 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5384;  Loss pred: 0.5384; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6879 score: 0.5102 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.5260;  Loss pred: 0.5260; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6884 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6868 score: 0.5102 time: 0.07s
Epoch 34/1000, LR 0.000270
Train loss: 0.5084;  Loss pred: 0.5084; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6874 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6858 score: 0.5102 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4980;  Loss pred: 0.4980; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6848 score: 0.5102 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4840;  Loss pred: 0.4840; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6851 score: 0.4898 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6837 score: 0.5102 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4752;  Loss pred: 0.4752; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6839 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6825 score: 0.5102 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4645;  Loss pred: 0.4645; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6825 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6812 score: 0.5102 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4443;  Loss pred: 0.4443; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6797 score: 0.5102 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.4355;  Loss pred: 0.4355; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6781 score: 0.5102 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.4174;  Loss pred: 0.4174; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6772 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6763 score: 0.5102 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.4007;  Loss pred: 0.4007; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6752 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6744 score: 0.5102 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3928;  Loss pred: 0.3928; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6730 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6724 score: 0.5102 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3648;  Loss pred: 0.3648; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6705 score: 0.4898 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6700 score: 0.5102 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3513;  Loss pred: 0.3513; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6676 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6674 score: 0.5102 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3391;  Loss pred: 0.3391; Loss self: 0.0000; time: 0.11s
Val loss: 0.6643 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6643 score: 0.5102 time: 0.08s
Epoch 47/1000, LR 0.000269
Train loss: 0.3263;  Loss pred: 0.3263; Loss self: 0.0000; time: 0.11s
Val loss: 0.6606 score: 0.5102 time: 0.07s
Test loss: 0.6609 score: 0.5510 time: 0.08s
Epoch 48/1000, LR 0.000269
Train loss: 0.3087;  Loss pred: 0.3087; Loss self: 0.0000; time: 0.11s
Val loss: 0.6564 score: 0.5102 time: 0.07s
Test loss: 0.6572 score: 0.5918 time: 0.08s
Epoch 49/1000, LR 0.000269
Train loss: 0.2951;  Loss pred: 0.2951; Loss self: 0.0000; time: 0.11s
Val loss: 0.6518 score: 0.6122 time: 0.08s
Test loss: 0.6530 score: 0.5918 time: 0.08s
Epoch 50/1000, LR 0.000269
Train loss: 0.2795;  Loss pred: 0.2795; Loss self: 0.0000; time: 0.11s
Val loss: 0.6469 score: 0.6939 time: 0.07s
Test loss: 0.6484 score: 0.6735 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2594;  Loss pred: 0.2594; Loss self: 0.0000; time: 0.11s
Val loss: 0.6416 score: 0.7347 time: 0.08s
Test loss: 0.6436 score: 0.7143 time: 0.08s
Epoch 52/1000, LR 0.000269
Train loss: 0.2451;  Loss pred: 0.2451; Loss self: 0.0000; time: 0.11s
Val loss: 0.6359 score: 0.8367 time: 0.08s
Test loss: 0.6384 score: 0.7551 time: 0.08s
Epoch 53/1000, LR 0.000269
Train loss: 0.2358;  Loss pred: 0.2358; Loss self: 0.0000; time: 0.11s
Val loss: 0.6298 score: 0.8776 time: 0.08s
Test loss: 0.6329 score: 0.7755 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.2204;  Loss pred: 0.2204; Loss self: 0.0000; time: 0.11s
Val loss: 0.6232 score: 0.8980 time: 0.07s
Test loss: 0.6269 score: 0.8571 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.2105;  Loss pred: 0.2105; Loss self: 0.0000; time: 0.11s
Val loss: 0.6160 score: 0.8980 time: 0.07s
Test loss: 0.6204 score: 0.8571 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1957;  Loss pred: 0.1957; Loss self: 0.0000; time: 0.11s
Val loss: 0.6084 score: 0.8776 time: 0.08s
Test loss: 0.6136 score: 0.8980 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1877;  Loss pred: 0.1877; Loss self: 0.0000; time: 0.11s
Val loss: 0.6003 score: 0.8776 time: 0.08s
Test loss: 0.6064 score: 0.8980 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1728;  Loss pred: 0.1728; Loss self: 0.0000; time: 0.11s
Val loss: 0.5918 score: 0.8980 time: 0.07s
Test loss: 0.5989 score: 0.8980 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1677;  Loss pred: 0.1677; Loss self: 0.0000; time: 0.11s
Val loss: 0.5826 score: 0.8980 time: 0.08s
Test loss: 0.5909 score: 0.8776 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1529;  Loss pred: 0.1529; Loss self: 0.0000; time: 0.11s
Val loss: 0.5729 score: 0.8980 time: 0.07s
Test loss: 0.5826 score: 0.8776 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1477;  Loss pred: 0.1477; Loss self: 0.0000; time: 0.11s
Val loss: 0.5627 score: 0.9184 time: 0.07s
Test loss: 0.5740 score: 0.8776 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1443;  Loss pred: 0.1443; Loss self: 0.0000; time: 0.11s
Val loss: 0.5520 score: 0.9184 time: 0.07s
Test loss: 0.5650 score: 0.8776 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1282;  Loss pred: 0.1282; Loss self: 0.0000; time: 0.11s
Val loss: 0.5407 score: 0.9184 time: 0.07s
Test loss: 0.5555 score: 0.8980 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.1185;  Loss pred: 0.1185; Loss self: 0.0000; time: 0.11s
Val loss: 0.5290 score: 0.9184 time: 0.07s
Test loss: 0.5457 score: 0.9184 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.1169;  Loss pred: 0.1169; Loss self: 0.0000; time: 0.11s
Val loss: 0.5169 score: 0.9184 time: 0.08s
Test loss: 0.5355 score: 0.9184 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0979;  Loss pred: 0.0979; Loss self: 0.0000; time: 0.11s
Val loss: 0.5043 score: 0.9184 time: 0.07s
Test loss: 0.5250 score: 0.9184 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0963;  Loss pred: 0.0963; Loss self: 0.0000; time: 0.11s
Val loss: 0.4913 score: 0.9388 time: 0.07s
Test loss: 0.5141 score: 0.9184 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0934;  Loss pred: 0.0934; Loss self: 0.0000; time: 0.11s
Val loss: 0.4778 score: 0.9388 time: 0.07s
Test loss: 0.5027 score: 0.8980 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0832;  Loss pred: 0.0832; Loss self: 0.0000; time: 0.11s
Val loss: 0.4634 score: 0.9388 time: 0.07s
Test loss: 0.4907 score: 0.8980 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0767;  Loss pred: 0.0767; Loss self: 0.0000; time: 0.11s
Val loss: 0.4486 score: 0.9388 time: 0.07s
Test loss: 0.4784 score: 0.8980 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0686;  Loss pred: 0.0686; Loss self: 0.0000; time: 0.11s
Val loss: 0.4336 score: 0.9388 time: 0.07s
Test loss: 0.4660 score: 0.8980 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0685;  Loss pred: 0.0685; Loss self: 0.0000; time: 0.11s
Val loss: 0.4184 score: 0.9388 time: 0.07s
Test loss: 0.4533 score: 0.9184 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0639;  Loss pred: 0.0639; Loss self: 0.0000; time: 0.11s
Val loss: 0.4026 score: 0.9388 time: 0.07s
Test loss: 0.4401 score: 0.9184 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0624;  Loss pred: 0.0624; Loss self: 0.0000; time: 0.11s
Val loss: 0.3873 score: 0.9388 time: 0.07s
Test loss: 0.4273 score: 0.9184 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0549;  Loss pred: 0.0549; Loss self: 0.0000; time: 0.11s
Val loss: 0.3723 score: 0.9388 time: 0.07s
Test loss: 0.4147 score: 0.9184 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0540;  Loss pred: 0.0540; Loss self: 0.0000; time: 0.11s
Val loss: 0.3574 score: 0.9388 time: 0.07s
Test loss: 0.4020 score: 0.9184 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0551;  Loss pred: 0.0551; Loss self: 0.0000; time: 0.11s
Val loss: 0.3427 score: 0.9184 time: 0.07s
Test loss: 0.3894 score: 0.9184 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0425;  Loss pred: 0.0425; Loss self: 0.0000; time: 0.11s
Val loss: 0.3290 score: 0.9184 time: 0.07s
Test loss: 0.3775 score: 0.9184 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0443;  Loss pred: 0.0443; Loss self: 0.0000; time: 0.11s
Val loss: 0.3155 score: 0.9184 time: 0.07s
Test loss: 0.3657 score: 0.9184 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0408;  Loss pred: 0.0408; Loss self: 0.0000; time: 0.11s
Val loss: 0.3025 score: 0.9184 time: 0.07s
Test loss: 0.3542 score: 0.9184 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0366;  Loss pred: 0.0366; Loss self: 0.0000; time: 0.11s
Val loss: 0.2905 score: 0.9184 time: 0.08s
Test loss: 0.3437 score: 0.9184 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0390;  Loss pred: 0.0390; Loss self: 0.0000; time: 0.11s
Val loss: 0.2789 score: 0.9388 time: 0.07s
Test loss: 0.3333 score: 0.9184 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0343;  Loss pred: 0.0343; Loss self: 0.0000; time: 0.11s
Val loss: 0.2678 score: 0.9388 time: 0.07s
Test loss: 0.3232 score: 0.9184 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0273;  Loss pred: 0.0273; Loss self: 0.0000; time: 0.11s
Val loss: 0.2574 score: 0.9388 time: 0.07s
Test loss: 0.3137 score: 0.9184 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0295;  Loss pred: 0.0295; Loss self: 0.0000; time: 0.11s
Val loss: 0.2478 score: 0.9388 time: 0.07s
Test loss: 0.3050 score: 0.9184 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0250;  Loss pred: 0.0250; Loss self: 0.0000; time: 0.11s
Val loss: 0.2390 score: 0.9388 time: 0.07s
Test loss: 0.2971 score: 0.9184 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0254;  Loss pred: 0.0254; Loss self: 0.0000; time: 0.11s
Val loss: 0.2308 score: 0.9388 time: 0.07s
Test loss: 0.2898 score: 0.9184 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0200;  Loss pred: 0.0200; Loss self: 0.0000; time: 0.11s
Val loss: 0.2228 score: 0.9388 time: 0.07s
Test loss: 0.2832 score: 0.9184 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0209;  Loss pred: 0.0209; Loss self: 0.0000; time: 0.11s
Val loss: 0.2151 score: 0.9388 time: 0.07s
Test loss: 0.2771 score: 0.9184 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.11s
Val loss: 0.2081 score: 0.9388 time: 0.07s
Test loss: 0.2717 score: 0.9184 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0188;  Loss pred: 0.0188; Loss self: 0.0000; time: 0.11s
Val loss: 0.2018 score: 0.9388 time: 0.07s
Test loss: 0.2672 score: 0.9184 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.11s
Val loss: 0.1962 score: 0.9388 time: 0.07s
Test loss: 0.2632 score: 0.9184 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.11s
Val loss: 0.1917 score: 0.9388 time: 0.07s
Test loss: 0.2602 score: 0.9184 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.11s
Val loss: 0.1879 score: 0.9388 time: 0.07s
Test loss: 0.2579 score: 0.9184 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.11s
Val loss: 0.1847 score: 0.9388 time: 0.08s
Test loss: 0.2561 score: 0.9184 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.11s
Val loss: 0.1821 score: 0.9388 time: 0.07s
Test loss: 0.2549 score: 0.9184 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0144;  Loss pred: 0.0144; Loss self: 0.0000; time: 0.11s
Val loss: 0.1803 score: 0.9388 time: 0.07s
Test loss: 0.2541 score: 0.9184 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.11s
Val loss: 0.1787 score: 0.9388 time: 0.07s
Test loss: 0.2540 score: 0.9184 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.11s
Val loss: 0.1774 score: 0.9388 time: 0.07s
Test loss: 0.2545 score: 0.9184 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.11s
Val loss: 0.1762 score: 0.9388 time: 0.07s
Test loss: 0.2555 score: 0.9184 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.11s
Val loss: 0.1754 score: 0.9388 time: 0.07s
Test loss: 0.2571 score: 0.9184 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0088;  Loss pred: 0.0088; Loss self: 0.0000; time: 0.11s
Val loss: 0.1751 score: 0.9388 time: 0.07s
Test loss: 0.2593 score: 0.9184 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.11s
Val loss: 0.1753 score: 0.9388 time: 0.08s
Test loss: 0.2619 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.1756 score: 0.9388 time: 0.08s
Test loss: 0.2650 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.11s
Val loss: 0.1761 score: 0.9388 time: 0.07s
Test loss: 0.2684 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.11s
Val loss: 0.1773 score: 0.9388 time: 0.07s
Test loss: 0.2722 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.11s
Val loss: 0.1783 score: 0.9388 time: 0.08s
Test loss: 0.2759 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.11s
Val loss: 0.1795 score: 0.9388 time: 0.08s
Test loss: 0.2800 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.11s
Val loss: 0.1809 score: 0.9388 time: 0.08s
Test loss: 0.2843 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.1825 score: 0.9388 time: 0.08s
Test loss: 0.2883 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.11s
Val loss: 0.1847 score: 0.9388 time: 0.08s
Test loss: 0.2914 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.11s
Val loss: 0.1879 score: 0.9388 time: 0.08s
Test loss: 0.2933 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.11s
Val loss: 0.1926 score: 0.9388 time: 0.07s
Test loss: 0.2934 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.1968 score: 0.9388 time: 0.08s
Test loss: 0.2941 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.2010 score: 0.9388 time: 0.08s
Test loss: 0.2958 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.11s
Val loss: 0.2047 score: 0.9388 time: 0.07s
Test loss: 0.2980 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.2084 score: 0.9388 time: 0.08s
Test loss: 0.3005 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.11s
Val loss: 0.2119 score: 0.9388 time: 0.08s
Test loss: 0.3031 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.11s
Val loss: 0.2151 score: 0.9388 time: 0.08s
Test loss: 0.3062 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.11s
Val loss: 0.2179 score: 0.9388 time: 0.07s
Test loss: 0.3096 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.11s
Val loss: 0.2206 score: 0.9388 time: 0.07s
Test loss: 0.3129 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 122/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.11s
Val loss: 0.2231 score: 0.9388 time: 0.07s
Test loss: 0.3164 score: 0.9184 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 101,   Train_Loss: 0.0088,   Val_Loss: 0.1751,   Val_Precision: 0.8929,   Val_Recall: 1.0000,   Val_accuracy: 0.9434,   Val_Score: 0.9388,   Val_Loss: 0.1751,   Test_Precision: 0.9167,   Test_Recall: 0.9167,   Test_accuracy: 0.9167,   Test_Score: 0.9184,   Test_loss: 0.2593


[0.07692270504776388, 0.07690094190184027, 0.121361089986749, 0.07645272894296795, 0.07627751096151769, 0.0776337559800595, 0.07663132704328746, 0.07894080993719399, 0.07557017600629479, 0.07605117000639439, 0.07573828496970236, 0.07558467809576541, 0.07529121998231858, 0.07402989803813398, 0.07729745900724083, 0.07580834708642215, 0.07672818098217249, 0.08082813303917646, 0.07603946700692177, 0.07745800900738686, 0.07941041002050042, 0.08151787798851728, 0.07800891401711851, 0.08020091301295906, 0.08173426298890263, 0.08089256496168673, 0.08147202502004802, 0.08065283601172268, 0.08018246898427606, 0.08813354501035064, 0.08016942301765084, 0.0800207790452987, 0.08000532700680196, 0.07459982798900455, 0.07629724498838186, 0.0764174279756844, 0.07580985501408577, 0.07629474601708353, 0.07727385603357106, 0.08043729700148106, 0.07726840500254184, 0.07704292994458228, 0.07708066399209201, 0.07716439198702574, 0.07762589899357408, 0.07802648900542408, 0.07865898101590574, 0.07654833304695785, 0.09658113098703325, 0.07646763499360532, 0.07673937000799924, 0.07670044107362628, 0.07732105604372919, 0.08018083509523422, 0.07825231493916363, 0.07921763497870415, 0.07782119803596288, 0.07773095101583749, 0.07757538394071162, 0.07747943396680057, 0.08174359297845513, 0.0782207460142672, 0.07875439606141299, 0.07709370204247534, 0.0766707540024072, 0.07659764599520713, 0.07775049598421901, 0.07911214500200003, 0.07660499901976436, 0.07618113700300455, 0.08172908402048051, 0.08207557210698724, 0.0783143910812214, 0.07696280989330262, 0.08478832698892802, 0.07846986106596887, 0.07849531702231616, 0.07872625603340566, 0.07818822609260678, 0.0785652210470289, 0.08084386889822781, 0.08127224107738584, 0.08547678391914815, 0.08255451510194689, 0.078014096012339, 0.08121871598996222, 0.08084443199913949, 0.07780081895180047, 0.07874972792342305, 0.0782552759628743, 0.0784106960054487, 0.07818221999332309, 0.07837291806936264, 0.07841281802393496, 0.07836256292648613, 0.07786862691864371, 0.07972017105203122, 0.07788557303138077, 0.0781248229322955, 0.07820378290489316, 0.07852463598828763, 0.07803174492437392, 0.07799423602409661, 0.07791354099754244, 0.07742156204767525, 0.07829624996520579, 0.07842620299197733, 0.07885711209382862, 0.07827096700202674, 0.07799642800819129, 0.07814664707984775, 0.07806266902480274, 0.07800916000269353, 0.07799114298541099, 0.07832160999532789, 0.07796404894907027, 0.07823255995754153, 0.0786545870359987, 0.07843319303356111, 0.07881217100657523, 0.0780914860079065, 0.07807123102247715, 0.07893109298311174, 0.07863889704458416, 0.07839964400045574, 0.07834683894179761, 0.07858940295409411, 0.07875724497716874, 0.07794274890329689, 0.07815687893889844, 0.07917897799052298, 0.07897563301958144, 0.07775064499583095, 0.07791092502884567, 0.07808588503394276, 0.0787189279217273, 0.07871981093194336, 0.07873524201568216, 0.07854553498327732, 0.07850083301309496, 0.07879852096084505, 0.07862390903756022, 0.07879290997516364, 0.07881562900729477, 0.07838873192667961, 0.07855042407754809, 0.07832488999702036, 0.07842142600566149, 0.07914623792748898, 0.07924642495345324, 0.0793402650160715, 0.07915928203146905, 0.079938855022192, 0.0788995010079816, 0.0782496890751645, 0.07877094601280987, 0.0781165671069175]
[0.0015698511234237527, 0.001569406977588577, 0.0024767569385050815, 0.0015602597743462846, 0.0015566838971738303, 0.0015843623669399899, 0.0015639046335364788, 0.0016110369374937549, 0.0015422484899243834, 0.0015520646940080486, 0.0015456792850959667, 0.001542544450933988, 0.0015365555098432364, 0.0015108142456762036, 0.0015774991634130782, 0.0015471091242126968, 0.0015658812445341324, 0.0016495537354933973, 0.0015518258572841178, 0.0015807756940283033, 0.001620620612663274, 0.001663630163030965, 0.0015920186534105819, 0.0016367533267950829, 0.0016680461834469925, 0.0016508686726874843, 0.0016626943881642453, 0.0016459762451371976, 0.0016363769180464502, 0.0017986437757214417, 0.001636110673829609, 0.0016330771233734427, 0.0016327617756490196, 0.0015224454691633582, 0.0015570866324159565, 0.001559539346442539, 0.0015471398982466484, 0.0015570356330017047, 0.0015770174700728788, 0.001641577489826144, 0.0015769062245416703, 0.0015723046927465772, 0.0015730747753488167, 0.0015747835099393008, 0.001584202020277022, 0.0015923773266413078, 0.0016052853268552192, 0.001562210878509344, 0.001971043489531291, 0.001560563979461333, 0.0015661095919999846, 0.0015653151239515568, 0.0015779807355863098, 0.0016363435733721269, 0.0015969860191666046, 0.0016166864281368194, 0.0015881877150196507, 0.0015863459390987242, 0.0015831711008308493, 0.0015812129380979709, 0.0016682365913970433, 0.0015963417553932083, 0.0016072325726818977, 0.001573340858009701, 0.001564709265355249, 0.0015632172652083089, 0.0015867448160044697, 0.0016145335714693885, 0.0015633673269339666, 0.0015547170816939703, 0.001667940490213888, 0.0016750116756528008, 0.0015982528792086001, 0.001570669589659237, 0.0017303740201822044, 0.0016014257360401811, 0.001601945245353391, 0.001606658286396034, 0.0015956780835225874, 0.0016033718581026305, 0.001649874875474037, 0.0016586171648446091, 0.0017444241616152683, 0.001684786022488712, 0.0015921244084150816, 0.001657524816121678, 0.0016498863673293773, 0.0015877718153428665, 0.0016071373045596542, 0.0015970464482219244, 0.0016002182858254835, 0.001595555510067818, 0.001599447307538013, 0.0016002615923252032, 0.0015992359780915538, 0.001589155651400892, 0.001626942266367984, 0.0015895014904363423, 0.0015943841414754183, 0.0015959955694876155, 0.0016025435915977067, 0.0015924845902933454, 0.0015917191025325839, 0.0015900722652559681, 0.0015800318785239846, 0.0015978826523511385, 0.0016005347549383128, 0.0016093288182414003, 0.0015973666735107498, 0.001591763836901863, 0.0015948295322417909, 0.0015931156943837295, 0.0015920236735243577, 0.0015916559792941017, 0.0015984002039862834, 0.0015911030397769443, 0.0015965828562763576, 0.0016051956537958918, 0.001600677408848186, 0.0016084116531954128, 0.0015937037960797244, 0.0015932904290301459, 0.0016108386323084028, 0.0016048754498894726, 0.0015999927347031782, 0.0015989150804448494, 0.001603865366410084, 0.0016072907138197702, 0.0015906683449652425, 0.001595038345691805, 0.001615897510010673, 0.001611747612644519, 0.0015867478570577745, 0.0015900188781397076, 0.0015935894904886277, 0.0016065087330964754, 0.0016065267537131297, 0.001606841673789432, 0.0016029701016995372, 0.0016020578165937746, 0.0016081330808335726, 0.0016045695721951065, 0.001608018570921707, 0.0016084822246386688, 0.001599770039319992, 0.0016030698791336343, 0.001598467142796334, 0.001600437265421663, 0.001615229345458959, 0.001617273978641903, 0.0016191890819606427, 0.0016154955516626335, 0.0016314052045345306, 0.0016101938981220735, 0.0015969324301053978, 0.0016075703267920383, 0.0015942156552432142]
[637.0030795143548, 637.1833528716169, 403.75378966479406, 640.918913915459, 642.3911764074302, 631.1687407290434, 639.4251788478217, 620.718232293092, 648.4039417338189, 644.3030395966305, 646.9647420667302, 648.2795354095077, 650.8062960263784, 661.894738457688, 633.9147577336265, 646.366816890752, 638.6180328109821, 606.2245675803283, 644.4022022871306, 632.6008198239006, 617.0475632521009, 601.0951365405047, 628.1333437002762, 610.9656132229126, 599.5037846814978, 605.7417022591377, 601.433436666665, 607.5421823093484, 611.1061510167391, 555.9744589219157, 611.2055962933862, 612.340951745318, 612.4592178197594, 656.8379756481775, 642.2250240812949, 641.2149858745772, 646.3539600609394, 642.2460596307401, 634.1083843248654, 609.1701465191923, 634.1531185791667, 636.0090411313039, 635.6976894364466, 635.0079193034886, 631.2326251327054, 627.9918605153914, 622.9422167329074, 640.1184460795693, 507.3454773125262, 640.7939777933196, 638.5249187593315, 638.8489989642162, 633.7212980160008, 611.1186038633871, 626.1795582417529, 618.5491401399768, 629.6484921416402, 630.3795252680798, 631.6436672417777, 632.425890217476, 599.4353589634206, 626.4322765607805, 622.1874898486886, 635.5901805442303, 639.0963625903767, 639.7063429738563, 630.2210600681635, 619.373927969735, 639.6449399778443, 643.2038418915625, 599.5417737426383, 597.0107638863299, 625.6832150962028, 636.6711411385726, 577.9097399385956, 624.4435676878052, 624.2410612351478, 622.4098854543265, 626.6928212690743, 623.6856378303671, 606.1065689679547, 602.9118841861781, 573.2550729371, 593.5471844209818, 628.0916206764734, 603.3092176199373, 606.1023472899353, 629.8134217630371, 622.2243719705044, 626.1558648549968, 624.9147437308173, 626.7409649429844, 625.2159700961163, 624.8978322019124, 625.29858863815, 629.2649805061371, 614.6499606482155, 629.1280668918938, 627.2014215310844, 626.568155399732, 624.0079865802703, 627.9495613931145, 628.2515541899951, 628.9022341000464, 632.898622864602, 625.8281848974274, 624.791181144043, 621.3770540023968, 626.0303389215978, 628.2338980299708, 627.0262619192524, 627.7008026004247, 628.1313630131142, 628.2764699212823, 625.6255457838902, 628.4948083187555, 626.3376786672114, 622.9770169357528, 624.7354991531861, 621.7313820210837, 627.4691711595668, 627.6319632502352, 620.7946469268345, 623.1013129828049, 625.0028380194578, 625.4240842620488, 623.4937301740546, 622.1649832241442, 628.666562181352, 626.9441751673229, 618.8511299787788, 620.4445362008153, 630.2198522292313, 628.9233503755511, 627.5141785061467, 622.4678269084436, 622.4608446069897, 622.3388503745297, 623.8419537206323, 624.1971979052269, 621.8390827963392, 623.2200942412023, 621.883365082535, 621.7041038328173, 625.0898413031076, 623.8031248771523, 625.599346540596, 624.8292398618528, 619.1071273013897, 618.3244231999234, 617.593097150285, 619.0051089715606, 612.9684993160961, 621.0432179418103, 626.2005712627426, 622.0567668697483, 627.2677079233923]
Elapsed: 0.07882275719308313~0.004124537044992768
Time per graph: 0.0016086276978180228~8.417422540801568e-05
Speed: 622.9028985549484~24.366299310692316
Total Time: 0.0788
best val loss: 0.17508894205093384 test_score: 0.9184

Testing...
Test loss: 0.5141 score: 0.9184 time: 0.07s
test Score 0.9184
Epoch Time List: [0.2731443481752649, 0.26727163803298026, 0.34975075197871774, 0.26702513894997537, 0.26408625789918005, 0.2645684687886387, 0.2678214611951262, 0.2806934468680993, 0.2654042668873444, 0.26154610491357744, 0.3622353959362954, 0.25896407198160887, 0.26023257290944457, 0.2578677381388843, 0.2647422271547839, 0.2647106309887022, 0.2611411309335381, 0.3916037258459255, 0.2628089791396633, 0.26124175800941885, 0.26840383606031537, 0.27843115385621786, 0.2649751431308687, 0.36986157100182027, 0.2771551989717409, 0.27500270097516477, 0.2773968109395355, 0.27889837289694697, 0.27538562996778637, 0.27805028192233294, 0.3762972039403394, 0.2732389367884025, 0.2734761780593544, 0.26391982287168503, 0.27540008805226535, 0.2502047768794, 0.24894882808439434, 0.2500641978112981, 0.25124207488261163, 0.25768170692026615, 0.25758186902385205, 0.253087360993959, 0.36069020617287606, 0.25349593616556376, 0.2541071887826547, 0.25685447303112596, 0.2622440828708932, 0.2542286610696465, 0.2694191540358588, 0.28970495401881635, 0.25078967097215354, 0.2505298600299284, 0.2524770798627287, 0.2585088168270886, 0.2594255961012095, 0.25475740095134825, 0.2973432228900492, 0.2518807720625773, 0.2518746060086414, 0.2537402840098366, 0.2600411350140348, 0.2579010990448296, 0.25416986702475697, 0.29389150196220726, 0.24933350016362965, 0.24962746107485145, 0.25001175014767796, 0.25248265999834985, 0.25161252298858017, 0.24765516782645136, 0.35337330400943756, 0.26456259202677757, 0.2663569508586079, 0.2547138888621703, 0.26289431285113096, 0.26101754093542695, 0.25514615804422647, 0.26624952105339617, 0.25890622509177774, 0.25994969287421554, 0.26207111799158156, 0.25854223396163434, 0.2637213111156598, 0.2628345239209011, 0.2551303240470588, 0.26600973098538816, 0.26834720303304493, 0.2562778670107946, 0.25704467622563243, 0.25566938100382686, 0.25700909504666924, 0.2563990610651672, 0.2565820011077449, 0.25690595689229667, 0.2568049099063501, 0.2555875381221995, 0.2575667389901355, 0.25680378801189363, 0.25497977808117867, 0.2579526649788022, 0.2568006260553375, 0.25466917909216136, 0.2554147868650034, 0.2553675038507208, 0.255504353903234, 0.2556164679117501, 0.25621825992129743, 0.2577374359825626, 0.257081997115165, 0.2567472639493644, 0.2566229869844392, 0.25591421709395945, 0.25666983996052295, 0.25752459303475916, 0.2571679060347378, 0.25692272605374455, 0.25651234306860715, 0.2572646379703656, 0.2572588480543345, 0.2570956130512059, 0.25633238011505455, 0.25588723400142044, 0.2583624181570485, 0.25776848604436964, 0.25666463805828243, 0.25731266604270786, 0.2569086658768356, 0.2575913720065728, 0.2574642510153353, 0.2569260240998119, 0.25896805396769196, 0.2586006539640948, 0.257301093894057, 0.2549469870282337, 0.25602945405989885, 0.25689621397759765, 0.2583161290967837, 0.25791086605750024, 0.2582536949776113, 0.2574827339267358, 0.2575202329317108, 0.25876641704235226, 0.2590331550454721, 0.26000137883238494, 0.25970119214616716, 0.25927490496542305, 0.25819192093331367, 0.2590796659933403, 0.25946939806453884, 0.2592976139858365, 0.2590146609582007, 0.2596805179491639, 0.25998986582271755, 0.25905089802108705, 0.2581317479489371, 0.2576052109943703, 0.2575614369707182]
Total Epoch List: [35, 122]
Total Time List: [0.0767092079622671, 0.07881162606645375]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d081a2020>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6921;  Loss pred: 0.6921; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6906;  Loss pred: 0.6906; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.6896;  Loss pred: 0.6896; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.6892;  Loss pred: 0.6892; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6893;  Loss pred: 0.6893; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6860;  Loss pred: 0.6860; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5102 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.09s
Epoch 7/1000, LR 0.000150
Train loss: 0.6833;  Loss pred: 0.6833; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6793;  Loss pred: 0.6793; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.08s
Epoch 9/1000, LR 0.000210
Train loss: 0.6752;  Loss pred: 0.6752; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6693;  Loss pred: 0.6693; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.08s
Epoch 11/1000, LR 0.000270
Train loss: 0.6658;  Loss pred: 0.6658; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6606;  Loss pred: 0.6606; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6568;  Loss pred: 0.6568; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6504;  Loss pred: 0.6504; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6397;  Loss pred: 0.6397; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6362;  Loss pred: 0.6362; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6280;  Loss pred: 0.6280; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6188;  Loss pred: 0.6188; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6123;  Loss pred: 0.6123; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.15s
Epoch 20/1000, LR 0.000270
Train loss: 0.6080;  Loss pred: 0.6080; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.5962;  Loss pred: 0.5962; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.5863;  Loss pred: 0.5863; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.5801;  Loss pred: 0.5801; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5621;  Loss pred: 0.5621; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5561;  Loss pred: 0.5561; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5481;  Loss pred: 0.5481; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5102 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.11s
Epoch 27/1000, LR 0.000270
Train loss: 0.5353;  Loss pred: 0.5353; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5277;  Loss pred: 0.5277; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5092;  Loss pred: 0.5092; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.4972;  Loss pred: 0.4972; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6877 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.4883;  Loss pred: 0.4883; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6869 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5000 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.4770;  Loss pred: 0.4770; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6859 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5000 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4620;  Loss pred: 0.4620; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6849 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5000 time: 0.20s
Epoch 34/1000, LR 0.000270
Train loss: 0.4555;  Loss pred: 0.4555; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6837 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.5000 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4384;  Loss pred: 0.4384; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6885 score: 0.5000 time: 0.07s
Epoch 36/1000, LR 0.000270
Train loss: 0.4167;  Loss pred: 0.4167; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6810 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5000 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4084;  Loss pred: 0.4084; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6794 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6868 score: 0.5000 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.3977;  Loss pred: 0.3977; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6777 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6857 score: 0.5000 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.3811;  Loss pred: 0.3811; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6758 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6846 score: 0.5000 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.3634;  Loss pred: 0.3634; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6737 score: 0.5102 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6833 score: 0.5000 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3489;  Loss pred: 0.3489; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6714 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6819 score: 0.5000 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3347;  Loss pred: 0.3347; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6689 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6803 score: 0.5000 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3151;  Loss pred: 0.3151; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6661 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6784 score: 0.5000 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3053;  Loss pred: 0.3053; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6629 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6762 score: 0.5000 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.2883;  Loss pred: 0.2883; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6594 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6738 score: 0.5000 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.2688;  Loss pred: 0.2688; Loss self: 0.0000; time: 0.13s
Val loss: 0.6555 score: 0.5306 time: 0.07s
Test loss: 0.6711 score: 0.5208 time: 0.09s
Epoch 47/1000, LR 0.000269
Train loss: 0.2554;  Loss pred: 0.2554; Loss self: 0.0000; time: 0.17s
Val loss: 0.6513 score: 0.5714 time: 0.07s
Test loss: 0.6680 score: 0.5208 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2480;  Loss pred: 0.2480; Loss self: 0.0000; time: 0.13s
Val loss: 0.6466 score: 0.5714 time: 0.07s
Test loss: 0.6646 score: 0.5208 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2327;  Loss pred: 0.2327; Loss self: 0.0000; time: 0.13s
Val loss: 0.6414 score: 0.5918 time: 0.07s
Test loss: 0.6608 score: 0.5208 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2130;  Loss pred: 0.2130; Loss self: 0.0000; time: 0.13s
Val loss: 0.6357 score: 0.6122 time: 0.07s
Test loss: 0.6565 score: 0.5208 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2096;  Loss pred: 0.2096; Loss self: 0.0000; time: 0.13s
Val loss: 0.6296 score: 0.6122 time: 0.07s
Test loss: 0.6519 score: 0.5208 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.1895;  Loss pred: 0.1895; Loss self: 0.0000; time: 0.13s
Val loss: 0.6229 score: 0.6122 time: 0.07s
Test loss: 0.6469 score: 0.5208 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.1819;  Loss pred: 0.1819; Loss self: 0.0000; time: 0.14s
Val loss: 0.6156 score: 0.6327 time: 0.20s
Test loss: 0.6412 score: 0.5208 time: 0.09s
Epoch 54/1000, LR 0.000269
Train loss: 0.1679;  Loss pred: 0.1679; Loss self: 0.0000; time: 0.13s
Val loss: 0.6077 score: 0.6735 time: 0.07s
Test loss: 0.6352 score: 0.5208 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1509;  Loss pred: 0.1509; Loss self: 0.0000; time: 0.12s
Val loss: 0.5990 score: 0.6735 time: 0.07s
Test loss: 0.6286 score: 0.5208 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1416;  Loss pred: 0.1416; Loss self: 0.0000; time: 0.13s
Val loss: 0.5895 score: 0.7143 time: 0.07s
Test loss: 0.6212 score: 0.5833 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1288;  Loss pred: 0.1288; Loss self: 0.0000; time: 0.13s
Val loss: 0.5794 score: 0.7143 time: 0.07s
Test loss: 0.6133 score: 0.6042 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1166;  Loss pred: 0.1166; Loss self: 0.0000; time: 0.13s
Val loss: 0.5684 score: 0.7143 time: 0.07s
Test loss: 0.6045 score: 0.6458 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1125;  Loss pred: 0.1125; Loss self: 0.0000; time: 0.13s
Val loss: 0.5565 score: 0.7959 time: 0.07s
Test loss: 0.5949 score: 0.6667 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1055;  Loss pred: 0.1055; Loss self: 0.0000; time: 0.14s
Val loss: 0.5441 score: 0.7959 time: 0.13s
Test loss: 0.5849 score: 0.7083 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.0968;  Loss pred: 0.0968; Loss self: 0.0000; time: 0.13s
Val loss: 0.5309 score: 0.8367 time: 0.07s
Test loss: 0.5740 score: 0.7708 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.0891;  Loss pred: 0.0891; Loss self: 0.0000; time: 0.13s
Val loss: 0.5167 score: 0.8571 time: 0.07s
Test loss: 0.5620 score: 0.7708 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.0817;  Loss pred: 0.0817; Loss self: 0.0000; time: 0.13s
Val loss: 0.5022 score: 0.8571 time: 0.07s
Test loss: 0.5495 score: 0.7708 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0727;  Loss pred: 0.0727; Loss self: 0.0000; time: 0.13s
Val loss: 0.4872 score: 0.8571 time: 0.07s
Test loss: 0.5364 score: 0.8125 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0654;  Loss pred: 0.0654; Loss self: 0.0000; time: 0.13s
Val loss: 0.4716 score: 0.8776 time: 0.07s
Test loss: 0.5226 score: 0.8333 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0620;  Loss pred: 0.0620; Loss self: 0.0000; time: 0.13s
Val loss: 0.4559 score: 0.8980 time: 0.07s
Test loss: 0.5087 score: 0.8542 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0567;  Loss pred: 0.0567; Loss self: 0.0000; time: 0.13s
Val loss: 0.4399 score: 0.8980 time: 0.18s
Test loss: 0.4943 score: 0.8542 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0510;  Loss pred: 0.0510; Loss self: 0.0000; time: 0.13s
Val loss: 0.4240 score: 0.9184 time: 0.07s
Test loss: 0.4798 score: 0.8542 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0483;  Loss pred: 0.0483; Loss self: 0.0000; time: 0.13s
Val loss: 0.4079 score: 0.9184 time: 0.07s
Test loss: 0.4648 score: 0.8542 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0443;  Loss pred: 0.0443; Loss self: 0.0000; time: 0.13s
Val loss: 0.3922 score: 0.9184 time: 0.07s
Test loss: 0.4500 score: 0.8542 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0414;  Loss pred: 0.0414; Loss self: 0.0000; time: 0.13s
Val loss: 0.3767 score: 0.9184 time: 0.07s
Test loss: 0.4347 score: 0.8750 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0382;  Loss pred: 0.0382; Loss self: 0.0000; time: 0.13s
Val loss: 0.3616 score: 0.9184 time: 0.07s
Test loss: 0.4197 score: 0.9167 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0323;  Loss pred: 0.0323; Loss self: 0.0000; time: 0.13s
Val loss: 0.3468 score: 0.9184 time: 0.07s
Test loss: 0.4048 score: 0.8958 time: 0.18s
Epoch 74/1000, LR 0.000267
Train loss: 0.0302;  Loss pred: 0.0302; Loss self: 0.0000; time: 0.13s
Val loss: 0.3324 score: 0.9184 time: 0.07s
Test loss: 0.3902 score: 0.8958 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0276;  Loss pred: 0.0276; Loss self: 0.0000; time: 0.13s
Val loss: 0.3187 score: 0.9184 time: 0.07s
Test loss: 0.3762 score: 0.9167 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0253;  Loss pred: 0.0253; Loss self: 0.0000; time: 0.13s
Val loss: 0.3055 score: 0.9184 time: 0.07s
Test loss: 0.3625 score: 0.9167 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0232;  Loss pred: 0.0232; Loss self: 0.0000; time: 0.13s
Val loss: 0.2930 score: 0.9184 time: 0.07s
Test loss: 0.3493 score: 0.9167 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0223;  Loss pred: 0.0223; Loss self: 0.0000; time: 0.13s
Val loss: 0.2810 score: 0.9388 time: 0.07s
Test loss: 0.3366 score: 0.9167 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0210;  Loss pred: 0.0210; Loss self: 0.0000; time: 0.13s
Val loss: 0.2698 score: 0.9388 time: 0.07s
Test loss: 0.3244 score: 0.9375 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.13s
Val loss: 0.2593 score: 0.9388 time: 0.12s
Test loss: 0.3131 score: 0.9375 time: 0.09s
Epoch 81/1000, LR 0.000267
Train loss: 0.0175;  Loss pred: 0.0175; Loss self: 0.0000; time: 0.13s
Val loss: 0.2493 score: 0.9388 time: 0.08s
Test loss: 0.3021 score: 0.9375 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0154;  Loss pred: 0.0154; Loss self: 0.0000; time: 0.13s
Val loss: 0.2400 score: 0.9592 time: 0.08s
Test loss: 0.2918 score: 0.9375 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0147;  Loss pred: 0.0147; Loss self: 0.0000; time: 0.13s
Val loss: 0.2316 score: 0.9592 time: 0.08s
Test loss: 0.2823 score: 0.9375 time: 0.08s
Epoch 84/1000, LR 0.000266
Train loss: 0.0135;  Loss pred: 0.0135; Loss self: 0.0000; time: 0.13s
Val loss: 0.2237 score: 0.9592 time: 0.08s
Test loss: 0.2731 score: 0.9375 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.14s
Val loss: 0.2164 score: 0.9592 time: 0.08s
Test loss: 0.2647 score: 0.9375 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.13s
Val loss: 0.2099 score: 0.9592 time: 0.07s
Test loss: 0.2571 score: 0.9375 time: 0.08s
Epoch 87/1000, LR 0.000266
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.18s
Val loss: 0.2040 score: 0.9592 time: 0.07s
Test loss: 0.2504 score: 0.9375 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.13s
Val loss: 0.1989 score: 0.9592 time: 0.07s
Test loss: 0.2446 score: 0.9375 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.13s
Val loss: 0.1944 score: 0.9592 time: 0.07s
Test loss: 0.2395 score: 0.9375 time: 0.08s
Epoch 90/1000, LR 0.000266
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.13s
Val loss: 0.1905 score: 0.9592 time: 0.08s
Test loss: 0.2350 score: 0.9375 time: 0.08s
Epoch 91/1000, LR 0.000266
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.14s
Val loss: 0.1872 score: 0.9592 time: 0.08s
Test loss: 0.2313 score: 0.9375 time: 0.08s
Epoch 92/1000, LR 0.000266
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.13s
Val loss: 0.1844 score: 0.9592 time: 0.07s
Test loss: 0.2282 score: 0.9375 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.13s
Val loss: 0.1821 score: 0.9592 time: 0.14s
Test loss: 0.2257 score: 0.9375 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.13s
Val loss: 0.1803 score: 0.9388 time: 0.07s
Test loss: 0.2238 score: 0.9375 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.13s
Val loss: 0.1788 score: 0.9388 time: 0.07s
Test loss: 0.2225 score: 0.9375 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.13s
Val loss: 0.1778 score: 0.9388 time: 0.07s
Test loss: 0.2217 score: 0.9375 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.13s
Val loss: 0.1771 score: 0.9388 time: 0.07s
Test loss: 0.2213 score: 0.9375 time: 0.08s
Epoch 98/1000, LR 0.000265
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.14s
Val loss: 0.1768 score: 0.9388 time: 0.07s
Test loss: 0.2213 score: 0.9375 time: 0.08s
Epoch 99/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.13s
Val loss: 0.1769 score: 0.9388 time: 0.07s
Test loss: 0.2216 score: 0.9375 time: 0.12s
     INFO: Early stopping counter 1 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.14s
Val loss: 0.1773 score: 0.9388 time: 0.07s
Test loss: 0.2221 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.13s
Val loss: 0.1779 score: 0.9388 time: 0.07s
Test loss: 0.2229 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.13s
Val loss: 0.1787 score: 0.9388 time: 0.07s
Test loss: 0.2240 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.13s
Val loss: 0.1795 score: 0.9388 time: 0.07s
Test loss: 0.2252 score: 0.9375 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.13s
Val loss: 0.1805 score: 0.9388 time: 0.08s
Test loss: 0.2267 score: 0.9375 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.13s
Val loss: 0.1816 score: 0.9388 time: 0.07s
Test loss: 0.2282 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.13s
Val loss: 0.1828 score: 0.9388 time: 0.07s
Test loss: 0.2300 score: 0.9375 time: 0.18s
     INFO: Early stopping counter 8 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.13s
Val loss: 0.1840 score: 0.9388 time: 0.07s
Test loss: 0.2318 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.13s
Val loss: 0.1852 score: 0.9388 time: 0.07s
Test loss: 0.2337 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.13s
Val loss: 0.1864 score: 0.9388 time: 0.07s
Test loss: 0.2354 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.13s
Val loss: 0.1877 score: 0.9388 time: 0.07s
Test loss: 0.2370 score: 0.9375 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.14s
Val loss: 0.1889 score: 0.9388 time: 0.07s
Test loss: 0.2386 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.13s
Val loss: 0.1901 score: 0.9388 time: 0.07s
Test loss: 0.2404 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.13s
Val loss: 0.1914 score: 0.9388 time: 0.22s
Test loss: 0.2423 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.13s
Val loss: 0.1925 score: 0.9388 time: 0.07s
Test loss: 0.2439 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.12s
Val loss: 0.1936 score: 0.9388 time: 0.07s
Test loss: 0.2455 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.12s
Val loss: 0.1948 score: 0.9388 time: 0.07s
Test loss: 0.2471 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.12s
Val loss: 0.1958 score: 0.9388 time: 0.07s
Test loss: 0.2486 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.13s
Val loss: 0.1969 score: 0.9388 time: 0.07s
Test loss: 0.2502 score: 0.9375 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 097,   Train_Loss: 0.0054,   Val_Loss: 0.1768,   Val_Precision: 0.9583,   Val_Recall: 0.9200,   Val_accuracy: 0.9388,   Val_Score: 0.9388,   Val_Loss: 0.1768,   Test_Precision: 0.9565,   Test_Recall: 0.9167,   Test_accuracy: 0.9362,   Test_Score: 0.9375,   Test_loss: 0.2213


[0.07692270504776388, 0.07690094190184027, 0.121361089986749, 0.07645272894296795, 0.07627751096151769, 0.0776337559800595, 0.07663132704328746, 0.07894080993719399, 0.07557017600629479, 0.07605117000639439, 0.07573828496970236, 0.07558467809576541, 0.07529121998231858, 0.07402989803813398, 0.07729745900724083, 0.07580834708642215, 0.07672818098217249, 0.08082813303917646, 0.07603946700692177, 0.07745800900738686, 0.07941041002050042, 0.08151787798851728, 0.07800891401711851, 0.08020091301295906, 0.08173426298890263, 0.08089256496168673, 0.08147202502004802, 0.08065283601172268, 0.08018246898427606, 0.08813354501035064, 0.08016942301765084, 0.0800207790452987, 0.08000532700680196, 0.07459982798900455, 0.07629724498838186, 0.0764174279756844, 0.07580985501408577, 0.07629474601708353, 0.07727385603357106, 0.08043729700148106, 0.07726840500254184, 0.07704292994458228, 0.07708066399209201, 0.07716439198702574, 0.07762589899357408, 0.07802648900542408, 0.07865898101590574, 0.07654833304695785, 0.09658113098703325, 0.07646763499360532, 0.07673937000799924, 0.07670044107362628, 0.07732105604372919, 0.08018083509523422, 0.07825231493916363, 0.07921763497870415, 0.07782119803596288, 0.07773095101583749, 0.07757538394071162, 0.07747943396680057, 0.08174359297845513, 0.0782207460142672, 0.07875439606141299, 0.07709370204247534, 0.0766707540024072, 0.07659764599520713, 0.07775049598421901, 0.07911214500200003, 0.07660499901976436, 0.07618113700300455, 0.08172908402048051, 0.08207557210698724, 0.0783143910812214, 0.07696280989330262, 0.08478832698892802, 0.07846986106596887, 0.07849531702231616, 0.07872625603340566, 0.07818822609260678, 0.0785652210470289, 0.08084386889822781, 0.08127224107738584, 0.08547678391914815, 0.08255451510194689, 0.078014096012339, 0.08121871598996222, 0.08084443199913949, 0.07780081895180047, 0.07874972792342305, 0.0782552759628743, 0.0784106960054487, 0.07818221999332309, 0.07837291806936264, 0.07841281802393496, 0.07836256292648613, 0.07786862691864371, 0.07972017105203122, 0.07788557303138077, 0.0781248229322955, 0.07820378290489316, 0.07852463598828763, 0.07803174492437392, 0.07799423602409661, 0.07791354099754244, 0.07742156204767525, 0.07829624996520579, 0.07842620299197733, 0.07885711209382862, 0.07827096700202674, 0.07799642800819129, 0.07814664707984775, 0.07806266902480274, 0.07800916000269353, 0.07799114298541099, 0.07832160999532789, 0.07796404894907027, 0.07823255995754153, 0.0786545870359987, 0.07843319303356111, 0.07881217100657523, 0.0780914860079065, 0.07807123102247715, 0.07893109298311174, 0.07863889704458416, 0.07839964400045574, 0.07834683894179761, 0.07858940295409411, 0.07875724497716874, 0.07794274890329689, 0.07815687893889844, 0.07917897799052298, 0.07897563301958144, 0.07775064499583095, 0.07791092502884567, 0.07808588503394276, 0.0787189279217273, 0.07871981093194336, 0.07873524201568216, 0.07854553498327732, 0.07850083301309496, 0.07879852096084505, 0.07862390903756022, 0.07879290997516364, 0.07881562900729477, 0.07838873192667961, 0.07855042407754809, 0.07832488999702036, 0.07842142600566149, 0.07914623792748898, 0.07924642495345324, 0.0793402650160715, 0.07915928203146905, 0.079938855022192, 0.0788995010079816, 0.0782496890751645, 0.07877094601280987, 0.0781165671069175, 0.07508853706531227, 0.07490072899963707, 0.07614593592006713, 0.07538220309652388, 0.07448421197477728, 0.09723348496481776, 0.07994035608135164, 0.08011817606166005, 0.08052894298452884, 0.08184500993229449, 0.08037584903649986, 0.07807213300839067, 0.07542231609113514, 0.0750650989357382, 0.07511829503346235, 0.075181610067375, 0.07359404093585908, 0.07589835999533534, 0.1526841459563002, 0.07495754607953131, 0.07574296102393419, 0.073627291014418, 0.07352155994158238, 0.07468854100443423, 0.07400054996833205, 0.11109023401513696, 0.07379792199935764, 0.07470305205788463, 0.0749044039985165, 0.07469116803258657, 0.07498443801887333, 0.07475225196685642, 0.20461670798249543, 0.07459533296059817, 0.07521332695614547, 0.07541684608440846, 0.0767405980732292, 0.0742994969477877, 0.07423791103065014, 0.07421993894968182, 0.07428117410745472, 0.07423437002580613, 0.07496156601700932, 0.07691086397971958, 0.07507545896805823, 0.10222484404221177, 0.07913665298838168, 0.07449711498338729, 0.07464979100041091, 0.07466449006460607, 0.07547085999976844, 0.07474762795027345, 0.10217268404085189, 0.07423547795042396, 0.07345624396111816, 0.07414495095144957, 0.07476112002041191, 0.07413182803429663, 0.07362802606076002, 0.07753730495460331, 0.07400386792141944, 0.07384460396133363, 0.07404977804981172, 0.07616588298697025, 0.07566427299752831, 0.07522003701888025, 0.07524493406526744, 0.074445637059398, 0.07540290302131325, 0.07581117493100464, 0.07587731396779418, 0.07552238600328565, 0.1873477620538324, 0.07488806592300534, 0.07499961997382343, 0.07509455690160394, 0.07526966603472829, 0.07596722198650241, 0.07515140599571168, 0.09088680904824287, 0.08030728797893971, 0.07997702609281987, 0.08024571102578193, 0.08121998002752662, 0.08026890200562775, 0.08196811494417489, 0.08000070205889642, 0.07972649007569999, 0.08011619804892689, 0.08153892203699797, 0.08010254590772092, 0.07994394097477198, 0.07968408102169633, 0.07933062396477908, 0.07974501606076956, 0.07985029206611216, 0.08091962698381394, 0.08023223502095789, 0.12834017700515687, 0.07736551598645747, 0.07893040007911623, 0.07884959899820387, 0.08016230398789048, 0.08041098504327238, 0.07879365899134427, 0.1833512099692598, 0.07854413392487913, 0.07888259901665151, 0.07920345105230808, 0.08054320304654539, 0.07965231698472053, 0.0790533380350098, 0.07931972399819642, 0.07128167001064867, 0.07204592099878937, 0.07237717800308019, 0.073574612964876, 0.07332483294885606]
[0.0015698511234237527, 0.001569406977588577, 0.0024767569385050815, 0.0015602597743462846, 0.0015566838971738303, 0.0015843623669399899, 0.0015639046335364788, 0.0016110369374937549, 0.0015422484899243834, 0.0015520646940080486, 0.0015456792850959667, 0.001542544450933988, 0.0015365555098432364, 0.0015108142456762036, 0.0015774991634130782, 0.0015471091242126968, 0.0015658812445341324, 0.0016495537354933973, 0.0015518258572841178, 0.0015807756940283033, 0.001620620612663274, 0.001663630163030965, 0.0015920186534105819, 0.0016367533267950829, 0.0016680461834469925, 0.0016508686726874843, 0.0016626943881642453, 0.0016459762451371976, 0.0016363769180464502, 0.0017986437757214417, 0.001636110673829609, 0.0016330771233734427, 0.0016327617756490196, 0.0015224454691633582, 0.0015570866324159565, 0.001559539346442539, 0.0015471398982466484, 0.0015570356330017047, 0.0015770174700728788, 0.001641577489826144, 0.0015769062245416703, 0.0015723046927465772, 0.0015730747753488167, 0.0015747835099393008, 0.001584202020277022, 0.0015923773266413078, 0.0016052853268552192, 0.001562210878509344, 0.001971043489531291, 0.001560563979461333, 0.0015661095919999846, 0.0015653151239515568, 0.0015779807355863098, 0.0016363435733721269, 0.0015969860191666046, 0.0016166864281368194, 0.0015881877150196507, 0.0015863459390987242, 0.0015831711008308493, 0.0015812129380979709, 0.0016682365913970433, 0.0015963417553932083, 0.0016072325726818977, 0.001573340858009701, 0.001564709265355249, 0.0015632172652083089, 0.0015867448160044697, 0.0016145335714693885, 0.0015633673269339666, 0.0015547170816939703, 0.001667940490213888, 0.0016750116756528008, 0.0015982528792086001, 0.001570669589659237, 0.0017303740201822044, 0.0016014257360401811, 0.001601945245353391, 0.001606658286396034, 0.0015956780835225874, 0.0016033718581026305, 0.001649874875474037, 0.0016586171648446091, 0.0017444241616152683, 0.001684786022488712, 0.0015921244084150816, 0.001657524816121678, 0.0016498863673293773, 0.0015877718153428665, 0.0016071373045596542, 0.0015970464482219244, 0.0016002182858254835, 0.001595555510067818, 0.001599447307538013, 0.0016002615923252032, 0.0015992359780915538, 0.001589155651400892, 0.001626942266367984, 0.0015895014904363423, 0.0015943841414754183, 0.0015959955694876155, 0.0016025435915977067, 0.0015924845902933454, 0.0015917191025325839, 0.0015900722652559681, 0.0015800318785239846, 0.0015978826523511385, 0.0016005347549383128, 0.0016093288182414003, 0.0015973666735107498, 0.001591763836901863, 0.0015948295322417909, 0.0015931156943837295, 0.0015920236735243577, 0.0015916559792941017, 0.0015984002039862834, 0.0015911030397769443, 0.0015965828562763576, 0.0016051956537958918, 0.001600677408848186, 0.0016084116531954128, 0.0015937037960797244, 0.0015932904290301459, 0.0016108386323084028, 0.0016048754498894726, 0.0015999927347031782, 0.0015989150804448494, 0.001603865366410084, 0.0016072907138197702, 0.0015906683449652425, 0.001595038345691805, 0.001615897510010673, 0.001611747612644519, 0.0015867478570577745, 0.0015900188781397076, 0.0015935894904886277, 0.0016065087330964754, 0.0016065267537131297, 0.001606841673789432, 0.0016029701016995372, 0.0016020578165937746, 0.0016081330808335726, 0.0016045695721951065, 0.001608018570921707, 0.0016084822246386688, 0.001599770039319992, 0.0016030698791336343, 0.001598467142796334, 0.001600437265421663, 0.001615229345458959, 0.001617273978641903, 0.0016191890819606427, 0.0016154955516626335, 0.0016314052045345306, 0.0016101938981220735, 0.0015969324301053978, 0.0016075703267920383, 0.0015942156552432142, 0.0015643445221940055, 0.0015604318541591056, 0.0015863736650013986, 0.0015704625645109143, 0.0015517544161411934, 0.0020256976034337035, 0.0016654240850281592, 0.0016691286679512511, 0.0016776863121776842, 0.0017051043735894684, 0.0016744968549270804, 0.0016265027710081388, 0.001571298251898649, 0.0015638562278278794, 0.001564964479863799, 0.0015662835430703126, 0.001533209186163731, 0.001581215833236153, 0.003180919707422921, 0.001561615543323569, 0.0015779783546652955, 0.0015339018961337085, 0.001531699165449633, 0.001556011270925713, 0.001541678124340251, 0.0023143798753153533, 0.0015374567083199508, 0.0015563135845392633, 0.0015605084166357603, 0.001556066000678887, 0.0015621757920598611, 0.001557338582642842, 0.004262848082968655, 0.0015540694366791286, 0.001566944311586364, 0.0015711842934251763, 0.0015987624598589416, 0.0015479061864122439, 0.0015466231464718778, 0.0015462487281183712, 0.0015475244605719733, 0.0015465493755376276, 0.0015616992920210275, 0.0016023096662441578, 0.0015640720618345465, 0.002129684250879412, 0.001648680270591285, 0.0015520232288205686, 0.0015552039791752275, 0.0015555102096792932, 0.001572309583328509, 0.0015572422489640303, 0.0021285975841844143, 0.001546572457300499, 0.0015303384158566284, 0.0015446864781551994, 0.0015575233337585814, 0.0015444130840478465, 0.0015339172095991671, 0.0016153605198875691, 0.001541747248362905, 0.0015384292491944507, 0.0015427037093710776, 0.0015867892288952135, 0.00157633902078184, 0.0015670841045600052, 0.0015676027930264051, 0.0015509507720707916, 0.001570893812944026, 0.0015793994777292635, 0.0015807773743290454, 0.0015733830417351176, 0.0039030783761215084, 0.0015601680400626112, 0.001562492082787988, 0.001564469935450082, 0.0015681180423901726, 0.0015826504580521334, 0.0015656542915773268, 0.0018934751885050598, 0.001673068499561244, 0.001666188043600414, 0.0016717856463704568, 0.001692082917240138, 0.0016722687917839114, 0.0017076690613369767, 0.0016666812928936754, 0.0016609685432437498, 0.0016690874593526435, 0.0016987275424374577, 0.001668803039744186, 0.0016654987703077495, 0.0016600850212853402, 0.0016527213325995642, 0.0016613545012660325, 0.0016635477513773367, 0.0016858255621627904, 0.001671504896269956, 0.002673753687607435, 0.0016117815830511972, 0.001644383334981588, 0.0016426999791292474, 0.0016700479997477184, 0.0016752288550681744, 0.0016415345623196724, 0.0038198168743595793, 0.001636336123434982, 0.0016433874795135732, 0.001650071896923085, 0.0016779833968030289, 0.001659423270515011, 0.0016469445423960376, 0.0016524942499624256, 0.0014850347918885138, 0.0015009566874747786, 0.0015078578750641707, 0.0015328044367682498, 0.001527600686434501]
[637.0030795143548, 637.1833528716169, 403.75378966479406, 640.918913915459, 642.3911764074302, 631.1687407290434, 639.4251788478217, 620.718232293092, 648.4039417338189, 644.3030395966305, 646.9647420667302, 648.2795354095077, 650.8062960263784, 661.894738457688, 633.9147577336265, 646.366816890752, 638.6180328109821, 606.2245675803283, 644.4022022871306, 632.6008198239006, 617.0475632521009, 601.0951365405047, 628.1333437002762, 610.9656132229126, 599.5037846814978, 605.7417022591377, 601.433436666665, 607.5421823093484, 611.1061510167391, 555.9744589219157, 611.2055962933862, 612.340951745318, 612.4592178197594, 656.8379756481775, 642.2250240812949, 641.2149858745772, 646.3539600609394, 642.2460596307401, 634.1083843248654, 609.1701465191923, 634.1531185791667, 636.0090411313039, 635.6976894364466, 635.0079193034886, 631.2326251327054, 627.9918605153914, 622.9422167329074, 640.1184460795693, 507.3454773125262, 640.7939777933196, 638.5249187593315, 638.8489989642162, 633.7212980160008, 611.1186038633871, 626.1795582417529, 618.5491401399768, 629.6484921416402, 630.3795252680798, 631.6436672417777, 632.425890217476, 599.4353589634206, 626.4322765607805, 622.1874898486886, 635.5901805442303, 639.0963625903767, 639.7063429738563, 630.2210600681635, 619.373927969735, 639.6449399778443, 643.2038418915625, 599.5417737426383, 597.0107638863299, 625.6832150962028, 636.6711411385726, 577.9097399385956, 624.4435676878052, 624.2410612351478, 622.4098854543265, 626.6928212690743, 623.6856378303671, 606.1065689679547, 602.9118841861781, 573.2550729371, 593.5471844209818, 628.0916206764734, 603.3092176199373, 606.1023472899353, 629.8134217630371, 622.2243719705044, 626.1558648549968, 624.9147437308173, 626.7409649429844, 625.2159700961163, 624.8978322019124, 625.29858863815, 629.2649805061371, 614.6499606482155, 629.1280668918938, 627.2014215310844, 626.568155399732, 624.0079865802703, 627.9495613931145, 628.2515541899951, 628.9022341000464, 632.898622864602, 625.8281848974274, 624.791181144043, 621.3770540023968, 626.0303389215978, 628.2338980299708, 627.0262619192524, 627.7008026004247, 628.1313630131142, 628.2764699212823, 625.6255457838902, 628.4948083187555, 626.3376786672114, 622.9770169357528, 624.7354991531861, 621.7313820210837, 627.4691711595668, 627.6319632502352, 620.7946469268345, 623.1013129828049, 625.0028380194578, 625.4240842620488, 623.4937301740546, 622.1649832241442, 628.666562181352, 626.9441751673229, 618.8511299787788, 620.4445362008153, 630.2198522292313, 628.9233503755511, 627.5141785061467, 622.4678269084436, 622.4608446069897, 622.3388503745297, 623.8419537206323, 624.1971979052269, 621.8390827963392, 623.2200942412023, 621.883365082535, 621.7041038328173, 625.0898413031076, 623.8031248771523, 625.599346540596, 624.8292398618528, 619.1071273013897, 618.3244231999234, 617.593097150285, 619.0051089715606, 612.9684993160961, 621.0432179418103, 626.2005712627426, 622.0567668697483, 627.2677079233923, 639.2453745403168, 640.8482352719502, 630.3685077872989, 636.7550698742239, 644.4318698874645, 493.6570978338168, 600.447663144665, 599.1149868796132, 596.0589847705032, 586.4743622086129, 597.1943136576074, 614.8160444757067, 636.4164147650955, 639.4449708391363, 638.9921387142483, 638.4540043367541, 652.2267209356586, 632.4247322728719, 314.3744866198361, 640.3624786365223, 633.7222542017122, 651.9321754021948, 652.8697165585047, 642.6688666625615, 648.6438279248089, 432.08118540338666, 650.4248182004069, 642.5440283591971, 640.8167936420755, 642.6462627958684, 640.1328231321619, 642.1211232710714, 234.5849489676391, 643.4718915371551, 638.1847731318586, 636.4625742407362, 625.4837883097591, 646.0339836988522, 646.5699173591044, 646.726481849333, 646.1933400589963, 646.6007589653383, 640.3281381435983, 624.0990871284062, 639.3567306784256, 469.55317417925653, 606.5457431848557, 644.320253350803, 643.0024700234698, 642.8758832808784, 636.0070628603845, 642.1608459860752, 469.79288496334374, 646.5911087964629, 653.4502366525485, 647.3805617786517, 642.0449558125217, 647.4951619673144, 651.9256670060525, 619.0568530606413, 648.6147460693339, 650.0136425016738, 648.212611355991, 630.2034207128065, 634.3813017481579, 638.1278433557802, 637.9166995928896, 644.7657901255141, 636.5802651713874, 633.1520391773977, 632.6001473954838, 635.5731398358062, 256.20802444497684, 640.9565984699116, 640.0032429064719, 639.1941304466872, 637.707094088255, 631.8514583635621, 638.7106051314462, 528.1294447747805, 597.7041587133141, 600.1723537993533, 598.162810029538, 590.9875868441744, 597.9899911504291, 585.5935571129191, 599.9947346044845, 602.0583617116995, 599.1297786083964, 588.6759206630201, 599.2318902734573, 600.4207375158979, 602.3787861333382, 605.062680728578, 601.9184943598441, 601.1249146121887, 593.1811822316145, 598.2632789359747, 374.00602928941964, 620.4314595200556, 608.1307069505158, 608.7538885403006, 598.7851847079021, 596.9333664320774, 609.1860768297731, 261.7926546983113, 611.1213861738926, 608.4992203396794, 606.0341987914077, 595.9534533567173, 602.6190049086418, 607.184986657269, 605.1458272987867, 673.3848967459566, 666.2417432460412, 663.1924775784605, 652.3989466708423, 654.6213345413267]
Elapsed: 0.08000734280329197~0.013837142144792534
Time per graph: 0.0016476867213899898~0.00029008787073873417
Speed: 616.1241345093787~54.41809558235807
Total Time: 0.0743
best val loss: 0.17681218683719635 test_score: 0.9375

Testing...
Test loss: 0.2918 score: 0.9375 time: 0.07s
test Score 0.9375
Epoch Time List: [0.2731443481752649, 0.26727163803298026, 0.34975075197871774, 0.26702513894997537, 0.26408625789918005, 0.2645684687886387, 0.2678214611951262, 0.2806934468680993, 0.2654042668873444, 0.26154610491357744, 0.3622353959362954, 0.25896407198160887, 0.26023257290944457, 0.2578677381388843, 0.2647422271547839, 0.2647106309887022, 0.2611411309335381, 0.3916037258459255, 0.2628089791396633, 0.26124175800941885, 0.26840383606031537, 0.27843115385621786, 0.2649751431308687, 0.36986157100182027, 0.2771551989717409, 0.27500270097516477, 0.2773968109395355, 0.27889837289694697, 0.27538562996778637, 0.27805028192233294, 0.3762972039403394, 0.2732389367884025, 0.2734761780593544, 0.26391982287168503, 0.27540008805226535, 0.2502047768794, 0.24894882808439434, 0.2500641978112981, 0.25124207488261163, 0.25768170692026615, 0.25758186902385205, 0.253087360993959, 0.36069020617287606, 0.25349593616556376, 0.2541071887826547, 0.25685447303112596, 0.2622440828708932, 0.2542286610696465, 0.2694191540358588, 0.28970495401881635, 0.25078967097215354, 0.2505298600299284, 0.2524770798627287, 0.2585088168270886, 0.2594255961012095, 0.25475740095134825, 0.2973432228900492, 0.2518807720625773, 0.2518746060086414, 0.2537402840098366, 0.2600411350140348, 0.2579010990448296, 0.25416986702475697, 0.29389150196220726, 0.24933350016362965, 0.24962746107485145, 0.25001175014767796, 0.25248265999834985, 0.25161252298858017, 0.24765516782645136, 0.35337330400943756, 0.26456259202677757, 0.2663569508586079, 0.2547138888621703, 0.26289431285113096, 0.26101754093542695, 0.25514615804422647, 0.26624952105339617, 0.25890622509177774, 0.25994969287421554, 0.26207111799158156, 0.25854223396163434, 0.2637213111156598, 0.2628345239209011, 0.2551303240470588, 0.26600973098538816, 0.26834720303304493, 0.2562778670107946, 0.25704467622563243, 0.25566938100382686, 0.25700909504666924, 0.2563990610651672, 0.2565820011077449, 0.25690595689229667, 0.2568049099063501, 0.2555875381221995, 0.2575667389901355, 0.25680378801189363, 0.25497977808117867, 0.2579526649788022, 0.2568006260553375, 0.25466917909216136, 0.2554147868650034, 0.2553675038507208, 0.255504353903234, 0.2556164679117501, 0.25621825992129743, 0.2577374359825626, 0.257081997115165, 0.2567472639493644, 0.2566229869844392, 0.25591421709395945, 0.25666983996052295, 0.25752459303475916, 0.2571679060347378, 0.25692272605374455, 0.25651234306860715, 0.2572646379703656, 0.2572588480543345, 0.2570956130512059, 0.25633238011505455, 0.25588723400142044, 0.2583624181570485, 0.25776848604436964, 0.25666463805828243, 0.25731266604270786, 0.2569086658768356, 0.2575913720065728, 0.2574642510153353, 0.2569260240998119, 0.25896805396769196, 0.2586006539640948, 0.257301093894057, 0.2549469870282337, 0.25602945405989885, 0.25689621397759765, 0.2583161290967837, 0.25791086605750024, 0.2582536949776113, 0.2574827339267358, 0.2575202329317108, 0.25876641704235226, 0.2590331550454721, 0.26000137883238494, 0.25970119214616716, 0.25927490496542305, 0.25819192093331367, 0.2590796659933403, 0.25946939806453884, 0.2592976139858365, 0.2590146609582007, 0.2596805179491639, 0.25998986582271755, 0.25905089802108705, 0.2581317479489371, 0.2576052109943703, 0.2575614369707182, 0.268537316005677, 0.26475732505787164, 0.26487790304236114, 0.2671325699193403, 0.26244351803325117, 0.34494419395923615, 0.2769110529916361, 0.27821430400945246, 0.27767099696211517, 0.2825101970229298, 0.2807683419669047, 0.26912960910703987, 0.38595020095817745, 0.2658961518900469, 0.2657548830611631, 0.26798420189879835, 0.26682101213373244, 0.2747274589492008, 0.3430273230187595, 0.26335320493672043, 0.2636760969180614, 0.26263481797650456, 0.2631770829902962, 0.2693008919013664, 0.2641556339804083, 0.3365642878925428, 0.26770412106998265, 0.26550097297877073, 0.26521887502167374, 0.2668533920077607, 0.27023209689650685, 0.2662740140222013, 0.4009919579839334, 0.2722722979960963, 0.2666741809807718, 0.2697086689295247, 0.2723909269552678, 0.2684210459701717, 0.26469307811930776, 0.3164578980067745, 0.265728723956272, 0.26559660804923624, 0.26598387700505555, 0.2722017300548032, 0.2691718201385811, 0.29093630181159824, 0.32096790487412363, 0.2660281650023535, 0.2655217678984627, 0.26691762800328434, 0.2715839658631012, 0.26964985905215144, 0.4344079539878294, 0.2639732388779521, 0.26259211311116815, 0.26354474702384323, 0.2666711510391906, 0.2677657390013337, 0.26232644089031965, 0.3442670340882614, 0.26360269298311323, 0.26409118284936994, 0.2659186290111393, 0.2672305090818554, 0.2724531830754131, 0.2686366190901026, 0.3873281858395785, 0.26820725097786635, 0.26841177814640105, 0.2720038910629228, 0.2781017111847177, 0.26991905516479164, 0.381855717045255, 0.2661540780682117, 0.26710979093331844, 0.2672096431488171, 0.2674767569405958, 0.27570498804561794, 0.26961757196113467, 0.33704446419142187, 0.28433131892234087, 0.28336765395943075, 0.28351837606169283, 0.28531326609663665, 0.2872137710219249, 0.2850187218282372, 0.33153042290359735, 0.2835749980295077, 0.2833111430518329, 0.28676352207548916, 0.28696718194987625, 0.2817477738717571, 0.3488173490623012, 0.28092430904507637, 0.2812501339940354, 0.2828087900998071, 0.28461394703481346, 0.2844287109328434, 0.3280331769492477, 0.2821731200674549, 0.27634317497722805, 0.27464069111738354, 0.2788765811128542, 0.28245898499153554, 0.2763142518233508, 0.3803188009187579, 0.27501930412836373, 0.27461479394696653, 0.27530503808520734, 0.27801142481621355, 0.2847705108579248, 0.2785091820405796, 0.42176483990624547, 0.257761127082631, 0.2532224979950115, 0.2559892029967159, 0.2585949689382687, 0.26215871109161526]
Total Epoch List: [35, 122, 118]
Total Time List: [0.0767092079622671, 0.07881162606645375, 0.07431196002289653]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d080ae230>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6954;  Loss pred: 0.6954; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.6961;  Loss pred: 0.6961; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6935;  Loss pred: 0.6935; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6881;  Loss pred: 0.6881; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6837;  Loss pred: 0.6837; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6784;  Loss pred: 0.6784; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6721;  Loss pred: 0.6721; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6718;  Loss pred: 0.6718; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6663;  Loss pred: 0.6663; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6585;  Loss pred: 0.6585; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6508;  Loss pred: 0.6508; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6448;  Loss pred: 0.6448; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6430;  Loss pred: 0.6430; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4898 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6342;  Loss pred: 0.6342; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6237;  Loss pred: 0.6237; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6190;  Loss pred: 0.6190; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6089;  Loss pred: 0.6089; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.4898 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5102 time: 0.08s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6954,   Val_Loss: 0.6940,   Val_Precision: 0.4898,   Val_Recall: 1.0000,   Val_accuracy: 0.6575,   Val_Score: 0.4898,   Val_Loss: 0.6940,   Test_Precision: 0.5102,   Test_Recall: 1.0000,   Test_accuracy: 0.6757,   Test_Score: 0.5102,   Test_loss: 0.6930


[0.07799731392879039, 0.08345408097375184, 0.08127321500796825, 0.0814093379303813, 0.08108883199747652, 0.08052210998721421, 0.08055499696638435, 0.0804555780487135, 0.08434840000700206, 0.08098557300399989, 0.08046741003636271, 0.0864179419586435, 0.08071994397323579, 0.08084409998264164, 0.08073175407480448, 0.08074441005010158, 0.08838433702476323, 0.0810352599946782, 0.08125073392875493, 0.08100439806003124, 0.08136705204378814]
[0.0015917819169140896, 0.0017031445096684049, 0.001658637040978944, 0.0016614150598037, 0.00165487412239748, 0.0016433083670860042, 0.0016439795299262113, 0.0016419505724227245, 0.001721395918510246, 0.0016527667959999976, 0.0016421920415584225, 0.001763631468543745, 0.001647345795372159, 0.0016498795914824825, 0.0016475868178531528, 0.0016478451030632975, 0.0018037619800972088, 0.0016537808162179223, 0.001658178243443978, 0.001653150980816964, 0.0016605520825262886]
[628.226762331018, 587.1492373801539, 602.9046592434655, 601.8965544456737, 604.2755678306586, 608.5285148114042, 608.2800800110232, 609.0317314025378, 580.9238823253593, 605.0460369969832, 608.9421789250731, 567.0118830583773, 607.0370913072842, 606.1048364756487, 606.948288954524, 606.8531551545884, 554.3968722226354, 604.6750513692183, 603.0714755508039, 604.9054270323295, 602.2093558659392]
Elapsed: 0.08166937042759466~0.0022084188335095727
Time per graph: 0.001666721845461115~4.506977211244028e-05
Speed: 600.4008877473666~15.570350794349984
Total Time: 0.0817
best val loss: 0.694025456905365 test_score: 0.5102

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5102 time: 0.08s
test Score 0.5102
Epoch Time List: [0.2700401711044833, 0.2617023950442672, 0.26317456318065524, 0.26385300303809345, 0.2621102900011465, 0.2625041489955038, 0.26167037803679705, 0.2615297739394009, 0.2735748258419335, 0.26466484798584133, 0.2615814749151468, 0.2794500798918307, 0.26244941109325737, 0.26298592099919915, 0.26183182292152196, 0.2636142171686515, 0.28063371195457876, 0.2664966029115021, 0.2640956579707563, 0.2637350030709058, 0.2647739560343325]
Total Epoch List: [21]
Total Time List: [0.0816929730353877]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d0821a4d0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7020;  Loss pred: 0.7020; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6974 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7021 score: 0.4898 time: 0.07s
Epoch 2/1000, LR 0.000000
Train loss: 0.7029;  Loss pred: 0.7029; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6974 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7020 score: 0.4898 time: 0.07s
Epoch 3/1000, LR 0.000030
Train loss: 0.7002;  Loss pred: 0.7002; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6973 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7019 score: 0.4898 time: 0.07s
Epoch 4/1000, LR 0.000060
Train loss: 0.7016;  Loss pred: 0.7016; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7018 score: 0.4898 time: 0.07s
Epoch 5/1000, LR 0.000090
Train loss: 0.6985;  Loss pred: 0.6985; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6971 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7017 score: 0.4898 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6973;  Loss pred: 0.6973; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6970 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7016 score: 0.4898 time: 0.07s
Epoch 7/1000, LR 0.000150
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7014 score: 0.4898 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7013 score: 0.4898 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6897;  Loss pred: 0.6897; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7010 score: 0.4898 time: 0.07s
Epoch 10/1000, LR 0.000240
Train loss: 0.6863;  Loss pred: 0.6863; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6965 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7008 score: 0.4898 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6843;  Loss pred: 0.6843; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7005 score: 0.4898 time: 0.07s
Epoch 12/1000, LR 0.000270
Train loss: 0.6806;  Loss pred: 0.6806; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7002 score: 0.4898 time: 0.07s
Epoch 13/1000, LR 0.000270
Train loss: 0.6796;  Loss pred: 0.6796; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6999 score: 0.4898 time: 0.08s
Epoch 14/1000, LR 0.000270
Train loss: 0.6735;  Loss pred: 0.6735; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6997 score: 0.4898 time: 0.08s
Epoch 15/1000, LR 0.000270
Train loss: 0.6691;  Loss pred: 0.6691; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6994 score: 0.4898 time: 0.08s
Epoch 16/1000, LR 0.000270
Train loss: 0.6625;  Loss pred: 0.6625; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6991 score: 0.4898 time: 0.08s
Epoch 17/1000, LR 0.000270
Train loss: 0.6620;  Loss pred: 0.6620; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6988 score: 0.4898 time: 0.08s
Epoch 18/1000, LR 0.000270
Train loss: 0.6562;  Loss pred: 0.6562; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6985 score: 0.4898 time: 0.08s
Epoch 19/1000, LR 0.000270
Train loss: 0.6495;  Loss pred: 0.6495; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.4898 time: 0.08s
Epoch 20/1000, LR 0.000270
Train loss: 0.6461;  Loss pred: 0.6461; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4898 time: 0.08s
Epoch 21/1000, LR 0.000270
Train loss: 0.6407;  Loss pred: 0.6407; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.4898 time: 0.08s
Epoch 22/1000, LR 0.000270
Train loss: 0.6304;  Loss pred: 0.6304; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.4898 time: 0.08s
Epoch 23/1000, LR 0.000270
Train loss: 0.6240;  Loss pred: 0.6240; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.4898 time: 0.08s
Epoch 24/1000, LR 0.000270
Train loss: 0.6187;  Loss pred: 0.6187; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4898 time: 0.08s
Epoch 25/1000, LR 0.000270
Train loss: 0.6082;  Loss pred: 0.6082; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.4898 time: 0.08s
Epoch 26/1000, LR 0.000270
Train loss: 0.5984;  Loss pred: 0.5984; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4898 time: 0.08s
Epoch 27/1000, LR 0.000270
Train loss: 0.5918;  Loss pred: 0.5918; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4898 time: 0.08s
Epoch 28/1000, LR 0.000270
Train loss: 0.5819;  Loss pred: 0.5819; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4898 time: 0.08s
Epoch 29/1000, LR 0.000270
Train loss: 0.5696;  Loss pred: 0.5696; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4898 time: 0.08s
Epoch 30/1000, LR 0.000270
Train loss: 0.5553;  Loss pred: 0.5553; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4898 time: 0.08s
Epoch 31/1000, LR 0.000270
Train loss: 0.5490;  Loss pred: 0.5490; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4898 time: 0.08s
Epoch 32/1000, LR 0.000270
Train loss: 0.5361;  Loss pred: 0.5361; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.4898 time: 0.08s
Epoch 33/1000, LR 0.000270
Train loss: 0.5227;  Loss pred: 0.5227; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.4898 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.5097;  Loss pred: 0.5097; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.4898 time: 0.08s
Epoch 35/1000, LR 0.000270
Train loss: 0.4991;  Loss pred: 0.4991; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.4898 time: 0.08s
Epoch 36/1000, LR 0.000270
Train loss: 0.4841;  Loss pred: 0.4841; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6852 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6879 score: 0.4898 time: 0.08s
Epoch 37/1000, LR 0.000270
Train loss: 0.4685;  Loss pred: 0.4685; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6839 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.4898 time: 0.08s
Epoch 38/1000, LR 0.000270
Train loss: 0.4560;  Loss pred: 0.4560; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6825 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6851 score: 0.4898 time: 0.08s
Epoch 39/1000, LR 0.000269
Train loss: 0.4330;  Loss pred: 0.4330; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6835 score: 0.4898 time: 0.08s
Epoch 40/1000, LR 0.000269
Train loss: 0.4204;  Loss pred: 0.4204; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.5102 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6817 score: 0.4898 time: 0.08s
Epoch 41/1000, LR 0.000269
Train loss: 0.4140;  Loss pred: 0.4140; Loss self: 0.0000; time: 0.12s
Val loss: 0.6771 score: 0.5306 time: 0.07s
Test loss: 0.6797 score: 0.5102 time: 0.08s
Epoch 42/1000, LR 0.000269
Train loss: 0.3912;  Loss pred: 0.3912; Loss self: 0.0000; time: 0.13s
Val loss: 0.6748 score: 0.5306 time: 0.07s
Test loss: 0.6774 score: 0.5510 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3782;  Loss pred: 0.3782; Loss self: 0.0000; time: 0.12s
Val loss: 0.6723 score: 0.5714 time: 0.07s
Test loss: 0.6748 score: 0.5510 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3613;  Loss pred: 0.3613; Loss self: 0.0000; time: 0.12s
Val loss: 0.6695 score: 0.5918 time: 0.07s
Test loss: 0.6719 score: 0.5510 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3440;  Loss pred: 0.3440; Loss self: 0.0000; time: 0.12s
Val loss: 0.6663 score: 0.6122 time: 0.07s
Test loss: 0.6687 score: 0.5714 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3255;  Loss pred: 0.3255; Loss self: 0.0000; time: 0.12s
Val loss: 0.6629 score: 0.6939 time: 0.07s
Test loss: 0.6651 score: 0.5918 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.3125;  Loss pred: 0.3125; Loss self: 0.0000; time: 0.12s
Val loss: 0.6590 score: 0.7347 time: 0.07s
Test loss: 0.6611 score: 0.6327 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2989;  Loss pred: 0.2989; Loss self: 0.0000; time: 0.11s
Val loss: 0.6548 score: 0.8163 time: 0.07s
Test loss: 0.6567 score: 0.6735 time: 0.07s
Epoch 49/1000, LR 0.000269
Train loss: 0.2840;  Loss pred: 0.2840; Loss self: 0.0000; time: 0.12s
Val loss: 0.6502 score: 0.8163 time: 0.07s
Test loss: 0.6519 score: 0.7755 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2707;  Loss pred: 0.2707; Loss self: 0.0000; time: 0.11s
Val loss: 0.6451 score: 0.8367 time: 0.07s
Test loss: 0.6465 score: 0.8571 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2538;  Loss pred: 0.2538; Loss self: 0.0000; time: 0.11s
Val loss: 0.6397 score: 0.8571 time: 0.07s
Test loss: 0.6407 score: 0.9184 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2371;  Loss pred: 0.2371; Loss self: 0.0000; time: 0.22s
Val loss: 0.6339 score: 0.8776 time: 0.07s
Test loss: 0.6345 score: 0.9592 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.2303;  Loss pred: 0.2303; Loss self: 0.0000; time: 0.11s
Val loss: 0.6275 score: 0.8776 time: 0.07s
Test loss: 0.6277 score: 0.9592 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.2095;  Loss pred: 0.2095; Loss self: 0.0000; time: 0.11s
Val loss: 0.6207 score: 0.8776 time: 0.07s
Test loss: 0.6204 score: 0.9388 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.2000;  Loss pred: 0.2000; Loss self: 0.0000; time: 0.11s
Val loss: 0.6136 score: 0.8980 time: 0.07s
Test loss: 0.6125 score: 0.9388 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1826;  Loss pred: 0.1826; Loss self: 0.0000; time: 0.11s
Val loss: 0.6061 score: 0.8776 time: 0.07s
Test loss: 0.6042 score: 0.9388 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1776;  Loss pred: 0.1776; Loss self: 0.0000; time: 0.11s
Val loss: 0.5981 score: 0.8776 time: 0.07s
Test loss: 0.5954 score: 0.9592 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1654;  Loss pred: 0.1654; Loss self: 0.0000; time: 0.11s
Val loss: 0.5901 score: 0.8776 time: 0.07s
Test loss: 0.5863 score: 0.9592 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1601;  Loss pred: 0.1601; Loss self: 0.0000; time: 0.12s
Val loss: 0.5819 score: 0.8776 time: 0.17s
Test loss: 0.5768 score: 0.9796 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1426;  Loss pred: 0.1426; Loss self: 0.0000; time: 0.11s
Val loss: 0.5733 score: 0.8776 time: 0.07s
Test loss: 0.5669 score: 0.9796 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1353;  Loss pred: 0.1353; Loss self: 0.0000; time: 0.11s
Val loss: 0.5643 score: 0.8980 time: 0.07s
Test loss: 0.5563 score: 0.9796 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1247;  Loss pred: 0.1247; Loss self: 0.0000; time: 0.11s
Val loss: 0.5549 score: 0.8980 time: 0.07s
Test loss: 0.5452 score: 0.9796 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1144;  Loss pred: 0.1144; Loss self: 0.0000; time: 0.11s
Val loss: 0.5450 score: 0.8980 time: 0.07s
Test loss: 0.5335 score: 0.9796 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.1049;  Loss pred: 0.1049; Loss self: 0.0000; time: 0.11s
Val loss: 0.5346 score: 0.8980 time: 0.07s
Test loss: 0.5210 score: 0.9796 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.1001;  Loss pred: 0.1001; Loss self: 0.0000; time: 0.12s
Val loss: 0.5238 score: 0.9184 time: 0.07s
Test loss: 0.5079 score: 0.9796 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0986;  Loss pred: 0.0986; Loss self: 0.0000; time: 0.11s
Val loss: 0.5127 score: 0.8980 time: 0.07s
Test loss: 0.4943 score: 0.9796 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0915;  Loss pred: 0.0915; Loss self: 0.0000; time: 0.12s
Val loss: 0.5010 score: 0.8980 time: 0.18s
Test loss: 0.4798 score: 1.0000 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0808;  Loss pred: 0.0808; Loss self: 0.0000; time: 0.11s
Val loss: 0.4893 score: 0.8980 time: 0.07s
Test loss: 0.4651 score: 1.0000 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0840;  Loss pred: 0.0840; Loss self: 0.0000; time: 0.11s
Val loss: 0.4775 score: 0.8980 time: 0.07s
Test loss: 0.4502 score: 1.0000 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0704;  Loss pred: 0.0704; Loss self: 0.0000; time: 0.11s
Val loss: 0.4654 score: 0.8980 time: 0.07s
Test loss: 0.4346 score: 1.0000 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0671;  Loss pred: 0.0671; Loss self: 0.0000; time: 0.11s
Val loss: 0.4534 score: 0.8980 time: 0.07s
Test loss: 0.4190 score: 1.0000 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0643;  Loss pred: 0.0643; Loss self: 0.0000; time: 0.12s
Val loss: 0.4414 score: 0.8980 time: 0.07s
Test loss: 0.4033 score: 1.0000 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0579;  Loss pred: 0.0579; Loss self: 0.0000; time: 0.11s
Val loss: 0.4290 score: 0.8980 time: 0.07s
Test loss: 0.3870 score: 1.0000 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0531;  Loss pred: 0.0531; Loss self: 0.0000; time: 0.12s
Val loss: 0.4168 score: 0.8776 time: 0.15s
Test loss: 0.3704 score: 1.0000 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0496;  Loss pred: 0.0496; Loss self: 0.0000; time: 0.11s
Val loss: 0.4049 score: 0.8776 time: 0.07s
Test loss: 0.3539 score: 1.0000 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0506;  Loss pred: 0.0506; Loss self: 0.0000; time: 0.11s
Val loss: 0.3933 score: 0.8776 time: 0.07s
Test loss: 0.3377 score: 1.0000 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0434;  Loss pred: 0.0434; Loss self: 0.0000; time: 0.11s
Val loss: 0.3820 score: 0.8776 time: 0.07s
Test loss: 0.3215 score: 1.0000 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0395;  Loss pred: 0.0395; Loss self: 0.0000; time: 0.11s
Val loss: 0.3710 score: 0.8776 time: 0.07s
Test loss: 0.3054 score: 1.0000 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0401;  Loss pred: 0.0401; Loss self: 0.0000; time: 0.12s
Val loss: 0.3601 score: 0.8980 time: 0.07s
Test loss: 0.2894 score: 1.0000 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0369;  Loss pred: 0.0369; Loss self: 0.0000; time: 0.12s
Val loss: 0.3497 score: 0.8980 time: 0.07s
Test loss: 0.2736 score: 1.0000 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0318;  Loss pred: 0.0318; Loss self: 0.0000; time: 0.11s
Val loss: 0.3399 score: 0.8980 time: 0.07s
Test loss: 0.2582 score: 1.0000 time: 0.08s
Epoch 82/1000, LR 0.000267
Train loss: 0.0334;  Loss pred: 0.0334; Loss self: 0.0000; time: 0.21s
Val loss: 0.3306 score: 0.8980 time: 0.07s
Test loss: 0.2433 score: 1.0000 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0294;  Loss pred: 0.0294; Loss self: 0.0000; time: 0.11s
Val loss: 0.3217 score: 0.8980 time: 0.07s
Test loss: 0.2289 score: 1.0000 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0316;  Loss pred: 0.0316; Loss self: 0.0000; time: 0.11s
Val loss: 0.3136 score: 0.8980 time: 0.07s
Test loss: 0.2151 score: 1.0000 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0292;  Loss pred: 0.0292; Loss self: 0.0000; time: 0.11s
Val loss: 0.3062 score: 0.8980 time: 0.07s
Test loss: 0.2020 score: 1.0000 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0253;  Loss pred: 0.0253; Loss self: 0.0000; time: 0.11s
Val loss: 0.2996 score: 0.8980 time: 0.07s
Test loss: 0.1896 score: 1.0000 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0222;  Loss pred: 0.0222; Loss self: 0.0000; time: 0.12s
Val loss: 0.2934 score: 0.8776 time: 0.07s
Test loss: 0.1774 score: 1.0000 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0198;  Loss pred: 0.0198; Loss self: 0.0000; time: 0.11s
Val loss: 0.2878 score: 0.8776 time: 0.07s
Test loss: 0.1656 score: 1.0000 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0248;  Loss pred: 0.0248; Loss self: 0.0000; time: 0.11s
Val loss: 0.2829 score: 0.8776 time: 0.07s
Test loss: 0.1546 score: 1.0000 time: 0.20s
Epoch 90/1000, LR 0.000266
Train loss: 0.0219;  Loss pred: 0.0219; Loss self: 0.0000; time: 0.12s
Val loss: 0.2786 score: 0.8776 time: 0.07s
Test loss: 0.1441 score: 1.0000 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0152;  Loss pred: 0.0152; Loss self: 0.0000; time: 0.12s
Val loss: 0.2749 score: 0.8776 time: 0.07s
Test loss: 0.1338 score: 1.0000 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.12s
Val loss: 0.2718 score: 0.8776 time: 0.07s
Test loss: 0.1242 score: 1.0000 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0172;  Loss pred: 0.0172; Loss self: 0.0000; time: 0.12s
Val loss: 0.2695 score: 0.8776 time: 0.07s
Test loss: 0.1151 score: 1.0000 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.12s
Val loss: 0.2678 score: 0.8776 time: 0.07s
Test loss: 0.1066 score: 1.0000 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0140;  Loss pred: 0.0140; Loss self: 0.0000; time: 0.11s
Val loss: 0.2667 score: 0.8776 time: 0.07s
Test loss: 0.0985 score: 1.0000 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.13s
Val loss: 0.2663 score: 0.8776 time: 0.14s
Test loss: 0.0911 score: 1.0000 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.12s
Val loss: 0.2665 score: 0.8776 time: 0.07s
Test loss: 0.0842 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.12s
Val loss: 0.2672 score: 0.8776 time: 0.07s
Test loss: 0.0781 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.12s
Val loss: 0.2685 score: 0.8776 time: 0.07s
Test loss: 0.0726 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.12s
Val loss: 0.2702 score: 0.8776 time: 0.07s
Test loss: 0.0676 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.12s
Val loss: 0.2724 score: 0.8776 time: 0.07s
Test loss: 0.0634 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.12s
Val loss: 0.2748 score: 0.8776 time: 0.07s
Test loss: 0.0595 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.13s
Val loss: 0.2773 score: 0.8776 time: 0.13s
Test loss: 0.0562 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.2800 score: 0.8776 time: 0.07s
Test loss: 0.0533 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.12s
Val loss: 0.2827 score: 0.8776 time: 0.07s
Test loss: 0.0507 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.12s
Val loss: 0.2851 score: 0.8980 time: 0.07s
Test loss: 0.0484 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.12s
Val loss: 0.2876 score: 0.8980 time: 0.07s
Test loss: 0.0462 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.12s
Val loss: 0.2901 score: 0.8980 time: 0.07s
Test loss: 0.0445 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.12s
Val loss: 0.2927 score: 0.8980 time: 0.07s
Test loss: 0.0428 score: 1.0000 time: 0.08s
     INFO: Early stopping counter 13 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.21s
Val loss: 0.2954 score: 0.8980 time: 0.07s
Test loss: 0.0413 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.2978 score: 0.8980 time: 0.07s
Test loss: 0.0400 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.12s
Val loss: 0.3000 score: 0.8980 time: 0.07s
Test loss: 0.0389 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.12s
Val loss: 0.3018 score: 0.8980 time: 0.07s
Test loss: 0.0379 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.12s
Val loss: 0.3039 score: 0.8980 time: 0.07s
Test loss: 0.0370 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.12s
Val loss: 0.3059 score: 0.8980 time: 0.07s
Test loss: 0.0362 score: 1.0000 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.12s
Val loss: 0.3075 score: 0.8980 time: 0.11s
Test loss: 0.0355 score: 1.0000 time: 0.09s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 095,   Train_Loss: 0.0116,   Val_Loss: 0.2663,   Val_Precision: 0.8800,   Val_Recall: 0.8800,   Val_accuracy: 0.8800,   Val_Score: 0.8776,   Val_Loss: 0.2663,   Test_Precision: 1.0000,   Test_Recall: 1.0000,   Test_accuracy: 1.0000,   Test_Score: 1.0000,   Test_loss: 0.0911


[0.07799731392879039, 0.08345408097375184, 0.08127321500796825, 0.0814093379303813, 0.08108883199747652, 0.08052210998721421, 0.08055499696638435, 0.0804555780487135, 0.08434840000700206, 0.08098557300399989, 0.08046741003636271, 0.0864179419586435, 0.08071994397323579, 0.08084409998264164, 0.08073175407480448, 0.08074441005010158, 0.08838433702476323, 0.0810352599946782, 0.08125073392875493, 0.08100439806003124, 0.08136705204378814, 0.07739571295678616, 0.0771207130746916, 0.07699342502746731, 0.07692588190548122, 0.07765289093367755, 0.07790500402916223, 0.07857631798833609, 0.07740421395283192, 0.07818210404366255, 0.07784694596193731, 0.07761060504708439, 0.07802865596022457, 0.08333502302411944, 0.08242595801129937, 0.08238968998193741, 0.08268499607220292, 0.08231602108571678, 0.08260897803120315, 0.08282512007281184, 0.08255240391008556, 0.08232958696316928, 0.08252207597251981, 0.08305186999496073, 0.08281986298970878, 0.0826049119932577, 0.08275404805317521, 0.08315647603012621, 0.08291980403009802, 0.08278189296834171, 0.08315020997542888, 0.08284865005407482, 0.08338698605075479, 0.0833380880067125, 0.08304740604944527, 0.08315717405639589, 0.08294230396859348, 0.08371702895965427, 0.08414118096698076, 0.08447614393662661, 0.0829820049693808, 0.08302698598708957, 0.07822106301318854, 0.07789036305621266, 0.07851926097646356, 0.07770803291350603, 0.07863956002984196, 0.07762567198369652, 0.0785252939676866, 0.07773583405651152, 0.07684487104415894, 0.07781616493593901, 0.0743599139386788, 0.07531266007572412, 0.0751617030473426, 0.07554948003962636, 0.07672151899896562, 0.07657294301316142, 0.07561138097662479, 0.07516432798001915, 0.07534158602356911, 0.07542747596744448, 0.07562344404868782, 0.0755131960613653, 0.07652309990953654, 0.07637487899046391, 0.07571139896754175, 0.07580044597852975, 0.07485717593226582, 0.07505399698857218, 0.07562266697641462, 0.07794163411017507, 0.0765172760002315, 0.07686591800302267, 0.07600937399547547, 0.07648778206203133, 0.07629500702023506, 0.0764374079881236, 0.07709925703238696, 0.07756235799752176, 0.07676115003414452, 0.08646674698684365, 0.07590293302200735, 0.07488451909739524, 0.07532410707790405, 0.0762197719886899, 0.07727422507014126, 0.07543761795386672, 0.07508821994997561, 0.20571971707977355, 0.07752792502287775, 0.07780860597267747, 0.07769753003958613, 0.07958729506935924, 0.07752460800111294, 0.07731329998932779, 0.0772199589991942, 0.07736793300136924, 0.07726221508346498, 0.0778865780448541, 0.07876700104679912, 0.07776625000406057, 0.07771913707256317, 0.07740912598092109, 0.07734693109523505, 0.07755539892241359, 0.07865331298671663, 0.07960228901356459, 0.07811279001180083, 0.08475926495157182, 0.07776159595232457, 0.07784286991227418, 0.07763928396161646, 0.07979501294903457, 0.07928435492794961, 0.07841640105471015, 0.09823486197274178]
[0.0015917819169140896, 0.0017031445096684049, 0.001658637040978944, 0.0016614150598037, 0.00165487412239748, 0.0016433083670860042, 0.0016439795299262113, 0.0016419505724227245, 0.001721395918510246, 0.0016527667959999976, 0.0016421920415584225, 0.001763631468543745, 0.001647345795372159, 0.0016498795914824825, 0.0016475868178531528, 0.0016478451030632975, 0.0018037619800972088, 0.0016537808162179223, 0.001658178243443978, 0.001653150980816964, 0.0016605520825262886, 0.0015795043460568603, 0.0015738921035651345, 0.0015712943883156593, 0.0015699159572547187, 0.001584752876197501, 0.001589898041411474, 0.0016035983262925732, 0.00157967783577208, 0.0015955531437482154, 0.0015887131828966798, 0.0015838898989200896, 0.0015924215502086648, 0.0017007147555942743, 0.0016821624083938648, 0.0016814222445293348, 0.0016874488994327126, 0.0016799187976676896, 0.0016858975108408807, 0.0016903085729145274, 0.0016847429369405216, 0.001680195652309577, 0.00168412399943918, 0.0016949361223461373, 0.0016902012855042608, 0.001685814530474647, 0.001688858123534188, 0.0016970709393903309, 0.001692240898573429, 0.0016894263871090145, 0.0016969430607230384, 0.001690788776613772, 0.001701775225525608, 0.0017007773062594387, 0.0016948450214172505, 0.0016970851848244059, 0.0016927000809917037, 0.0017085107950949852, 0.0017171669585098112, 0.0017240029374821757, 0.0016935103054975672, 0.0016944282854508077, 0.0015963482247589498, 0.0015895992460451564, 0.001602433897478848, 0.0015858782227246128, 0.0016048889802008563, 0.001584197387422378, 0.001602557019748706, 0.0015864455929900311, 0.0015682626743705906, 0.001588084998692633, 0.0015175492640546694, 0.0015369930627698802, 0.0015339123070886244, 0.0015418261232576808, 0.001565745285693176, 0.00156271312271758, 0.0015430894076862202, 0.001533965877143248, 0.0015375833882361042, 0.0015393362442335608, 0.0015433355928303636, 0.0015410856339054145, 0.001561695916521154, 0.001558670999805386, 0.0015451305911743215, 0.001546947877112852, 0.001527697468005425, 0.001531714224256575, 0.0015433197342125432, 0.0015906455940852056, 0.0015615770612292144, 0.0015686922041433199, 0.001551211714193377, 0.0015609751441230883, 0.001557040959596634, 0.0015599471017984407, 0.0015734542251507543, 0.0015829052652555462, 0.00156655408232948, 0.0017646274895274214, 0.0015490394494287213, 0.0015282554917835764, 0.0015372266750592663, 0.0015555055507895897, 0.0015770250014314543, 0.0015395432235483005, 0.0015324126520403186, 0.004198361573056603, 0.0015822025514873011, 0.001587930734136275, 0.0015856638783589005, 0.0016242305116195763, 0.00158213485716557, 0.0015778224487617916, 0.0015759175305958002, 0.001578937408191209, 0.0015767798996625506, 0.0015895220009153898, 0.0016074898172816147, 0.0015870663266134809, 0.001586104838215575, 0.0015797780812432875, 0.0015785087978619399, 0.001582763243314563, 0.0016051696527901354, 0.00162453651048091, 0.0015941385716694047, 0.0017297809173790167, 0.0015869713459658076, 0.0015886299982096773, 0.0015844751828901318, 0.0016284696520211138, 0.0016180480597540736, 0.001600334715402248, 0.002004793101484526]
[628.226762331018, 587.1492373801539, 602.9046592434655, 601.8965544456737, 604.2755678306586, 608.5285148114042, 608.2800800110232, 609.0317314025378, 580.9238823253593, 605.0460369969832, 608.9421789250731, 567.0118830583773, 607.0370913072842, 606.1048364756487, 606.948288954524, 606.8531551545884, 554.3968722226354, 604.6750513692183, 603.0714755508039, 604.9054270323295, 602.2093558659392, 633.1100021955882, 635.3675691839543, 636.417979619939, 636.976772787685, 631.0132103368867, 628.9711503212014, 623.5975578198203, 633.0404702495823, 626.7418944447294, 629.4402355097936, 631.3570158391748, 627.9744203844541, 587.9880777835516, 594.4729206942651, 594.7346083076955, 592.6105379168403, 595.2668672964116, 593.1558671684774, 591.6079560998395, 593.5623637728324, 595.1687820554778, 593.7805056712, 589.9927359007465, 591.6455090741789, 593.185063909994, 592.1160493383248, 589.2505591777135, 590.9324144352066, 591.9168823397054, 589.2949640714032, 591.4399325519244, 587.6216700070606, 587.9664529387005, 590.0244490577596, 589.2456129734395, 590.7721109188635, 585.305052137177, 582.3545550095013, 580.045415386851, 590.4894683863124, 590.1695625518593, 626.4297378794034, 629.0893773936733, 624.0507028547802, 630.5654404421755, 623.096059812715, 631.2344711204731, 624.0027578905168, 630.3399274571176, 637.6482819763226, 629.6892174053876, 658.9571908381719, 650.6210237526107, 651.9277506143793, 648.5815650127449, 638.6734861266319, 639.9127168401748, 648.0505893041197, 651.9049836117156, 650.3712303676662, 649.630646810309, 647.9472155282014, 648.8932074889331, 640.3295221694681, 641.5722112779791, 647.1944868038537, 646.4341913486776, 654.5798634500643, 652.8632979728022, 647.9538736088512, 628.6755539502242, 640.3782591509367, 637.473684996166, 644.6573287515401, 640.6251910960259, 642.2438625243741, 641.0473783675833, 635.5443863670002, 631.7497464629122, 638.343745217523, 566.6918405922637, 645.5613511772056, 654.3408516287634, 650.5221488961256, 642.8778087563817, 634.1053560294271, 649.5433091480376, 652.565742437951, 238.18815568854242, 632.0303295301734, 629.7503905571367, 630.6506780207168, 615.6761573225622, 632.057372019173, 633.7848728066696, 634.5509714724313, 633.337328517395, 634.203924221771, 629.1199489054634, 622.0879219571509, 630.09338880866, 630.4753481018544, 633.0003004048509, 633.5092977337098, 631.8064336052167, 622.9871080989985, 615.5601881203464, 627.298039061175, 578.1078921342312, 630.1311000618065, 629.4731945934298, 631.1238009900345, 614.073463855398, 618.0286141512938, 624.8692791424246, 498.80458949081157]
Elapsed: 0.08024071821480663~0.01128845681774897
Time per graph: 0.0016375656778531964~0.00023037666974997902
Speed: 616.078952776676~41.08840917263862
Total Time: 0.0989
best val loss: 0.2662598192691803 test_score: 1.0000

Testing...
Test loss: 0.5079 score: 0.9796 time: 0.08s
test Score 0.9796
Epoch Time List: [0.2700401711044833, 0.2617023950442672, 0.26317456318065524, 0.26385300303809345, 0.2621102900011465, 0.2625041489955038, 0.26167037803679705, 0.2615297739394009, 0.2735748258419335, 0.26466484798584133, 0.2615814749151468, 0.2794500798918307, 0.26244941109325737, 0.26298592099919915, 0.26183182292152196, 0.2636142171686515, 0.28063371195457876, 0.2664966029115021, 0.2640956579707563, 0.2637350030709058, 0.2647739560343325, 0.25815458898432553, 0.25694242608733475, 0.2539452649652958, 0.2552071699174121, 0.25679801707156, 0.25712122896220535, 0.25784410315100104, 0.25636984512675554, 0.25757800589781255, 0.25761660910211504, 0.2559020161861554, 0.2568856200668961, 0.27070278802420944, 0.26985299901571125, 0.2709582431707531, 0.26977210806217045, 0.2693900018930435, 0.2691405931254849, 0.2700407721567899, 0.2711341209942475, 0.2700587750878185, 0.2702789169270545, 0.2714692479930818, 0.27252188499551266, 0.2700457989703864, 0.2720533849205822, 0.2717806580476463, 0.271514326101169, 0.2732513638911769, 0.2731949791777879, 0.2722191899083555, 0.27272861602250487, 0.27172798092942685, 0.27142982895020396, 0.2742327079176903, 0.27122031594626606, 0.2735692020505667, 0.2729600890306756, 0.2752383800689131, 0.27236519986763597, 0.2734396312152967, 0.2666901859920472, 0.2577300239354372, 0.25805654912255704, 0.2582491639768705, 0.25778018799610436, 0.2574176910566166, 0.25708865001797676, 0.2578935669735074, 0.2523410849971697, 0.2528001399477944, 0.36134089913684875, 0.25043424090836197, 0.2501501579536125, 0.2489588458556682, 0.2525709989713505, 0.2539430499309674, 0.25037521694321185, 0.3590739999199286, 0.2482403399189934, 0.24808924400713295, 0.24873658909928054, 0.24900180590339005, 0.2521285960683599, 0.25510963588021696, 0.2509048630017787, 0.36779309797566384, 0.2502971620997414, 0.24931477499194443, 0.24990070995409042, 0.255124271963723, 0.2560840619262308, 0.2533539419528097, 0.34962567884940654, 0.2523592980578542, 0.25301542901434004, 0.25306818110402673, 0.25556522398255765, 0.25767744483891875, 0.2554030630271882, 0.26136157696601003, 0.3512723660096526, 0.24887304997537285, 0.24933615396730602, 0.24884395499248058, 0.251426086993888, 0.2555793699575588, 0.24982917797751725, 0.3792236199369654, 0.25673203507903963, 0.25728075101505965, 0.2589027239009738, 0.2617415830027312, 0.2583588339621201, 0.2546552689746022, 0.3469538699137047, 0.256243493873626, 0.2580781269352883, 0.2572821278590709, 0.26097255991771817, 0.2613416409585625, 0.25859386392403394, 0.3378381779184565, 0.2591766439145431, 0.25901453709229827, 0.26206376624759287, 0.2652928769821301, 0.26176412298809737, 0.26256444805767387, 0.3566622310318053, 0.25531340087763965, 0.25715445703826845, 0.2583212699973956, 0.2654841060284525, 0.2609533100621775, 0.32417216803878546]
Total Epoch List: [21, 116]
Total Time List: [0.0816929730353877, 0.09885171195492148]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x773d08079b10>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6982;  Loss pred: 0.6982; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.06s
Epoch 2/1000, LR 0.000000
Train loss: 0.6992;  Loss pred: 0.6992; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.06s
Epoch 3/1000, LR 0.000030
Train loss: 0.6984;  Loss pred: 0.6984; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.06s
Epoch 4/1000, LR 0.000060
Train loss: 0.6967;  Loss pred: 0.6967; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5000 time: 0.06s
Epoch 5/1000, LR 0.000090
Train loss: 0.6962;  Loss pred: 0.6962; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5102 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5000 time: 0.07s
Epoch 6/1000, LR 0.000120
Train loss: 0.6933;  Loss pred: 0.6933; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.5000 time: 0.06s
Epoch 7/1000, LR 0.000150
Train loss: 0.6923;  Loss pred: 0.6923; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.06s
Epoch 8/1000, LR 0.000180
Train loss: 0.6878;  Loss pred: 0.6878; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6845;  Loss pred: 0.6845; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.06s
Epoch 10/1000, LR 0.000240
Train loss: 0.6813;  Loss pred: 0.6813; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.07s
Epoch 11/1000, LR 0.000270
Train loss: 0.6772;  Loss pred: 0.6772; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5000 time: 0.06s
Epoch 12/1000, LR 0.000270
Train loss: 0.6752;  Loss pred: 0.6752; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.12s
Epoch 13/1000, LR 0.000270
Train loss: 0.6676;  Loss pred: 0.6676; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.07s
Epoch 14/1000, LR 0.000270
Train loss: 0.6618;  Loss pred: 0.6618; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.07s
Epoch 15/1000, LR 0.000270
Train loss: 0.6591;  Loss pred: 0.6591; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.07s
Epoch 16/1000, LR 0.000270
Train loss: 0.6518;  Loss pred: 0.6518; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.07s
Epoch 17/1000, LR 0.000270
Train loss: 0.6498;  Loss pred: 0.6498; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 18/1000, LR 0.000270
Train loss: 0.6399;  Loss pred: 0.6399; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.07s
Epoch 19/1000, LR 0.000270
Train loss: 0.6350;  Loss pred: 0.6350; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5102 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
Epoch 20/1000, LR 0.000270
Train loss: 0.6277;  Loss pred: 0.6277; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.07s
Epoch 21/1000, LR 0.000270
Train loss: 0.6221;  Loss pred: 0.6221; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.07s
Epoch 22/1000, LR 0.000270
Train loss: 0.6150;  Loss pred: 0.6150; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.07s
Epoch 23/1000, LR 0.000270
Train loss: 0.6033;  Loss pred: 0.6033; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.07s
Epoch 24/1000, LR 0.000270
Train loss: 0.5993;  Loss pred: 0.5993; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5000 time: 0.07s
Epoch 25/1000, LR 0.000270
Train loss: 0.5861;  Loss pred: 0.5861; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.07s
Epoch 26/1000, LR 0.000270
Train loss: 0.5766;  Loss pred: 0.5766; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5102 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5000 time: 0.06s
Epoch 27/1000, LR 0.000270
Train loss: 0.5696;  Loss pred: 0.5696; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5000 time: 0.07s
Epoch 28/1000, LR 0.000270
Train loss: 0.5599;  Loss pred: 0.5599; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5000 time: 0.07s
Epoch 29/1000, LR 0.000270
Train loss: 0.5453;  Loss pred: 0.5453; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.5102 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5000 time: 0.07s
Epoch 30/1000, LR 0.000270
Train loss: 0.5351;  Loss pred: 0.5351; Loss self: 0.0000; time: 0.11s
Val loss: 0.6891 score: 0.5306 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.5000 time: 0.07s
Epoch 31/1000, LR 0.000270
Train loss: 0.5289;  Loss pred: 0.5289; Loss self: 0.0000; time: 0.11s
Val loss: 0.6885 score: 0.5714 time: 0.08s
Test loss: 0.6886 score: 0.6042 time: 0.07s
Epoch 32/1000, LR 0.000270
Train loss: 0.5140;  Loss pred: 0.5140; Loss self: 0.0000; time: 0.11s
Val loss: 0.6878 score: 0.6939 time: 0.08s
Test loss: 0.6878 score: 0.6667 time: 0.07s
Epoch 33/1000, LR 0.000270
Train loss: 0.4991;  Loss pred: 0.4991; Loss self: 0.0000; time: 0.12s
Val loss: 0.6871 score: 0.8776 time: 0.16s
Test loss: 0.6870 score: 0.8333 time: 0.06s
Epoch 34/1000, LR 0.000270
Train loss: 0.4857;  Loss pred: 0.4857; Loss self: 0.0000; time: 0.11s
Val loss: 0.6862 score: 0.9592 time: 0.08s
Test loss: 0.6860 score: 0.9167 time: 0.07s
Epoch 35/1000, LR 0.000270
Train loss: 0.4756;  Loss pred: 0.4756; Loss self: 0.0000; time: 0.11s
Val loss: 0.6852 score: 0.9388 time: 0.08s
Test loss: 0.6849 score: 0.9167 time: 0.06s
Epoch 36/1000, LR 0.000270
Train loss: 0.4655;  Loss pred: 0.4655; Loss self: 0.0000; time: 0.11s
Val loss: 0.6840 score: 0.8163 time: 0.08s
Test loss: 0.6837 score: 0.8333 time: 0.07s
Epoch 37/1000, LR 0.000270
Train loss: 0.4435;  Loss pred: 0.4435; Loss self: 0.0000; time: 0.11s
Val loss: 0.6826 score: 0.7551 time: 0.08s
Test loss: 0.6821 score: 0.7708 time: 0.07s
Epoch 38/1000, LR 0.000270
Train loss: 0.4320;  Loss pred: 0.4320; Loss self: 0.0000; time: 0.11s
Val loss: 0.6809 score: 0.7347 time: 0.08s
Test loss: 0.6803 score: 0.7500 time: 0.07s
Epoch 39/1000, LR 0.000269
Train loss: 0.4188;  Loss pred: 0.4188; Loss self: 0.0000; time: 0.11s
Val loss: 0.6789 score: 0.7347 time: 0.08s
Test loss: 0.6782 score: 0.7083 time: 0.07s
Epoch 40/1000, LR 0.000269
Train loss: 0.4030;  Loss pred: 0.4030; Loss self: 0.0000; time: 0.11s
Val loss: 0.6767 score: 0.7143 time: 0.08s
Test loss: 0.6759 score: 0.7083 time: 0.07s
Epoch 41/1000, LR 0.000269
Train loss: 0.3920;  Loss pred: 0.3920; Loss self: 0.0000; time: 0.22s
Val loss: 0.6745 score: 0.6735 time: 0.08s
Test loss: 0.6735 score: 0.7083 time: 0.07s
Epoch 42/1000, LR 0.000269
Train loss: 0.3723;  Loss pred: 0.3723; Loss self: 0.0000; time: 0.11s
Val loss: 0.6723 score: 0.6531 time: 0.08s
Test loss: 0.6711 score: 0.7083 time: 0.07s
Epoch 43/1000, LR 0.000269
Train loss: 0.3595;  Loss pred: 0.3595; Loss self: 0.0000; time: 0.11s
Val loss: 0.6699 score: 0.6327 time: 0.08s
Test loss: 0.6684 score: 0.7083 time: 0.07s
Epoch 44/1000, LR 0.000269
Train loss: 0.3435;  Loss pred: 0.3435; Loss self: 0.0000; time: 0.11s
Val loss: 0.6674 score: 0.5918 time: 0.08s
Test loss: 0.6657 score: 0.6875 time: 0.07s
Epoch 45/1000, LR 0.000269
Train loss: 0.3297;  Loss pred: 0.3297; Loss self: 0.0000; time: 0.11s
Val loss: 0.6647 score: 0.5918 time: 0.08s
Test loss: 0.6626 score: 0.6875 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3120;  Loss pred: 0.3120; Loss self: 0.0000; time: 0.11s
Val loss: 0.6617 score: 0.6122 time: 0.08s
Test loss: 0.6594 score: 0.6875 time: 0.07s
Epoch 47/1000, LR 0.000269
Train loss: 0.2967;  Loss pred: 0.2967; Loss self: 0.0000; time: 0.11s
Val loss: 0.6585 score: 0.6122 time: 0.08s
Test loss: 0.6558 score: 0.6875 time: 0.07s
Epoch 48/1000, LR 0.000269
Train loss: 0.2843;  Loss pred: 0.2843; Loss self: 0.0000; time: 0.11s
Val loss: 0.6550 score: 0.6122 time: 0.08s
Test loss: 0.6520 score: 0.6875 time: 0.19s
Epoch 49/1000, LR 0.000269
Train loss: 0.2705;  Loss pred: 0.2705; Loss self: 0.0000; time: 0.11s
Val loss: 0.6511 score: 0.6122 time: 0.08s
Test loss: 0.6477 score: 0.6875 time: 0.07s
Epoch 50/1000, LR 0.000269
Train loss: 0.2553;  Loss pred: 0.2553; Loss self: 0.0000; time: 0.11s
Val loss: 0.6469 score: 0.6122 time: 0.08s
Test loss: 0.6430 score: 0.7083 time: 0.07s
Epoch 51/1000, LR 0.000269
Train loss: 0.2413;  Loss pred: 0.2413; Loss self: 0.0000; time: 0.11s
Val loss: 0.6424 score: 0.6122 time: 0.08s
Test loss: 0.6380 score: 0.7083 time: 0.07s
Epoch 52/1000, LR 0.000269
Train loss: 0.2251;  Loss pred: 0.2251; Loss self: 0.0000; time: 0.11s
Val loss: 0.6375 score: 0.6327 time: 0.08s
Test loss: 0.6325 score: 0.7083 time: 0.07s
Epoch 53/1000, LR 0.000269
Train loss: 0.2120;  Loss pred: 0.2120; Loss self: 0.0000; time: 0.11s
Val loss: 0.6322 score: 0.6531 time: 0.08s
Test loss: 0.6267 score: 0.7083 time: 0.07s
Epoch 54/1000, LR 0.000269
Train loss: 0.2000;  Loss pred: 0.2000; Loss self: 0.0000; time: 0.11s
Val loss: 0.6266 score: 0.6531 time: 0.08s
Test loss: 0.6205 score: 0.7083 time: 0.07s
Epoch 55/1000, LR 0.000269
Train loss: 0.1884;  Loss pred: 0.1884; Loss self: 0.0000; time: 0.11s
Val loss: 0.6206 score: 0.6531 time: 0.08s
Test loss: 0.6137 score: 0.7292 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.1714;  Loss pred: 0.1714; Loss self: 0.0000; time: 0.11s
Val loss: 0.6142 score: 0.6531 time: 0.08s
Test loss: 0.6067 score: 0.7292 time: 0.07s
Epoch 57/1000, LR 0.000269
Train loss: 0.1670;  Loss pred: 0.1670; Loss self: 0.0000; time: 0.11s
Val loss: 0.6075 score: 0.6939 time: 0.08s
Test loss: 0.5993 score: 0.7292 time: 0.07s
Epoch 58/1000, LR 0.000269
Train loss: 0.1550;  Loss pred: 0.1550; Loss self: 0.0000; time: 0.11s
Val loss: 0.6005 score: 0.7143 time: 0.08s
Test loss: 0.5916 score: 0.7292 time: 0.07s
Epoch 59/1000, LR 0.000268
Train loss: 0.1396;  Loss pred: 0.1396; Loss self: 0.0000; time: 0.11s
Val loss: 0.5932 score: 0.7347 time: 0.08s
Test loss: 0.5836 score: 0.7292 time: 0.07s
Epoch 60/1000, LR 0.000268
Train loss: 0.1306;  Loss pred: 0.1306; Loss self: 0.0000; time: 0.11s
Val loss: 0.5856 score: 0.7347 time: 0.08s
Test loss: 0.5752 score: 0.7292 time: 0.07s
Epoch 61/1000, LR 0.000268
Train loss: 0.1179;  Loss pred: 0.1179; Loss self: 0.0000; time: 0.11s
Val loss: 0.5777 score: 0.7347 time: 0.08s
Test loss: 0.5665 score: 0.7292 time: 0.07s
Epoch 62/1000, LR 0.000268
Train loss: 0.1146;  Loss pred: 0.1146; Loss self: 0.0000; time: 0.11s
Val loss: 0.5697 score: 0.7347 time: 0.08s
Test loss: 0.5576 score: 0.7292 time: 0.07s
Epoch 63/1000, LR 0.000268
Train loss: 0.1047;  Loss pred: 0.1047; Loss self: 0.0000; time: 0.11s
Val loss: 0.5614 score: 0.7347 time: 0.08s
Test loss: 0.5484 score: 0.7292 time: 0.07s
Epoch 64/1000, LR 0.000268
Train loss: 0.0901;  Loss pred: 0.0901; Loss self: 0.0000; time: 0.11s
Val loss: 0.5529 score: 0.7347 time: 0.08s
Test loss: 0.5389 score: 0.7500 time: 0.07s
Epoch 65/1000, LR 0.000268
Train loss: 0.0846;  Loss pred: 0.0846; Loss self: 0.0000; time: 0.11s
Val loss: 0.5446 score: 0.7347 time: 0.08s
Test loss: 0.5295 score: 0.7500 time: 0.07s
Epoch 66/1000, LR 0.000268
Train loss: 0.0758;  Loss pred: 0.0758; Loss self: 0.0000; time: 0.11s
Val loss: 0.5364 score: 0.7347 time: 0.08s
Test loss: 0.5201 score: 0.7500 time: 0.07s
Epoch 67/1000, LR 0.000268
Train loss: 0.0675;  Loss pred: 0.0675; Loss self: 0.0000; time: 0.11s
Val loss: 0.5280 score: 0.7347 time: 0.08s
Test loss: 0.5104 score: 0.7708 time: 0.07s
Epoch 68/1000, LR 0.000268
Train loss: 0.0634;  Loss pred: 0.0634; Loss self: 0.0000; time: 0.11s
Val loss: 0.5191 score: 0.7347 time: 0.08s
Test loss: 0.5004 score: 0.7708 time: 0.07s
Epoch 69/1000, LR 0.000268
Train loss: 0.0619;  Loss pred: 0.0619; Loss self: 0.0000; time: 0.11s
Val loss: 0.5105 score: 0.7347 time: 0.08s
Test loss: 0.4905 score: 0.7708 time: 0.07s
Epoch 70/1000, LR 0.000268
Train loss: 0.0512;  Loss pred: 0.0512; Loss self: 0.0000; time: 0.11s
Val loss: 0.5016 score: 0.7347 time: 0.08s
Test loss: 0.4804 score: 0.7917 time: 0.07s
Epoch 71/1000, LR 0.000268
Train loss: 0.0470;  Loss pred: 0.0470; Loss self: 0.0000; time: 0.11s
Val loss: 0.4926 score: 0.7551 time: 0.08s
Test loss: 0.4699 score: 0.7917 time: 0.07s
Epoch 72/1000, LR 0.000267
Train loss: 0.0446;  Loss pred: 0.0446; Loss self: 0.0000; time: 0.11s
Val loss: 0.4838 score: 0.7755 time: 0.08s
Test loss: 0.4596 score: 0.7917 time: 0.07s
Epoch 73/1000, LR 0.000267
Train loss: 0.0388;  Loss pred: 0.0388; Loss self: 0.0000; time: 0.11s
Val loss: 0.4754 score: 0.7959 time: 0.08s
Test loss: 0.4496 score: 0.7917 time: 0.07s
Epoch 74/1000, LR 0.000267
Train loss: 0.0348;  Loss pred: 0.0348; Loss self: 0.0000; time: 0.11s
Val loss: 0.4668 score: 0.7959 time: 0.08s
Test loss: 0.4393 score: 0.7917 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0349;  Loss pred: 0.0349; Loss self: 0.0000; time: 0.11s
Val loss: 0.4582 score: 0.7959 time: 0.08s
Test loss: 0.4290 score: 0.8125 time: 0.07s
Epoch 76/1000, LR 0.000267
Train loss: 0.0341;  Loss pred: 0.0341; Loss self: 0.0000; time: 0.11s
Val loss: 0.4503 score: 0.7959 time: 0.08s
Test loss: 0.4192 score: 0.8125 time: 0.07s
Epoch 77/1000, LR 0.000267
Train loss: 0.0284;  Loss pred: 0.0284; Loss self: 0.0000; time: 0.11s
Val loss: 0.4423 score: 0.8163 time: 0.08s
Test loss: 0.4093 score: 0.8125 time: 0.07s
Epoch 78/1000, LR 0.000267
Train loss: 0.0258;  Loss pred: 0.0258; Loss self: 0.0000; time: 0.11s
Val loss: 0.4344 score: 0.8163 time: 0.08s
Test loss: 0.3996 score: 0.8333 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0258;  Loss pred: 0.0258; Loss self: 0.0000; time: 0.11s
Val loss: 0.4268 score: 0.8163 time: 0.08s
Test loss: 0.3900 score: 0.8542 time: 0.07s
Epoch 80/1000, LR 0.000267
Train loss: 0.0208;  Loss pred: 0.0208; Loss self: 0.0000; time: 0.11s
Val loss: 0.4194 score: 0.8163 time: 0.08s
Test loss: 0.3805 score: 0.8542 time: 0.07s
Epoch 81/1000, LR 0.000267
Train loss: 0.0201;  Loss pred: 0.0201; Loss self: 0.0000; time: 0.11s
Val loss: 0.4121 score: 0.8163 time: 0.08s
Test loss: 0.3711 score: 0.8750 time: 0.07s
Epoch 82/1000, LR 0.000267
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.11s
Val loss: 0.4045 score: 0.8163 time: 0.08s
Test loss: 0.3614 score: 0.8750 time: 0.07s
Epoch 83/1000, LR 0.000266
Train loss: 0.0165;  Loss pred: 0.0165; Loss self: 0.0000; time: 0.11s
Val loss: 0.3963 score: 0.8163 time: 0.08s
Test loss: 0.3514 score: 0.8750 time: 0.07s
Epoch 84/1000, LR 0.000266
Train loss: 0.0168;  Loss pred: 0.0168; Loss self: 0.0000; time: 0.11s
Val loss: 0.3882 score: 0.8163 time: 0.08s
Test loss: 0.3416 score: 0.9167 time: 0.07s
Epoch 85/1000, LR 0.000266
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.11s
Val loss: 0.3810 score: 0.8163 time: 0.08s
Test loss: 0.3328 score: 0.9167 time: 0.07s
Epoch 86/1000, LR 0.000266
Train loss: 0.0131;  Loss pred: 0.0131; Loss self: 0.0000; time: 0.11s
Val loss: 0.3730 score: 0.8163 time: 0.08s
Test loss: 0.3235 score: 0.9167 time: 0.07s
Epoch 87/1000, LR 0.000266
Train loss: 0.0118;  Loss pred: 0.0118; Loss self: 0.0000; time: 0.11s
Val loss: 0.3655 score: 0.8367 time: 0.08s
Test loss: 0.3149 score: 0.9167 time: 0.07s
Epoch 88/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.11s
Val loss: 0.3576 score: 0.8367 time: 0.08s
Test loss: 0.3063 score: 0.9167 time: 0.07s
Epoch 89/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.11s
Val loss: 0.3510 score: 0.8571 time: 0.08s
Test loss: 0.2991 score: 0.9167 time: 0.07s
Epoch 90/1000, LR 0.000266
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.11s
Val loss: 0.3445 score: 0.8571 time: 0.08s
Test loss: 0.2924 score: 0.9167 time: 0.07s
Epoch 91/1000, LR 0.000266
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.11s
Val loss: 0.3380 score: 0.8571 time: 0.08s
Test loss: 0.2859 score: 0.9167 time: 0.07s
Epoch 92/1000, LR 0.000266
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.11s
Val loss: 0.3322 score: 0.8776 time: 0.08s
Test loss: 0.2803 score: 0.9167 time: 0.07s
Epoch 93/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.11s
Val loss: 0.3272 score: 0.8776 time: 0.08s
Test loss: 0.2755 score: 0.8958 time: 0.07s
Epoch 94/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.11s
Val loss: 0.3226 score: 0.8980 time: 0.08s
Test loss: 0.2714 score: 0.8958 time: 0.07s
Epoch 95/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.11s
Val loss: 0.3184 score: 0.8980 time: 0.08s
Test loss: 0.2680 score: 0.8958 time: 0.07s
Epoch 96/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.11s
Val loss: 0.3150 score: 0.8980 time: 0.08s
Test loss: 0.2653 score: 0.8958 time: 0.07s
Epoch 97/1000, LR 0.000265
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.11s
Val loss: 0.3120 score: 0.9184 time: 0.08s
Test loss: 0.2632 score: 0.8958 time: 0.07s
Epoch 98/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.3098 score: 0.9184 time: 0.08s
Test loss: 0.2619 score: 0.8958 time: 0.07s
Epoch 99/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.11s
Val loss: 0.3076 score: 0.9184 time: 0.08s
Test loss: 0.2609 score: 0.8958 time: 0.07s
Epoch 100/1000, LR 0.000265
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.11s
Val loss: 0.3063 score: 0.9184 time: 0.08s
Test loss: 0.2607 score: 0.8958 time: 0.07s
Epoch 101/1000, LR 0.000265
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.11s
Val loss: 0.3057 score: 0.9184 time: 0.08s
Test loss: 0.2610 score: 0.8958 time: 0.07s
Epoch 102/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.11s
Val loss: 0.3051 score: 0.9184 time: 0.08s
Test loss: 0.2615 score: 0.8958 time: 0.07s
Epoch 103/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.11s
Val loss: 0.3048 score: 0.9184 time: 0.08s
Test loss: 0.2624 score: 0.8958 time: 0.07s
Epoch 104/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.3048 score: 0.9184 time: 0.08s
Test loss: 0.2635 score: 0.8958 time: 0.07s
     INFO: Early stopping counter 1 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.3051 score: 0.9184 time: 0.08s
Test loss: 0.2648 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 2 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.3058 score: 0.9184 time: 0.08s
Test loss: 0.2665 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 3 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.11s
Val loss: 0.3068 score: 0.9184 time: 0.08s
Test loss: 0.2682 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 4 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.11s
Val loss: 0.3076 score: 0.9184 time: 0.08s
Test loss: 0.2700 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 5 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.11s
Val loss: 0.3087 score: 0.9184 time: 0.08s
Test loss: 0.2719 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 6 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.11s
Val loss: 0.3098 score: 0.9184 time: 0.08s
Test loss: 0.2738 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 7 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.3107 score: 0.9184 time: 0.08s
Test loss: 0.2757 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 8 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.11s
Val loss: 0.3121 score: 0.9184 time: 0.08s
Test loss: 0.2777 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 9 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.11s
Val loss: 0.3140 score: 0.9184 time: 0.08s
Test loss: 0.2798 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.11s
Val loss: 0.3158 score: 0.9184 time: 0.08s
Test loss: 0.2819 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 11 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.11s
Val loss: 0.3179 score: 0.9184 time: 0.08s
Test loss: 0.2841 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 12 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.3191 score: 0.9184 time: 0.08s
Test loss: 0.2859 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 13 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.11s
Val loss: 0.3201 score: 0.9184 time: 0.08s
Test loss: 0.2875 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 14 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.11s
Val loss: 0.3211 score: 0.9184 time: 0.08s
Test loss: 0.2892 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 15 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.11s
Val loss: 0.3218 score: 0.9184 time: 0.08s
Test loss: 0.2907 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 16 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0030;  Loss pred: 0.0030; Loss self: 0.0000; time: 0.11s
Val loss: 0.3224 score: 0.9184 time: 0.08s
Test loss: 0.2920 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.11s
Val loss: 0.3232 score: 0.9184 time: 0.08s
Test loss: 0.2934 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 18 of 20
Epoch 122/1000, LR 0.000262
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.11s
Val loss: 0.3240 score: 0.9184 time: 0.08s
Test loss: 0.2949 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.11s
Val loss: 0.3246 score: 0.9184 time: 0.08s
Test loss: 0.2961 score: 0.9167 time: 0.07s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 102,   Train_Loss: 0.0057,   Val_Loss: 0.3048,   Val_Precision: 1.0000,   Val_Recall: 0.8400,   Val_accuracy: 0.9130,   Val_Score: 0.9184,   Val_Loss: 0.3048,   Test_Precision: 0.9524,   Test_Recall: 0.8333,   Test_accuracy: 0.8889,   Test_Score: 0.8958,   Test_loss: 0.2624


[0.07799731392879039, 0.08345408097375184, 0.08127321500796825, 0.0814093379303813, 0.08108883199747652, 0.08052210998721421, 0.08055499696638435, 0.0804555780487135, 0.08434840000700206, 0.08098557300399989, 0.08046741003636271, 0.0864179419586435, 0.08071994397323579, 0.08084409998264164, 0.08073175407480448, 0.08074441005010158, 0.08838433702476323, 0.0810352599946782, 0.08125073392875493, 0.08100439806003124, 0.08136705204378814, 0.07739571295678616, 0.0771207130746916, 0.07699342502746731, 0.07692588190548122, 0.07765289093367755, 0.07790500402916223, 0.07857631798833609, 0.07740421395283192, 0.07818210404366255, 0.07784694596193731, 0.07761060504708439, 0.07802865596022457, 0.08333502302411944, 0.08242595801129937, 0.08238968998193741, 0.08268499607220292, 0.08231602108571678, 0.08260897803120315, 0.08282512007281184, 0.08255240391008556, 0.08232958696316928, 0.08252207597251981, 0.08305186999496073, 0.08281986298970878, 0.0826049119932577, 0.08275404805317521, 0.08315647603012621, 0.08291980403009802, 0.08278189296834171, 0.08315020997542888, 0.08284865005407482, 0.08338698605075479, 0.0833380880067125, 0.08304740604944527, 0.08315717405639589, 0.08294230396859348, 0.08371702895965427, 0.08414118096698076, 0.08447614393662661, 0.0829820049693808, 0.08302698598708957, 0.07822106301318854, 0.07789036305621266, 0.07851926097646356, 0.07770803291350603, 0.07863956002984196, 0.07762567198369652, 0.0785252939676866, 0.07773583405651152, 0.07684487104415894, 0.07781616493593901, 0.0743599139386788, 0.07531266007572412, 0.0751617030473426, 0.07554948003962636, 0.07672151899896562, 0.07657294301316142, 0.07561138097662479, 0.07516432798001915, 0.07534158602356911, 0.07542747596744448, 0.07562344404868782, 0.0755131960613653, 0.07652309990953654, 0.07637487899046391, 0.07571139896754175, 0.07580044597852975, 0.07485717593226582, 0.07505399698857218, 0.07562266697641462, 0.07794163411017507, 0.0765172760002315, 0.07686591800302267, 0.07600937399547547, 0.07648778206203133, 0.07629500702023506, 0.0764374079881236, 0.07709925703238696, 0.07756235799752176, 0.07676115003414452, 0.08646674698684365, 0.07590293302200735, 0.07488451909739524, 0.07532410707790405, 0.0762197719886899, 0.07727422507014126, 0.07543761795386672, 0.07508821994997561, 0.20571971707977355, 0.07752792502287775, 0.07780860597267747, 0.07769753003958613, 0.07958729506935924, 0.07752460800111294, 0.07731329998932779, 0.0772199589991942, 0.07736793300136924, 0.07726221508346498, 0.0778865780448541, 0.07876700104679912, 0.07776625000406057, 0.07771913707256317, 0.07740912598092109, 0.07734693109523505, 0.07755539892241359, 0.07865331298671663, 0.07960228901356459, 0.07811279001180083, 0.08475926495157182, 0.07776159595232457, 0.07784286991227418, 0.07763928396161646, 0.07979501294903457, 0.07928435492794961, 0.07841640105471015, 0.09823486197274178, 0.07007120701018721, 0.06962478999048471, 0.06944940204266459, 0.06946592195890844, 0.07057918200735003, 0.06921739294193685, 0.06922591698821634, 0.07010719599202275, 0.06963219004683197, 0.07102971407584846, 0.06977931899018586, 0.13064420502632856, 0.07081764296162874, 0.07041068305261433, 0.07069740304723382, 0.07236624998040497, 0.0718577429652214, 0.07141535601112992, 0.07101347402203828, 0.07069449196569622, 0.07110213104169816, 0.0713602239266038, 0.07309959398116916, 0.07264618901535869, 0.07120662403758615, 0.06989728391636163, 0.07086183503270149, 0.07077516196295619, 0.0711972169810906, 0.07322280202060938, 0.07111776899546385, 0.07116238994058222, 0.06939367193263024, 0.07000681106001139, 0.069782754057087, 0.0703645859612152, 0.0710969630163163, 0.07621292897965759, 0.07016710506286472, 0.07170253805816174, 0.07109883590601385, 0.07090551499277353, 0.07158980704843998, 0.0709725059568882, 0.07231039099860936, 0.07246937206946313, 0.07186289096716791, 0.19777466298546642, 0.07038640405517071, 0.07116214302368462, 0.07101750397123396, 0.07343115110415965, 0.07212007802445441, 0.07145528309047222, 0.07172796200029552, 0.07157194800674915, 0.07187082199379802, 0.07196427299641073, 0.07212452997919172, 0.07165990397334099, 0.07175141898915172, 0.07212062098551542, 0.07211110298521817, 0.07197789708152413, 0.07206078397575766, 0.07142538402695209, 0.07197209890000522, 0.07168420997913927, 0.07170267205219716, 0.07174967497121543, 0.07162822398822755, 0.07260506297461689, 0.07146160292904824, 0.07163711206521839, 0.07169027905911207, 0.07151912001427263, 0.07192416791804135, 0.07227999099995941, 0.07171262800693512, 0.0715591290500015, 0.07143291109241545, 0.0718196629313752, 0.07159612304531038, 0.07165921700652689, 0.07135440898127854, 0.07110439299140126, 0.07108074601273984, 0.07157495606224984, 0.07239732600282878, 0.07172162807546556, 0.07203914993442595, 0.0714479610323906, 0.07187268603593111, 0.07159510301426053, 0.07217162498272955, 0.07194872805848718, 0.07194108399562538, 0.07178803603164852, 0.07163703697733581, 0.07131767901591957, 0.07211659895256162, 0.07161058695055544, 0.07174657203722745, 0.0718877170002088, 0.07226395700126886, 0.07129641505889595, 0.07173698709812015, 0.07260142092127353, 0.07214155595283955, 0.07171676389407367, 0.07202333107125014, 0.07241701800376177, 0.07156528800260276, 0.07157803699374199, 0.07215372705832124, 0.07142738602124155, 0.07176364492624998, 0.0713522779988125, 0.07133726007305086, 0.07166578492615372, 0.0725111480569467, 0.07158587197773159, 0.07210024411324412]
[0.0015917819169140896, 0.0017031445096684049, 0.001658637040978944, 0.0016614150598037, 0.00165487412239748, 0.0016433083670860042, 0.0016439795299262113, 0.0016419505724227245, 0.001721395918510246, 0.0016527667959999976, 0.0016421920415584225, 0.001763631468543745, 0.001647345795372159, 0.0016498795914824825, 0.0016475868178531528, 0.0016478451030632975, 0.0018037619800972088, 0.0016537808162179223, 0.001658178243443978, 0.001653150980816964, 0.0016605520825262886, 0.0015795043460568603, 0.0015738921035651345, 0.0015712943883156593, 0.0015699159572547187, 0.001584752876197501, 0.001589898041411474, 0.0016035983262925732, 0.00157967783577208, 0.0015955531437482154, 0.0015887131828966798, 0.0015838898989200896, 0.0015924215502086648, 0.0017007147555942743, 0.0016821624083938648, 0.0016814222445293348, 0.0016874488994327126, 0.0016799187976676896, 0.0016858975108408807, 0.0016903085729145274, 0.0016847429369405216, 0.001680195652309577, 0.00168412399943918, 0.0016949361223461373, 0.0016902012855042608, 0.001685814530474647, 0.001688858123534188, 0.0016970709393903309, 0.001692240898573429, 0.0016894263871090145, 0.0016969430607230384, 0.001690788776613772, 0.001701775225525608, 0.0017007773062594387, 0.0016948450214172505, 0.0016970851848244059, 0.0016927000809917037, 0.0017085107950949852, 0.0017171669585098112, 0.0017240029374821757, 0.0016935103054975672, 0.0016944282854508077, 0.0015963482247589498, 0.0015895992460451564, 0.001602433897478848, 0.0015858782227246128, 0.0016048889802008563, 0.001584197387422378, 0.001602557019748706, 0.0015864455929900311, 0.0015682626743705906, 0.001588084998692633, 0.0015175492640546694, 0.0015369930627698802, 0.0015339123070886244, 0.0015418261232576808, 0.001565745285693176, 0.00156271312271758, 0.0015430894076862202, 0.001533965877143248, 0.0015375833882361042, 0.0015393362442335608, 0.0015433355928303636, 0.0015410856339054145, 0.001561695916521154, 0.001558670999805386, 0.0015451305911743215, 0.001546947877112852, 0.001527697468005425, 0.001531714224256575, 0.0015433197342125432, 0.0015906455940852056, 0.0015615770612292144, 0.0015686922041433199, 0.001551211714193377, 0.0015609751441230883, 0.001557040959596634, 0.0015599471017984407, 0.0015734542251507543, 0.0015829052652555462, 0.00156655408232948, 0.0017646274895274214, 0.0015490394494287213, 0.0015282554917835764, 0.0015372266750592663, 0.0015555055507895897, 0.0015770250014314543, 0.0015395432235483005, 0.0015324126520403186, 0.004198361573056603, 0.0015822025514873011, 0.001587930734136275, 0.0015856638783589005, 0.0016242305116195763, 0.00158213485716557, 0.0015778224487617916, 0.0015759175305958002, 0.001578937408191209, 0.0015767798996625506, 0.0015895220009153898, 0.0016074898172816147, 0.0015870663266134809, 0.001586104838215575, 0.0015797780812432875, 0.0015785087978619399, 0.001582763243314563, 0.0016051696527901354, 0.00162453651048091, 0.0015941385716694047, 0.0017297809173790167, 0.0015869713459658076, 0.0015886299982096773, 0.0015844751828901318, 0.0016284696520211138, 0.0016180480597540736, 0.001600334715402248, 0.002004793101484526, 0.0014598168127122335, 0.0014505164581350982, 0.0014468625425555122, 0.0014472067074772592, 0.0014703996251531255, 0.0014420290196236845, 0.0014422066039211738, 0.0014605665831671406, 0.0014506706259756659, 0.0014797857099135097, 0.0014537358122955386, 0.0027217542713818452, 0.0014753675617005986, 0.0014668892302627985, 0.001472862563484038, 0.0015076302079251036, 0.001497036311775446, 0.00148781991689854, 0.0014794473754591309, 0.0014728019159520045, 0.0014812943967020449, 0.0014866713318042457, 0.0015229082079410243, 0.001513462271153306, 0.001483471334116378, 0.0014561934149242006, 0.0014762882298479478, 0.0014744825408949207, 0.001483275353772721, 0.0015254750420960288, 0.0014816201874054968, 0.001482549790428796, 0.0014457014985964634, 0.001458475230416904, 0.0014538073761893127, 0.0014659288741919834, 0.0014811867295065895, 0.0015877693537428665, 0.0014618146888096817, 0.0014938028762117028, 0.001481225748041955, 0.0014771982290161152, 0.0014914543135091662, 0.0014785938741018374, 0.0015064664791376952, 0.0015097785847804819, 0.0014971435618159983, 0.004120305478863884, 0.0014663834178160566, 0.0014825446463267629, 0.001479531332734041, 0.001529815648003326, 0.001502501625509467, 0.0014886517310515046, 0.0014943325416728233, 0.0014910822501406074, 0.0014973087915374588, 0.0014992556874252234, 0.0015025943745664942, 0.0014929146661112707, 0.0014948212289406608, 0.0015025129371982378, 0.0015023146455253784, 0.0014995395225317527, 0.0015012663328282845, 0.001488028833894835, 0.001499418727083442, 0.001493421041232068, 0.0014938056677541074, 0.0014947848952336547, 0.0014922546664214071, 0.0015126054786378518, 0.0014887833943551716, 0.0014924398346920498, 0.001493547480398168, 0.0014899816669640131, 0.0014984201649591948, 0.0015058331458324876, 0.001494013083477815, 0.001490815188541698, 0.0014881856477586553, 0.0014962429777369834, 0.0014915858967772995, 0.0014929003543026436, 0.0014865501871099696, 0.0014813415206541929, 0.0014808488752654132, 0.0014911449179635383, 0.001508277625058933, 0.0014942005849055324, 0.0015008156236338739, 0.001488499188174804, 0.0014973476257485647, 0.0014915646461304277, 0.0015035755204735324, 0.0014989318345518161, 0.0014987725832421954, 0.0014955840839926775, 0.0014924382703611627, 0.0014857849794983242, 0.0015024291448450338, 0.0014918872281365718, 0.001494720250775572, 0.0014976607708376832, 0.0015054991041931014, 0.0014853419803936656, 0.00149452056454417, 0.0015125296025265318, 0.001502949082350824, 0.0014940992477932014, 0.001500486063984378, 0.00150868787507837, 0.0014909435000542242, 0.0014912091040362914, 0.001503202647048359, 0.0014880705421091989, 0.0014950759359635413, 0.001486505791641927, 0.0014861929181885596, 0.001493037185961536, 0.0015106489178530562, 0.001491372332869408, 0.0015020884190259192]
[628.226762331018, 587.1492373801539, 602.9046592434655, 601.8965544456737, 604.2755678306586, 608.5285148114042, 608.2800800110232, 609.0317314025378, 580.9238823253593, 605.0460369969832, 608.9421789250731, 567.0118830583773, 607.0370913072842, 606.1048364756487, 606.948288954524, 606.8531551545884, 554.3968722226354, 604.6750513692183, 603.0714755508039, 604.9054270323295, 602.2093558659392, 633.1100021955882, 635.3675691839543, 636.417979619939, 636.976772787685, 631.0132103368867, 628.9711503212014, 623.5975578198203, 633.0404702495823, 626.7418944447294, 629.4402355097936, 631.3570158391748, 627.9744203844541, 587.9880777835516, 594.4729206942651, 594.7346083076955, 592.6105379168403, 595.2668672964116, 593.1558671684774, 591.6079560998395, 593.5623637728324, 595.1687820554778, 593.7805056712, 589.9927359007465, 591.6455090741789, 593.185063909994, 592.1160493383248, 589.2505591777135, 590.9324144352066, 591.9168823397054, 589.2949640714032, 591.4399325519244, 587.6216700070606, 587.9664529387005, 590.0244490577596, 589.2456129734395, 590.7721109188635, 585.305052137177, 582.3545550095013, 580.045415386851, 590.4894683863124, 590.1695625518593, 626.4297378794034, 629.0893773936733, 624.0507028547802, 630.5654404421755, 623.096059812715, 631.2344711204731, 624.0027578905168, 630.3399274571176, 637.6482819763226, 629.6892174053876, 658.9571908381719, 650.6210237526107, 651.9277506143793, 648.5815650127449, 638.6734861266319, 639.9127168401748, 648.0505893041197, 651.9049836117156, 650.3712303676662, 649.630646810309, 647.9472155282014, 648.8932074889331, 640.3295221694681, 641.5722112779791, 647.1944868038537, 646.4341913486776, 654.5798634500643, 652.8632979728022, 647.9538736088512, 628.6755539502242, 640.3782591509367, 637.473684996166, 644.6573287515401, 640.6251910960259, 642.2438625243741, 641.0473783675833, 635.5443863670002, 631.7497464629122, 638.343745217523, 566.6918405922637, 645.5613511772056, 654.3408516287634, 650.5221488961256, 642.8778087563817, 634.1053560294271, 649.5433091480376, 652.565742437951, 238.18815568854242, 632.0303295301734, 629.7503905571367, 630.6506780207168, 615.6761573225622, 632.057372019173, 633.7848728066696, 634.5509714724313, 633.337328517395, 634.203924221771, 629.1199489054634, 622.0879219571509, 630.09338880866, 630.4753481018544, 633.0003004048509, 633.5092977337098, 631.8064336052167, 622.9871080989985, 615.5601881203464, 627.298039061175, 578.1078921342312, 630.1311000618065, 629.4731945934298, 631.1238009900345, 614.073463855398, 618.0286141512938, 624.8692791424246, 498.80458949081157, 685.0174564999513, 689.4096198575239, 691.1506591592012, 690.9862943789, 680.087224516166, 693.4673202769266, 693.3819310500513, 684.665808135612, 689.3363538862849, 675.7735213286037, 687.8828956005, 367.4100966845534, 677.7971984468325, 681.7147330346453, 678.9499745546608, 663.2926262311124, 667.9864690883992, 672.1243536546862, 675.9280638080558, 678.9779325847834, 675.0852512683507, 672.64362916475, 656.638394084173, 660.7366559841419, 674.0945894958224, 686.7219627222755, 677.374498950653, 678.2040290508027, 674.1836554194022, 655.5335042558172, 674.9368080298134, 674.513602481284, 691.7057227725325, 685.6475716177579, 687.8490344581809, 682.1613364776636, 675.1343230931582, 629.8143981949827, 684.0812365993356, 669.4323701772544, 675.116538665297, 676.9572155972918, 670.486511683453, 676.318235531338, 663.8050124901566, 662.3487775496548, 667.9386169132803, 242.7004514907317, 681.9498828548811, 674.5159428943047, 675.8897076901304, 653.6735333470886, 665.5566842804053, 671.7487906279148, 669.1950901909389, 670.6538153114633, 667.8649091301903, 666.9976364854549, 665.5156021654246, 669.8306491989862, 668.9763167925256, 665.5516736279939, 665.6395203085352, 666.8713861650318, 666.104326815927, 672.0299884126264, 666.9251103360072, 669.6035293402608, 669.4311191786214, 668.9925775866813, 670.1269042757368, 661.1109202781224, 671.6893832854204, 670.0437610648071, 669.5468427514656, 671.149197451268, 667.3695558730233, 664.0842000108572, 669.3381812106796, 670.773954871087, 671.9591749228949, 668.3406471270234, 670.4273633590842, 669.8370705840681, 672.698445482099, 675.0637756770485, 675.2883543371497, 670.6256299794815, 663.007912724905, 669.2541885621218, 666.3043642754291, 671.8176321118447, 667.8475878305633, 670.4369150839718, 665.0813254029717, 667.1417451741573, 667.212631977005, 668.6350909340756, 670.0444633854136, 673.0448980158961, 665.5887922775512, 670.2919504505987, 669.021510534246, 667.7079479358148, 664.2315476739972, 673.2456317803435, 669.1108999928689, 661.1440849353285, 665.3585352578008, 669.2995806516933, 666.4507082089176, 662.8276242679117, 670.7162276529131, 670.5967642587991, 665.2463005993026, 672.0111524972431, 668.8623473532958, 672.7185360612993, 672.8601568219327, 669.7756823491216, 661.9671772718749, 670.5233682832206, 665.7397709307182]
Elapsed: 0.07680616798058439~0.01242719671579441
Time per graph: 0.0015821520173947157~0.00025212970264488436
Speed: 639.5709123315742~50.861982079630614
Total Time: 0.0730
best val loss: 0.3048434257507324 test_score: 0.8958

Testing...
Test loss: 0.6860 score: 0.9167 time: 0.07s
test Score 0.9167
Epoch Time List: [0.2700401711044833, 0.2617023950442672, 0.26317456318065524, 0.26385300303809345, 0.2621102900011465, 0.2625041489955038, 0.26167037803679705, 0.2615297739394009, 0.2735748258419335, 0.26466484798584133, 0.2615814749151468, 0.2794500798918307, 0.26244941109325737, 0.26298592099919915, 0.26183182292152196, 0.2636142171686515, 0.28063371195457876, 0.2664966029115021, 0.2640956579707563, 0.2637350030709058, 0.2647739560343325, 0.25815458898432553, 0.25694242608733475, 0.2539452649652958, 0.2552071699174121, 0.25679801707156, 0.25712122896220535, 0.25784410315100104, 0.25636984512675554, 0.25757800589781255, 0.25761660910211504, 0.2559020161861554, 0.2568856200668961, 0.27070278802420944, 0.26985299901571125, 0.2709582431707531, 0.26977210806217045, 0.2693900018930435, 0.2691405931254849, 0.2700407721567899, 0.2711341209942475, 0.2700587750878185, 0.2702789169270545, 0.2714692479930818, 0.27252188499551266, 0.2700457989703864, 0.2720533849205822, 0.2717806580476463, 0.271514326101169, 0.2732513638911769, 0.2731949791777879, 0.2722191899083555, 0.27272861602250487, 0.27172798092942685, 0.27142982895020396, 0.2742327079176903, 0.27122031594626606, 0.2735692020505667, 0.2729600890306756, 0.2752383800689131, 0.27236519986763597, 0.2734396312152967, 0.2666901859920472, 0.2577300239354372, 0.25805654912255704, 0.2582491639768705, 0.25778018799610436, 0.2574176910566166, 0.25708865001797676, 0.2578935669735074, 0.2523410849971697, 0.2528001399477944, 0.36134089913684875, 0.25043424090836197, 0.2501501579536125, 0.2489588458556682, 0.2525709989713505, 0.2539430499309674, 0.25037521694321185, 0.3590739999199286, 0.2482403399189934, 0.24808924400713295, 0.24873658909928054, 0.24900180590339005, 0.2521285960683599, 0.25510963588021696, 0.2509048630017787, 0.36779309797566384, 0.2502971620997414, 0.24931477499194443, 0.24990070995409042, 0.255124271963723, 0.2560840619262308, 0.2533539419528097, 0.34962567884940654, 0.2523592980578542, 0.25301542901434004, 0.25306818110402673, 0.25556522398255765, 0.25767744483891875, 0.2554030630271882, 0.26136157696601003, 0.3512723660096526, 0.24887304997537285, 0.24933615396730602, 0.24884395499248058, 0.251426086993888, 0.2555793699575588, 0.24982917797751725, 0.3792236199369654, 0.25673203507903963, 0.25728075101505965, 0.2589027239009738, 0.2617415830027312, 0.2583588339621201, 0.2546552689746022, 0.3469538699137047, 0.256243493873626, 0.2580781269352883, 0.2572821278590709, 0.26097255991771817, 0.2613416409585625, 0.25859386392403394, 0.3378381779184565, 0.2591766439145431, 0.25901453709229827, 0.26206376624759287, 0.2652928769821301, 0.26176412298809737, 0.26256444805767387, 0.3566622310318053, 0.25531340087763965, 0.25715445703826845, 0.2583212699973956, 0.2654841060284525, 0.2609533100621775, 0.32417216803878546, 0.2471970849437639, 0.24576694797724485, 0.247856747941114, 0.24571685318369418, 0.3425017310073599, 0.24586485396139324, 0.2457907450152561, 0.24733311496675014, 0.2487296819454059, 0.25375656713731587, 0.24853952578268945, 0.30721961497329175, 0.2546380809508264, 0.250573487021029, 0.25077659299131483, 0.25282658310607076, 0.25743674917612225, 0.2529597309185192, 0.36463982495479286, 0.2514543338911608, 0.25098730088211596, 0.25300645898096263, 0.2551990848733112, 0.2573429500916973, 0.2522091509308666, 0.35502394405193627, 0.25146834715269506, 0.252154458896257, 0.2523299999302253, 0.2560032521141693, 0.25642626208718866, 0.2525852139806375, 0.3489410011097789, 0.24625341303180903, 0.24699382192920893, 0.24820824095513672, 0.24899342993739992, 0.2603890021564439, 0.251572075067088, 0.24888046900741756, 0.36730180913582444, 0.24992708605714142, 0.2520650728838518, 0.25194767699576914, 0.25384362100157887, 0.2639900860376656, 0.2562551508890465, 0.381707021035254, 0.2496439729584381, 0.25043571786955, 0.2509819489205256, 0.2565531579311937, 0.25632805295754224, 0.25438310601748526, 0.25527805485762656, 0.2559040979249403, 0.25565117108635604, 0.2567363630514592, 0.2567622800124809, 0.2560802490916103, 0.2562044048681855, 0.25649222801439464, 0.2553169830935076, 0.2565026031807065, 0.2557727991370484, 0.256468218867667, 0.2553556920029223, 0.25496421102434397, 0.25630416395142674, 0.25633497908711433, 0.2551652849651873, 0.2564776010112837, 0.25595287105534226, 0.2558924269396812, 0.2556285980390385, 0.2566179229179397, 0.25675465597305447, 0.2559696020325646, 0.25671184388920665, 0.2549139579059556, 0.25539024686440825, 0.2542692219140008, 0.2580382761079818, 0.2552660909714177, 0.25520833709742874, 0.2552893490064889, 0.2548033162020147, 0.25585946906358004, 0.25802401395048946, 0.256150086177513, 0.2547826860100031, 0.25600147689692676, 0.25633290701080114, 0.25750684505328536, 0.2583983208751306, 0.2573087160708383, 0.25678522512316704, 0.2566120130941272, 0.25603981188032776, 0.2562174570048228, 0.25652452011127025, 0.25737325311638415, 0.2586714649805799, 0.25789273099508137, 0.25802872399799526, 0.2557089689653367, 0.2565814519766718, 0.2579624169738963, 0.25729963404592127, 0.2579310310538858, 0.2568488731049001, 0.25787692703306675, 0.25619424891192466, 0.25751616805791855, 0.2561943639302626, 0.25641832686960697, 0.25714188313577324, 0.2558490199735388, 0.2551684291101992, 0.2583911068504676, 0.2571676099905744, 0.2567680600332096, 0.25794501102063805]
Total Epoch List: [21, 116, 123]
Total Time List: [0.0816929730353877, 0.09885171195492148, 0.07301427703350782]
T-times Epoch Time: 0.2710387382376559 ~ 0.0049803013755338535
T-times Total Epoch: 99.8888888888889 ~ 15.30028644934789
T-times Total Time: 0.07906441646628082 ~ 0.0038639238896739114
T-times Inference Elapsed: 0.07837429815000128 ~ 0.0013076800013883836
T-times Time Per Graph: 0.0016126040356009162 ~ 2.695405558395438e-05
T-times Speed: 630.3587852347955 ~ 10.209706337958355
T-times cross validation test micro f1 score:0.7955116552971008 ~ 0.05982643320475761
T-times cross validation test precision:0.8022654249362323 ~ 0.13826448691375887
T-times cross validation test recall:0.8105555555555556 ~ 0.14376120460895317
T-times cross validation test f1_score:0.7955116552971008 ~ 0.12809548792137126
