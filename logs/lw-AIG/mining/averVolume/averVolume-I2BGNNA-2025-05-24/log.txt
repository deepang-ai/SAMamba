Namespace(seed=15, model='I2BGNNA', dataset='mining/averVolume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/mining/averVolume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 436], edge_attr=[436, 2], x=[115, 14887], y=[1, 1], num_nodes=115)
Data(edge_index=[2, 436], edge_attr=[436, 2], x=[115, 14887], y=[1, 1], num_nodes=115)
Data(edge_index=[2, 382], edge_attr=[382, 2], x=[103, 14887], y=[1, 1], num_nodes=115)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce1076d0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6936;  Loss pred: 0.6936; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6937;  Loss pred: 0.6937; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6904;  Loss pred: 0.6904; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6875;  Loss pred: 0.6875; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6850;  Loss pred: 0.6850; Loss self: 0.0000; time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6843;  Loss pred: 0.6843; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6819;  Loss pred: 0.6819; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6766;  Loss pred: 0.6766; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.07s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6723;  Loss pred: 0.6723; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6698;  Loss pred: 0.6698; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6683;  Loss pred: 0.6683; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6590;  Loss pred: 0.6590; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6579;  Loss pred: 0.6579; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6499;  Loss pred: 0.6499; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6490;  Loss pred: 0.6490; Loss self: 0.0000; time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6389;  Loss pred: 0.6389; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6325;  Loss pred: 0.6325; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6327;  Loss pred: 0.6327; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6302;  Loss pred: 0.6302; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6204;  Loss pred: 0.6204; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.06s
Epoch 24/1000, LR 0.000270
Train loss: 0.6078;  Loss pred: 0.6078; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6024;  Loss pred: 0.6024; Loss self: 0.0000; time: 0.07s
Val loss: 0.6922 score: 0.5116 time: 0.05s
Test loss: 0.6921 score: 0.5455 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5894;  Loss pred: 0.5894; Loss self: 0.0000; time: 0.07s
Val loss: 0.6921 score: 0.6047 time: 0.05s
Test loss: 0.6919 score: 0.6364 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5859;  Loss pred: 0.5859; Loss self: 0.0000; time: 0.07s
Val loss: 0.6918 score: 0.7442 time: 0.05s
Test loss: 0.6916 score: 0.7045 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5787;  Loss pred: 0.5787; Loss self: 0.0000; time: 0.19s
Val loss: 0.6916 score: 0.7442 time: 0.05s
Test loss: 0.6914 score: 0.7500 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5709;  Loss pred: 0.5709; Loss self: 0.0000; time: 0.07s
Val loss: 0.6913 score: 0.7674 time: 0.05s
Test loss: 0.6911 score: 0.8409 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5561;  Loss pred: 0.5561; Loss self: 0.0000; time: 0.07s
Val loss: 0.6909 score: 0.8372 time: 0.05s
Test loss: 0.6907 score: 0.7955 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5556;  Loss pred: 0.5556; Loss self: 0.0000; time: 0.07s
Val loss: 0.6905 score: 0.7442 time: 0.05s
Test loss: 0.6903 score: 0.7273 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5352;  Loss pred: 0.5352; Loss self: 0.0000; time: 0.07s
Val loss: 0.6900 score: 0.7442 time: 0.05s
Test loss: 0.6899 score: 0.7273 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5247;  Loss pred: 0.5247; Loss self: 0.0000; time: 0.07s
Val loss: 0.6894 score: 0.7674 time: 0.05s
Test loss: 0.6894 score: 0.7273 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5155;  Loss pred: 0.5155; Loss self: 0.0000; time: 0.07s
Val loss: 0.6889 score: 0.7209 time: 0.06s
Test loss: 0.6888 score: 0.6818 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5118;  Loss pred: 0.5118; Loss self: 0.0000; time: 0.07s
Val loss: 0.6882 score: 0.7442 time: 0.05s
Test loss: 0.6882 score: 0.6591 time: 0.06s
Epoch 36/1000, LR 0.000270
Train loss: 0.5039;  Loss pred: 0.5039; Loss self: 0.0000; time: 0.08s
Val loss: 0.6874 score: 0.7442 time: 0.05s
Test loss: 0.6875 score: 0.6591 time: 0.06s
Epoch 37/1000, LR 0.000270
Train loss: 0.4904;  Loss pred: 0.4904; Loss self: 0.0000; time: 0.07s
Val loss: 0.6866 score: 0.7442 time: 0.05s
Test loss: 0.6867 score: 0.6591 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4768;  Loss pred: 0.4768; Loss self: 0.0000; time: 0.07s
Val loss: 0.6855 score: 0.6977 time: 0.05s
Test loss: 0.6857 score: 0.6591 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4628;  Loss pred: 0.4628; Loss self: 0.0000; time: 0.21s
Val loss: 0.6843 score: 0.7209 time: 0.06s
Test loss: 0.6846 score: 0.6591 time: 0.06s
Epoch 40/1000, LR 0.000269
Train loss: 0.4580;  Loss pred: 0.4580; Loss self: 0.0000; time: 0.07s
Val loss: 0.6829 score: 0.6977 time: 0.05s
Test loss: 0.6835 score: 0.6591 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4447;  Loss pred: 0.4447; Loss self: 0.0000; time: 0.07s
Val loss: 0.6815 score: 0.6744 time: 0.05s
Test loss: 0.6822 score: 0.6591 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4298;  Loss pred: 0.4298; Loss self: 0.0000; time: 0.07s
Val loss: 0.6799 score: 0.6977 time: 0.05s
Test loss: 0.6809 score: 0.6591 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4092;  Loss pred: 0.4092; Loss self: 0.0000; time: 0.07s
Val loss: 0.6782 score: 0.6977 time: 0.05s
Test loss: 0.6794 score: 0.6818 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3984;  Loss pred: 0.3984; Loss self: 0.0000; time: 0.08s
Val loss: 0.6763 score: 0.6977 time: 0.05s
Test loss: 0.6778 score: 0.6818 time: 0.06s
Epoch 45/1000, LR 0.000269
Train loss: 0.3870;  Loss pred: 0.3870; Loss self: 0.0000; time: 0.08s
Val loss: 0.6741 score: 0.7209 time: 0.05s
Test loss: 0.6761 score: 0.6818 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3801;  Loss pred: 0.3801; Loss self: 0.0000; time: 0.08s
Val loss: 0.6718 score: 0.7209 time: 0.05s
Test loss: 0.6741 score: 0.6818 time: 0.06s
Epoch 47/1000, LR 0.000269
Train loss: 0.3648;  Loss pred: 0.3648; Loss self: 0.0000; time: 0.07s
Val loss: 0.6691 score: 0.7209 time: 0.05s
Test loss: 0.6718 score: 0.6818 time: 0.06s
Epoch 48/1000, LR 0.000269
Train loss: 0.3476;  Loss pred: 0.3476; Loss self: 0.0000; time: 0.09s
Val loss: 0.6662 score: 0.7209 time: 0.10s
Test loss: 0.6694 score: 0.6818 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3397;  Loss pred: 0.3397; Loss self: 0.0000; time: 0.07s
Val loss: 0.6629 score: 0.7209 time: 0.05s
Test loss: 0.6665 score: 0.7045 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3240;  Loss pred: 0.3240; Loss self: 0.0000; time: 0.07s
Val loss: 0.6593 score: 0.7209 time: 0.05s
Test loss: 0.6634 score: 0.7045 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3139;  Loss pred: 0.3139; Loss self: 0.0000; time: 0.07s
Val loss: 0.6554 score: 0.7442 time: 0.05s
Test loss: 0.6601 score: 0.7045 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2952;  Loss pred: 0.2952; Loss self: 0.0000; time: 0.07s
Val loss: 0.6511 score: 0.7674 time: 0.05s
Test loss: 0.6563 score: 0.7045 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2841;  Loss pred: 0.2841; Loss self: 0.0000; time: 0.07s
Val loss: 0.6463 score: 0.7674 time: 0.05s
Test loss: 0.6521 score: 0.7045 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2655;  Loss pred: 0.2655; Loss self: 0.0000; time: 0.08s
Val loss: 0.6409 score: 0.7674 time: 0.05s
Test loss: 0.6475 score: 0.7045 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2507;  Loss pred: 0.2507; Loss self: 0.0000; time: 0.07s
Val loss: 0.6352 score: 0.7674 time: 0.05s
Test loss: 0.6427 score: 0.7273 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2504;  Loss pred: 0.2504; Loss self: 0.0000; time: 0.07s
Val loss: 0.6292 score: 0.7674 time: 0.05s
Test loss: 0.6376 score: 0.7273 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2275;  Loss pred: 0.2275; Loss self: 0.0000; time: 0.07s
Val loss: 0.6230 score: 0.7674 time: 0.05s
Test loss: 0.6324 score: 0.7273 time: 0.06s
Epoch 58/1000, LR 0.000269
Train loss: 0.2241;  Loss pred: 0.2241; Loss self: 0.0000; time: 0.07s
Val loss: 0.6163 score: 0.7674 time: 0.05s
Test loss: 0.6268 score: 0.7273 time: 0.06s
Epoch 59/1000, LR 0.000268
Train loss: 0.2096;  Loss pred: 0.2096; Loss self: 0.0000; time: 0.19s
Val loss: 0.6092 score: 0.7674 time: 0.05s
Test loss: 0.6210 score: 0.7273 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1944;  Loss pred: 0.1944; Loss self: 0.0000; time: 0.07s
Val loss: 0.6019 score: 0.7674 time: 0.05s
Test loss: 0.6150 score: 0.7273 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1790;  Loss pred: 0.1790; Loss self: 0.0000; time: 0.07s
Val loss: 0.5945 score: 0.7674 time: 0.05s
Test loss: 0.6091 score: 0.7273 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1661;  Loss pred: 0.1661; Loss self: 0.0000; time: 0.07s
Val loss: 0.5869 score: 0.7674 time: 0.05s
Test loss: 0.6029 score: 0.7273 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1631;  Loss pred: 0.1631; Loss self: 0.0000; time: 0.07s
Val loss: 0.5786 score: 0.7674 time: 0.05s
Test loss: 0.5963 score: 0.7273 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1494;  Loss pred: 0.1494; Loss self: 0.0000; time: 0.07s
Val loss: 0.5701 score: 0.7674 time: 0.05s
Test loss: 0.5893 score: 0.7273 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1351;  Loss pred: 0.1351; Loss self: 0.0000; time: 0.07s
Val loss: 0.5609 score: 0.7674 time: 0.05s
Test loss: 0.5819 score: 0.7273 time: 0.06s
Epoch 66/1000, LR 0.000268
Train loss: 0.1254;  Loss pred: 0.1254; Loss self: 0.0000; time: 0.07s
Val loss: 0.5517 score: 0.7907 time: 0.05s
Test loss: 0.5744 score: 0.7273 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1179;  Loss pred: 0.1179; Loss self: 0.0000; time: 0.07s
Val loss: 0.5422 score: 0.8140 time: 0.04s
Test loss: 0.5670 score: 0.7273 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1096;  Loss pred: 0.1096; Loss self: 0.0000; time: 0.07s
Val loss: 0.5329 score: 0.8140 time: 0.05s
Test loss: 0.5598 score: 0.7273 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1017;  Loss pred: 0.1017; Loss self: 0.0000; time: 0.07s
Val loss: 0.5240 score: 0.7907 time: 0.05s
Test loss: 0.5534 score: 0.7273 time: 0.19s
Epoch 70/1000, LR 0.000268
Train loss: 0.0951;  Loss pred: 0.0951; Loss self: 0.0000; time: 0.07s
Val loss: 0.5148 score: 0.7907 time: 0.05s
Test loss: 0.5469 score: 0.7273 time: 0.06s
Epoch 71/1000, LR 0.000268
Train loss: 0.0852;  Loss pred: 0.0852; Loss self: 0.0000; time: 0.07s
Val loss: 0.5058 score: 0.7907 time: 0.05s
Test loss: 0.5407 score: 0.7273 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.0784;  Loss pred: 0.0784; Loss self: 0.0000; time: 0.07s
Val loss: 0.4966 score: 0.7907 time: 0.05s
Test loss: 0.5346 score: 0.7273 time: 0.06s
Epoch 73/1000, LR 0.000267
Train loss: 0.0751;  Loss pred: 0.0751; Loss self: 0.0000; time: 0.07s
Val loss: 0.4872 score: 0.7907 time: 0.05s
Test loss: 0.5285 score: 0.7273 time: 0.06s
Epoch 74/1000, LR 0.000267
Train loss: 0.0639;  Loss pred: 0.0639; Loss self: 0.0000; time: 0.07s
Val loss: 0.4774 score: 0.7907 time: 0.05s
Test loss: 0.5221 score: 0.7273 time: 0.06s
Epoch 75/1000, LR 0.000267
Train loss: 0.0614;  Loss pred: 0.0614; Loss self: 0.0000; time: 0.08s
Val loss: 0.4663 score: 0.8140 time: 0.05s
Test loss: 0.5149 score: 0.7273 time: 0.06s
Epoch 76/1000, LR 0.000267
Train loss: 0.0540;  Loss pred: 0.0540; Loss self: 0.0000; time: 0.07s
Val loss: 0.4552 score: 0.7907 time: 0.05s
Test loss: 0.5079 score: 0.7273 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0504;  Loss pred: 0.0504; Loss self: 0.0000; time: 0.07s
Val loss: 0.4447 score: 0.8372 time: 0.05s
Test loss: 0.5018 score: 0.7273 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0473;  Loss pred: 0.0473; Loss self: 0.0000; time: 0.07s
Val loss: 0.4347 score: 0.8372 time: 0.05s
Test loss: 0.4963 score: 0.7273 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0433;  Loss pred: 0.0433; Loss self: 0.0000; time: 0.07s
Val loss: 0.4238 score: 0.8605 time: 0.05s
Test loss: 0.4901 score: 0.7273 time: 0.19s
Epoch 80/1000, LR 0.000267
Train loss: 0.0378;  Loss pred: 0.0378; Loss self: 0.0000; time: 0.07s
Val loss: 0.4148 score: 0.8837 time: 0.05s
Test loss: 0.4862 score: 0.7273 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0361;  Loss pred: 0.0361; Loss self: 0.0000; time: 0.07s
Val loss: 0.4037 score: 0.9070 time: 0.05s
Test loss: 0.4800 score: 0.7273 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0333;  Loss pred: 0.0333; Loss self: 0.0000; time: 0.07s
Val loss: 0.3931 score: 0.9070 time: 0.05s
Test loss: 0.4744 score: 0.7273 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0288;  Loss pred: 0.0288; Loss self: 0.0000; time: 0.07s
Val loss: 0.3829 score: 0.9070 time: 0.05s
Test loss: 0.4692 score: 0.7273 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0267;  Loss pred: 0.0267; Loss self: 0.0000; time: 0.07s
Val loss: 0.3723 score: 0.8837 time: 0.05s
Test loss: 0.4635 score: 0.7273 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0272;  Loss pred: 0.0272; Loss self: 0.0000; time: 0.07s
Val loss: 0.3605 score: 0.8837 time: 0.05s
Test loss: 0.4560 score: 0.7500 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0242;  Loss pred: 0.0242; Loss self: 0.0000; time: 0.07s
Val loss: 0.3514 score: 0.8837 time: 0.05s
Test loss: 0.4513 score: 0.7500 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0207;  Loss pred: 0.0207; Loss self: 0.0000; time: 0.07s
Val loss: 0.3435 score: 0.8837 time: 0.05s
Test loss: 0.4480 score: 0.7500 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.07s
Val loss: 0.3370 score: 0.8837 time: 0.05s
Test loss: 0.4467 score: 0.7500 time: 0.06s
Epoch 89/1000, LR 0.000266
Train loss: 0.0220;  Loss pred: 0.0220; Loss self: 0.0000; time: 0.20s
Val loss: 0.3330 score: 0.8837 time: 0.05s
Test loss: 0.4490 score: 0.7500 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0172;  Loss pred: 0.0172; Loss self: 0.0000; time: 0.07s
Val loss: 0.3323 score: 0.8837 time: 0.05s
Test loss: 0.4569 score: 0.7500 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0140;  Loss pred: 0.0140; Loss self: 0.0000; time: 0.07s
Val loss: 0.3335 score: 0.8837 time: 0.05s
Test loss: 0.4674 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.07s
Val loss: 0.3305 score: 0.8837 time: 0.05s
Test loss: 0.4712 score: 0.7273 time: 0.06s
Epoch 93/1000, LR 0.000265
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.07s
Val loss: 0.3289 score: 0.8837 time: 0.05s
Test loss: 0.4767 score: 0.7273 time: 0.06s
Epoch 94/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.07s
Val loss: 0.3283 score: 0.8837 time: 0.05s
Test loss: 0.4835 score: 0.7273 time: 0.06s
Epoch 95/1000, LR 0.000265
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.07s
Val loss: 0.3301 score: 0.8837 time: 0.05s
Test loss: 0.4941 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.08s
Val loss: 0.3329 score: 0.8837 time: 0.05s
Test loss: 0.5063 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.07s
Val loss: 0.3366 score: 0.8837 time: 0.05s
Test loss: 0.5201 score: 0.7273 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.07s
Val loss: 0.3339 score: 0.8837 time: 0.05s
Test loss: 0.5225 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.07s
Val loss: 0.3334 score: 0.8837 time: 0.05s
Test loss: 0.5280 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.22s
Val loss: 0.3337 score: 0.8837 time: 0.06s
Test loss: 0.5347 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.07s
Val loss: 0.3329 score: 0.8837 time: 0.05s
Test loss: 0.5381 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.07s
Val loss: 0.3320 score: 0.8837 time: 0.05s
Test loss: 0.5404 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.07s
Val loss: 0.3318 score: 0.8837 time: 0.05s
Test loss: 0.5430 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.07s
Val loss: 0.3304 score: 0.8837 time: 0.05s
Test loss: 0.5409 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.07s
Val loss: 0.3305 score: 0.8837 time: 0.05s
Test loss: 0.5412 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.07s
Val loss: 0.3315 score: 0.8837 time: 0.05s
Test loss: 0.5429 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.07s
Val loss: 0.3319 score: 0.8605 time: 0.05s
Test loss: 0.5407 score: 0.7727 time: 0.06s
     INFO: Early stopping counter 13 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.07s
Val loss: 0.3325 score: 0.8605 time: 0.05s
Test loss: 0.5368 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.07s
Val loss: 0.3341 score: 0.8605 time: 0.05s
Test loss: 0.5324 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.3366 score: 0.8605 time: 0.05s
Test loss: 0.5277 score: 0.7727 time: 0.06s
     INFO: Early stopping counter 16 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.3404 score: 0.8605 time: 0.05s
Test loss: 0.5275 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.07s
Val loss: 0.3440 score: 0.8605 time: 0.05s
Test loss: 0.5288 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.07s
Val loss: 0.3478 score: 0.8605 time: 0.05s
Test loss: 0.5319 score: 0.7955 time: 0.06s
     INFO: Early stopping counter 19 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.07s
Val loss: 0.3513 score: 0.8605 time: 0.05s
Test loss: 0.5374 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 093,   Train_Loss: 0.0111,   Val_Loss: 0.3283,   Val_Precision: 0.8696,   Val_Recall: 0.9091,   Val_accuracy: 0.8889,   Val_Score: 0.8837,   Val_Loss: 0.3283,   Test_Precision: 0.6667,   Test_Recall: 0.9091,   Test_accuracy: 0.7692,   Test_Score: 0.7273,   Test_loss: 0.4835


[0.06074426101986319, 0.059028086019679904, 0.05874600599054247, 0.06079551507718861, 0.06321562407538295, 0.06270843907259405, 0.06536631390918046, 0.06283698603510857, 0.06271927093621343, 0.06306841899640858, 0.07520813902374357, 0.05976025993004441, 0.06243361404631287, 0.05957525398116559, 0.059525432996451855, 0.059973533032462, 0.05800680606625974, 0.056894168024882674, 0.05510518199298531, 0.05449301900807768, 0.05515331099741161, 0.05549279798287898, 0.06334471795707941, 0.05661569791845977, 0.055145860998891294, 0.05496636999305338, 0.05719642201438546, 0.05918717698659748, 0.05913324898574501, 0.05909340491052717, 0.05927100498229265, 0.059538622037507594, 0.059240264003165066, 0.05963940196670592, 0.06032122194301337, 0.0626551799941808, 0.05608038103673607, 0.055358786950819194, 0.06604191299993545, 0.05650275596417487, 0.05742081208154559, 0.057418336044065654, 0.058398799039423466, 0.061070100986398757, 0.05906275298912078, 0.061187247978523374, 0.06133498402778059, 0.05932216008659452, 0.0595215029316023, 0.0594805390574038, 0.05977310996968299, 0.059653901029378176, 0.05981613998301327, 0.059609813964925706, 0.0589029339607805, 0.05933281499892473, 0.05992406199220568, 0.06144561502151191, 0.059153751004487276, 0.05911252205260098, 0.059136906056664884, 0.05914165894500911, 0.059589818003587425, 0.05873132194392383, 0.06986286002211273, 0.0588657520711422, 0.05314820702187717, 0.055647752014920115, 0.1930290349991992, 0.060329369036480784, 0.060372709995135665, 0.060540712089277804, 0.06010044598951936, 0.06088265299331397, 0.060538665973581374, 0.05823659198358655, 0.05594830203335732, 0.055836500017903745, 0.1920686640078202, 0.05938835896085948, 0.05949453799985349, 0.059269950026646256, 0.0596458240179345, 0.05953155003953725, 0.059728470048867166, 0.059596647042781115, 0.05962085200008005, 0.06127785798162222, 0.05942752293776721, 0.059349951916374266, 0.05943524499889463, 0.05986315000336617, 0.06029568798840046, 0.06033212994225323, 0.05627713992726058, 0.05973769898992032, 0.05985945393331349, 0.05583558394573629, 0.06282017903868109, 0.05733621004037559, 0.058079159003682435, 0.05885315500199795, 0.058433050056919456, 0.05882444197777659, 0.058866948005743325, 0.05945258401334286, 0.06700974598061293, 0.05944264598656446, 0.05956155096646398, 0.06455620599444956, 0.05978387000504881, 0.05973589501809329, 0.06001776293851435, 0.05954045907128602]
[0.0013805513868150724, 0.0013415474095381796, 0.0013351364997850562, 0.0013817162517542865, 0.001436718728985976, 0.0014251917971044102, 0.0014855980433904651, 0.0014281133189797401, 0.0014254379758230325, 0.001433373159009286, 0.001709275886903263, 0.0013581877256828275, 0.001418945773779838, 0.0013539830450264906, 0.0013528507499193604, 0.0013630348416468637, 0.0013183365015059032, 0.001293049273292788, 0.001252390499840575, 0.0012384777047290381, 0.0012534843408502638, 0.0012611999541563405, 0.0014396526808427138, 0.0012867204072377222, 0.0012533150227020749, 0.001249235681660304, 0.0012999186821451242, 0.0013451631133317608, 0.0013439374769487504, 0.0013430319297847084, 0.0013470682950521057, 0.0013531505008524453, 0.0013463696364355696, 0.001355440953788771, 0.0013709368623412129, 0.0014239813635041091, 0.0012745541144712743, 0.0012581542488822545, 0.0015009525681803511, 0.001284153544640338, 0.0013050184563987634, 0.001304962182819674, 0.0013272454327141697, 0.0013879568405999717, 0.0013423352952072905, 0.0013906192722391677, 0.0013939769097222861, 0.0013482309110589665, 0.0013527614302636887, 0.0013518304331228137, 0.0013584797720382498, 0.001355770477940413, 0.0013594577268866653, 0.001354768499202857, 0.0013387030445631933, 0.0013484730681573803, 0.0013619104998228563, 0.001396491250488907, 0.0013444034319201653, 0.001343466410286386, 0.001344020592196929, 0.0013441286123865707, 0.0013543140455360779, 0.0013348027714528143, 0.0015877922732298348, 0.001337858001616868, 0.0012079137959517539, 0.00126472163670273, 0.004387023522709073, 0.0013711220235563815, 0.0013721070453439925, 0.0013759252747563137, 0.0013659192270345309, 0.0013836966589389538, 0.0013758787721268493, 0.0013235589087178762, 0.0012715523189399391, 0.001269011364043267, 0.00436519690926864, 0.0013497354309286245, 0.0013521485909057612, 0.001347044318787415, 0.0013555869094985114, 0.0013529897736258465, 0.0013574652283833448, 0.0013544692509722981, 0.001355019363638183, 0.001392678590491414, 0.0013506255213128911, 0.0013488625435539607, 0.0013508010227021507, 0.0013605261364401404, 0.0013703565451909196, 0.0013711847714148462, 0.0012790259074377404, 0.0013576749770436436, 0.001360442134848034, 0.0012689905442212794, 0.0014277313417882067, 0.0013030956827358089, 0.001319980886447328, 0.0013375717045908625, 0.0013280238649299877, 0.0013369191358585588, 0.001337885181948712, 0.0013511950912123377, 0.0015229487722866577, 0.001350969226967374, 0.0013536716128741814, 0.0014671864998738536, 0.001358724318296564, 0.0013576339776839384, 0.0013640400667844171, 0.0013531922516201369]
[724.3482637086017, 745.4078722005394, 748.9870887066529, 723.7375971588644, 696.0304615126661, 701.6599464238564, 673.1295887532119, 700.2245457065067, 701.5387670043032, 697.6550340116434, 585.0430627742163, 736.2752446442931, 704.7485664911385, 738.561685593659, 739.1798393574511, 733.6569612496237, 758.5316790195255, 773.365733738414, 798.4730003359946, 807.4428761870898, 797.7762205802106, 792.8956837529652, 694.6119805887075, 777.1696122755669, 797.883997148664, 800.4894630218567, 769.2788893146771, 743.4042682921588, 744.0822338479471, 744.5839356628719, 742.3528589256265, 739.0160956745234, 742.7380809384845, 737.7672905667847, 729.4281943022914, 702.2563817402898, 784.5881070454445, 794.8151038621862, 666.2435717154802, 778.7230772937493, 766.2726876365635, 766.3057314345061, 753.4401515739523, 720.4834982964818, 744.9703539573358, 719.1040854696379, 717.3719973591415, 741.7127079622816, 739.2286456637619, 739.7377477957326, 736.1169599894813, 737.5879739755999, 735.5874185879467, 738.1334896614425, 746.99165289961, 741.5795121265929, 734.262640702212, 716.0803905143717, 743.8243433905359, 744.3431352979123, 744.0362192408118, 743.9764251610176, 738.3811777601186, 749.1743509878908, 629.8053069409596, 747.4634817682072, 827.8736474005317, 790.6878248775054, 227.94498247469627, 729.3296897137028, 728.8061112967292, 726.7836548588056, 732.1077119406561, 722.7017522516965, 726.8082190512965, 755.5387171763244, 786.4403100878103, 788.0150078513442, 229.0847402271123, 740.885937410708, 739.5636890248371, 742.3660721869804, 737.687855343736, 739.1038864396755, 736.6671197839349, 738.2965684028306, 737.99683372423, 718.0407646297949, 740.3976781276416, 741.3653858051515, 740.3014827451002, 735.0097680714401, 729.7370917878011, 729.2963142875033, 781.8449917119269, 736.5533112921578, 735.0551518398123, 788.0279364994431, 700.4118847370254, 767.4033559074734, 757.5867274044074, 747.6234706279772, 752.9985163728359, 747.9883959906132, 747.4482963802907, 740.0855779477162, 656.6209042596573, 740.2093104998239, 738.7316026201889, 681.5766094398896, 735.9844720036383, 736.5755545584933, 733.1162950054658, 738.9932944138054]
Elapsed: 0.06195977342155713~0.01768820158834621
Time per graph: 0.001408176668671753~0.00040200458155332294
Speed: 730.5942931910093~75.06734626590907
Total Time: 0.0601
best val loss: 0.3283497989177704 test_score: 0.7273

Testing...
Test loss: 0.4800 score: 0.7273 time: 0.05s
test Score 0.7273
Epoch Time List: [0.36252292699646205, 0.17585298896301538, 0.17699241894297302, 0.19013942300807685, 0.1860430199885741, 0.18583217996638268, 0.1871291009010747, 0.3122514970600605, 0.1866011469392106, 0.18643719202373177, 0.19955656491219997, 0.17864725599065423, 0.18055730685591698, 0.17791697196662426, 0.17772243113722652, 0.17938545299693942, 0.17950201698113233, 0.2761366720078513, 0.16401567799039185, 0.16457327897660434, 0.165421576006338, 0.17067032889463007, 0.17727166682016104, 0.17041036405134946, 0.16698420408647507, 0.16483752604108304, 0.1658637758810073, 0.2981450309744105, 0.17669245088472962, 0.17761647095903754, 0.17726971313823014, 0.17808674392290413, 0.17804095102474093, 0.18344914796762168, 0.18059850600548089, 0.1867371939588338, 0.17077136191073805, 0.16687174909748137, 0.33689167292322963, 0.16621388599742204, 0.17274088005069643, 0.17163564800284803, 0.1751059809466824, 0.1857604261022061, 0.18185617891140282, 0.1822875359794125, 0.179985360824503, 0.24431791913229972, 0.18015804106835276, 0.18029065593145788, 0.17981343402061611, 0.1807570798555389, 0.1807817880762741, 0.18157147290185094, 0.17913489404600114, 0.1785621070303023, 0.17989255592692643, 0.18110319890547544, 0.29709769401233643, 0.1779034190112725, 0.17735126393381506, 0.17848623706959188, 0.1790919229388237, 0.17769003997091204, 0.18611655198037624, 0.1758458949625492, 0.16179840883705765, 0.16509067418519408, 0.30610773898661137, 0.1800620690919459, 0.1812744998605922, 0.1819184529595077, 0.1800069579621777, 0.1806415340397507, 0.18364306702278554, 0.18109729222487658, 0.16986623802222311, 0.16877145902253687, 0.3112798990914598, 0.18039796606171876, 0.17948741593863815, 0.17961129697505385, 0.17996804194990546, 0.18076479097362608, 0.17893189005553722, 0.17946866096463054, 0.1794285780051723, 0.17944774101488292, 0.30402283393777907, 0.17925130110234022, 0.17927048518322408, 0.17981454997789115, 0.18044375302270055, 0.18139954307116568, 0.176535211969167, 0.18506514001637697, 0.17956836812663823, 0.17148038209415972, 0.1714168981416151, 0.3307177349925041, 0.17233454110100865, 0.17572528088930994, 0.17533049802295864, 0.17559965688269585, 0.17693818092811853, 0.17799312679562718, 0.1848073760047555, 0.18068460910581052, 0.17970253096427768, 0.18387515610083938, 0.17904849303886294, 0.17763584689237177, 0.17744557501282543, 0.17755294404923916]
Total Epoch List: [114]
Total Time List: [0.06013755197636783]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce1e4c70>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6891;  Loss pred: 0.6891; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6883;  Loss pred: 0.6883; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6884;  Loss pred: 0.6884; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6865;  Loss pred: 0.6865; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.07s
Epoch 9/1000, LR 0.000210
Train loss: 0.6784;  Loss pred: 0.6784; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.06s
Epoch 10/1000, LR 0.000240
Train loss: 0.6758;  Loss pred: 0.6758; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6767;  Loss pred: 0.6767; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6683;  Loss pred: 0.6683; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6656;  Loss pred: 0.6656; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6604;  Loss pred: 0.6604; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6541;  Loss pred: 0.6541; Loss self: 0.0000; time: 0.09s
Val loss: 0.6929 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6506;  Loss pred: 0.6506; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6476;  Loss pred: 0.6476; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6398;  Loss pred: 0.6398; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6358;  Loss pred: 0.6358; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6213;  Loss pred: 0.6213; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6197;  Loss pred: 0.6197; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6160;  Loss pred: 0.6160; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.6043;  Loss pred: 0.6043; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.5966;  Loss pred: 0.5966; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5918;  Loss pred: 0.5918; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.5805;  Loss pred: 0.5805; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5700;  Loss pred: 0.5700; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5611;  Loss pred: 0.5611; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5432;  Loss pred: 0.5432; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.5428;  Loss pred: 0.5428; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.5201;  Loss pred: 0.5201; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.5086;  Loss pred: 0.5086; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 33/1000, LR 0.000270
Train loss: 0.4978;  Loss pred: 0.4978; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 34/1000, LR 0.000270
Train loss: 0.4827;  Loss pred: 0.4827; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 35/1000, LR 0.000270
Train loss: 0.4720;  Loss pred: 0.4720; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4544;  Loss pred: 0.4544; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5116 time: 0.06s
Epoch 37/1000, LR 0.000270
Train loss: 0.4441;  Loss pred: 0.4441; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4279;  Loss pred: 0.4279; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4133;  Loss pred: 0.4133; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4013;  Loss pred: 0.4013; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3904;  Loss pred: 0.3904; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6879 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3681;  Loss pred: 0.3681; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3529;  Loss pred: 0.3529; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6862 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3438;  Loss pred: 0.3438; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6852 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3166;  Loss pred: 0.3166; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6872 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6843 score: 0.5116 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3116;  Loss pred: 0.3116; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6861 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6831 score: 0.5116 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2948;  Loss pred: 0.2948; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6851 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6820 score: 0.5116 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2817;  Loss pred: 0.2817; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6839 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6805 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2598;  Loss pred: 0.2598; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6825 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6789 score: 0.5116 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2564;  Loss pred: 0.2564; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6810 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6772 score: 0.5116 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2412;  Loss pred: 0.2412; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6794 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6754 score: 0.5116 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2253;  Loss pred: 0.2253; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6780 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6737 score: 0.5116 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2143;  Loss pred: 0.2143; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6767 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6722 score: 0.5116 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2007;  Loss pred: 0.2007; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6754 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6705 score: 0.5116 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1802;  Loss pred: 0.1802; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6739 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6688 score: 0.5116 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1779;  Loss pred: 0.1779; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6722 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6667 score: 0.5116 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1644;  Loss pred: 0.1644; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6705 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6647 score: 0.5116 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1557;  Loss pred: 0.1557; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6687 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6625 score: 0.5116 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1419;  Loss pred: 0.1419; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6671 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6605 score: 0.5116 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1432;  Loss pred: 0.1432; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6649 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6580 score: 0.5116 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1270;  Loss pred: 0.1270; Loss self: 0.0000; time: 0.09s
Val loss: 0.6632 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6557 score: 0.5116 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1176;  Loss pred: 0.1176; Loss self: 0.0000; time: 0.09s
Val loss: 0.6601 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6519 score: 0.5116 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1087;  Loss pred: 0.1087; Loss self: 0.0000; time: 0.09s
Val loss: 0.6566 score: 0.5455 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6476 score: 0.5116 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0962;  Loss pred: 0.0962; Loss self: 0.0000; time: 0.09s
Val loss: 0.6523 score: 0.5455 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6426 score: 0.5116 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0962;  Loss pred: 0.0962; Loss self: 0.0000; time: 0.09s
Val loss: 0.6479 score: 0.5455 time: 0.05s
Test loss: 0.6374 score: 0.5349 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0882;  Loss pred: 0.0882; Loss self: 0.0000; time: 0.09s
Val loss: 0.6435 score: 0.5682 time: 0.05s
Test loss: 0.6321 score: 0.5581 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0804;  Loss pred: 0.0804; Loss self: 0.0000; time: 0.09s
Val loss: 0.6386 score: 0.5909 time: 0.06s
Test loss: 0.6262 score: 0.5581 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0758;  Loss pred: 0.0758; Loss self: 0.0000; time: 0.09s
Val loss: 0.6329 score: 0.5909 time: 0.05s
Test loss: 0.6195 score: 0.5814 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0690;  Loss pred: 0.0690; Loss self: 0.0000; time: 0.09s
Val loss: 0.6262 score: 0.6136 time: 0.05s
Test loss: 0.6116 score: 0.6279 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0648;  Loss pred: 0.0648; Loss self: 0.0000; time: 0.09s
Val loss: 0.6184 score: 0.5909 time: 0.05s
Test loss: 0.6022 score: 0.6279 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0619;  Loss pred: 0.0619; Loss self: 0.0000; time: 0.09s
Val loss: 0.6091 score: 0.5909 time: 0.05s
Test loss: 0.5908 score: 0.6279 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0521;  Loss pred: 0.0521; Loss self: 0.0000; time: 0.09s
Val loss: 0.5985 score: 0.5909 time: 0.05s
Test loss: 0.5775 score: 0.6279 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0543;  Loss pred: 0.0543; Loss self: 0.0000; time: 0.09s
Val loss: 0.5880 score: 0.5909 time: 0.05s
Test loss: 0.5643 score: 0.6512 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0458;  Loss pred: 0.0458; Loss self: 0.0000; time: 0.09s
Val loss: 0.5770 score: 0.6364 time: 0.05s
Test loss: 0.5505 score: 0.6512 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0468;  Loss pred: 0.0468; Loss self: 0.0000; time: 0.09s
Val loss: 0.5644 score: 0.6136 time: 0.05s
Test loss: 0.5345 score: 0.6512 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0381;  Loss pred: 0.0381; Loss self: 0.0000; time: 0.09s
Val loss: 0.5519 score: 0.6136 time: 0.05s
Test loss: 0.5183 score: 0.6512 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0354;  Loss pred: 0.0354; Loss self: 0.0000; time: 0.09s
Val loss: 0.5389 score: 0.6136 time: 0.05s
Test loss: 0.5012 score: 0.6744 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0327;  Loss pred: 0.0327; Loss self: 0.0000; time: 0.09s
Val loss: 0.5256 score: 0.6136 time: 0.05s
Test loss: 0.4832 score: 0.6977 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0328;  Loss pred: 0.0328; Loss self: 0.0000; time: 0.09s
Val loss: 0.5134 score: 0.6364 time: 0.05s
Test loss: 0.4661 score: 0.7209 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0282;  Loss pred: 0.0282; Loss self: 0.0000; time: 0.09s
Val loss: 0.5025 score: 0.6818 time: 0.05s
Test loss: 0.4496 score: 0.7209 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0282;  Loss pred: 0.0282; Loss self: 0.0000; time: 0.09s
Val loss: 0.4922 score: 0.6591 time: 0.05s
Test loss: 0.4337 score: 0.7674 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.09s
Val loss: 0.4833 score: 0.7273 time: 0.05s
Test loss: 0.4190 score: 0.7907 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0248;  Loss pred: 0.0248; Loss self: 0.0000; time: 0.09s
Val loss: 0.4754 score: 0.7273 time: 0.05s
Test loss: 0.4051 score: 0.7907 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0216;  Loss pred: 0.0216; Loss self: 0.0000; time: 0.09s
Val loss: 0.4686 score: 0.7500 time: 0.05s
Test loss: 0.3921 score: 0.7907 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0209;  Loss pred: 0.0209; Loss self: 0.0000; time: 0.09s
Val loss: 0.4622 score: 0.7955 time: 0.05s
Test loss: 0.3789 score: 0.8140 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.09s
Val loss: 0.4573 score: 0.7955 time: 0.05s
Test loss: 0.3667 score: 0.8140 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.09s
Val loss: 0.4532 score: 0.8182 time: 0.05s
Test loss: 0.3551 score: 0.8372 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0165;  Loss pred: 0.0165; Loss self: 0.0000; time: 0.09s
Val loss: 0.4501 score: 0.8182 time: 0.05s
Test loss: 0.3440 score: 0.8372 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.09s
Val loss: 0.4482 score: 0.8182 time: 0.05s
Test loss: 0.3339 score: 0.8372 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0155;  Loss pred: 0.0155; Loss self: 0.0000; time: 0.09s
Val loss: 0.4474 score: 0.7727 time: 0.05s
Test loss: 0.3243 score: 0.8372 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.09s
Val loss: 0.4485 score: 0.7727 time: 0.05s
Test loss: 0.3169 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.09s
Val loss: 0.4510 score: 0.7727 time: 0.05s
Test loss: 0.3106 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.09s
Val loss: 0.4548 score: 0.7727 time: 0.05s
Test loss: 0.3057 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.09s
Val loss: 0.4599 score: 0.7727 time: 0.05s
Test loss: 0.3018 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.09s
Val loss: 0.4662 score: 0.7955 time: 0.05s
Test loss: 0.2994 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.09s
Val loss: 0.4741 score: 0.8182 time: 0.05s
Test loss: 0.2983 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.09s
Val loss: 0.4829 score: 0.8182 time: 0.05s
Test loss: 0.2985 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.09s
Val loss: 0.4928 score: 0.8182 time: 0.05s
Test loss: 0.2999 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.09s
Val loss: 0.5038 score: 0.8182 time: 0.05s
Test loss: 0.3026 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.09s
Val loss: 0.5155 score: 0.8182 time: 0.05s
Test loss: 0.3063 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.09s
Val loss: 0.5280 score: 0.8182 time: 0.05s
Test loss: 0.3109 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.09s
Val loss: 0.5409 score: 0.8182 time: 0.05s
Test loss: 0.3161 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.09s
Val loss: 0.5548 score: 0.8182 time: 0.05s
Test loss: 0.3220 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.09s
Val loss: 0.5696 score: 0.8182 time: 0.05s
Test loss: 0.3292 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.09s
Val loss: 0.5835 score: 0.8182 time: 0.05s
Test loss: 0.3363 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.09s
Val loss: 0.5975 score: 0.8182 time: 0.05s
Test loss: 0.3433 score: 0.8605 time: 0.18s
     INFO: Early stopping counter 16 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.09s
Val loss: 0.6131 score: 0.8182 time: 0.05s
Test loss: 0.3521 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.09s
Val loss: 0.6270 score: 0.8182 time: 0.05s
Test loss: 0.3598 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.09s
Val loss: 0.6403 score: 0.8182 time: 0.05s
Test loss: 0.3673 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.09s
Val loss: 0.6525 score: 0.8182 time: 0.05s
Test loss: 0.3742 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 089,   Train_Loss: 0.0155,   Val_Loss: 0.4474,   Val_Precision: 0.7727,   Val_Recall: 0.7727,   Val_accuracy: 0.7727,   Val_Score: 0.7727,   Val_Loss: 0.4474,   Test_Precision: 0.8000,   Test_Recall: 0.9091,   Test_accuracy: 0.8511,   Test_Score: 0.8372,   Test_loss: 0.3243


[0.06074426101986319, 0.059028086019679904, 0.05874600599054247, 0.06079551507718861, 0.06321562407538295, 0.06270843907259405, 0.06536631390918046, 0.06283698603510857, 0.06271927093621343, 0.06306841899640858, 0.07520813902374357, 0.05976025993004441, 0.06243361404631287, 0.05957525398116559, 0.059525432996451855, 0.059973533032462, 0.05800680606625974, 0.056894168024882674, 0.05510518199298531, 0.05449301900807768, 0.05515331099741161, 0.05549279798287898, 0.06334471795707941, 0.05661569791845977, 0.055145860998891294, 0.05496636999305338, 0.05719642201438546, 0.05918717698659748, 0.05913324898574501, 0.05909340491052717, 0.05927100498229265, 0.059538622037507594, 0.059240264003165066, 0.05963940196670592, 0.06032122194301337, 0.0626551799941808, 0.05608038103673607, 0.055358786950819194, 0.06604191299993545, 0.05650275596417487, 0.05742081208154559, 0.057418336044065654, 0.058398799039423466, 0.061070100986398757, 0.05906275298912078, 0.061187247978523374, 0.06133498402778059, 0.05932216008659452, 0.0595215029316023, 0.0594805390574038, 0.05977310996968299, 0.059653901029378176, 0.05981613998301327, 0.059609813964925706, 0.0589029339607805, 0.05933281499892473, 0.05992406199220568, 0.06144561502151191, 0.059153751004487276, 0.05911252205260098, 0.059136906056664884, 0.05914165894500911, 0.059589818003587425, 0.05873132194392383, 0.06986286002211273, 0.0588657520711422, 0.05314820702187717, 0.055647752014920115, 0.1930290349991992, 0.060329369036480784, 0.060372709995135665, 0.060540712089277804, 0.06010044598951936, 0.06088265299331397, 0.060538665973581374, 0.05823659198358655, 0.05594830203335732, 0.055836500017903745, 0.1920686640078202, 0.05938835896085948, 0.05949453799985349, 0.059269950026646256, 0.0596458240179345, 0.05953155003953725, 0.059728470048867166, 0.059596647042781115, 0.05962085200008005, 0.06127785798162222, 0.05942752293776721, 0.059349951916374266, 0.05943524499889463, 0.05986315000336617, 0.06029568798840046, 0.06033212994225323, 0.05627713992726058, 0.05973769898992032, 0.05985945393331349, 0.05583558394573629, 0.06282017903868109, 0.05733621004037559, 0.058079159003682435, 0.05885315500199795, 0.058433050056919456, 0.05882444197777659, 0.058866948005743325, 0.05945258401334286, 0.06700974598061293, 0.05944264598656446, 0.05956155096646398, 0.06455620599444956, 0.05978387000504881, 0.05973589501809329, 0.06001776293851435, 0.05954045907128602, 0.057491942890919745, 0.05729704594705254, 0.05748383095487952, 0.05761027801781893, 0.0573397750267759, 0.05768566601909697, 0.057488169986754656, 0.08332827396225184, 0.0676330920541659, 0.057601311011239886, 0.056528884917497635, 0.05701617000158876, 0.05657009105198085, 0.05669385998044163, 0.05685853597242385, 0.056949632009491324, 0.0566585500491783, 0.05657975596841425, 0.05690919701009989, 0.05984611401800066, 0.05618844705168158, 0.05660704802721739, 0.055755109060555696, 0.056033573928289115, 0.05639624397736043, 0.05619603698141873, 0.05695629504043609, 0.05575331998988986, 0.05658595100976527, 0.05609816708602011, 0.05638951703440398, 0.055910701979883015, 0.05592777696438134, 0.056523610022850335, 0.05684299499262124, 0.06353142799343914, 0.05583205004222691, 0.056003840058110654, 0.056638103909790516, 0.05590864398982376, 0.05630275805015117, 0.05551802203990519, 0.05630700895562768, 0.05582375102676451, 0.054988033953122795, 0.055796333006583154, 0.056013581925071776, 0.055429956992156804, 0.05571288906503469, 0.055632036994211376, 0.055381382000632584, 0.05562333995476365, 0.055667171953246, 0.055540955043397844, 0.05556309793610126, 0.055575556005351245, 0.05617575498763472, 0.0558155809994787, 0.055649518966674805, 0.05571041605435312, 0.05594007100444287, 0.05534966895356774, 0.0555379610741511, 0.05560658103786409, 0.05643460096325725, 0.05738639703486115, 0.05911720707081258, 0.056746899033896625, 0.05656960606575012, 0.05659650801680982, 0.056346245924942195, 0.05709314497653395, 0.056751328986138105, 0.0568376500159502, 0.05691105290316045, 0.05764693394303322, 0.056587903993204236, 0.056852829991839826, 0.057263875962235034, 0.05613934004213661, 0.05710114096291363, 0.05697847704868764, 0.05639104195870459, 0.05671604792587459, 0.05676563398446888, 0.05717651697341353, 0.056953751016408205, 0.05790471995715052, 0.05704191199038178, 0.05749804596416652, 0.05726881406735629, 0.05728642002213746, 0.05742248601745814, 0.0574717529816553, 0.05710292898584157, 0.056902440963312984, 0.057091495022177696, 0.057472466956824064, 0.0570435969857499, 0.05693352408707142, 0.05667173396795988, 0.05744160898029804, 0.05844489694572985, 0.05719871702603996, 0.05645713396370411, 0.18293511401861906, 0.055894774035550654, 0.05545684590470046, 0.05586858105380088, 0.05580561002716422]
[0.0013805513868150724, 0.0013415474095381796, 0.0013351364997850562, 0.0013817162517542865, 0.001436718728985976, 0.0014251917971044102, 0.0014855980433904651, 0.0014281133189797401, 0.0014254379758230325, 0.001433373159009286, 0.001709275886903263, 0.0013581877256828275, 0.001418945773779838, 0.0013539830450264906, 0.0013528507499193604, 0.0013630348416468637, 0.0013183365015059032, 0.001293049273292788, 0.001252390499840575, 0.0012384777047290381, 0.0012534843408502638, 0.0012611999541563405, 0.0014396526808427138, 0.0012867204072377222, 0.0012533150227020749, 0.001249235681660304, 0.0012999186821451242, 0.0013451631133317608, 0.0013439374769487504, 0.0013430319297847084, 0.0013470682950521057, 0.0013531505008524453, 0.0013463696364355696, 0.001355440953788771, 0.0013709368623412129, 0.0014239813635041091, 0.0012745541144712743, 0.0012581542488822545, 0.0015009525681803511, 0.001284153544640338, 0.0013050184563987634, 0.001304962182819674, 0.0013272454327141697, 0.0013879568405999717, 0.0013423352952072905, 0.0013906192722391677, 0.0013939769097222861, 0.0013482309110589665, 0.0013527614302636887, 0.0013518304331228137, 0.0013584797720382498, 0.001355770477940413, 0.0013594577268866653, 0.001354768499202857, 0.0013387030445631933, 0.0013484730681573803, 0.0013619104998228563, 0.001396491250488907, 0.0013444034319201653, 0.001343466410286386, 0.001344020592196929, 0.0013441286123865707, 0.0013543140455360779, 0.0013348027714528143, 0.0015877922732298348, 0.001337858001616868, 0.0012079137959517539, 0.00126472163670273, 0.004387023522709073, 0.0013711220235563815, 0.0013721070453439925, 0.0013759252747563137, 0.0013659192270345309, 0.0013836966589389538, 0.0013758787721268493, 0.0013235589087178762, 0.0012715523189399391, 0.001269011364043267, 0.00436519690926864, 0.0013497354309286245, 0.0013521485909057612, 0.001347044318787415, 0.0013555869094985114, 0.0013529897736258465, 0.0013574652283833448, 0.0013544692509722981, 0.001355019363638183, 0.001392678590491414, 0.0013506255213128911, 0.0013488625435539607, 0.0013508010227021507, 0.0013605261364401404, 0.0013703565451909196, 0.0013711847714148462, 0.0012790259074377404, 0.0013576749770436436, 0.001360442134848034, 0.0012689905442212794, 0.0014277313417882067, 0.0013030956827358089, 0.001319980886447328, 0.0013375717045908625, 0.0013280238649299877, 0.0013369191358585588, 0.001337885181948712, 0.0013511950912123377, 0.0015229487722866577, 0.001350969226967374, 0.0013536716128741814, 0.0014671864998738536, 0.001358724318296564, 0.0013576339776839384, 0.0013640400667844171, 0.0013531922516201369, 0.001337021927695808, 0.0013324894406291287, 0.001336833278020454, 0.0013397739073911378, 0.001333483140157579, 0.0013415271167231853, 0.0013369341857384803, 0.0019378668363314382, 0.001572862605910835, 0.001339565372354416, 0.0013146252306394798, 0.001325957441897413, 0.001315583512836764, 0.0013184618600102704, 0.0013222915342424152, 0.0013244100467323563, 0.0013176406988181, 0.001315808278335215, 0.0013234696979092997, 0.0013917700934418758, 0.001306708070969339, 0.0013164429773771485, 0.001296630443268737, 0.0013031063704253283, 0.0013115405576130331, 0.0013068845809632262, 0.001324565000940374, 0.0012965888369741829, 0.0013159523490643085, 0.0013046085368841887, 0.0013113841170791624, 0.0013002488832530934, 0.0013006459759158451, 0.001314502558670938, 0.0013219301161074707, 0.0014774750696148636, 0.0012984197684238817, 0.0013024148850723407, 0.0013171652072044306, 0.001300201023019157, 0.0013093664662825854, 0.0012911167916257022, 0.001309465324549481, 0.001298226768064291, 0.0012787914872819254, 0.0012975891396879804, 0.0013026414401179484, 0.0012890687672594606, 0.0012956485829077834, 0.0012937683021909622, 0.0012879391162937811, 0.0012935660454596197, 0.0012945853942615349, 0.001291650117288322, 0.0012921650682814246, 0.001292454790822122, 0.0013064129066891795, 0.0012980367674297372, 0.0012941748596901118, 0.0012955910710314678, 0.001300931883824253, 0.0012872016035713428, 0.0012915804900965372, 0.0012931763032061417, 0.0013124325805408663, 0.0013345673729037476, 0.0013748187690886648, 0.001319695326369689, 0.0013155722340872122, 0.0013161978608560423, 0.001310377812207958, 0.0013277475575938127, 0.0013197983485148397, 0.0013218058143244233, 0.0013235128582130338, 0.0013406263707682145, 0.0013159977672838193, 0.0013221588370195309, 0.001331718045633373, 0.001305566047491549, 0.0013279335107654333, 0.001325080861597387, 0.0013114195804349905, 0.0013189778587412695, 0.001320131022894625, 0.001329686441242175, 0.0013245058375908885, 0.0013466213943523376, 0.0013265560927995762, 0.0013371638596317795, 0.0013318328852873556, 0.00133224232609622, 0.001335406651568794, 0.0013365523949222162, 0.00132797509269399, 0.0013233125805421624, 0.001327709186562272, 0.0013365689989959086, 0.0013265952787383697, 0.001324035443885382, 0.0013179473015804623, 0.0013358513716348382, 0.0013591836499006942, 0.001330202721535813, 0.0013129566038070724, 0.004254304977177188, 0.0012998784659430385, 0.0012896940908069874, 0.0012992693268325786, 0.0012978048843526563]
[724.3482637086017, 745.4078722005394, 748.9870887066529, 723.7375971588644, 696.0304615126661, 701.6599464238564, 673.1295887532119, 700.2245457065067, 701.5387670043032, 697.6550340116434, 585.0430627742163, 736.2752446442931, 704.7485664911385, 738.561685593659, 739.1798393574511, 733.6569612496237, 758.5316790195255, 773.365733738414, 798.4730003359946, 807.4428761870898, 797.7762205802106, 792.8956837529652, 694.6119805887075, 777.1696122755669, 797.883997148664, 800.4894630218567, 769.2788893146771, 743.4042682921588, 744.0822338479471, 744.5839356628719, 742.3528589256265, 739.0160956745234, 742.7380809384845, 737.7672905667847, 729.4281943022914, 702.2563817402898, 784.5881070454445, 794.8151038621862, 666.2435717154802, 778.7230772937493, 766.2726876365635, 766.3057314345061, 753.4401515739523, 720.4834982964818, 744.9703539573358, 719.1040854696379, 717.3719973591415, 741.7127079622816, 739.2286456637619, 739.7377477957326, 736.1169599894813, 737.5879739755999, 735.5874185879467, 738.1334896614425, 746.99165289961, 741.5795121265929, 734.262640702212, 716.0803905143717, 743.8243433905359, 744.3431352979123, 744.0362192408118, 743.9764251610176, 738.3811777601186, 749.1743509878908, 629.8053069409596, 747.4634817682072, 827.8736474005317, 790.6878248775054, 227.94498247469627, 729.3296897137028, 728.8061112967292, 726.7836548588056, 732.1077119406561, 722.7017522516965, 726.8082190512965, 755.5387171763244, 786.4403100878103, 788.0150078513442, 229.0847402271123, 740.885937410708, 739.5636890248371, 742.3660721869804, 737.687855343736, 739.1038864396755, 736.6671197839349, 738.2965684028306, 737.99683372423, 718.0407646297949, 740.3976781276416, 741.3653858051515, 740.3014827451002, 735.0097680714401, 729.7370917878011, 729.2963142875033, 781.8449917119269, 736.5533112921578, 735.0551518398123, 788.0279364994431, 700.4118847370254, 767.4033559074734, 757.5867274044074, 747.6234706279772, 752.9985163728359, 747.9883959906132, 747.4482963802907, 740.0855779477162, 656.6209042596573, 740.2093104998239, 738.7316026201889, 681.5766094398896, 735.9844720036383, 736.5755545584933, 733.1162950054658, 738.9932944138054, 747.9308897524039, 750.4749902767369, 748.0364353891404, 746.3945927617299, 749.9157431280527, 745.4191477266597, 747.9799758786417, 516.031329527829, 635.7834411232037, 746.5107867355537, 760.6730623248155, 754.1720181976762, 760.1189816097055, 758.4595583160898, 756.2628770613231, 755.0531668551176, 758.9322346349669, 759.989138588806, 755.5896455957484, 718.5094756038187, 765.2818729880365, 759.6227236460918, 771.2297711281964, 767.3970618941909, 762.4621245567669, 765.178512752029, 754.964836976706, 771.2545191532538, 759.9059348243403, 766.5134572768559, 762.5530818745111, 769.0835292225743, 768.8487248006543, 760.7440498336314, 756.469640728498, 676.8303713311873, 770.166955493811, 767.8044926094778, 759.2062062756833, 769.1118390892591, 763.7281278778233, 774.5232704632831, 763.6704701165326, 770.2814520540512, 781.9883147060218, 770.65996424759, 767.6709562605766, 775.7538041403205, 771.8142196827256, 772.9359254717607, 776.4342175409931, 773.0567785927682, 772.4480783057389, 774.2034678085971, 773.8949338183215, 773.7214540122573, 765.4547768777663, 770.3942022999207, 772.693112149813, 771.8484808666234, 768.679753670403, 776.8790818978927, 774.2452039711877, 773.2897653017021, 761.9439008348072, 749.30649460147, 727.3685975809573, 757.7506565480311, 760.1254983112602, 759.7641887592871, 763.1386846477671, 753.1552171048482, 757.6915072861649, 756.5407786552228, 755.5650055037388, 745.9199832291629, 759.8797086593623, 756.3387786706811, 750.9097014033433, 765.9512913355485, 753.0497512812901, 754.6709253611124, 762.5324609445786, 758.1628405455741, 757.5005682445973, 752.057003052399, 754.9985599300005, 742.5992221673811, 753.8316739321522, 747.8515013675094, 750.8449528817878, 750.6141941385638, 748.8355691693098, 748.1936389468647, 753.0261715762718, 755.679357019563, 753.1769834245235, 748.184344206132, 753.8094067024185, 755.2667903402194, 758.7556792299778, 748.5862733188518, 735.7357484936365, 751.7651135500831, 761.6397960910377, 235.05602098689198, 769.3026895976141, 775.3776706647388, 769.6633633596571, 770.5318511717568]
Elapsed: 0.060087966021196086~0.015400996840099976
Time per graph: 0.0013807280158346493~0.0003510379519312564
Speed: 740.6586453048288~67.70355162870845
Total Time: 0.0567
best val loss: 0.4473572075366974 test_score: 0.8372

Testing...
Test loss: 0.3551 score: 0.8372 time: 0.05s
test Score 0.8372
Epoch Time List: [0.36252292699646205, 0.17585298896301538, 0.17699241894297302, 0.19013942300807685, 0.1860430199885741, 0.18583217996638268, 0.1871291009010747, 0.3122514970600605, 0.1866011469392106, 0.18643719202373177, 0.19955656491219997, 0.17864725599065423, 0.18055730685591698, 0.17791697196662426, 0.17772243113722652, 0.17938545299693942, 0.17950201698113233, 0.2761366720078513, 0.16401567799039185, 0.16457327897660434, 0.165421576006338, 0.17067032889463007, 0.17727166682016104, 0.17041036405134946, 0.16698420408647507, 0.16483752604108304, 0.1658637758810073, 0.2981450309744105, 0.17669245088472962, 0.17761647095903754, 0.17726971313823014, 0.17808674392290413, 0.17804095102474093, 0.18344914796762168, 0.18059850600548089, 0.1867371939588338, 0.17077136191073805, 0.16687174909748137, 0.33689167292322963, 0.16621388599742204, 0.17274088005069643, 0.17163564800284803, 0.1751059809466824, 0.1857604261022061, 0.18185617891140282, 0.1822875359794125, 0.179985360824503, 0.24431791913229972, 0.18015804106835276, 0.18029065593145788, 0.17981343402061611, 0.1807570798555389, 0.1807817880762741, 0.18157147290185094, 0.17913489404600114, 0.1785621070303023, 0.17989255592692643, 0.18110319890547544, 0.29709769401233643, 0.1779034190112725, 0.17735126393381506, 0.17848623706959188, 0.1790919229388237, 0.17769003997091204, 0.18611655198037624, 0.1758458949625492, 0.16179840883705765, 0.16509067418519408, 0.30610773898661137, 0.1800620690919459, 0.1812744998605922, 0.1819184529595077, 0.1800069579621777, 0.1806415340397507, 0.18364306702278554, 0.18109729222487658, 0.16986623802222311, 0.16877145902253687, 0.3112798990914598, 0.18039796606171876, 0.17948741593863815, 0.17961129697505385, 0.17996804194990546, 0.18076479097362608, 0.17893189005553722, 0.17946866096463054, 0.1794285780051723, 0.17944774101488292, 0.30402283393777907, 0.17925130110234022, 0.17927048518322408, 0.17981454997789115, 0.18044375302270055, 0.18139954307116568, 0.176535211969167, 0.18506514001637697, 0.17956836812663823, 0.17148038209415972, 0.1714168981416151, 0.3307177349925041, 0.17233454110100865, 0.17572528088930994, 0.17533049802295864, 0.17559965688269585, 0.17693818092811853, 0.17799312679562718, 0.1848073760047555, 0.18068460910581052, 0.17970253096427768, 0.18387515610083938, 0.17904849303886294, 0.17763584689237177, 0.17744557501282543, 0.17755294404923916, 0.18514871201477945, 0.18371394276618958, 0.18487619108054787, 0.1847538659349084, 0.1858885909896344, 0.18539738398976624, 0.18582684395369142, 0.2272212109528482, 0.23486842995043844, 0.19687164400238544, 0.19182004500180483, 0.19220284989569336, 0.19056342693511397, 0.1912429879885167, 0.19134836795274168, 0.19261908100452274, 0.19202827801927924, 0.19151143508497626, 0.19178863684646785, 0.21156541805248708, 0.19109548802953213, 0.19181929004844278, 0.1905146238859743, 0.18960893899202347, 0.19274502992630005, 0.19114589598029852, 0.19312970608007163, 0.190692875883542, 0.19110561592970043, 0.19077330292202532, 0.19149778492283076, 0.19131369492970407, 0.1918536729644984, 0.19177204684820026, 0.19249795901123434, 0.2085207209456712, 0.19941265089437366, 0.19101122091524303, 0.19059635803569108, 0.19054442597553134, 0.19042814010754228, 0.19031000102404505, 0.18927522690501064, 0.18913876311853528, 0.18884039903059602, 0.18758902000263333, 0.18915503099560738, 0.18817844602745026, 0.19020171696320176, 0.19128971197642386, 0.19029825902543962, 0.188995894161053, 0.18913068203255534, 0.18962398602161556, 0.1891186919528991, 0.1894437219016254, 0.18970524705946445, 0.1899910030188039, 0.18981951812747866, 0.18987335287965834, 0.1894952580332756, 0.19015675398986787, 0.18922902806662023, 0.19417838286608458, 0.19586363004054874, 0.19447565695736557, 0.19872316683176905, 0.19504042295739055, 0.1925878239562735, 0.19340803695376962, 0.19173084909562021, 0.19344290089793503, 0.19278348004445434, 0.19258210598491132, 0.1927204019157216, 0.19384300394449383, 0.1931531480513513, 0.19351577223278582, 0.19257843308150768, 0.1906252191402018, 0.19253523694351315, 0.19486966205295175, 0.19237812492065132, 0.19362932699732482, 0.19338167796377093, 0.1961036049760878, 0.19414619693998247, 0.19399298704229295, 0.19469866889994591, 0.1942349299788475, 0.1930617339676246, 0.19345364288892597, 0.1935014941263944, 0.19439183198846877, 0.1940211660694331, 0.19279075402300805, 0.19471140403766185, 0.1939054278191179, 0.19539969810284674, 0.1922340210294351, 0.19272853794973344, 0.19328581006266177, 0.1987704539205879, 0.19411346095148474, 0.1908356740605086, 0.3181701930006966, 0.18851372797507793, 0.18712106603197753, 0.18643995001912117, 0.1866554708685726]
Total Epoch List: [114, 110]
Total Time List: [0.06013755197636783, 0.05672051291912794]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce1e4730>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6936;  Loss pred: 0.6936; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6959;  Loss pred: 0.6959; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6937;  Loss pred: 0.6937; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6921;  Loss pred: 0.6921; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6919;  Loss pred: 0.6919; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.09s
Epoch 8/1000, LR 0.000180
Train loss: 0.6904;  Loss pred: 0.6904; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6874;  Loss pred: 0.6874; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6821;  Loss pred: 0.6821; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.06s
Epoch 11/1000, LR 0.000270
Train loss: 0.6809;  Loss pred: 0.6809; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.06s
Epoch 12/1000, LR 0.000270
Train loss: 0.6783;  Loss pred: 0.6783; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.06s
Epoch 13/1000, LR 0.000270
Train loss: 0.6776;  Loss pred: 0.6776; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6743;  Loss pred: 0.6743; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6703;  Loss pred: 0.6703; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6671;  Loss pred: 0.6671; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6635;  Loss pred: 0.6635; Loss self: 0.0000; time: 0.22s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6598;  Loss pred: 0.6598; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6559;  Loss pred: 0.6559; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6511;  Loss pred: 0.6511; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6467;  Loss pred: 0.6467; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6432;  Loss pred: 0.6432; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6345;  Loss pred: 0.6345; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6284;  Loss pred: 0.6284; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6200;  Loss pred: 0.6200; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.06s
Test loss: 0.6915 score: 0.5349 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6140;  Loss pred: 0.6140; Loss self: 0.0000; time: 0.09s
Val loss: 0.6913 score: 0.5682 time: 0.06s
Test loss: 0.6913 score: 0.6744 time: 0.14s
Epoch 27/1000, LR 0.000270
Train loss: 0.6078;  Loss pred: 0.6078; Loss self: 0.0000; time: 0.09s
Val loss: 0.6909 score: 0.7955 time: 0.05s
Test loss: 0.6910 score: 0.7907 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.6028;  Loss pred: 0.6028; Loss self: 0.0000; time: 0.09s
Val loss: 0.6905 score: 0.8636 time: 0.05s
Test loss: 0.6906 score: 0.7209 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5945;  Loss pred: 0.5945; Loss self: 0.0000; time: 0.08s
Val loss: 0.6901 score: 0.7500 time: 0.05s
Test loss: 0.6902 score: 0.6744 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5797;  Loss pred: 0.5797; Loss self: 0.0000; time: 0.08s
Val loss: 0.6896 score: 0.6591 time: 0.05s
Test loss: 0.6898 score: 0.6279 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5777;  Loss pred: 0.5777; Loss self: 0.0000; time: 0.09s
Val loss: 0.6890 score: 0.6591 time: 0.05s
Test loss: 0.6892 score: 0.6047 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5627;  Loss pred: 0.5627; Loss self: 0.0000; time: 0.08s
Val loss: 0.6883 score: 0.6364 time: 0.06s
Test loss: 0.6886 score: 0.5581 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5579;  Loss pred: 0.5579; Loss self: 0.0000; time: 0.09s
Val loss: 0.6876 score: 0.6364 time: 0.06s
Test loss: 0.6879 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5451;  Loss pred: 0.5451; Loss self: 0.0000; time: 0.09s
Val loss: 0.6867 score: 0.6364 time: 0.05s
Test loss: 0.6871 score: 0.5349 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5346;  Loss pred: 0.5346; Loss self: 0.0000; time: 0.09s
Val loss: 0.6858 score: 0.5909 time: 0.05s
Test loss: 0.6863 score: 0.5581 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5251;  Loss pred: 0.5251; Loss self: 0.0000; time: 0.12s
Val loss: 0.6847 score: 0.5909 time: 0.09s
Test loss: 0.6853 score: 0.5581 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5145;  Loss pred: 0.5145; Loss self: 0.0000; time: 0.08s
Val loss: 0.6836 score: 0.5909 time: 0.05s
Test loss: 0.6842 score: 0.5581 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.5006;  Loss pred: 0.5006; Loss self: 0.0000; time: 0.08s
Val loss: 0.6822 score: 0.5682 time: 0.05s
Test loss: 0.6830 score: 0.5581 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4876;  Loss pred: 0.4876; Loss self: 0.0000; time: 0.08s
Val loss: 0.6807 score: 0.5682 time: 0.05s
Test loss: 0.6817 score: 0.5581 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4787;  Loss pred: 0.4787; Loss self: 0.0000; time: 0.08s
Val loss: 0.6790 score: 0.5682 time: 0.06s
Test loss: 0.6802 score: 0.5581 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4641;  Loss pred: 0.4641; Loss self: 0.0000; time: 0.08s
Val loss: 0.6773 score: 0.5682 time: 0.05s
Test loss: 0.6786 score: 0.5581 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4448;  Loss pred: 0.4448; Loss self: 0.0000; time: 0.09s
Val loss: 0.6755 score: 0.5682 time: 0.06s
Test loss: 0.6770 score: 0.5581 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4428;  Loss pred: 0.4428; Loss self: 0.0000; time: 0.09s
Val loss: 0.6735 score: 0.5682 time: 0.06s
Test loss: 0.6752 score: 0.5581 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4268;  Loss pred: 0.4268; Loss self: 0.0000; time: 0.09s
Val loss: 0.6715 score: 0.5455 time: 0.06s
Test loss: 0.6734 score: 0.5581 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4109;  Loss pred: 0.4109; Loss self: 0.0000; time: 0.09s
Val loss: 0.6693 score: 0.5455 time: 0.06s
Test loss: 0.6714 score: 0.5581 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3985;  Loss pred: 0.3985; Loss self: 0.0000; time: 0.19s
Val loss: 0.6668 score: 0.5455 time: 0.06s
Test loss: 0.6692 score: 0.5581 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3838;  Loss pred: 0.3838; Loss self: 0.0000; time: 0.09s
Val loss: 0.6642 score: 0.5455 time: 0.06s
Test loss: 0.6669 score: 0.5581 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3671;  Loss pred: 0.3671; Loss self: 0.0000; time: 0.08s
Val loss: 0.6613 score: 0.5455 time: 0.05s
Test loss: 0.6645 score: 0.5581 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3535;  Loss pred: 0.3535; Loss self: 0.0000; time: 0.09s
Val loss: 0.6582 score: 0.5455 time: 0.05s
Test loss: 0.6619 score: 0.5581 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3503;  Loss pred: 0.3503; Loss self: 0.0000; time: 0.09s
Val loss: 0.6548 score: 0.5455 time: 0.05s
Test loss: 0.6592 score: 0.5581 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3307;  Loss pred: 0.3307; Loss self: 0.0000; time: 0.09s
Val loss: 0.6511 score: 0.5455 time: 0.06s
Test loss: 0.6562 score: 0.5581 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3159;  Loss pred: 0.3159; Loss self: 0.0000; time: 0.09s
Val loss: 0.6472 score: 0.5682 time: 0.06s
Test loss: 0.6531 score: 0.5581 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.3049;  Loss pred: 0.3049; Loss self: 0.0000; time: 0.09s
Val loss: 0.6430 score: 0.5682 time: 0.06s
Test loss: 0.6500 score: 0.5581 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2883;  Loss pred: 0.2883; Loss self: 0.0000; time: 0.09s
Val loss: 0.6386 score: 0.5682 time: 0.05s
Test loss: 0.6467 score: 0.5581 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2712;  Loss pred: 0.2712; Loss self: 0.0000; time: 0.09s
Val loss: 0.6336 score: 0.5682 time: 0.06s
Test loss: 0.6431 score: 0.5581 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2635;  Loss pred: 0.2635; Loss self: 0.0000; time: 0.21s
Val loss: 0.6284 score: 0.5682 time: 0.06s
Test loss: 0.6394 score: 0.5581 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2489;  Loss pred: 0.2489; Loss self: 0.0000; time: 0.09s
Val loss: 0.6226 score: 0.5682 time: 0.05s
Test loss: 0.6352 score: 0.5581 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2321;  Loss pred: 0.2321; Loss self: 0.0000; time: 0.09s
Val loss: 0.6164 score: 0.5682 time: 0.05s
Test loss: 0.6309 score: 0.5581 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2198;  Loss pred: 0.2198; Loss self: 0.0000; time: 0.09s
Val loss: 0.6096 score: 0.6364 time: 0.05s
Test loss: 0.6260 score: 0.5581 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2086;  Loss pred: 0.2086; Loss self: 0.0000; time: 0.09s
Val loss: 0.6019 score: 0.6364 time: 0.05s
Test loss: 0.6205 score: 0.5349 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1959;  Loss pred: 0.1959; Loss self: 0.0000; time: 0.09s
Val loss: 0.5936 score: 0.6591 time: 0.06s
Test loss: 0.6145 score: 0.5349 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1860;  Loss pred: 0.1860; Loss self: 0.0000; time: 0.09s
Val loss: 0.5849 score: 0.6591 time: 0.06s
Test loss: 0.6083 score: 0.5349 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1738;  Loss pred: 0.1738; Loss self: 0.0000; time: 0.09s
Val loss: 0.5753 score: 0.6591 time: 0.05s
Test loss: 0.6014 score: 0.5581 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1627;  Loss pred: 0.1627; Loss self: 0.0000; time: 0.10s
Val loss: 0.5646 score: 0.6591 time: 0.17s
Test loss: 0.5937 score: 0.5814 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1442;  Loss pred: 0.1442; Loss self: 0.0000; time: 0.09s
Val loss: 0.5529 score: 0.6591 time: 0.06s
Test loss: 0.5851 score: 0.5814 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1421;  Loss pred: 0.1421; Loss self: 0.0000; time: 0.09s
Val loss: 0.5409 score: 0.6818 time: 0.06s
Test loss: 0.5764 score: 0.6047 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1358;  Loss pred: 0.1358; Loss self: 0.0000; time: 0.09s
Val loss: 0.5288 score: 0.7045 time: 0.06s
Test loss: 0.5679 score: 0.6047 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1205;  Loss pred: 0.1205; Loss self: 0.0000; time: 0.09s
Val loss: 0.5155 score: 0.7273 time: 0.06s
Test loss: 0.5586 score: 0.6512 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1126;  Loss pred: 0.1126; Loss self: 0.0000; time: 0.09s
Val loss: 0.5017 score: 0.7500 time: 0.06s
Test loss: 0.5489 score: 0.6512 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1050;  Loss pred: 0.1050; Loss self: 0.0000; time: 0.09s
Val loss: 0.4874 score: 0.7500 time: 0.06s
Test loss: 0.5389 score: 0.6512 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0993;  Loss pred: 0.0993; Loss self: 0.0000; time: 0.09s
Val loss: 0.4729 score: 0.7727 time: 0.06s
Test loss: 0.5289 score: 0.6512 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0876;  Loss pred: 0.0876; Loss self: 0.0000; time: 0.09s
Val loss: 0.4582 score: 0.7955 time: 0.06s
Test loss: 0.5189 score: 0.6744 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0809;  Loss pred: 0.0809; Loss self: 0.0000; time: 0.09s
Val loss: 0.4433 score: 0.8409 time: 0.06s
Test loss: 0.5092 score: 0.6977 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0754;  Loss pred: 0.0754; Loss self: 0.0000; time: 0.10s
Val loss: 0.4283 score: 0.8409 time: 0.14s
Test loss: 0.4994 score: 0.7209 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0716;  Loss pred: 0.0716; Loss self: 0.0000; time: 0.09s
Val loss: 0.4138 score: 0.8409 time: 0.06s
Test loss: 0.4906 score: 0.7209 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0667;  Loss pred: 0.0667; Loss self: 0.0000; time: 0.09s
Val loss: 0.3993 score: 0.8636 time: 0.06s
Test loss: 0.4819 score: 0.7209 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0621;  Loss pred: 0.0621; Loss self: 0.0000; time: 0.09s
Val loss: 0.3851 score: 0.8636 time: 0.06s
Test loss: 0.4735 score: 0.6977 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0557;  Loss pred: 0.0557; Loss self: 0.0000; time: 0.09s
Val loss: 0.3710 score: 0.8636 time: 0.06s
Test loss: 0.4654 score: 0.7209 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0482;  Loss pred: 0.0482; Loss self: 0.0000; time: 0.09s
Val loss: 0.3570 score: 0.8636 time: 0.06s
Test loss: 0.4574 score: 0.7209 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0505;  Loss pred: 0.0505; Loss self: 0.0000; time: 0.09s
Val loss: 0.3439 score: 0.8864 time: 0.06s
Test loss: 0.4507 score: 0.7209 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0421;  Loss pred: 0.0421; Loss self: 0.0000; time: 0.09s
Val loss: 0.3317 score: 0.8864 time: 0.06s
Test loss: 0.4451 score: 0.7209 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0387;  Loss pred: 0.0387; Loss self: 0.0000; time: 0.09s
Val loss: 0.3196 score: 0.8864 time: 0.05s
Test loss: 0.4397 score: 0.7209 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0381;  Loss pred: 0.0381; Loss self: 0.0000; time: 0.13s
Val loss: 0.3075 score: 0.9091 time: 0.08s
Test loss: 0.4342 score: 0.7209 time: 0.06s
Epoch 84/1000, LR 0.000266
Train loss: 0.0338;  Loss pred: 0.0338; Loss self: 0.0000; time: 0.09s
Val loss: 0.2956 score: 0.9091 time: 0.06s
Test loss: 0.4292 score: 0.7442 time: 0.06s
Epoch 85/1000, LR 0.000266
Train loss: 0.0284;  Loss pred: 0.0284; Loss self: 0.0000; time: 0.09s
Val loss: 0.2851 score: 0.9091 time: 0.06s
Test loss: 0.4256 score: 0.7674 time: 0.06s
Epoch 86/1000, LR 0.000266
Train loss: 0.0286;  Loss pred: 0.0286; Loss self: 0.0000; time: 0.09s
Val loss: 0.2749 score: 0.9318 time: 0.06s
Test loss: 0.4223 score: 0.7674 time: 0.06s
Epoch 87/1000, LR 0.000266
Train loss: 0.0291;  Loss pred: 0.0291; Loss self: 0.0000; time: 0.09s
Val loss: 0.2654 score: 0.9545 time: 0.06s
Test loss: 0.4202 score: 0.7674 time: 0.06s
Epoch 88/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.09s
Val loss: 0.2567 score: 0.9545 time: 0.06s
Test loss: 0.4190 score: 0.8140 time: 0.06s
Epoch 89/1000, LR 0.000266
Train loss: 0.0247;  Loss pred: 0.0247; Loss self: 0.0000; time: 0.09s
Val loss: 0.2486 score: 0.9545 time: 0.06s
Test loss: 0.4188 score: 0.8140 time: 0.06s
Epoch 90/1000, LR 0.000266
Train loss: 0.0223;  Loss pred: 0.0223; Loss self: 0.0000; time: 0.09s
Val loss: 0.2413 score: 0.9545 time: 0.06s
Test loss: 0.4193 score: 0.8140 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0203;  Loss pred: 0.0203; Loss self: 0.0000; time: 0.09s
Val loss: 0.2348 score: 0.9318 time: 0.06s
Test loss: 0.4208 score: 0.8140 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0193;  Loss pred: 0.0193; Loss self: 0.0000; time: 0.11s
Val loss: 0.2294 score: 0.9318 time: 0.10s
Test loss: 0.4228 score: 0.8140 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.09s
Val loss: 0.2246 score: 0.9318 time: 0.06s
Test loss: 0.4260 score: 0.8140 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0163;  Loss pred: 0.0163; Loss self: 0.0000; time: 0.09s
Val loss: 0.2205 score: 0.9318 time: 0.06s
Test loss: 0.4299 score: 0.8140 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.09s
Val loss: 0.2167 score: 0.9318 time: 0.06s
Test loss: 0.4344 score: 0.8140 time: 0.05s
Epoch 96/1000, LR 0.000265
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.09s
Val loss: 0.2136 score: 0.9318 time: 0.06s
Test loss: 0.4391 score: 0.8140 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.09s
Val loss: 0.2108 score: 0.9091 time: 0.06s
Test loss: 0.4445 score: 0.8140 time: 0.05s
Epoch 98/1000, LR 0.000265
Train loss: 0.0127;  Loss pred: 0.0127; Loss self: 0.0000; time: 0.09s
Val loss: 0.2089 score: 0.9091 time: 0.06s
Test loss: 0.4502 score: 0.8140 time: 0.05s
Epoch 99/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.09s
Val loss: 0.2072 score: 0.9091 time: 0.06s
Test loss: 0.4563 score: 0.8605 time: 0.05s
Epoch 100/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.09s
Val loss: 0.2061 score: 0.9091 time: 0.06s
Test loss: 0.4622 score: 0.8605 time: 0.05s
Epoch 101/1000, LR 0.000265
Train loss: 0.0110;  Loss pred: 0.0110; Loss self: 0.0000; time: 0.09s
Val loss: 0.2053 score: 0.9091 time: 0.06s
Test loss: 0.4682 score: 0.8605 time: 0.08s
Epoch 102/1000, LR 0.000264
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.16s
Val loss: 0.2048 score: 0.9091 time: 0.06s
Test loss: 0.4744 score: 0.8605 time: 0.05s
Epoch 103/1000, LR 0.000264
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.09s
Val loss: 0.2048 score: 0.9091 time: 0.06s
Test loss: 0.4805 score: 0.8605 time: 0.05s
Epoch 104/1000, LR 0.000264
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.08s
Val loss: 0.2050 score: 0.9091 time: 0.06s
Test loss: 0.4865 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.08s
Val loss: 0.2058 score: 0.8864 time: 0.06s
Test loss: 0.4934 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.08s
Val loss: 0.2068 score: 0.8636 time: 0.06s
Test loss: 0.5001 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.09s
Val loss: 0.2084 score: 0.8636 time: 0.06s
Test loss: 0.5066 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.09s
Val loss: 0.2099 score: 0.8636 time: 0.06s
Test loss: 0.5128 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.09s
Val loss: 0.2113 score: 0.8636 time: 0.06s
Test loss: 0.5192 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.09s
Val loss: 0.2127 score: 0.8636 time: 0.06s
Test loss: 0.5255 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.09s
Val loss: 0.2141 score: 0.8636 time: 0.16s
Test loss: 0.5320 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.09s
Val loss: 0.2155 score: 0.8636 time: 0.06s
Test loss: 0.5383 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.09s
Val loss: 0.2168 score: 0.8409 time: 0.06s
Test loss: 0.5446 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.09s
Val loss: 0.2186 score: 0.8409 time: 0.06s
Test loss: 0.5513 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.09s
Val loss: 0.2198 score: 0.8409 time: 0.06s
Test loss: 0.5570 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.09s
Val loss: 0.2206 score: 0.8409 time: 0.06s
Test loss: 0.5629 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.09s
Val loss: 0.2210 score: 0.8409 time: 0.06s
Test loss: 0.5686 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.09s
Val loss: 0.2208 score: 0.8636 time: 0.06s
Test loss: 0.5731 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.09s
Val loss: 0.2212 score: 0.8636 time: 0.06s
Test loss: 0.5788 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.11s
Val loss: 0.2211 score: 0.8636 time: 0.11s
Test loss: 0.5832 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.09s
Val loss: 0.2210 score: 0.8636 time: 0.06s
Test loss: 0.5878 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 122/1000, LR 0.000262
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.08s
Val loss: 0.2205 score: 0.8636 time: 0.06s
Test loss: 0.5908 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.09s
Val loss: 0.2201 score: 0.8636 time: 0.06s
Test loss: 0.5936 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 102,   Train_Loss: 0.0093,   Val_Loss: 0.2048,   Val_Precision: 0.9091,   Val_Recall: 0.9091,   Val_accuracy: 0.9091,   Val_Score: 0.9091,   Val_Loss: 0.2048,   Test_Precision: 0.8947,   Test_Recall: 0.8095,   Test_accuracy: 0.8500,   Test_Score: 0.8605,   Test_loss: 0.4805


[0.06074426101986319, 0.059028086019679904, 0.05874600599054247, 0.06079551507718861, 0.06321562407538295, 0.06270843907259405, 0.06536631390918046, 0.06283698603510857, 0.06271927093621343, 0.06306841899640858, 0.07520813902374357, 0.05976025993004441, 0.06243361404631287, 0.05957525398116559, 0.059525432996451855, 0.059973533032462, 0.05800680606625974, 0.056894168024882674, 0.05510518199298531, 0.05449301900807768, 0.05515331099741161, 0.05549279798287898, 0.06334471795707941, 0.05661569791845977, 0.055145860998891294, 0.05496636999305338, 0.05719642201438546, 0.05918717698659748, 0.05913324898574501, 0.05909340491052717, 0.05927100498229265, 0.059538622037507594, 0.059240264003165066, 0.05963940196670592, 0.06032122194301337, 0.0626551799941808, 0.05608038103673607, 0.055358786950819194, 0.06604191299993545, 0.05650275596417487, 0.05742081208154559, 0.057418336044065654, 0.058398799039423466, 0.061070100986398757, 0.05906275298912078, 0.061187247978523374, 0.06133498402778059, 0.05932216008659452, 0.0595215029316023, 0.0594805390574038, 0.05977310996968299, 0.059653901029378176, 0.05981613998301327, 0.059609813964925706, 0.0589029339607805, 0.05933281499892473, 0.05992406199220568, 0.06144561502151191, 0.059153751004487276, 0.05911252205260098, 0.059136906056664884, 0.05914165894500911, 0.059589818003587425, 0.05873132194392383, 0.06986286002211273, 0.0588657520711422, 0.05314820702187717, 0.055647752014920115, 0.1930290349991992, 0.060329369036480784, 0.060372709995135665, 0.060540712089277804, 0.06010044598951936, 0.06088265299331397, 0.060538665973581374, 0.05823659198358655, 0.05594830203335732, 0.055836500017903745, 0.1920686640078202, 0.05938835896085948, 0.05949453799985349, 0.059269950026646256, 0.0596458240179345, 0.05953155003953725, 0.059728470048867166, 0.059596647042781115, 0.05962085200008005, 0.06127785798162222, 0.05942752293776721, 0.059349951916374266, 0.05943524499889463, 0.05986315000336617, 0.06029568798840046, 0.06033212994225323, 0.05627713992726058, 0.05973769898992032, 0.05985945393331349, 0.05583558394573629, 0.06282017903868109, 0.05733621004037559, 0.058079159003682435, 0.05885315500199795, 0.058433050056919456, 0.05882444197777659, 0.058866948005743325, 0.05945258401334286, 0.06700974598061293, 0.05944264598656446, 0.05956155096646398, 0.06455620599444956, 0.05978387000504881, 0.05973589501809329, 0.06001776293851435, 0.05954045907128602, 0.057491942890919745, 0.05729704594705254, 0.05748383095487952, 0.05761027801781893, 0.0573397750267759, 0.05768566601909697, 0.057488169986754656, 0.08332827396225184, 0.0676330920541659, 0.057601311011239886, 0.056528884917497635, 0.05701617000158876, 0.05657009105198085, 0.05669385998044163, 0.05685853597242385, 0.056949632009491324, 0.0566585500491783, 0.05657975596841425, 0.05690919701009989, 0.05984611401800066, 0.05618844705168158, 0.05660704802721739, 0.055755109060555696, 0.056033573928289115, 0.05639624397736043, 0.05619603698141873, 0.05695629504043609, 0.05575331998988986, 0.05658595100976527, 0.05609816708602011, 0.05638951703440398, 0.055910701979883015, 0.05592777696438134, 0.056523610022850335, 0.05684299499262124, 0.06353142799343914, 0.05583205004222691, 0.056003840058110654, 0.056638103909790516, 0.05590864398982376, 0.05630275805015117, 0.05551802203990519, 0.05630700895562768, 0.05582375102676451, 0.054988033953122795, 0.055796333006583154, 0.056013581925071776, 0.055429956992156804, 0.05571288906503469, 0.055632036994211376, 0.055381382000632584, 0.05562333995476365, 0.055667171953246, 0.055540955043397844, 0.05556309793610126, 0.055575556005351245, 0.05617575498763472, 0.0558155809994787, 0.055649518966674805, 0.05571041605435312, 0.05594007100444287, 0.05534966895356774, 0.0555379610741511, 0.05560658103786409, 0.05643460096325725, 0.05738639703486115, 0.05911720707081258, 0.056746899033896625, 0.05656960606575012, 0.05659650801680982, 0.056346245924942195, 0.05709314497653395, 0.056751328986138105, 0.0568376500159502, 0.05691105290316045, 0.05764693394303322, 0.056587903993204236, 0.056852829991839826, 0.057263875962235034, 0.05613934004213661, 0.05710114096291363, 0.05697847704868764, 0.05639104195870459, 0.05671604792587459, 0.05676563398446888, 0.05717651697341353, 0.056953751016408205, 0.05790471995715052, 0.05704191199038178, 0.05749804596416652, 0.05726881406735629, 0.05728642002213746, 0.05742248601745814, 0.0574717529816553, 0.05710292898584157, 0.056902440963312984, 0.057091495022177696, 0.057472466956824064, 0.0570435969857499, 0.05693352408707142, 0.05667173396795988, 0.05744160898029804, 0.05844489694572985, 0.05719871702603996, 0.05645713396370411, 0.18293511401861906, 0.055894774035550654, 0.05545684590470046, 0.05586858105380088, 0.05580561002716422, 0.05443222005851567, 0.055165020981803536, 0.05568624206352979, 0.05516287207137793, 0.05384043394587934, 0.05359101598151028, 0.09577506093773991, 0.05747771798633039, 0.05744578596204519, 0.06442181288730353, 0.06436469801701605, 0.0652468460611999, 0.055496177985332906, 0.05564308597240597, 0.05521599599160254, 0.055539494031108916, 0.05503086501266807, 0.05543628707528114, 0.05406488198786974, 0.05463579192291945, 0.054293327033519745, 0.055637720040977, 0.05547460599336773, 0.053458018926903605, 0.05387968698050827, 0.14806498191319406, 0.05319308093748987, 0.052828366053290665, 0.05363326508086175, 0.05266005406156182, 0.05296875303611159, 0.05657820706255734, 0.05437559902202338, 0.05573109001852572, 0.05483961489517242, 0.05288202199153602, 0.05335725599434227, 0.05251801200211048, 0.0528626210289076, 0.053006435045972466, 0.05285660095978528, 0.055546985007822514, 0.05468584306072444, 0.054454869008623064, 0.0552299830596894, 0.05424290394876152, 0.05358449695631862, 0.05381018994376063, 0.05313229106832296, 0.05394623102620244, 0.05611319502349943, 0.05423488805536181, 0.05371647502761334, 0.05458005506079644, 0.05692319991067052, 0.05514142999891192, 0.05471170705277473, 0.05443317792378366, 0.05430263408925384, 0.054919349029660225, 0.05534929898567498, 0.05475407594349235, 0.05453781702090055, 0.058557276031933725, 0.055306358030065894, 0.05446347105316818, 0.05393676192034036, 0.055088254041038454, 0.05431164207402617, 0.055916589917615056, 0.05510157090611756, 0.05459993495605886, 0.056178230908699334, 0.05414019199088216, 0.054852253990247846, 0.05546309892088175, 0.054795420030131936, 0.05554509593639523, 0.05669534194748849, 0.05555107106920332, 0.05500232905615121, 0.05510191502980888, 0.05997767695225775, 0.060650288010947406, 0.060749031021259725, 0.0609059400158003, 0.06115644401870668, 0.062155370018444955, 0.061421946971677244, 0.05742088600527495, 0.05747518700081855, 0.05929614801425487, 0.059794720029458404, 0.05979873600881547, 0.059420066070742905, 0.05512156896293163, 0.05610890802927315, 0.05663292505778372, 0.05676694307476282, 0.055574481026269495, 0.08420116594061255, 0.0559616630198434, 0.05526259797625244, 0.05463468004018068, 0.05490891495719552, 0.055312252952717245, 0.05753467895556241, 0.05656348401680589, 0.055629254900850356, 0.05540235107764602, 0.055070495000109076, 0.0553154869703576, 0.0553718029987067, 0.055056090001016855, 0.05535780300851911, 0.057047521928325295, 0.05686640599742532, 0.055847479961812496, 0.0571620489936322, 0.05552467692177743, 0.055125150945968926, 0.05521705199498683, 0.055117160896770656]
[0.0013805513868150724, 0.0013415474095381796, 0.0013351364997850562, 0.0013817162517542865, 0.001436718728985976, 0.0014251917971044102, 0.0014855980433904651, 0.0014281133189797401, 0.0014254379758230325, 0.001433373159009286, 0.001709275886903263, 0.0013581877256828275, 0.001418945773779838, 0.0013539830450264906, 0.0013528507499193604, 0.0013630348416468637, 0.0013183365015059032, 0.001293049273292788, 0.001252390499840575, 0.0012384777047290381, 0.0012534843408502638, 0.0012611999541563405, 0.0014396526808427138, 0.0012867204072377222, 0.0012533150227020749, 0.001249235681660304, 0.0012999186821451242, 0.0013451631133317608, 0.0013439374769487504, 0.0013430319297847084, 0.0013470682950521057, 0.0013531505008524453, 0.0013463696364355696, 0.001355440953788771, 0.0013709368623412129, 0.0014239813635041091, 0.0012745541144712743, 0.0012581542488822545, 0.0015009525681803511, 0.001284153544640338, 0.0013050184563987634, 0.001304962182819674, 0.0013272454327141697, 0.0013879568405999717, 0.0013423352952072905, 0.0013906192722391677, 0.0013939769097222861, 0.0013482309110589665, 0.0013527614302636887, 0.0013518304331228137, 0.0013584797720382498, 0.001355770477940413, 0.0013594577268866653, 0.001354768499202857, 0.0013387030445631933, 0.0013484730681573803, 0.0013619104998228563, 0.001396491250488907, 0.0013444034319201653, 0.001343466410286386, 0.001344020592196929, 0.0013441286123865707, 0.0013543140455360779, 0.0013348027714528143, 0.0015877922732298348, 0.001337858001616868, 0.0012079137959517539, 0.00126472163670273, 0.004387023522709073, 0.0013711220235563815, 0.0013721070453439925, 0.0013759252747563137, 0.0013659192270345309, 0.0013836966589389538, 0.0013758787721268493, 0.0013235589087178762, 0.0012715523189399391, 0.001269011364043267, 0.00436519690926864, 0.0013497354309286245, 0.0013521485909057612, 0.001347044318787415, 0.0013555869094985114, 0.0013529897736258465, 0.0013574652283833448, 0.0013544692509722981, 0.001355019363638183, 0.001392678590491414, 0.0013506255213128911, 0.0013488625435539607, 0.0013508010227021507, 0.0013605261364401404, 0.0013703565451909196, 0.0013711847714148462, 0.0012790259074377404, 0.0013576749770436436, 0.001360442134848034, 0.0012689905442212794, 0.0014277313417882067, 0.0013030956827358089, 0.001319980886447328, 0.0013375717045908625, 0.0013280238649299877, 0.0013369191358585588, 0.001337885181948712, 0.0013511950912123377, 0.0015229487722866577, 0.001350969226967374, 0.0013536716128741814, 0.0014671864998738536, 0.001358724318296564, 0.0013576339776839384, 0.0013640400667844171, 0.0013531922516201369, 0.001337021927695808, 0.0013324894406291287, 0.001336833278020454, 0.0013397739073911378, 0.001333483140157579, 0.0013415271167231853, 0.0013369341857384803, 0.0019378668363314382, 0.001572862605910835, 0.001339565372354416, 0.0013146252306394798, 0.001325957441897413, 0.001315583512836764, 0.0013184618600102704, 0.0013222915342424152, 0.0013244100467323563, 0.0013176406988181, 0.001315808278335215, 0.0013234696979092997, 0.0013917700934418758, 0.001306708070969339, 0.0013164429773771485, 0.001296630443268737, 0.0013031063704253283, 0.0013115405576130331, 0.0013068845809632262, 0.001324565000940374, 0.0012965888369741829, 0.0013159523490643085, 0.0013046085368841887, 0.0013113841170791624, 0.0013002488832530934, 0.0013006459759158451, 0.001314502558670938, 0.0013219301161074707, 0.0014774750696148636, 0.0012984197684238817, 0.0013024148850723407, 0.0013171652072044306, 0.001300201023019157, 0.0013093664662825854, 0.0012911167916257022, 0.001309465324549481, 0.001298226768064291, 0.0012787914872819254, 0.0012975891396879804, 0.0013026414401179484, 0.0012890687672594606, 0.0012956485829077834, 0.0012937683021909622, 0.0012879391162937811, 0.0012935660454596197, 0.0012945853942615349, 0.001291650117288322, 0.0012921650682814246, 0.001292454790822122, 0.0013064129066891795, 0.0012980367674297372, 0.0012941748596901118, 0.0012955910710314678, 0.001300931883824253, 0.0012872016035713428, 0.0012915804900965372, 0.0012931763032061417, 0.0013124325805408663, 0.0013345673729037476, 0.0013748187690886648, 0.001319695326369689, 0.0013155722340872122, 0.0013161978608560423, 0.001310377812207958, 0.0013277475575938127, 0.0013197983485148397, 0.0013218058143244233, 0.0013235128582130338, 0.0013406263707682145, 0.0013159977672838193, 0.0013221588370195309, 0.001331718045633373, 0.001305566047491549, 0.0013279335107654333, 0.001325080861597387, 0.0013114195804349905, 0.0013189778587412695, 0.001320131022894625, 0.001329686441242175, 0.0013245058375908885, 0.0013466213943523376, 0.0013265560927995762, 0.0013371638596317795, 0.0013318328852873556, 0.00133224232609622, 0.001335406651568794, 0.0013365523949222162, 0.00132797509269399, 0.0013233125805421624, 0.001327709186562272, 0.0013365689989959086, 0.0013265952787383697, 0.001324035443885382, 0.0013179473015804623, 0.0013358513716348382, 0.0013591836499006942, 0.001330202721535813, 0.0013129566038070724, 0.004254304977177188, 0.0012998784659430385, 0.0012896940908069874, 0.0012992693268325786, 0.0012978048843526563, 0.0012658655827561783, 0.0012829074646931054, 0.0012950288851983672, 0.001282857490032045, 0.0012521031150204498, 0.001246302697244425, 0.002227326998552091, 0.001336691115961172, 0.0013359485107452371, 0.0014981816950535706, 0.0014968534422561872, 0.0015173685130511606, 0.0012906087903565792, 0.001294025255172232, 0.0012840929300372685, 0.0012916161402583468, 0.0012797875584341413, 0.0012892159784949103, 0.0012573228369272033, 0.0012705998121609176, 0.001262635512407436, 0.0012939004660692326, 0.0012901071161248309, 0.0012432097424861304, 0.00125301597629089, 0.0034433716723998617, 0.0012370483938951133, 0.0012285666524021084, 0.0012472852344386452, 0.0012246524200363214, 0.0012318314659560835, 0.0013157722572687753, 0.00126454881446566, 0.001296071860895947, 0.0012753398812830794, 0.0012298144649194424, 0.001240866418473076, 0.0012213491163281507, 0.001229363279742037, 0.0012327077917668016, 0.0012292232781345414, 0.0012917903490191282, 0.0012717637921098707, 0.0012663923025261177, 0.0012844182106904513, 0.0012614628825293377, 0.0012461510920074098, 0.0012513997661339682, 0.0012356346760075106, 0.001254563512237266, 0.0013049580238023123, 0.001261276466403763, 0.00124922034947938, 0.0012693036060650335, 0.0013237953467597795, 0.001282358837183998, 0.0012723652802970867, 0.0012658878586926433, 0.0012628519555640428, 0.0012771941634804704, 0.0012871929996668599, 0.0012733506033370315, 0.0012683213260674545, 0.0013617971170217145, 0.00128619437279223, 0.0012665923500736786, 0.0012543433004730316, 0.0012811221870008944, 0.0012630614435820038, 0.0013003858120375594, 0.0012814318815376176, 0.0012697659292106713, 0.0013064704862488217, 0.0012590742323460968, 0.001275633813726694, 0.0012898395097879476, 0.0012743120937239985, 0.0012917464171254703, 0.0013184963243601973, 0.0012918853737024028, 0.0012791239315384003, 0.00128143988441416, 0.0013948296965641338, 0.0014104718142080792, 0.0014127681632851098, 0.0014164172096697743, 0.0014222428841559694, 0.001445473721359185, 0.0014284173714343546, 0.0013353694419831383, 0.0013366322558329895, 0.0013789801863780201, 0.0013905748844060095, 0.0013906682792747783, 0.0013818620016451837, 0.001281896952626317, 0.0013048583262621663, 0.001317044768785668, 0.0013201614668549493, 0.001292429791308593, 0.001958166649781687, 0.0013014340237172883, 0.0012851766971221498, 0.0012705739544228065, 0.001276951510632454, 0.00128633146401668, 0.001338015789664242, 0.0013154298608559509, 0.0012937036023453572, 0.0012884267692475817, 0.0012807091860490482, 0.0012864066737292464, 0.0012877163488071324, 0.0012803741860701594, 0.0012873907676399794, 0.0013266865564726812, 0.0013224745580796586, 0.0012987786037630814, 0.0013293499765960977, 0.0012912715563204052, 0.0012819802545574169, 0.0012841174882555076, 0.0012817944394597827]
[724.3482637086017, 745.4078722005394, 748.9870887066529, 723.7375971588644, 696.0304615126661, 701.6599464238564, 673.1295887532119, 700.2245457065067, 701.5387670043032, 697.6550340116434, 585.0430627742163, 736.2752446442931, 704.7485664911385, 738.561685593659, 739.1798393574511, 733.6569612496237, 758.5316790195255, 773.365733738414, 798.4730003359946, 807.4428761870898, 797.7762205802106, 792.8956837529652, 694.6119805887075, 777.1696122755669, 797.883997148664, 800.4894630218567, 769.2788893146771, 743.4042682921588, 744.0822338479471, 744.5839356628719, 742.3528589256265, 739.0160956745234, 742.7380809384845, 737.7672905667847, 729.4281943022914, 702.2563817402898, 784.5881070454445, 794.8151038621862, 666.2435717154802, 778.7230772937493, 766.2726876365635, 766.3057314345061, 753.4401515739523, 720.4834982964818, 744.9703539573358, 719.1040854696379, 717.3719973591415, 741.7127079622816, 739.2286456637619, 739.7377477957326, 736.1169599894813, 737.5879739755999, 735.5874185879467, 738.1334896614425, 746.99165289961, 741.5795121265929, 734.262640702212, 716.0803905143717, 743.8243433905359, 744.3431352979123, 744.0362192408118, 743.9764251610176, 738.3811777601186, 749.1743509878908, 629.8053069409596, 747.4634817682072, 827.8736474005317, 790.6878248775054, 227.94498247469627, 729.3296897137028, 728.8061112967292, 726.7836548588056, 732.1077119406561, 722.7017522516965, 726.8082190512965, 755.5387171763244, 786.4403100878103, 788.0150078513442, 229.0847402271123, 740.885937410708, 739.5636890248371, 742.3660721869804, 737.687855343736, 739.1038864396755, 736.6671197839349, 738.2965684028306, 737.99683372423, 718.0407646297949, 740.3976781276416, 741.3653858051515, 740.3014827451002, 735.0097680714401, 729.7370917878011, 729.2963142875033, 781.8449917119269, 736.5533112921578, 735.0551518398123, 788.0279364994431, 700.4118847370254, 767.4033559074734, 757.5867274044074, 747.6234706279772, 752.9985163728359, 747.9883959906132, 747.4482963802907, 740.0855779477162, 656.6209042596573, 740.2093104998239, 738.7316026201889, 681.5766094398896, 735.9844720036383, 736.5755545584933, 733.1162950054658, 738.9932944138054, 747.9308897524039, 750.4749902767369, 748.0364353891404, 746.3945927617299, 749.9157431280527, 745.4191477266597, 747.9799758786417, 516.031329527829, 635.7834411232037, 746.5107867355537, 760.6730623248155, 754.1720181976762, 760.1189816097055, 758.4595583160898, 756.2628770613231, 755.0531668551176, 758.9322346349669, 759.989138588806, 755.5896455957484, 718.5094756038187, 765.2818729880365, 759.6227236460918, 771.2297711281964, 767.3970618941909, 762.4621245567669, 765.178512752029, 754.964836976706, 771.2545191532538, 759.9059348243403, 766.5134572768559, 762.5530818745111, 769.0835292225743, 768.8487248006543, 760.7440498336314, 756.469640728498, 676.8303713311873, 770.166955493811, 767.8044926094778, 759.2062062756833, 769.1118390892591, 763.7281278778233, 774.5232704632831, 763.6704701165326, 770.2814520540512, 781.9883147060218, 770.65996424759, 767.6709562605766, 775.7538041403205, 771.8142196827256, 772.9359254717607, 776.4342175409931, 773.0567785927682, 772.4480783057389, 774.2034678085971, 773.8949338183215, 773.7214540122573, 765.4547768777663, 770.3942022999207, 772.693112149813, 771.8484808666234, 768.679753670403, 776.8790818978927, 774.2452039711877, 773.2897653017021, 761.9439008348072, 749.30649460147, 727.3685975809573, 757.7506565480311, 760.1254983112602, 759.7641887592871, 763.1386846477671, 753.1552171048482, 757.6915072861649, 756.5407786552228, 755.5650055037388, 745.9199832291629, 759.8797086593623, 756.3387786706811, 750.9097014033433, 765.9512913355485, 753.0497512812901, 754.6709253611124, 762.5324609445786, 758.1628405455741, 757.5005682445973, 752.057003052399, 754.9985599300005, 742.5992221673811, 753.8316739321522, 747.8515013675094, 750.8449528817878, 750.6141941385638, 748.8355691693098, 748.1936389468647, 753.0261715762718, 755.679357019563, 753.1769834245235, 748.184344206132, 753.8094067024185, 755.2667903402194, 758.7556792299778, 748.5862733188518, 735.7357484936365, 751.7651135500831, 761.6397960910377, 235.05602098689198, 769.3026895976141, 775.3776706647388, 769.6633633596571, 770.5318511717568, 789.9732907049205, 779.4794461182888, 772.1835485135331, 779.5098113158466, 798.6562672066092, 802.3732935915165, 448.9686519536942, 748.1159918392455, 748.531842325395, 667.4757830119149, 668.0680765197114, 659.035686716061, 774.8281334142412, 772.7824445488911, 778.7598363079352, 774.2238338706279, 781.3796855655717, 775.6652234231891, 795.3406799195028, 787.0298660750574, 791.9941979877666, 772.8569748783854, 775.1294349912258, 804.369500837592, 798.074421173899, 290.4130297683052, 808.3758120822458, 813.9566526934358, 801.7412315877059, 816.5582198174576, 811.799363498035, 760.0099443316717, 790.7958859006593, 771.5621565217234, 784.1047039115027, 813.1307839719578, 805.8885187903873, 818.7667118525356, 813.4292088257545, 811.2222593861691, 813.521853830812, 774.1194232944316, 786.3095381422902, 789.6447238389435, 778.5626143236015, 792.730419459443, 802.4709093574778, 799.1051517368953, 809.3006933336676, 797.0899761118492, 766.3081737190726, 792.8475846784551, 800.4992877491596, 787.8335767910553, 755.403773285406, 779.8129283344393, 785.9378242123271, 789.9593894776419, 791.8584562458534, 782.9663089556477, 776.8842747426464, 785.3296628433129, 788.4437322366807, 734.3237751795406, 777.487463134422, 789.5200061344357, 797.2299127542556, 780.5656713673807, 791.7271207044611, 769.0025458160849, 780.3770254257124, 787.5467257352175, 765.4210412905926, 794.2343464027927, 783.9240299522595, 775.2902530985441, 784.7371181086731, 774.1457508551135, 758.4397328413121, 774.0624829075268, 781.7850759756341, 780.3721517979544, 716.9334023094627, 708.9826183882009, 707.8302201223872, 706.0066717440842, 703.1147852031269, 691.8147215154461, 700.0754961386696, 748.8564352011186, 748.1489359814976, 725.1735810842679, 719.1270396251654, 719.0787443008993, 723.6612619852374, 780.0939053261856, 766.3667234009621, 759.2756326134705, 757.4830996865276, 773.7364201327284, 510.68176455333275, 768.3831694700114, 778.1031217258019, 787.0458830979876, 783.1150922126368, 777.4046021368508, 747.3753357207669, 760.2077691541072, 772.9745810300741, 776.1403471801367, 780.8173868768536, 777.3591512091865, 776.568536173625, 781.021681692358, 776.7649303817684, 753.7575436497548, 756.158214077163, 769.954168556981, 752.2473521687468, 774.4304403711874, 780.04321552147, 778.744942846713, 780.1562943442428]
Elapsed: 0.059024067445301184~0.013714180511782205
Time per graph: 0.0013618939255606818~0.00031303121133728233
Speed: 748.7793794787494~67.51536764307025
Total Time: 0.0561
best val loss: 0.20482906699180603 test_score: 0.8605

Testing...
Test loss: 0.4202 score: 0.7674 time: 0.05s
test Score 0.7674
Epoch Time List: [0.36252292699646205, 0.17585298896301538, 0.17699241894297302, 0.19013942300807685, 0.1860430199885741, 0.18583217996638268, 0.1871291009010747, 0.3122514970600605, 0.1866011469392106, 0.18643719202373177, 0.19955656491219997, 0.17864725599065423, 0.18055730685591698, 0.17791697196662426, 0.17772243113722652, 0.17938545299693942, 0.17950201698113233, 0.2761366720078513, 0.16401567799039185, 0.16457327897660434, 0.165421576006338, 0.17067032889463007, 0.17727166682016104, 0.17041036405134946, 0.16698420408647507, 0.16483752604108304, 0.1658637758810073, 0.2981450309744105, 0.17669245088472962, 0.17761647095903754, 0.17726971313823014, 0.17808674392290413, 0.17804095102474093, 0.18344914796762168, 0.18059850600548089, 0.1867371939588338, 0.17077136191073805, 0.16687174909748137, 0.33689167292322963, 0.16621388599742204, 0.17274088005069643, 0.17163564800284803, 0.1751059809466824, 0.1857604261022061, 0.18185617891140282, 0.1822875359794125, 0.179985360824503, 0.24431791913229972, 0.18015804106835276, 0.18029065593145788, 0.17981343402061611, 0.1807570798555389, 0.1807817880762741, 0.18157147290185094, 0.17913489404600114, 0.1785621070303023, 0.17989255592692643, 0.18110319890547544, 0.29709769401233643, 0.1779034190112725, 0.17735126393381506, 0.17848623706959188, 0.1790919229388237, 0.17769003997091204, 0.18611655198037624, 0.1758458949625492, 0.16179840883705765, 0.16509067418519408, 0.30610773898661137, 0.1800620690919459, 0.1812744998605922, 0.1819184529595077, 0.1800069579621777, 0.1806415340397507, 0.18364306702278554, 0.18109729222487658, 0.16986623802222311, 0.16877145902253687, 0.3112798990914598, 0.18039796606171876, 0.17948741593863815, 0.17961129697505385, 0.17996804194990546, 0.18076479097362608, 0.17893189005553722, 0.17946866096463054, 0.1794285780051723, 0.17944774101488292, 0.30402283393777907, 0.17925130110234022, 0.17927048518322408, 0.17981454997789115, 0.18044375302270055, 0.18139954307116568, 0.176535211969167, 0.18506514001637697, 0.17956836812663823, 0.17148038209415972, 0.1714168981416151, 0.3307177349925041, 0.17233454110100865, 0.17572528088930994, 0.17533049802295864, 0.17559965688269585, 0.17693818092811853, 0.17799312679562718, 0.1848073760047555, 0.18068460910581052, 0.17970253096427768, 0.18387515610083938, 0.17904849303886294, 0.17763584689237177, 0.17744557501282543, 0.17755294404923916, 0.18514871201477945, 0.18371394276618958, 0.18487619108054787, 0.1847538659349084, 0.1858885909896344, 0.18539738398976624, 0.18582684395369142, 0.2272212109528482, 0.23486842995043844, 0.19687164400238544, 0.19182004500180483, 0.19220284989569336, 0.19056342693511397, 0.1912429879885167, 0.19134836795274168, 0.19261908100452274, 0.19202827801927924, 0.19151143508497626, 0.19178863684646785, 0.21156541805248708, 0.19109548802953213, 0.19181929004844278, 0.1905146238859743, 0.18960893899202347, 0.19274502992630005, 0.19114589598029852, 0.19312970608007163, 0.190692875883542, 0.19110561592970043, 0.19077330292202532, 0.19149778492283076, 0.19131369492970407, 0.1918536729644984, 0.19177204684820026, 0.19249795901123434, 0.2085207209456712, 0.19941265089437366, 0.19101122091524303, 0.19059635803569108, 0.19054442597553134, 0.19042814010754228, 0.19031000102404505, 0.18927522690501064, 0.18913876311853528, 0.18884039903059602, 0.18758902000263333, 0.18915503099560738, 0.18817844602745026, 0.19020171696320176, 0.19128971197642386, 0.19029825902543962, 0.188995894161053, 0.18913068203255534, 0.18962398602161556, 0.1891186919528991, 0.1894437219016254, 0.18970524705946445, 0.1899910030188039, 0.18981951812747866, 0.18987335287965834, 0.1894952580332756, 0.19015675398986787, 0.18922902806662023, 0.19417838286608458, 0.19586363004054874, 0.19447565695736557, 0.19872316683176905, 0.19504042295739055, 0.1925878239562735, 0.19340803695376962, 0.19173084909562021, 0.19344290089793503, 0.19278348004445434, 0.19258210598491132, 0.1927204019157216, 0.19384300394449383, 0.1931531480513513, 0.19351577223278582, 0.19257843308150768, 0.1906252191402018, 0.19253523694351315, 0.19486966205295175, 0.19237812492065132, 0.19362932699732482, 0.19338167796377093, 0.1961036049760878, 0.19414619693998247, 0.19399298704229295, 0.19469866889994591, 0.1942349299788475, 0.1930617339676246, 0.19345364288892597, 0.1935014941263944, 0.19439183198846877, 0.1940211660694331, 0.19279075402300805, 0.19471140403766185, 0.1939054278191179, 0.19539969810284674, 0.1922340210294351, 0.19272853794973344, 0.19328581006266177, 0.1987704539205879, 0.19411346095148474, 0.1908356740605086, 0.3181701930006966, 0.18851372797507793, 0.18712106603197753, 0.18643995001912117, 0.1866554708685726, 0.1922381758922711, 0.19152079720515758, 0.19318134593777359, 0.19874472508672625, 0.19292477506678551, 0.18812530185095966, 0.2289152251323685, 0.2571132758166641, 0.19884457695297897, 0.21737883402965963, 0.21727012319024652, 0.2202220589388162, 0.20918758888728917, 0.19637975201476365, 0.1937595100607723, 0.19381969107780606, 0.3232256571063772, 0.19323290092870593, 0.19198751111980528, 0.192288952996023, 0.18958232586737722, 0.19118086202070117, 0.19971753901336342, 0.190777896088548, 0.19006642291788012, 0.2847926439717412, 0.18853090098127723, 0.1873264330206439, 0.18777281302027404, 0.1862450969638303, 0.18733702297322452, 0.19083011685870588, 0.19514446007087827, 0.19248265109490603, 0.19058754097204655, 0.24904220108874142, 0.18637756805401295, 0.18565666396170855, 0.18606037087738514, 0.18802216101903468, 0.18603442003950477, 0.19482255692128092, 0.19148270704317838, 0.1920501230051741, 0.19241278595291078, 0.29055168107151985, 0.19011663692072034, 0.18786008306778967, 0.1881330410251394, 0.18900386011227965, 0.19179992307908833, 0.1934955280739814, 0.19080817291978747, 0.19163705897517502, 0.19253166811540723, 0.3149465039605275, 0.1928561070235446, 0.18994551990181208, 0.19000759918708354, 0.190938068786636, 0.19804120098706335, 0.1940973880700767, 0.19136071612592787, 0.31778885587118566, 0.19507500901818275, 0.193211629986763, 0.19265013001859188, 0.19360974710434675, 0.19334116310346872, 0.1930849419441074, 0.19446152506861836, 0.19291028112638742, 0.19140726199839264, 0.28601969487499446, 0.1921062549808994, 0.19390566705260426, 0.1920026809675619, 0.19383157114498317, 0.19528276997152716, 0.19528300291858613, 0.1941924880957231, 0.19149804580956697, 0.25618259294424206, 0.20898705208674073, 0.2085463759722188, 0.2085522279376164, 0.20962733402848244, 0.2091453931061551, 0.2120410359930247, 0.19960986205842346, 0.19660484394989908, 0.2699608429102227, 0.20581024698913097, 0.20419990306254476, 0.20429795992095023, 0.19534272199962288, 0.19356968102511019, 0.19692404509987682, 0.19568646198604256, 0.19233242911286652, 0.2194839350413531, 0.26284295704681426, 0.19168317702133209, 0.19008269405458122, 0.1898390610003844, 0.19016895606182516, 0.19461478991433978, 0.19692221703007817, 0.19482972100377083, 0.19211978209204972, 0.29574762796983123, 0.19162288994994015, 0.19351114379242063, 0.19309719605371356, 0.19376853900030255, 0.19661782693583518, 0.1989331260556355, 0.19675091316457838, 0.19467118789907545, 0.27051010983996093, 0.1915349760092795, 0.19074966094922274, 0.19220391300041229]
Total Epoch List: [114, 110, 123]
Total Time List: [0.06013755197636783, 0.05672051291912794, 0.05611437396146357]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce0c2560>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6929;  Loss pred: 0.6929; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6932;  Loss pred: 0.6932; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6907;  Loss pred: 0.6907; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6900;  Loss pred: 0.6900; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6897;  Loss pred: 0.6897; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.18s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6896;  Loss pred: 0.6896; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6847;  Loss pred: 0.6847; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6830;  Loss pred: 0.6830; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6808;  Loss pred: 0.6808; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6782;  Loss pred: 0.6782; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6752;  Loss pred: 0.6752; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6716;  Loss pred: 0.6716; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6691;  Loss pred: 0.6691; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6650;  Loss pred: 0.6650; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6624;  Loss pred: 0.6624; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6546;  Loss pred: 0.6546; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6515;  Loss pred: 0.6515; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6502;  Loss pred: 0.6502; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6479;  Loss pred: 0.6479; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6953,   Val_Loss: 0.6938,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.4884,   Val_Loss: 0.6938,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.5000,   Test_loss: 0.6933


[0.059250109014101326, 0.059568543918430805, 0.05919622804503888, 0.06063406995963305, 0.05964412703178823, 0.05993950192350894, 0.18574074597563595, 0.05967470596078783, 0.06061991897877306, 0.059877497027628124, 0.05965579394251108, 0.05997841607313603, 0.06160526000894606, 0.06027685001026839, 0.05972012202255428, 0.059860168024897575, 0.06475911301095039, 0.07051941810641438, 0.06105661892797798, 0.06163387803826481, 0.06753696594387293]
[0.001346593386684121, 0.0013538305436007001, 0.001345368819205429, 0.0013780470445371147, 0.0013555483416315508, 0.001362261407352476, 0.004221380590355362, 0.0013562433172906326, 0.0013777254313357514, 0.0013608522051733664, 0.0013558134986934338, 0.0013631458198440007, 0.001400119545657865, 0.0013699284093242816, 0.0013572755005125973, 0.0013604583642022176, 0.0014717980229761451, 0.0016027140478730541, 0.0013876504301813177, 0.0014007699554151093, 0.0015349310441789303]
[742.6146674182177, 738.644880429689, 743.2906023424841, 725.6646309458175, 737.7088439327738, 734.0735005798023, 236.88932532752713, 737.3308220221871, 725.8340285048424, 734.833655115843, 737.5645698790262, 733.5972318166523, 714.2247268108357, 729.9651523346763, 736.7700954023952, 735.0463831257395, 679.4410539959041, 623.9416203577239, 720.642589985242, 713.8930958179042, 651.4950647407896]
Elapsed: 0.06717847866405334~0.026661721304911117
Time per graph: 0.001526783606001212~0.0006059482114752525
Speed: 696.831740042194~107.20697445786338
Total Time: 0.0679
best val loss: 0.6937988996505737 test_score: 0.5000

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.06s
test Score 0.5000
Epoch Time List: [0.18147643096745014, 0.18395806709304452, 0.18323602399323136, 0.18905723688658327, 0.1855300449533388, 0.1833313669776544, 0.310766956070438, 0.18400421703699976, 0.1835572940763086, 0.18476721306797117, 0.18431131693068892, 0.185238266014494, 0.18579593184404075, 0.18902515689842403, 0.1873923601815477, 0.18503436807077378, 0.30588470702059567, 0.2030300849583, 0.19226663117296994, 0.19295232906006277, 0.21055712294764817]
Total Epoch List: [21]
Total Time List: [0.06786648801062256]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce23ba30>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6907;  Loss pred: 0.6907; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6880;  Loss pred: 0.6880; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6842;  Loss pred: 0.6842; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6818;  Loss pred: 0.6818; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6786;  Loss pred: 0.6786; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6758;  Loss pred: 0.6758; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6732;  Loss pred: 0.6732; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6697;  Loss pred: 0.6697; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6680;  Loss pred: 0.6680; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6633;  Loss pred: 0.6633; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6589;  Loss pred: 0.6589; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6569;  Loss pred: 0.6569; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6523;  Loss pred: 0.6523; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6483;  Loss pred: 0.6483; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6442;  Loss pred: 0.6442; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.06s
Epoch 21/1000, LR 0.000270
Train loss: 0.6369;  Loss pred: 0.6369; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.06s
Epoch 22/1000, LR 0.000270
Train loss: 0.6316;  Loss pred: 0.6316; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6253;  Loss pred: 0.6253; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6152;  Loss pred: 0.6152; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6138;  Loss pred: 0.6138; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6075;  Loss pred: 0.6075; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5961;  Loss pred: 0.5961; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5931;  Loss pred: 0.5931; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5799;  Loss pred: 0.5799; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5752;  Loss pred: 0.5752; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5655;  Loss pred: 0.5655; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5534;  Loss pred: 0.5534; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5460;  Loss pred: 0.5460; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.4884 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5342;  Loss pred: 0.5342; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5274;  Loss pred: 0.5274; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.4884 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5213;  Loss pred: 0.5213; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.4884 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5044;  Loss pred: 0.5044; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.4884 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4874;  Loss pred: 0.4874; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6878 score: 0.4884 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4796;  Loss pred: 0.4796; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.4884 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4702;  Loss pred: 0.4702; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6862 score: 0.4884 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4581;  Loss pred: 0.4581; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6853 score: 0.4884 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4484;  Loss pred: 0.4484; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6843 score: 0.4884 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4324;  Loss pred: 0.4324; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6866 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6831 score: 0.4884 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4192;  Loss pred: 0.4192; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6857 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6818 score: 0.4884 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4073;  Loss pred: 0.4073; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6846 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6801 score: 0.4884 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3952;  Loss pred: 0.3952; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6833 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6783 score: 0.4884 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3762;  Loss pred: 0.3762; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6819 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6763 score: 0.4884 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3749;  Loss pred: 0.3749; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6803 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6742 score: 0.4884 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3544;  Loss pred: 0.3544; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6788 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6721 score: 0.4884 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3397;  Loss pred: 0.3397; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6772 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6699 score: 0.4884 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3299;  Loss pred: 0.3299; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6757 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6678 score: 0.4884 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3119;  Loss pred: 0.3119; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6738 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6653 score: 0.4884 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2911;  Loss pred: 0.2911; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6718 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6626 score: 0.4884 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2833;  Loss pred: 0.2833; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6696 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6596 score: 0.4884 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2780;  Loss pred: 0.2780; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6676 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6567 score: 0.4884 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2605;  Loss pred: 0.2605; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6655 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6540 score: 0.4884 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2509;  Loss pred: 0.2509; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6633 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6510 score: 0.4884 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2391;  Loss pred: 0.2391; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6615 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6485 score: 0.4884 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2244;  Loss pred: 0.2244; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6595 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6458 score: 0.4884 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2103;  Loss pred: 0.2103; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6576 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6433 score: 0.4884 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.2022;  Loss pred: 0.2022; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6559 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6409 score: 0.4884 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1850;  Loss pred: 0.1850; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6542 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6385 score: 0.4884 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1649;  Loss pred: 0.1649; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6528 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6364 score: 0.4884 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1637;  Loss pred: 0.1637; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6517 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6348 score: 0.4884 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1510;  Loss pred: 0.1510; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6505 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6331 score: 0.4884 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1486;  Loss pred: 0.1486; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6491 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6311 score: 0.4884 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1361;  Loss pred: 0.1361; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6469 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6283 score: 0.4884 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1253;  Loss pred: 0.1253; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6442 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6251 score: 0.4884 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1198;  Loss pred: 0.1198; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6410 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6212 score: 0.4884 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1052;  Loss pred: 0.1052; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6385 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6180 score: 0.4884 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.1035;  Loss pred: 0.1035; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6363 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6151 score: 0.4884 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0892;  Loss pred: 0.0892; Loss self: 0.0000; time: 0.09s
Val loss: 0.6343 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6126 score: 0.4884 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0875;  Loss pred: 0.0875; Loss self: 0.0000; time: 0.09s
Val loss: 0.6314 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6090 score: 0.4884 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0738;  Loss pred: 0.0738; Loss self: 0.0000; time: 0.09s
Val loss: 0.6276 score: 0.5227 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6046 score: 0.4884 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0724;  Loss pred: 0.0724; Loss self: 0.0000; time: 0.09s
Val loss: 0.6216 score: 0.5227 time: 0.05s
Test loss: 0.5977 score: 0.5349 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0641;  Loss pred: 0.0641; Loss self: 0.0000; time: 0.09s
Val loss: 0.6158 score: 0.5455 time: 0.06s
Test loss: 0.5912 score: 0.6047 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0630;  Loss pred: 0.0630; Loss self: 0.0000; time: 0.09s
Val loss: 0.6082 score: 0.5909 time: 0.06s
Test loss: 0.5825 score: 0.6279 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0569;  Loss pred: 0.0569; Loss self: 0.0000; time: 0.09s
Val loss: 0.5991 score: 0.6136 time: 0.06s
Test loss: 0.5719 score: 0.6512 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0508;  Loss pred: 0.0508; Loss self: 0.0000; time: 0.09s
Val loss: 0.5917 score: 0.6136 time: 0.06s
Test loss: 0.5631 score: 0.7209 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0459;  Loss pred: 0.0459; Loss self: 0.0000; time: 0.09s
Val loss: 0.5813 score: 0.6591 time: 0.06s
Test loss: 0.5510 score: 0.7442 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0447;  Loss pred: 0.0447; Loss self: 0.0000; time: 0.09s
Val loss: 0.5702 score: 0.6818 time: 0.06s
Test loss: 0.5382 score: 0.7442 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0431;  Loss pred: 0.0431; Loss self: 0.0000; time: 0.09s
Val loss: 0.5571 score: 0.6818 time: 0.06s
Test loss: 0.5230 score: 0.7674 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0352;  Loss pred: 0.0352; Loss self: 0.0000; time: 0.09s
Val loss: 0.5410 score: 0.7045 time: 0.06s
Test loss: 0.5049 score: 0.7907 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0324;  Loss pred: 0.0324; Loss self: 0.0000; time: 0.09s
Val loss: 0.5255 score: 0.7273 time: 0.06s
Test loss: 0.4879 score: 0.8140 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0298;  Loss pred: 0.0298; Loss self: 0.0000; time: 0.09s
Val loss: 0.5092 score: 0.7727 time: 0.06s
Test loss: 0.4707 score: 0.8372 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0302;  Loss pred: 0.0302; Loss self: 0.0000; time: 0.09s
Val loss: 0.4925 score: 0.8182 time: 0.06s
Test loss: 0.4541 score: 0.8372 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0261;  Loss pred: 0.0261; Loss self: 0.0000; time: 0.09s
Val loss: 0.4759 score: 0.8182 time: 0.06s
Test loss: 0.4384 score: 0.8605 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.09s
Val loss: 0.4589 score: 0.8182 time: 0.06s
Test loss: 0.4230 score: 0.8605 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0238;  Loss pred: 0.0238; Loss self: 0.0000; time: 0.09s
Val loss: 0.4445 score: 0.8182 time: 0.06s
Test loss: 0.4103 score: 0.8605 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0218;  Loss pred: 0.0218; Loss self: 0.0000; time: 0.09s
Val loss: 0.4316 score: 0.8409 time: 0.06s
Test loss: 0.3994 score: 0.8605 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0174;  Loss pred: 0.0174; Loss self: 0.0000; time: 0.09s
Val loss: 0.4201 score: 0.8409 time: 0.06s
Test loss: 0.3898 score: 0.8605 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.09s
Val loss: 0.4115 score: 0.8409 time: 0.06s
Test loss: 0.3828 score: 0.8605 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0185;  Loss pred: 0.0185; Loss self: 0.0000; time: 0.09s
Val loss: 0.4060 score: 0.8409 time: 0.06s
Test loss: 0.3783 score: 0.8605 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0135;  Loss pred: 0.0135; Loss self: 0.0000; time: 0.09s
Val loss: 0.4021 score: 0.8409 time: 0.06s
Test loss: 0.3749 score: 0.8605 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.09s
Val loss: 0.4004 score: 0.8409 time: 0.06s
Test loss: 0.3735 score: 0.8605 time: 0.05s
Epoch 96/1000, LR 0.000265
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.09s
Val loss: 0.4002 score: 0.7955 time: 0.06s
Test loss: 0.3740 score: 0.8837 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.09s
Val loss: 0.4000 score: 0.7955 time: 0.06s
Test loss: 0.3751 score: 0.8837 time: 0.05s
Epoch 98/1000, LR 0.000265
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.09s
Val loss: 0.4011 score: 0.7955 time: 0.06s
Test loss: 0.3770 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.09s
Val loss: 0.4027 score: 0.8182 time: 0.05s
Test loss: 0.3795 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.09s
Val loss: 0.4030 score: 0.8182 time: 0.06s
Test loss: 0.3793 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.09s
Val loss: 0.4051 score: 0.8182 time: 0.06s
Test loss: 0.3812 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.09s
Val loss: 0.4080 score: 0.8182 time: 0.05s
Test loss: 0.3837 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.09s
Val loss: 0.4110 score: 0.8182 time: 0.05s
Test loss: 0.3860 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.09s
Val loss: 0.4146 score: 0.8182 time: 0.06s
Test loss: 0.3887 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.09s
Val loss: 0.4195 score: 0.8182 time: 0.05s
Test loss: 0.3927 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.09s
Val loss: 0.4248 score: 0.8182 time: 0.06s
Test loss: 0.3970 score: 0.9070 time: 0.06s
     INFO: Early stopping counter 9 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.10s
Val loss: 0.4305 score: 0.8182 time: 0.06s
Test loss: 0.4022 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.10s
Val loss: 0.4366 score: 0.8182 time: 0.06s
Test loss: 0.4085 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.09s
Val loss: 0.4425 score: 0.8182 time: 0.05s
Test loss: 0.4143 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.08s
Val loss: 0.4478 score: 0.8182 time: 0.05s
Test loss: 0.4195 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.08s
Val loss: 0.4531 score: 0.8182 time: 0.05s
Test loss: 0.4250 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.08s
Val loss: 0.4586 score: 0.8182 time: 0.05s
Test loss: 0.4303 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.08s
Val loss: 0.4645 score: 0.8182 time: 0.05s
Test loss: 0.4373 score: 0.9070 time: 0.17s
     INFO: Early stopping counter 16 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.08s
Val loss: 0.4699 score: 0.8182 time: 0.05s
Test loss: 0.4443 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.08s
Val loss: 0.4755 score: 0.8182 time: 0.05s
Test loss: 0.4510 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.08s
Val loss: 0.4804 score: 0.8182 time: 0.05s
Test loss: 0.4567 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.08s
Val loss: 0.4848 score: 0.8182 time: 0.05s
Test loss: 0.4626 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 096,   Train_Loss: 0.0121,   Val_Loss: 0.4000,   Val_Precision: 0.8421,   Val_Recall: 0.7273,   Val_accuracy: 0.7805,   Val_Score: 0.7955,   Val_Loss: 0.4000,   Test_Precision: 1.0000,   Test_Recall: 0.7727,   Test_accuracy: 0.8718,   Test_Score: 0.8837,   Test_loss: 0.3751


[0.059250109014101326, 0.059568543918430805, 0.05919622804503888, 0.06063406995963305, 0.05964412703178823, 0.05993950192350894, 0.18574074597563595, 0.05967470596078783, 0.06061991897877306, 0.059877497027628124, 0.05965579394251108, 0.05997841607313603, 0.06160526000894606, 0.06027685001026839, 0.05972012202255428, 0.059860168024897575, 0.06475911301095039, 0.07051941810641438, 0.06105661892797798, 0.06163387803826481, 0.06753696594387293, 0.05752631602808833, 0.05673855694476515, 0.05871643405407667, 0.05634016101248562, 0.0577489510178566, 0.057895050034858286, 0.056435397011227906, 0.05587092705536634, 0.05542631901334971, 0.055472987005487084, 0.056097386055625975, 0.05747763405088335, 0.05582983198110014, 0.05605291202664375, 0.05610996705945581, 0.05706338002346456, 0.05711629497818649, 0.05680124100763351, 0.05675588210579008, 0.06800657510757446, 0.0645287960069254, 0.05619614303577691, 0.05572037701494992, 0.05591290001757443, 0.054170420044101775, 0.054506671032868326, 0.05504792393185198, 0.05483308993279934, 0.054616737994365394, 0.055476963985711336, 0.05579941801261157, 0.05444352107588202, 0.05486837902572006, 0.05520388495642692, 0.054866092978045344, 0.05535955401137471, 0.05449552298523486, 0.054558029980398715, 0.05381317401770502, 0.05372760503087193, 0.05540557694621384, 0.05422455398365855, 0.05385781603399664, 0.05536041094455868, 0.05379760998766869, 0.05494386504869908, 0.05524723406415433, 0.05491651291958988, 0.054843585938215256, 0.05494840501341969, 0.055803146911785007, 0.0544571690261364, 0.05405442405026406, 0.05516266205813736, 0.05416386993601918, 0.05453913996461779, 0.05537671595811844, 0.05496792297344655, 0.05476674600504339, 0.05556893500033766, 0.05500866298098117, 0.054660899098962545, 0.054931536084041, 0.05553414800669998, 0.05555833189282566, 0.05488007701933384, 0.054912924068048596, 0.05513063899707049, 0.05557951796799898, 0.055597085040062666, 0.05562367592938244, 0.05504160199780017, 0.055695799994282424, 0.055034062010236084, 0.05564815690740943, 0.0558126230025664, 0.055845313938334584, 0.056592799024656415, 0.056084592011757195, 0.05551976105198264, 0.05634352599736303, 0.05594716197811067, 0.05615190602838993, 0.05685933097265661, 0.056783062987960875, 0.05672965303529054, 0.056163132074289024, 0.05602044390980154, 0.05647916707675904, 0.05615818896330893, 0.056116131017915905, 0.055676941992715, 0.05604333698283881, 0.05608152598142624, 0.05593286803923547, 0.05591687199193984, 0.055632864008657634, 0.05663527094293386, 0.05590531101915985, 0.056559124030172825, 0.05652319802902639, 0.05560363503172994, 0.055747137987054884, 0.05588103400077671, 0.05573811801150441, 0.06824970792513341, 0.05969686491880566, 0.056657185894437134, 0.0549888089299202, 0.05442599195521325, 0.053924522013403475, 0.053578255930915475, 0.17915149498730898, 0.053530783974565566, 0.05331114202272147, 0.05337323504500091, 0.053301746025681496]
[0.001346593386684121, 0.0013538305436007001, 0.001345368819205429, 0.0013780470445371147, 0.0013555483416315508, 0.001362261407352476, 0.004221380590355362, 0.0013562433172906326, 0.0013777254313357514, 0.0013608522051733664, 0.0013558134986934338, 0.0013631458198440007, 0.001400119545657865, 0.0013699284093242816, 0.0013572755005125973, 0.0013604583642022176, 0.0014717980229761451, 0.0016027140478730541, 0.0013876504301813177, 0.0014007699554151093, 0.0015349310441789303, 0.0013378213029787984, 0.001319501324296864, 0.001365498466373876, 0.0013102363026159447, 0.001342998860880386, 0.0013463965124385648, 0.0013124510932843699, 0.0012993238850085194, 0.001288984163101156, 0.0012900694652438858, 0.0013045903733866506, 0.0013366891639740315, 0.0012983681856069801, 0.001303556093642878, 0.0013048829548710653, 0.0013270553493828967, 0.0013282859297252673, 0.0013209590932007791, 0.001319904235018374, 0.0015815482583156851, 0.0015006696745796606, 0.0013068870473436492, 0.001295822721277905, 0.0013003000004087077, 0.0012597772103279483, 0.0012675970007643797, 0.0012801842774849297, 0.0012751881379720776, 0.0012701566975433813, 0.0012901619531560777, 0.0012976608840142225, 0.0012661283971135352, 0.0012760088145516294, 0.00128381127805644, 0.0012759556506522173, 0.0012874314886366213, 0.0012673377438426712, 0.0012687913948929933, 0.0012514691632024425, 0.0012494791867644634, 0.0012885017894468335, 0.00126103613915485, 0.0012525073496278288, 0.0012874514173153182, 0.001251107209015551, 0.0012777643034581183, 0.0012848193968407983, 0.0012771282074323228, 0.001275432231121285, 0.001277869884033016, 0.0012977476025996513, 0.0012664457913054976, 0.0012570796290759085, 0.0012828526060031944, 0.0012596248822330043, 0.0012683520922004137, 0.001287830603677173, 0.0012783237900801522, 0.0012736452559312416, 0.001292300813961341, 0.001279271232115841, 0.0012711836999758732, 0.0012774775833497907, 0.0012914918141093018, 0.0012920542300657132, 0.0012762808609147404, 0.001277044745768572, 0.0012821078836528022, 0.0012925469294883484, 0.001292955466047969, 0.0012935738588228476, 0.0012800372557627948, 0.001295251162657731, 0.0012798619072147926, 0.0012941431838932426, 0.0012979679768038697, 0.00129872823112406, 0.0013161116052245677, 0.0013042928374827254, 0.001291157233767038, 0.00131031455807821, 0.0013010967901886203, 0.0013058582797299983, 0.001322310022619921, 0.0013205363485572297, 0.0013192942566346638, 0.0013061193505648611, 0.0013028010211581754, 0.001313469001785094, 0.0013060043944955566, 0.0013050263027422303, 0.0012948126044817442, 0.0013033334182055538, 0.001304221534451773, 0.0013007643730054762, 0.0013003923719055778, 0.0012937875350850613, 0.0013170993242542757, 0.001300123512073485, 0.0013153284658179727, 0.0013144929774192183, 0.00129310779143558, 0.0012964450694663927, 0.001299558930250621, 0.0012962353025931259, 0.0015872025098868233, 0.001388299184158271, 0.0013176089742892357, 0.001278809509998144, 0.0012657207431444942, 0.0012540586514744995, 0.0012460059518817552, 0.004166313836914163, 0.0012449019528968737, 0.0012397940005284063, 0.0012412380243023468, 0.0012395754889693372]
[742.6146674182177, 738.644880429689, 743.2906023424841, 725.6646309458175, 737.7088439327738, 734.0735005798023, 236.88932532752713, 737.3308220221871, 725.8340285048424, 734.833655115843, 737.5645698790262, 733.5972318166523, 714.2247268108357, 729.9651523346763, 736.7700954023952, 735.0463831257395, 679.4410539959041, 623.9416203577239, 720.642589985242, 713.8930958179042, 651.4950647407896, 747.4839859205381, 757.8620662111728, 732.33330144671, 763.2211059970296, 744.6022696880492, 742.7232548224752, 761.9331532556613, 769.631045452107, 775.8047217539962, 775.152057266119, 766.524129259095, 748.1170843241963, 770.1975534254989, 767.132312047601, 766.3522588497674, 753.5480720265489, 752.8499531775004, 757.025713473782, 757.6307231002099, 632.2918031378812, 666.3691663390888, 765.1770686935637, 771.7104998852213, 769.0532951516435, 793.7911495792796, 788.8942616596484, 781.1375421393361, 784.1980098640917, 787.3044341175438, 775.0964888971771, 770.6173564441355, 789.8093133996178, 783.6936458400448, 778.9306863808663, 783.7262991772795, 776.7403615853698, 789.0556442893578, 788.1516252593575, 799.0608393746224, 800.3334594068015, 776.0951581055311, 792.9986849307926, 798.3985086372074, 776.7283382896642, 799.2920133414164, 782.6169484416008, 778.3195073633449, 783.0067444916189, 784.0479294778828, 782.5522868133914, 770.5658619571306, 789.6113729188237, 795.4945548955477, 779.5127790366822, 793.8871437877971, 788.4246071334496, 776.4996398941573, 782.2744188601066, 785.1479800541773, 773.8136424557842, 781.6950580105341, 786.6683627385876, 782.7926008516006, 774.2983649413729, 773.9613220020499, 783.5265971811851, 783.0579181453534, 779.96556510591, 773.6662996026362, 773.4218434116583, 773.052109223976, 781.227261548793, 772.051034448096, 781.3342942413045, 772.7120247943853, 770.4350321973357, 769.9840320976866, 759.813982363122, 766.698989108912, 774.4990105367978, 763.1755244074087, 768.5823280334354, 765.7798824898225, 756.2523030859878, 757.2680608849305, 757.9810152064642, 765.6268162381388, 767.5769236893991, 761.342672450535, 765.6942076264984, 766.2680804967044, 772.3125312023476, 767.2633771462815, 766.7409052713948, 768.7787432934174, 768.9986665598578, 772.9244353357092, 759.244182716582, 769.1576921066238, 760.2663714710401, 760.7495948463176, 773.3307359395167, 771.340046371261, 769.4918458273755, 771.4648706137647, 630.039326280618, 720.3058327851012, 758.9505077099486, 781.9772938672088, 790.0636893377044, 797.4108697581394, 802.564384616117, 240.02032471482363, 803.2761115628509, 806.5856098463092, 805.6472492953658, 806.7277942317692]
Elapsed: 0.0584586424064701~0.015324804886786482
Time per graph: 0.0013541001342040526~0.00034979516766210525
Speed: 755.8990208968133~70.43128238756331
Total Time: 0.0539
best val loss: 0.39997243881225586 test_score: 0.8837

Testing...
Test loss: 0.3994 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.18147643096745014, 0.18395806709304452, 0.18323602399323136, 0.18905723688658327, 0.1855300449533388, 0.1833313669776544, 0.310766956070438, 0.18400421703699976, 0.1835572940763086, 0.18476721306797117, 0.18431131693068892, 0.185238266014494, 0.18579593184404075, 0.18902515689842403, 0.1873923601815477, 0.18503436807077378, 0.30588470702059567, 0.2030300849583, 0.19226663117296994, 0.19295232906006277, 0.21055712294764817, 0.2037318799411878, 0.19787091203033924, 0.20105997403152287, 0.19740025606006384, 0.20018024113960564, 0.202452351921238, 0.19923009793274105, 0.19652956095524132, 0.19381547113880515, 0.19627830805256963, 0.19602644292172045, 0.19832146493718028, 0.2008767951047048, 0.1968101520324126, 0.19676292699296027, 0.196882807998918, 0.1997454420197755, 0.19858740991912782, 0.19863588199950755, 0.2147769290022552, 0.22516425990033895, 0.19963994587305933, 0.1947060179663822, 0.1940508319530636, 0.19323793100193143, 0.19027630891650915, 0.1943620778620243, 0.1912236319622025, 0.19228634296450764, 0.1919725590851158, 0.19441399001516402, 0.19194538099691272, 0.19276434590574354, 0.1913485418772325, 0.19298584503121674, 0.19154103507753462, 0.19482996815349907, 0.19234793609939516, 0.1912803379818797, 0.1916248460765928, 0.19292688206769526, 0.19077371200546622, 0.1899694639723748, 0.1909499199828133, 0.18955640611238778, 0.1926437719957903, 0.19309437996707857, 0.19223813083954155, 0.19155029312241822, 0.19112843496259302, 0.19403037801384926, 0.19216607708949596, 0.19079667690675706, 0.1919445360545069, 0.19140635209623724, 0.19267867994494736, 0.19398666894994676, 0.19264864991419017, 0.19250706396996975, 0.19384713005274534, 0.19356688112020493, 0.19183324091136456, 0.19096378388348967, 0.19267801009118557, 0.19245294097345322, 0.1940115160541609, 0.19361458194907755, 0.19334598490968347, 0.19293982884846628, 0.19344324991106987, 0.1951396861113608, 0.19355915300548077, 0.1940374900586903, 0.19501839496660978, 0.19526302407030016, 0.19540651701390743, 0.19608785910531878, 0.1951395629439503, 0.1957723330706358, 0.1955338199622929, 0.19512296083848923, 0.19600310001987964, 0.19640121387783438, 0.1975813809549436, 0.19708274595905095, 0.19751121406443417, 0.19823079206980765, 0.19564600405283272, 0.19655198708642274, 0.19643731298856437, 0.19713636592496186, 0.19674337597098202, 0.19630946102552116, 0.19754230079706758, 0.1962137019727379, 0.19584155618213117, 0.19737168413121253, 0.1977033430011943, 0.19588870590087026, 0.1962624239968136, 0.197051377967, 0.1951486059697345, 0.19597293809056282, 0.1953103750711307, 0.1956892650341615, 0.208089247928001, 0.2072958400240168, 0.2113389529986307, 0.19144996418617666, 0.18841299193445593, 0.1862454239744693, 0.1840906449360773, 0.31186090887058526, 0.18428188911639154, 0.18345096497796476, 0.18274574493989348, 0.18176430312450975]
Total Epoch List: [21, 117]
Total Time List: [0.06786648801062256, 0.05390143708791584]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce23b9d0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7032;  Loss pred: 0.7032; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7011 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7040 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.7041;  Loss pred: 0.7041; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7010 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7039 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.7046;  Loss pred: 0.7046; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7008 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7037 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.7070;  Loss pred: 0.7070; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7007 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7036 score: 0.4884 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.7060;  Loss pred: 0.7060; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7005 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7033 score: 0.4884 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.7009;  Loss pred: 0.7009; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7002 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7030 score: 0.4884 time: 0.06s
Epoch 7/1000, LR 0.000150
Train loss: 0.6966;  Loss pred: 0.6966; Loss self: 0.0000; time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6998 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7025 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6994 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7020 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6889;  Loss pred: 0.6889; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6990 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7014 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6841;  Loss pred: 0.6841; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6985 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7009 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6767;  Loss pred: 0.6767; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6980 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7003 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6723;  Loss pred: 0.6723; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6997 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6728;  Loss pred: 0.6728; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6971 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6992 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6658;  Loss pred: 0.6658; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6987 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6606;  Loss pred: 0.6606; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6962 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6554;  Loss pred: 0.6554; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6977 score: 0.4884 time: 0.16s
Epoch 17/1000, LR 0.000270
Train loss: 0.6440;  Loss pred: 0.6440; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6373;  Loss pred: 0.6373; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6366;  Loss pred: 0.6366; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6284;  Loss pred: 0.6284; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6213;  Loss pred: 0.6213; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6095;  Loss pred: 0.6095; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6098;  Loss pred: 0.6098; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5933;  Loss pred: 0.5933; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5904;  Loss pred: 0.5904; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5850;  Loss pred: 0.5850; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.10s
Epoch 27/1000, LR 0.000270
Train loss: 0.5722;  Loss pred: 0.5722; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5617;  Loss pred: 0.5617; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5507;  Loss pred: 0.5507; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5413;  Loss pred: 0.5413; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5323;  Loss pred: 0.5323; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5258;  Loss pred: 0.5258; Loss self: 0.0000; time: 0.08s
Val loss: 0.6889 score: 0.5455 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5128;  Loss pred: 0.5128; Loss self: 0.0000; time: 0.08s
Val loss: 0.6881 score: 0.5682 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.4884 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4948;  Loss pred: 0.4948; Loss self: 0.0000; time: 0.08s
Val loss: 0.6872 score: 0.5909 time: 0.05s
Test loss: 0.6895 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4872;  Loss pred: 0.4872; Loss self: 0.0000; time: 0.08s
Val loss: 0.6862 score: 0.5909 time: 0.05s
Test loss: 0.6887 score: 0.5581 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4737;  Loss pred: 0.4737; Loss self: 0.0000; time: 0.08s
Val loss: 0.6850 score: 0.5909 time: 0.17s
Test loss: 0.6878 score: 0.5581 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4629;  Loss pred: 0.4629; Loss self: 0.0000; time: 0.07s
Val loss: 0.6837 score: 0.5909 time: 0.05s
Test loss: 0.6868 score: 0.6279 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4493;  Loss pred: 0.4493; Loss self: 0.0000; time: 0.07s
Val loss: 0.6824 score: 0.6818 time: 0.05s
Test loss: 0.6857 score: 0.6512 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4237;  Loss pred: 0.4237; Loss self: 0.0000; time: 0.08s
Val loss: 0.6809 score: 0.7273 time: 0.05s
Test loss: 0.6845 score: 0.6512 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4166;  Loss pred: 0.4166; Loss self: 0.0000; time: 0.07s
Val loss: 0.6794 score: 0.8182 time: 0.07s
Test loss: 0.6833 score: 0.6977 time: 0.06s
Epoch 41/1000, LR 0.000269
Train loss: 0.4102;  Loss pred: 0.4102; Loss self: 0.0000; time: 0.07s
Val loss: 0.6776 score: 0.8182 time: 0.05s
Test loss: 0.6819 score: 0.7442 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3845;  Loss pred: 0.3845; Loss self: 0.0000; time: 0.08s
Val loss: 0.6757 score: 0.7727 time: 0.05s
Test loss: 0.6804 score: 0.7442 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3855;  Loss pred: 0.3855; Loss self: 0.0000; time: 0.08s
Val loss: 0.6737 score: 0.8182 time: 0.05s
Test loss: 0.6787 score: 0.7674 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3537;  Loss pred: 0.3537; Loss self: 0.0000; time: 0.08s
Val loss: 0.6714 score: 0.8182 time: 0.05s
Test loss: 0.6768 score: 0.7674 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3607;  Loss pred: 0.3607; Loss self: 0.0000; time: 0.08s
Val loss: 0.6689 score: 0.8182 time: 0.05s
Test loss: 0.6748 score: 0.7907 time: 0.11s
Epoch 46/1000, LR 0.000269
Train loss: 0.3333;  Loss pred: 0.3333; Loss self: 0.0000; time: 0.11s
Val loss: 0.6660 score: 0.8409 time: 0.06s
Test loss: 0.6725 score: 0.7674 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3253;  Loss pred: 0.3253; Loss self: 0.0000; time: 0.08s
Val loss: 0.6630 score: 0.8409 time: 0.05s
Test loss: 0.6701 score: 0.7674 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2999;  Loss pred: 0.2999; Loss self: 0.0000; time: 0.07s
Val loss: 0.6596 score: 0.8409 time: 0.05s
Test loss: 0.6674 score: 0.7674 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3021;  Loss pred: 0.3021; Loss self: 0.0000; time: 0.07s
Val loss: 0.6559 score: 0.8409 time: 0.05s
Test loss: 0.6644 score: 0.7674 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2692;  Loss pred: 0.2692; Loss self: 0.0000; time: 0.07s
Val loss: 0.6520 score: 0.8636 time: 0.05s
Test loss: 0.6612 score: 0.7674 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2648;  Loss pred: 0.2648; Loss self: 0.0000; time: 0.08s
Val loss: 0.6478 score: 0.8636 time: 0.05s
Test loss: 0.6578 score: 0.7674 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2396;  Loss pred: 0.2396; Loss self: 0.0000; time: 0.08s
Val loss: 0.6432 score: 0.8636 time: 0.05s
Test loss: 0.6539 score: 0.7674 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2351;  Loss pred: 0.2351; Loss self: 0.0000; time: 0.07s
Val loss: 0.6381 score: 0.8636 time: 0.05s
Test loss: 0.6497 score: 0.7674 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2340;  Loss pred: 0.2340; Loss self: 0.0000; time: 0.07s
Val loss: 0.6327 score: 0.8636 time: 0.05s
Test loss: 0.6453 score: 0.7907 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2067;  Loss pred: 0.2067; Loss self: 0.0000; time: 0.07s
Val loss: 0.6268 score: 0.8636 time: 0.05s
Test loss: 0.6403 score: 0.7907 time: 0.16s
Epoch 56/1000, LR 0.000269
Train loss: 0.2035;  Loss pred: 0.2035; Loss self: 0.0000; time: 0.07s
Val loss: 0.6202 score: 0.8636 time: 0.05s
Test loss: 0.6349 score: 0.7907 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1825;  Loss pred: 0.1825; Loss self: 0.0000; time: 0.07s
Val loss: 0.6129 score: 0.8864 time: 0.05s
Test loss: 0.6288 score: 0.7907 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1829;  Loss pred: 0.1829; Loss self: 0.0000; time: 0.07s
Val loss: 0.6052 score: 0.8864 time: 0.05s
Test loss: 0.6224 score: 0.8140 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1640;  Loss pred: 0.1640; Loss self: 0.0000; time: 0.07s
Val loss: 0.5968 score: 0.8864 time: 0.05s
Test loss: 0.6155 score: 0.8140 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1572;  Loss pred: 0.1572; Loss self: 0.0000; time: 0.07s
Val loss: 0.5878 score: 0.8636 time: 0.05s
Test loss: 0.6081 score: 0.8140 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1425;  Loss pred: 0.1425; Loss self: 0.0000; time: 0.07s
Val loss: 0.5785 score: 0.8636 time: 0.05s
Test loss: 0.6003 score: 0.7907 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1334;  Loss pred: 0.1334; Loss self: 0.0000; time: 0.08s
Val loss: 0.5687 score: 0.8636 time: 0.06s
Test loss: 0.5922 score: 0.7907 time: 0.06s
Epoch 63/1000, LR 0.000268
Train loss: 0.1237;  Loss pred: 0.1237; Loss self: 0.0000; time: 0.08s
Val loss: 0.5582 score: 0.8864 time: 0.06s
Test loss: 0.5836 score: 0.7907 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1169;  Loss pred: 0.1169; Loss self: 0.0000; time: 0.07s
Val loss: 0.5474 score: 0.8864 time: 0.05s
Test loss: 0.5748 score: 0.8140 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1072;  Loss pred: 0.1072; Loss self: 0.0000; time: 0.07s
Val loss: 0.5363 score: 0.8864 time: 0.05s
Test loss: 0.5658 score: 0.8140 time: 0.06s
Epoch 66/1000, LR 0.000268
Train loss: 0.1040;  Loss pred: 0.1040; Loss self: 0.0000; time: 0.17s
Val loss: 0.5248 score: 0.8864 time: 0.05s
Test loss: 0.5564 score: 0.8140 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0947;  Loss pred: 0.0947; Loss self: 0.0000; time: 0.08s
Val loss: 0.5132 score: 0.8864 time: 0.05s
Test loss: 0.5469 score: 0.7907 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0898;  Loss pred: 0.0898; Loss self: 0.0000; time: 0.07s
Val loss: 0.5014 score: 0.8864 time: 0.05s
Test loss: 0.5374 score: 0.8140 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0811;  Loss pred: 0.0811; Loss self: 0.0000; time: 0.07s
Val loss: 0.4890 score: 0.8864 time: 0.05s
Test loss: 0.5275 score: 0.8140 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0733;  Loss pred: 0.0733; Loss self: 0.0000; time: 0.07s
Val loss: 0.4768 score: 0.8864 time: 0.05s
Test loss: 0.5179 score: 0.8140 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0633;  Loss pred: 0.0633; Loss self: 0.0000; time: 0.07s
Val loss: 0.4645 score: 0.8864 time: 0.05s
Test loss: 0.5084 score: 0.8140 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0646;  Loss pred: 0.0646; Loss self: 0.0000; time: 0.08s
Val loss: 0.4523 score: 0.8864 time: 0.05s
Test loss: 0.4990 score: 0.8140 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.07s
Val loss: 0.4400 score: 0.8864 time: 0.05s
Test loss: 0.4894 score: 0.8140 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0541;  Loss pred: 0.0541; Loss self: 0.0000; time: 0.08s
Val loss: 0.4281 score: 0.8864 time: 0.05s
Test loss: 0.4802 score: 0.7907 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0464;  Loss pred: 0.0464; Loss self: 0.0000; time: 0.08s
Val loss: 0.4160 score: 0.8864 time: 0.17s
Test loss: 0.4708 score: 0.8140 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0502;  Loss pred: 0.0502; Loss self: 0.0000; time: 0.07s
Val loss: 0.4048 score: 0.8864 time: 0.05s
Test loss: 0.4621 score: 0.8140 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0416;  Loss pred: 0.0416; Loss self: 0.0000; time: 0.07s
Val loss: 0.3940 score: 0.8864 time: 0.05s
Test loss: 0.4536 score: 0.8140 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0366;  Loss pred: 0.0366; Loss self: 0.0000; time: 0.07s
Val loss: 0.3838 score: 0.8864 time: 0.05s
Test loss: 0.4456 score: 0.8140 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0353;  Loss pred: 0.0353; Loss self: 0.0000; time: 0.08s
Val loss: 0.3739 score: 0.8864 time: 0.05s
Test loss: 0.4379 score: 0.8140 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0305;  Loss pred: 0.0305; Loss self: 0.0000; time: 0.08s
Val loss: 0.3646 score: 0.8864 time: 0.05s
Test loss: 0.4306 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0289;  Loss pred: 0.0289; Loss self: 0.0000; time: 0.08s
Val loss: 0.3561 score: 0.8864 time: 0.05s
Test loss: 0.4240 score: 0.8140 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0268;  Loss pred: 0.0268; Loss self: 0.0000; time: 0.08s
Val loss: 0.3483 score: 0.8864 time: 0.05s
Test loss: 0.4182 score: 0.8140 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0227;  Loss pred: 0.0227; Loss self: 0.0000; time: 0.07s
Val loss: 0.3413 score: 0.8636 time: 0.05s
Test loss: 0.4130 score: 0.8140 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0233;  Loss pred: 0.0233; Loss self: 0.0000; time: 0.08s
Val loss: 0.3351 score: 0.8636 time: 0.05s
Test loss: 0.4086 score: 0.8140 time: 0.08s
Epoch 85/1000, LR 0.000266
Train loss: 0.0229;  Loss pred: 0.0229; Loss self: 0.0000; time: 0.13s
Val loss: 0.3298 score: 0.8636 time: 0.06s
Test loss: 0.4050 score: 0.8140 time: 0.06s
Epoch 86/1000, LR 0.000266
Train loss: 0.0200;  Loss pred: 0.0200; Loss self: 0.0000; time: 0.08s
Val loss: 0.3254 score: 0.8636 time: 0.06s
Test loss: 0.4023 score: 0.8140 time: 0.06s
Epoch 87/1000, LR 0.000266
Train loss: 0.0191;  Loss pred: 0.0191; Loss self: 0.0000; time: 0.08s
Val loss: 0.3220 score: 0.8636 time: 0.06s
Test loss: 0.4006 score: 0.8140 time: 0.06s
Epoch 88/1000, LR 0.000266
Train loss: 0.0164;  Loss pred: 0.0164; Loss self: 0.0000; time: 0.08s
Val loss: 0.3193 score: 0.8636 time: 0.06s
Test loss: 0.3998 score: 0.8140 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0176;  Loss pred: 0.0176; Loss self: 0.0000; time: 0.08s
Val loss: 0.3174 score: 0.8636 time: 0.05s
Test loss: 0.3998 score: 0.8140 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.08s
Val loss: 0.3162 score: 0.8636 time: 0.05s
Test loss: 0.4007 score: 0.8140 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0125;  Loss pred: 0.0125; Loss self: 0.0000; time: 0.08s
Val loss: 0.3159 score: 0.8409 time: 0.05s
Test loss: 0.4022 score: 0.8140 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.07s
Val loss: 0.3161 score: 0.8409 time: 0.05s
Test loss: 0.4043 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.08s
Val loss: 0.3171 score: 0.8409 time: 0.05s
Test loss: 0.4073 score: 0.8140 time: 0.10s
     INFO: Early stopping counter 2 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.12s
Val loss: 0.3188 score: 0.8409 time: 0.06s
Test loss: 0.4110 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.08s
Val loss: 0.3206 score: 0.8409 time: 0.05s
Test loss: 0.4150 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.08s
Val loss: 0.3230 score: 0.8409 time: 0.05s
Test loss: 0.4195 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.08s
Val loss: 0.3259 score: 0.8409 time: 0.05s
Test loss: 0.4246 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.08s
Val loss: 0.3289 score: 0.8409 time: 0.06s
Test loss: 0.4300 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.08s
Val loss: 0.3324 score: 0.8409 time: 0.05s
Test loss: 0.4357 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.08s
Val loss: 0.3360 score: 0.8636 time: 0.05s
Test loss: 0.4417 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.08s
Val loss: 0.3399 score: 0.8636 time: 0.05s
Test loss: 0.4479 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.08s
Val loss: 0.3442 score: 0.8636 time: 0.05s
Test loss: 0.4546 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.12s
Val loss: 0.3484 score: 0.8636 time: 0.06s
Test loss: 0.4611 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 12 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.08s
Val loss: 0.3526 score: 0.8636 time: 0.06s
Test loss: 0.4676 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 13 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.08s
Val loss: 0.3571 score: 0.8636 time: 0.06s
Test loss: 0.4744 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 14 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.08s
Val loss: 0.3613 score: 0.8636 time: 0.05s
Test loss: 0.4806 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.08s
Val loss: 0.3655 score: 0.8636 time: 0.05s
Test loss: 0.4867 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.08s
Val loss: 0.3692 score: 0.8636 time: 0.05s
Test loss: 0.4926 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 17 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.08s
Val loss: 0.3732 score: 0.8636 time: 0.05s
Test loss: 0.4987 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.08s
Val loss: 0.3778 score: 0.8636 time: 0.05s
Test loss: 0.5051 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.08s
Val loss: 0.3821 score: 0.8636 time: 0.05s
Test loss: 0.5112 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 090,   Train_Loss: 0.0125,   Val_Loss: 0.3159,   Val_Precision: 0.8947,   Val_Recall: 0.7727,   Val_accuracy: 0.8293,   Val_Score: 0.8409,   Val_Loss: 0.3159,   Test_Precision: 0.8421,   Test_Recall: 0.7619,   Test_accuracy: 0.8000,   Test_Score: 0.8140,   Test_loss: 0.4022


[0.059250109014101326, 0.059568543918430805, 0.05919622804503888, 0.06063406995963305, 0.05964412703178823, 0.05993950192350894, 0.18574074597563595, 0.05967470596078783, 0.06061991897877306, 0.059877497027628124, 0.05965579394251108, 0.05997841607313603, 0.06160526000894606, 0.06027685001026839, 0.05972012202255428, 0.059860168024897575, 0.06475911301095039, 0.07051941810641438, 0.06105661892797798, 0.06163387803826481, 0.06753696594387293, 0.05752631602808833, 0.05673855694476515, 0.05871643405407667, 0.05634016101248562, 0.0577489510178566, 0.057895050034858286, 0.056435397011227906, 0.05587092705536634, 0.05542631901334971, 0.055472987005487084, 0.056097386055625975, 0.05747763405088335, 0.05582983198110014, 0.05605291202664375, 0.05610996705945581, 0.05706338002346456, 0.05711629497818649, 0.05680124100763351, 0.05675588210579008, 0.06800657510757446, 0.0645287960069254, 0.05619614303577691, 0.05572037701494992, 0.05591290001757443, 0.054170420044101775, 0.054506671032868326, 0.05504792393185198, 0.05483308993279934, 0.054616737994365394, 0.055476963985711336, 0.05579941801261157, 0.05444352107588202, 0.05486837902572006, 0.05520388495642692, 0.054866092978045344, 0.05535955401137471, 0.05449552298523486, 0.054558029980398715, 0.05381317401770502, 0.05372760503087193, 0.05540557694621384, 0.05422455398365855, 0.05385781603399664, 0.05536041094455868, 0.05379760998766869, 0.05494386504869908, 0.05524723406415433, 0.05491651291958988, 0.054843585938215256, 0.05494840501341969, 0.055803146911785007, 0.0544571690261364, 0.05405442405026406, 0.05516266205813736, 0.05416386993601918, 0.05453913996461779, 0.05537671595811844, 0.05496792297344655, 0.05476674600504339, 0.05556893500033766, 0.05500866298098117, 0.054660899098962545, 0.054931536084041, 0.05553414800669998, 0.05555833189282566, 0.05488007701933384, 0.054912924068048596, 0.05513063899707049, 0.05557951796799898, 0.055597085040062666, 0.05562367592938244, 0.05504160199780017, 0.055695799994282424, 0.055034062010236084, 0.05564815690740943, 0.0558126230025664, 0.055845313938334584, 0.056592799024656415, 0.056084592011757195, 0.05551976105198264, 0.05634352599736303, 0.05594716197811067, 0.05615190602838993, 0.05685933097265661, 0.056783062987960875, 0.05672965303529054, 0.056163132074289024, 0.05602044390980154, 0.05647916707675904, 0.05615818896330893, 0.056116131017915905, 0.055676941992715, 0.05604333698283881, 0.05608152598142624, 0.05593286803923547, 0.05591687199193984, 0.055632864008657634, 0.05663527094293386, 0.05590531101915985, 0.056559124030172825, 0.05652319802902639, 0.05560363503172994, 0.055747137987054884, 0.05588103400077671, 0.05573811801150441, 0.06824970792513341, 0.05969686491880566, 0.056657185894437134, 0.0549888089299202, 0.05442599195521325, 0.053924522013403475, 0.053578255930915475, 0.17915149498730898, 0.053530783974565566, 0.05331114202272147, 0.05337323504500091, 0.053301746025681496, 0.05698535300325602, 0.056460554944351315, 0.05706854700110853, 0.05660039698705077, 0.05635737907141447, 0.06916755391284823, 0.057277254993095994, 0.05697021901141852, 0.056501677026972175, 0.05676263093482703, 0.05679141101427376, 0.05855672305915505, 0.05770192597992718, 0.05613219796214253, 0.05578308296389878, 0.16458558198064566, 0.056567813036963344, 0.055680386954918504, 0.05602376698516309, 0.055814503924921155, 0.055721745011396706, 0.05857198289595544, 0.05701481702271849, 0.056429013959132135, 0.056252331007272005, 0.10363469994626939, 0.05679083103314042, 0.05664031999185681, 0.056454631965607405, 0.05662966403178871, 0.056637400994077325, 0.05905753490515053, 0.058055323897860944, 0.05617604695726186, 0.05605664697941393, 0.05645412299782038, 0.05693766206968576, 0.056583142024464905, 0.05596754094585776, 0.06448609405197203, 0.054873535060323775, 0.05705046094954014, 0.056503487983718514, 0.05672451399732381, 0.11274531797971576, 0.0585509940283373, 0.054658310022205114, 0.05503819801378995, 0.05613074405118823, 0.05617772205732763, 0.05791746801696718, 0.05590012494940311, 0.05558090005069971, 0.0555259280372411, 0.1687906529987231, 0.05581670394167304, 0.05558016605209559, 0.055287520051933825, 0.05558557598851621, 0.05578845401760191, 0.055658162105828524, 0.06204014096874744, 0.057721584918908775, 0.05634499609004706, 0.06558179890271276, 0.059443299076519907, 0.05510430200956762, 0.05504237697459757, 0.054962993948720396, 0.05541547096800059, 0.05651339201722294, 0.05584852199535817, 0.056083631003275514, 0.05549301696009934, 0.05636051995679736, 0.05599839997012168, 0.055948961060494184, 0.056202242034487426, 0.0570735780056566, 0.05617902707308531, 0.057166486978530884, 0.05663261597510427, 0.05637901299633086, 0.08840245299506932, 0.06209465395659208, 0.061879524029791355, 0.06197850999888033, 0.057227837969549, 0.05742872506380081, 0.05930304899811745, 0.05837573600001633, 0.05700769100803882, 0.10710023005958647, 0.06276813906151801, 0.05660618096590042, 0.05702507006935775, 0.05713832005858421, 0.057776640984229743, 0.059047800954431295, 0.05897547001950443, 0.057594750076532364, 0.05991618998814374, 0.06165997905191034, 0.06154650391545147, 0.0620491310255602, 0.05787068698555231, 0.05770456092432141, 0.06100137101020664, 0.058474997989833355, 0.058331176987849176, 0.05915546405594796]
[0.001346593386684121, 0.0013538305436007001, 0.001345368819205429, 0.0013780470445371147, 0.0013555483416315508, 0.001362261407352476, 0.004221380590355362, 0.0013562433172906326, 0.0013777254313357514, 0.0013608522051733664, 0.0013558134986934338, 0.0013631458198440007, 0.001400119545657865, 0.0013699284093242816, 0.0013572755005125973, 0.0013604583642022176, 0.0014717980229761451, 0.0016027140478730541, 0.0013876504301813177, 0.0014007699554151093, 0.0015349310441789303, 0.0013378213029787984, 0.001319501324296864, 0.001365498466373876, 0.0013102363026159447, 0.001342998860880386, 0.0013463965124385648, 0.0013124510932843699, 0.0012993238850085194, 0.001288984163101156, 0.0012900694652438858, 0.0013045903733866506, 0.0013366891639740315, 0.0012983681856069801, 0.001303556093642878, 0.0013048829548710653, 0.0013270553493828967, 0.0013282859297252673, 0.0013209590932007791, 0.001319904235018374, 0.0015815482583156851, 0.0015006696745796606, 0.0013068870473436492, 0.001295822721277905, 0.0013003000004087077, 0.0012597772103279483, 0.0012675970007643797, 0.0012801842774849297, 0.0012751881379720776, 0.0012701566975433813, 0.0012901619531560777, 0.0012976608840142225, 0.0012661283971135352, 0.0012760088145516294, 0.00128381127805644, 0.0012759556506522173, 0.0012874314886366213, 0.0012673377438426712, 0.0012687913948929933, 0.0012514691632024425, 0.0012494791867644634, 0.0012885017894468335, 0.00126103613915485, 0.0012525073496278288, 0.0012874514173153182, 0.001251107209015551, 0.0012777643034581183, 0.0012848193968407983, 0.0012771282074323228, 0.001275432231121285, 0.001277869884033016, 0.0012977476025996513, 0.0012664457913054976, 0.0012570796290759085, 0.0012828526060031944, 0.0012596248822330043, 0.0012683520922004137, 0.001287830603677173, 0.0012783237900801522, 0.0012736452559312416, 0.001292300813961341, 0.001279271232115841, 0.0012711836999758732, 0.0012774775833497907, 0.0012914918141093018, 0.0012920542300657132, 0.0012762808609147404, 0.001277044745768572, 0.0012821078836528022, 0.0012925469294883484, 0.001292955466047969, 0.0012935738588228476, 0.0012800372557627948, 0.001295251162657731, 0.0012798619072147926, 0.0012941431838932426, 0.0012979679768038697, 0.00129872823112406, 0.0013161116052245677, 0.0013042928374827254, 0.001291157233767038, 0.00131031455807821, 0.0013010967901886203, 0.0013058582797299983, 0.001322310022619921, 0.0013205363485572297, 0.0013192942566346638, 0.0013061193505648611, 0.0013028010211581754, 0.001313469001785094, 0.0013060043944955566, 0.0013050263027422303, 0.0012948126044817442, 0.0013033334182055538, 0.001304221534451773, 0.0013007643730054762, 0.0013003923719055778, 0.0012937875350850613, 0.0013170993242542757, 0.001300123512073485, 0.0013153284658179727, 0.0013144929774192183, 0.00129310779143558, 0.0012964450694663927, 0.001299558930250621, 0.0012962353025931259, 0.0015872025098868233, 0.001388299184158271, 0.0013176089742892357, 0.001278809509998144, 0.0012657207431444942, 0.0012540586514744995, 0.0012460059518817552, 0.004166313836914163, 0.0012449019528968737, 0.0012397940005284063, 0.0012412380243023468, 0.0012395754889693372, 0.001325240767517582, 0.0013130361614965421, 0.0013271755116536867, 0.0013162883020244366, 0.001310636722591034, 0.0016085477654150752, 0.0013320291858859533, 0.0013248888142190355, 0.0013139924889993529, 0.001320061184530861, 0.001320730488704041, 0.0013617842571896522, 0.0013419052553471438, 0.0013053999526079657, 0.0012972809991604367, 0.0038275716739685035, 0.0013155305357433337, 0.0012948927198818258, 0.001302878301980537, 0.001298011719184213, 0.0012958545351487605, 0.0013621391371152428, 0.001325925977272523, 0.0013123026502123753, 0.0013081937443551628, 0.0024101093010760323, 0.0013207170007707074, 0.00131721674399667, 0.0013128984178048234, 0.0013169689309718304, 0.0013171488603273796, 0.0013734310443058264, 0.0013501238115781614, 0.0013064196966805083, 0.0013036429530096261, 0.00131288658134466, 0.0013241316760392037, 0.0013158870238247653, 0.0013015707196711108, 0.0014996766058598147, 0.0012761287223331111, 0.001326754905803259, 0.0013140346042725237, 0.0013191747441238097, 0.002621984139063157, 0.0013616510239148208, 0.001271123488888491, 0.0012799580933439525, 0.0013053661407253078, 0.0013064586524959914, 0.0013469178608597019, 0.0013000029058000723, 0.0012925790709465048, 0.0012913006520288628, 0.003925364023226119, 0.0012980628823644894, 0.0012925620012115254, 0.0012857562802775309, 0.0012926878136864236, 0.001297405907386091, 0.0012943758629262447, 0.0014427939760173823, 0.0013423624399746226, 0.0013103487462801642, 0.001525158114016576, 0.0013824023041051142, 0.00128149539557134, 0.0012800552784790133, 0.0012782091615981487, 0.0012887318829767579, 0.0013142649306330917, 0.0012988028371013528, 0.0013042704884482677, 0.001290535278141845, 0.0013107097664371479, 0.0013022883713981787, 0.0013011386293138181, 0.0013070288845229633, 0.0013272925117594559, 0.0013064890016996583, 0.00132945318554723, 0.0013170375808163784, 0.0013111398371239735, 0.002055870999885333, 0.001444061719920746, 0.0014390586983672408, 0.0014413606976483796, 0.0013308799527802092, 0.0013355517456697863, 0.0013791406743748243, 0.0013575752558143332, 0.0013257602560009028, 0.0024907030246415457, 0.0014597241642213491, 0.001316422813160475, 0.001326164420217622, 0.0013287981408973072, 0.0013436428135867383, 0.0013732046733588674, 0.0013715225585931262, 0.001339412792477497, 0.0013933997671661336, 0.0014339530012072172, 0.001431314044545383, 0.0014430030471060513, 0.0013458299298965653, 0.0013419665331237537, 0.0014186365351210846, 0.0013598836741821711, 0.0013565389997174228, 0.0013757084664173943]
[742.6146674182177, 738.644880429689, 743.2906023424841, 725.6646309458175, 737.7088439327738, 734.0735005798023, 236.88932532752713, 737.3308220221871, 725.8340285048424, 734.833655115843, 737.5645698790262, 733.5972318166523, 714.2247268108357, 729.9651523346763, 736.7700954023952, 735.0463831257395, 679.4410539959041, 623.9416203577239, 720.642589985242, 713.8930958179042, 651.4950647407896, 747.4839859205381, 757.8620662111728, 732.33330144671, 763.2211059970296, 744.6022696880492, 742.7232548224752, 761.9331532556613, 769.631045452107, 775.8047217539962, 775.152057266119, 766.524129259095, 748.1170843241963, 770.1975534254989, 767.132312047601, 766.3522588497674, 753.5480720265489, 752.8499531775004, 757.025713473782, 757.6307231002099, 632.2918031378812, 666.3691663390888, 765.1770686935637, 771.7104998852213, 769.0532951516435, 793.7911495792796, 788.8942616596484, 781.1375421393361, 784.1980098640917, 787.3044341175438, 775.0964888971771, 770.6173564441355, 789.8093133996178, 783.6936458400448, 778.9306863808663, 783.7262991772795, 776.7403615853698, 789.0556442893578, 788.1516252593575, 799.0608393746224, 800.3334594068015, 776.0951581055311, 792.9986849307926, 798.3985086372074, 776.7283382896642, 799.2920133414164, 782.6169484416008, 778.3195073633449, 783.0067444916189, 784.0479294778828, 782.5522868133914, 770.5658619571306, 789.6113729188237, 795.4945548955477, 779.5127790366822, 793.8871437877971, 788.4246071334496, 776.4996398941573, 782.2744188601066, 785.1479800541773, 773.8136424557842, 781.6950580105341, 786.6683627385876, 782.7926008516006, 774.2983649413729, 773.9613220020499, 783.5265971811851, 783.0579181453534, 779.96556510591, 773.6662996026362, 773.4218434116583, 773.052109223976, 781.227261548793, 772.051034448096, 781.3342942413045, 772.7120247943853, 770.4350321973357, 769.9840320976866, 759.813982363122, 766.698989108912, 774.4990105367978, 763.1755244074087, 768.5823280334354, 765.7798824898225, 756.2523030859878, 757.2680608849305, 757.9810152064642, 765.6268162381388, 767.5769236893991, 761.342672450535, 765.6942076264984, 766.2680804967044, 772.3125312023476, 767.2633771462815, 766.7409052713948, 768.7787432934174, 768.9986665598578, 772.9244353357092, 759.244182716582, 769.1576921066238, 760.2663714710401, 760.7495948463176, 773.3307359395167, 771.340046371261, 769.4918458273755, 771.4648706137647, 630.039326280618, 720.3058327851012, 758.9505077099486, 781.9772938672088, 790.0636893377044, 797.4108697581394, 802.564384616117, 240.02032471482363, 803.2761115628509, 806.5856098463092, 805.6472492953658, 806.7277942317692, 754.5798654181026, 761.5936478552449, 753.4798458976842, 759.711985939563, 762.987930036839, 621.6787723067438, 750.7343011668955, 754.780317614393, 761.0393578136294, 757.5406441144557, 757.156746628333, 734.3307096703589, 745.2090943196323, 766.0487485097353, 770.8430175476027, 261.2622532455884, 760.149591993283, 772.2647479949242, 767.5313945131143, 770.4090689015426, 771.6915540101132, 734.1393935114543, 754.189914928008, 762.0193404609569, 764.4127670805533, 414.9189414577728, 757.1644791552222, 759.1765019368202, 761.6735510063361, 759.3193555918365, 759.2156286355122, 728.1035361374334, 740.6728119483344, 765.4507984998294, 767.0811994122872, 761.6804179503448, 755.2119008218582, 759.9436592158147, 768.3024709196642, 666.8104283901039, 783.6200083105468, 753.7187129483939, 761.0149662334201, 758.0496855738364, 381.39056034004193, 734.4025616232751, 786.7056259611962, 781.2755786304314, 766.0685908739479, 765.4279743867121, 742.4357706280074, 769.2290498262857, 773.6470615045154, 774.4129908312385, 254.75344301396416, 770.3787032092373, 773.6572783840887, 777.7523744890049, 773.5819812118822, 770.7688043557006, 772.57312087021, 693.099650138789, 744.9552894365139, 763.1556124572284, 655.6697242140048, 723.3784239439192, 780.3383480392151, 781.2162621509749, 782.3445724248268, 775.9565920648794, 760.8815975317033, 769.9398025891165, 766.7121267074991, 774.8722696212014, 762.9454098890723, 767.8790826692001, 768.5576136705512, 765.0940326119708, 753.4134270631893, 765.4101938087991, 752.188953226194, 759.2797764966891, 762.6951540070139, 486.4118420152701, 692.4911769386717, 694.8986869921305, 693.7888632814312, 751.3825705398892, 748.7542158080103, 725.0891940035835, 736.6074151080163, 754.2841893725611, 401.4930684656461, 685.0609344632061, 759.6343591153625, 754.0543123875251, 752.5597524728042, 744.2454124623988, 728.2235630279306, 729.1166986168826, 746.5958258844992, 717.6691309729285, 697.3729258616701, 698.6586932552752, 692.9992296312224, 743.0359347684114, 745.1750660817573, 704.9021897033317, 735.3570154457485, 737.1701073159766, 726.8981942112994]
Elapsed: 0.059624479196677696~0.016089457201605505
Time per graph: 0.00138362126312195~0.000370936568246297
Speed: 743.8046381626109~82.37906578401548
Total Time: 0.0600
best val loss: 0.3159480392932892 test_score: 0.8140

Testing...
Test loss: 0.6288 score: 0.7907 time: 0.06s
test Score 0.7907
Epoch Time List: [0.18147643096745014, 0.18395806709304452, 0.18323602399323136, 0.18905723688658327, 0.1855300449533388, 0.1833313669776544, 0.310766956070438, 0.18400421703699976, 0.1835572940763086, 0.18476721306797117, 0.18431131693068892, 0.185238266014494, 0.18579593184404075, 0.18902515689842403, 0.1873923601815477, 0.18503436807077378, 0.30588470702059567, 0.2030300849583, 0.19226663117296994, 0.19295232906006277, 0.21055712294764817, 0.2037318799411878, 0.19787091203033924, 0.20105997403152287, 0.19740025606006384, 0.20018024113960564, 0.202452351921238, 0.19923009793274105, 0.19652956095524132, 0.19381547113880515, 0.19627830805256963, 0.19602644292172045, 0.19832146493718028, 0.2008767951047048, 0.1968101520324126, 0.19676292699296027, 0.196882807998918, 0.1997454420197755, 0.19858740991912782, 0.19863588199950755, 0.2147769290022552, 0.22516425990033895, 0.19963994587305933, 0.1947060179663822, 0.1940508319530636, 0.19323793100193143, 0.19027630891650915, 0.1943620778620243, 0.1912236319622025, 0.19228634296450764, 0.1919725590851158, 0.19441399001516402, 0.19194538099691272, 0.19276434590574354, 0.1913485418772325, 0.19298584503121674, 0.19154103507753462, 0.19482996815349907, 0.19234793609939516, 0.1912803379818797, 0.1916248460765928, 0.19292688206769526, 0.19077371200546622, 0.1899694639723748, 0.1909499199828133, 0.18955640611238778, 0.1926437719957903, 0.19309437996707857, 0.19223813083954155, 0.19155029312241822, 0.19112843496259302, 0.19403037801384926, 0.19216607708949596, 0.19079667690675706, 0.1919445360545069, 0.19140635209623724, 0.19267867994494736, 0.19398666894994676, 0.19264864991419017, 0.19250706396996975, 0.19384713005274534, 0.19356688112020493, 0.19183324091136456, 0.19096378388348967, 0.19267801009118557, 0.19245294097345322, 0.1940115160541609, 0.19361458194907755, 0.19334598490968347, 0.19293982884846628, 0.19344324991106987, 0.1951396861113608, 0.19355915300548077, 0.1940374900586903, 0.19501839496660978, 0.19526302407030016, 0.19540651701390743, 0.19608785910531878, 0.1951395629439503, 0.1957723330706358, 0.1955338199622929, 0.19512296083848923, 0.19600310001987964, 0.19640121387783438, 0.1975813809549436, 0.19708274595905095, 0.19751121406443417, 0.19823079206980765, 0.19564600405283272, 0.19655198708642274, 0.19643731298856437, 0.19713636592496186, 0.19674337597098202, 0.19630946102552116, 0.19754230079706758, 0.1962137019727379, 0.19584155618213117, 0.19737168413121253, 0.1977033430011943, 0.19588870590087026, 0.1962624239968136, 0.197051377967, 0.1951486059697345, 0.19597293809056282, 0.1953103750711307, 0.1956892650341615, 0.208089247928001, 0.2072958400240168, 0.2113389529986307, 0.19144996418617666, 0.18841299193445593, 0.1862454239744693, 0.1840906449360773, 0.31186090887058526, 0.18428188911639154, 0.18345096497796476, 0.18274574493989348, 0.18176430312450975, 0.18283355399034917, 0.17732790403533727, 0.18302346393465996, 0.18029229203239083, 0.17824673687573522, 0.1886572529328987, 0.25552227394655347, 0.1809528840240091, 0.17936361185275018, 0.17856528796255589, 0.17953149497043341, 0.1810633190907538, 0.1862615840509534, 0.1787021131021902, 0.17628144402988255, 0.2897771750576794, 0.17682801908813417, 0.17680775397457182, 0.17696581105701625, 0.17645448306575418, 0.17793839995283633, 0.17958028404973447, 0.18214448494836688, 0.18024418782442808, 0.17756004387047142, 0.22257858503144234, 0.21785096114035696, 0.18128198804333806, 0.17954923305660486, 0.17929615103639662, 0.1805064808577299, 0.18230335100088269, 0.18523390195332468, 0.18235090805683285, 0.17841755296103656, 0.30021518107969314, 0.17918169195763767, 0.17904759501107037, 0.17854003584943712, 0.20116020902059972, 0.1750487919198349, 0.18454439588822424, 0.18051821098197252, 0.17977634107228369, 0.23438651696778834, 0.21898554894141853, 0.17691633489448577, 0.17286153708118945, 0.17650786705780774, 0.17717112100217491, 0.18049612594768405, 0.1818273039534688, 0.17762710701208562, 0.17534924997016788, 0.2902722719591111, 0.1752471700310707, 0.17619654501322657, 0.17507663695141673, 0.1761417150264606, 0.1761471489444375, 0.1771496250294149, 0.19109172991011292, 0.1891654629725963, 0.17759754904545844, 0.18559159594587982, 0.2802712169941515, 0.1760419070487842, 0.1744507469702512, 0.17459796695038676, 0.17546344501897693, 0.17615907499566674, 0.179999393876642, 0.17753016692586243, 0.17861248110421002, 0.3021531740669161, 0.17787032609339803, 0.17782133084256202, 0.1780684469267726, 0.18026581790763885, 0.17881265794858336, 0.1845816019922495, 0.1810964730102569, 0.1787598099326715, 0.20891016104724258, 0.2422573760850355, 0.1950620209099725, 0.19487330806441605, 0.18920219887513667, 0.18345717201009393, 0.1850822470150888, 0.1882933290908113, 0.1798062458401546, 0.23162300302647054, 0.2367646781494841, 0.18511658406350762, 0.1815603959839791, 0.1812391448765993, 0.18411073402967304, 0.1853854269720614, 0.18695789203047752, 0.18347084801644087, 0.18469722103327513, 0.24076927197165787, 0.19545408594422042, 0.1961037339642644, 0.18444550188723952, 0.18315988406538963, 0.18806971609592438, 0.18733762705232948, 0.18633779778610915, 0.18683842290192842]
Total Epoch List: [21, 117, 111]
Total Time List: [0.06786648801062256, 0.05390143708791584, 0.05999268696177751]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce0f4a90>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6923;  Loss pred: 0.6923; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6916;  Loss pred: 0.6916; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6922;  Loss pred: 0.6922; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6918;  Loss pred: 0.6918; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6897;  Loss pred: 0.6897; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6876;  Loss pred: 0.6876; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6840;  Loss pred: 0.6840; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6827;  Loss pred: 0.6827; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6772;  Loss pred: 0.6772; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.18s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6748;  Loss pred: 0.6748; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6711;  Loss pred: 0.6711; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6682;  Loss pred: 0.6682; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6665;  Loss pred: 0.6665; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6584;  Loss pred: 0.6584; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6591;  Loss pred: 0.6591; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6514;  Loss pred: 0.6514; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6481;  Loss pred: 0.6481; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6411;  Loss pred: 0.6411; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.13s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6941,   Val_Loss: 0.6930,   Val_Precision: 0.5116,   Val_Recall: 1.0000,   Val_accuracy: 0.6769,   Val_Score: 0.5116,   Val_Loss: 0.6930,   Test_Precision: 0.5000,   Test_Recall: 1.0000,   Test_accuracy: 0.6667,   Test_Score: 0.5000,   Test_loss: 0.6932


[0.05398091103415936, 0.05478711100295186, 0.05506024102214724, 0.05493348999880254, 0.05413235095329583, 0.05530108604580164, 0.055622874991968274, 0.05615065002348274, 0.05598636798094958, 0.05662048305384815, 0.05456368706654757, 0.18771029904019088, 0.05804494605399668, 0.054866013932041824, 0.05528550292365253, 0.05488117295317352, 0.056372769991867244, 0.056792474002577364, 0.05486922699492425, 0.054599024006165564, 0.13967880397103727]
[0.0012268388871399854, 0.0012451616137034514, 0.00125136911413971, 0.0012484884090636942, 0.0012302807034839961, 0.00125684286467731, 0.0012641562498174608, 0.001276151136897335, 0.0012724174541124905, 0.0012868291603147306, 0.0012400837969669903, 0.004266143160004338, 0.0013192033194090154, 0.0012469548620918597, 0.0012564887028102848, 0.0012472993852993982, 0.001281199317996983, 0.001290738045513122, 0.0012470278862482783, 0.0012408869092310356, 0.0031745182720690286]
[815.1029531931501, 803.1085997148003, 799.1247256309974, 800.9685894881087, 812.8226324026128, 795.6444103748375, 791.0414556305014, 783.6062446578762, 785.9055978586043, 777.1039317724363, 806.3971180381602, 234.4037606086766, 758.0332654468956, 801.9536475622104, 795.8686757496366, 801.7321356732352, 780.5186796098146, 774.7505417355684, 801.9066863119883, 805.8752111581944, 315.00842467926276]
Elapsed: 0.06572568985921819~0.03265167658838794
Time per graph: 0.001493765678618595~0.0007420835588269985
Speed: 744.8036803475032~153.60936889984063
Total Time: 0.1400
best val loss: 0.6930060982704163 test_score: 0.5000

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.06s
test Score 0.5000
Epoch Time List: [0.17656972806435078, 0.17082605510950089, 0.24712744180578738, 0.1780299679376185, 0.1740488229552284, 0.175734311924316, 0.17778047500178218, 0.1777336581144482, 0.18057681212667376, 0.18666719703469425, 0.17936126701533794, 0.3143267191480845, 0.1974648729665205, 0.1805724089499563, 0.1768344360170886, 0.17752416373696178, 0.1803921170067042, 0.18702582106925547, 0.1798931659432128, 0.17771824507508427, 0.2790121278958395]
Total Epoch List: [21]
Total Time List: [0.14001657301560044]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce0c23b0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6932;  Loss pred: 0.6932; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.15s
Epoch 2/1000, LR 0.000000
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6944;  Loss pred: 0.6944; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6938;  Loss pred: 0.6938; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6915;  Loss pred: 0.6915; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6897;  Loss pred: 0.6897; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6886;  Loss pred: 0.6886; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6880;  Loss pred: 0.6880; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6845;  Loss pred: 0.6845; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6816;  Loss pred: 0.6816; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6788;  Loss pred: 0.6788; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6769;  Loss pred: 0.6769; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6755;  Loss pred: 0.6755; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6680;  Loss pred: 0.6680; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6667;  Loss pred: 0.6667; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6640;  Loss pred: 0.6640; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.06s
Epoch 18/1000, LR 0.000270
Train loss: 0.6604;  Loss pred: 0.6604; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6566;  Loss pred: 0.6566; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6544;  Loss pred: 0.6544; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6473;  Loss pred: 0.6473; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6429;  Loss pred: 0.6429; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6374;  Loss pred: 0.6374; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6339;  Loss pred: 0.6339; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6281;  Loss pred: 0.6281; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.06s
Epoch 26/1000, LR 0.000270
Train loss: 0.6174;  Loss pred: 0.6174; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6138;  Loss pred: 0.6138; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.6070;  Loss pred: 0.6070; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.6020;  Loss pred: 0.6020; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
Test loss: 0.6918 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5940;  Loss pred: 0.5940; Loss self: 0.0000; time: 0.07s
Val loss: 0.6917 score: 0.5455 time: 0.05s
Test loss: 0.6914 score: 0.5581 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5769;  Loss pred: 0.5769; Loss self: 0.0000; time: 0.07s
Val loss: 0.6915 score: 0.6591 time: 0.05s
Test loss: 0.6911 score: 0.7442 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5791;  Loss pred: 0.5791; Loss self: 0.0000; time: 0.07s
Val loss: 0.6912 score: 0.7273 time: 0.05s
Test loss: 0.6907 score: 0.7674 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5606;  Loss pred: 0.5606; Loss self: 0.0000; time: 0.07s
Val loss: 0.6909 score: 0.6591 time: 0.05s
Test loss: 0.6902 score: 0.6977 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5570;  Loss pred: 0.5570; Loss self: 0.0000; time: 0.07s
Val loss: 0.6905 score: 0.6364 time: 0.05s
Test loss: 0.6898 score: 0.5814 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5467;  Loss pred: 0.5467; Loss self: 0.0000; time: 0.07s
Val loss: 0.6901 score: 0.5682 time: 0.05s
Test loss: 0.6893 score: 0.5814 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5329;  Loss pred: 0.5329; Loss self: 0.0000; time: 0.07s
Val loss: 0.6897 score: 0.5455 time: 0.05s
Test loss: 0.6887 score: 0.5349 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5231;  Loss pred: 0.5231; Loss self: 0.0000; time: 0.07s
Val loss: 0.6892 score: 0.5455 time: 0.05s
Test loss: 0.6880 score: 0.5349 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.5138;  Loss pred: 0.5138; Loss self: 0.0000; time: 0.07s
Val loss: 0.6887 score: 0.5455 time: 0.05s
Test loss: 0.6873 score: 0.5349 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.5048;  Loss pred: 0.5048; Loss self: 0.0000; time: 0.07s
Val loss: 0.6881 score: 0.5455 time: 0.05s
Test loss: 0.6866 score: 0.5349 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4912;  Loss pred: 0.4912; Loss self: 0.0000; time: 0.07s
Val loss: 0.6875 score: 0.5227 time: 0.05s
Test loss: 0.6857 score: 0.5349 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4825;  Loss pred: 0.4825; Loss self: 0.0000; time: 0.07s
Val loss: 0.6867 score: 0.5227 time: 0.05s
Test loss: 0.6848 score: 0.5349 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4635;  Loss pred: 0.4635; Loss self: 0.0000; time: 0.07s
Val loss: 0.6860 score: 0.5227 time: 0.05s
Test loss: 0.6839 score: 0.5349 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4523;  Loss pred: 0.4523; Loss self: 0.0000; time: 0.07s
Val loss: 0.6852 score: 0.5227 time: 0.05s
Test loss: 0.6829 score: 0.5349 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4449;  Loss pred: 0.4449; Loss self: 0.0000; time: 0.07s
Val loss: 0.6842 score: 0.5227 time: 0.05s
Test loss: 0.6818 score: 0.5349 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4199;  Loss pred: 0.4199; Loss self: 0.0000; time: 0.07s
Val loss: 0.6831 score: 0.5227 time: 0.05s
Test loss: 0.6804 score: 0.5349 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.4155;  Loss pred: 0.4155; Loss self: 0.0000; time: 0.07s
Val loss: 0.6819 score: 0.5227 time: 0.05s
Test loss: 0.6790 score: 0.5349 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3956;  Loss pred: 0.3956; Loss self: 0.0000; time: 0.08s
Val loss: 0.6805 score: 0.5455 time: 0.05s
Test loss: 0.6775 score: 0.5349 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3808;  Loss pred: 0.3808; Loss self: 0.0000; time: 0.07s
Val loss: 0.6791 score: 0.5455 time: 0.05s
Test loss: 0.6758 score: 0.5349 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3666;  Loss pred: 0.3666; Loss self: 0.0000; time: 0.07s
Val loss: 0.6773 score: 0.5455 time: 0.05s
Test loss: 0.6739 score: 0.5349 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3618;  Loss pred: 0.3618; Loss self: 0.0000; time: 0.08s
Val loss: 0.6753 score: 0.5455 time: 0.05s
Test loss: 0.6717 score: 0.5349 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3359;  Loss pred: 0.3359; Loss self: 0.0000; time: 0.07s
Val loss: 0.6730 score: 0.5455 time: 0.05s
Test loss: 0.6693 score: 0.5349 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3171;  Loss pred: 0.3171; Loss self: 0.0000; time: 0.07s
Val loss: 0.6704 score: 0.5455 time: 0.05s
Test loss: 0.6665 score: 0.5349 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.3105;  Loss pred: 0.3105; Loss self: 0.0000; time: 0.08s
Val loss: 0.6674 score: 0.5455 time: 0.05s
Test loss: 0.6635 score: 0.5349 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.3021;  Loss pred: 0.3021; Loss self: 0.0000; time: 0.08s
Val loss: 0.6641 score: 0.5455 time: 0.05s
Test loss: 0.6602 score: 0.5349 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2802;  Loss pred: 0.2802; Loss self: 0.0000; time: 0.07s
Val loss: 0.6605 score: 0.5455 time: 0.05s
Test loss: 0.6565 score: 0.5349 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2636;  Loss pred: 0.2636; Loss self: 0.0000; time: 0.07s
Val loss: 0.6564 score: 0.5455 time: 0.05s
Test loss: 0.6525 score: 0.5349 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2564;  Loss pred: 0.2564; Loss self: 0.0000; time: 0.08s
Val loss: 0.6520 score: 0.5682 time: 0.05s
Test loss: 0.6482 score: 0.5581 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2326;  Loss pred: 0.2326; Loss self: 0.0000; time: 0.07s
Val loss: 0.6473 score: 0.5909 time: 0.05s
Test loss: 0.6435 score: 0.5814 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2270;  Loss pred: 0.2270; Loss self: 0.0000; time: 0.07s
Val loss: 0.6422 score: 0.6136 time: 0.05s
Test loss: 0.6385 score: 0.6047 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2074;  Loss pred: 0.2074; Loss self: 0.0000; time: 0.07s
Val loss: 0.6369 score: 0.6591 time: 0.05s
Test loss: 0.6332 score: 0.6047 time: 0.06s
Epoch 61/1000, LR 0.000268
Train loss: 0.1922;  Loss pred: 0.1922; Loss self: 0.0000; time: 0.07s
Val loss: 0.6311 score: 0.6818 time: 0.05s
Test loss: 0.6275 score: 0.6047 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1839;  Loss pred: 0.1839; Loss self: 0.0000; time: 0.07s
Val loss: 0.6251 score: 0.7045 time: 0.05s
Test loss: 0.6216 score: 0.6047 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1690;  Loss pred: 0.1690; Loss self: 0.0000; time: 0.07s
Val loss: 0.6185 score: 0.6818 time: 0.05s
Test loss: 0.6149 score: 0.6279 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1558;  Loss pred: 0.1558; Loss self: 0.0000; time: 0.07s
Val loss: 0.6113 score: 0.6818 time: 0.05s
Test loss: 0.6076 score: 0.6279 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1477;  Loss pred: 0.1477; Loss self: 0.0000; time: 0.07s
Val loss: 0.6035 score: 0.6818 time: 0.05s
Test loss: 0.5998 score: 0.6744 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1359;  Loss pred: 0.1359; Loss self: 0.0000; time: 0.08s
Val loss: 0.5950 score: 0.7045 time: 0.05s
Test loss: 0.5911 score: 0.7209 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1245;  Loss pred: 0.1245; Loss self: 0.0000; time: 0.08s
Val loss: 0.5860 score: 0.7727 time: 0.05s
Test loss: 0.5820 score: 0.7442 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1137;  Loss pred: 0.1137; Loss self: 0.0000; time: 0.08s
Val loss: 0.5764 score: 0.7727 time: 0.05s
Test loss: 0.5723 score: 0.7442 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1011;  Loss pred: 0.1011; Loss self: 0.0000; time: 0.08s
Val loss: 0.5660 score: 0.7500 time: 0.05s
Test loss: 0.5617 score: 0.7674 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0991;  Loss pred: 0.0991; Loss self: 0.0000; time: 0.08s
Val loss: 0.5558 score: 0.7500 time: 0.05s
Test loss: 0.5513 score: 0.7907 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0928;  Loss pred: 0.0928; Loss self: 0.0000; time: 0.08s
Val loss: 0.5457 score: 0.7500 time: 0.05s
Test loss: 0.5407 score: 0.7907 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0795;  Loss pred: 0.0795; Loss self: 0.0000; time: 0.08s
Val loss: 0.5354 score: 0.7727 time: 0.05s
Test loss: 0.5299 score: 0.7907 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0728;  Loss pred: 0.0728; Loss self: 0.0000; time: 0.08s
Val loss: 0.5253 score: 0.7955 time: 0.05s
Test loss: 0.5191 score: 0.7674 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0739;  Loss pred: 0.0739; Loss self: 0.0000; time: 0.08s
Val loss: 0.5157 score: 0.7955 time: 0.05s
Test loss: 0.5086 score: 0.7907 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0616;  Loss pred: 0.0616; Loss self: 0.0000; time: 0.07s
Val loss: 0.5065 score: 0.7955 time: 0.05s
Test loss: 0.4983 score: 0.7907 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0558;  Loss pred: 0.0558; Loss self: 0.0000; time: 0.08s
Val loss: 0.4976 score: 0.7955 time: 0.05s
Test loss: 0.4881 score: 0.7907 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0499;  Loss pred: 0.0499; Loss self: 0.0000; time: 0.07s
Val loss: 0.4890 score: 0.7955 time: 0.05s
Test loss: 0.4778 score: 0.7907 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0475;  Loss pred: 0.0475; Loss self: 0.0000; time: 0.08s
Val loss: 0.4806 score: 0.7955 time: 0.05s
Test loss: 0.4675 score: 0.7907 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0419;  Loss pred: 0.0419; Loss self: 0.0000; time: 0.07s
Val loss: 0.4725 score: 0.7955 time: 0.05s
Test loss: 0.4574 score: 0.7907 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0395;  Loss pred: 0.0395; Loss self: 0.0000; time: 0.08s
Val loss: 0.4649 score: 0.7955 time: 0.05s
Test loss: 0.4474 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0368;  Loss pred: 0.0368; Loss self: 0.0000; time: 0.07s
Val loss: 0.4579 score: 0.7955 time: 0.05s
Test loss: 0.4378 score: 0.7907 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0318;  Loss pred: 0.0318; Loss self: 0.0000; time: 0.07s
Val loss: 0.4513 score: 0.7727 time: 0.05s
Test loss: 0.4282 score: 0.7907 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0298;  Loss pred: 0.0298; Loss self: 0.0000; time: 0.07s
Val loss: 0.4452 score: 0.7727 time: 0.05s
Test loss: 0.4189 score: 0.8140 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0271;  Loss pred: 0.0271; Loss self: 0.0000; time: 0.08s
Val loss: 0.4396 score: 0.7727 time: 0.05s
Test loss: 0.4101 score: 0.8140 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0259;  Loss pred: 0.0259; Loss self: 0.0000; time: 0.07s
Val loss: 0.4347 score: 0.7955 time: 0.05s
Test loss: 0.4018 score: 0.8140 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0221;  Loss pred: 0.0221; Loss self: 0.0000; time: 0.08s
Val loss: 0.4308 score: 0.7955 time: 0.05s
Test loss: 0.3941 score: 0.8140 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0196;  Loss pred: 0.0196; Loss self: 0.0000; time: 0.08s
Val loss: 0.4277 score: 0.7955 time: 0.05s
Test loss: 0.3872 score: 0.8140 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0195;  Loss pred: 0.0195; Loss self: 0.0000; time: 0.08s
Val loss: 0.4256 score: 0.8182 time: 0.05s
Test loss: 0.3809 score: 0.7907 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0168;  Loss pred: 0.0168; Loss self: 0.0000; time: 0.07s
Val loss: 0.4248 score: 0.7955 time: 0.05s
Test loss: 0.3757 score: 0.7907 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.08s
Val loss: 0.4248 score: 0.7955 time: 0.05s
Test loss: 0.3715 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0160;  Loss pred: 0.0160; Loss self: 0.0000; time: 0.07s
Val loss: 0.4259 score: 0.7955 time: 0.05s
Test loss: 0.3682 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0133;  Loss pred: 0.0133; Loss self: 0.0000; time: 0.08s
Val loss: 0.4278 score: 0.7955 time: 0.05s
Test loss: 0.3658 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.08s
Val loss: 0.4309 score: 0.7955 time: 0.05s
Test loss: 0.3643 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.08s
Val loss: 0.4343 score: 0.7955 time: 0.05s
Test loss: 0.3635 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.08s
Val loss: 0.4389 score: 0.8182 time: 0.05s
Test loss: 0.3636 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.08s
Val loss: 0.4444 score: 0.8182 time: 0.05s
Test loss: 0.3646 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.08s
Val loss: 0.4501 score: 0.8182 time: 0.05s
Test loss: 0.3660 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.08s
Val loss: 0.4565 score: 0.8182 time: 0.05s
Test loss: 0.3681 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.07s
Val loss: 0.4635 score: 0.8182 time: 0.05s
Test loss: 0.3706 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.08s
Val loss: 0.4705 score: 0.8182 time: 0.05s
Test loss: 0.3736 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.08s
Val loss: 0.4775 score: 0.8182 time: 0.05s
Test loss: 0.3767 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.08s
Val loss: 0.4848 score: 0.8182 time: 0.05s
Test loss: 0.3803 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.4921 score: 0.8182 time: 0.05s
Test loss: 0.3839 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.4995 score: 0.8182 time: 0.05s
Test loss: 0.3877 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.08s
Val loss: 0.5083 score: 0.7955 time: 0.05s
Test loss: 0.3923 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.08s
Val loss: 0.5165 score: 0.7955 time: 0.05s
Test loss: 0.3965 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.08s
Val loss: 0.5241 score: 0.7727 time: 0.05s
Test loss: 0.4005 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.08s
Val loss: 0.5313 score: 0.7727 time: 0.05s
Test loss: 0.4044 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.08s
Val loss: 0.5381 score: 0.7727 time: 0.05s
Test loss: 0.4080 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 088,   Train_Loss: 0.0168,   Val_Loss: 0.4248,   Val_Precision: 0.8824,   Val_Recall: 0.6818,   Val_accuracy: 0.7692,   Val_Score: 0.7955,   Val_Loss: 0.4248,   Test_Precision: 0.8095,   Test_Recall: 0.7727,   Test_accuracy: 0.7907,   Test_Score: 0.7907,   Test_loss: 0.3757


[0.05398091103415936, 0.05478711100295186, 0.05506024102214724, 0.05493348999880254, 0.05413235095329583, 0.05530108604580164, 0.055622874991968274, 0.05615065002348274, 0.05598636798094958, 0.05662048305384815, 0.05456368706654757, 0.18771029904019088, 0.05804494605399668, 0.054866013932041824, 0.05528550292365253, 0.05488117295317352, 0.056372769991867244, 0.056792474002577364, 0.05486922699492425, 0.054599024006165564, 0.13967880397103727, 0.15446632902603596, 0.05544342007488012, 0.056126474984921515, 0.055968486005440354, 0.0558024849742651, 0.05628076894208789, 0.056663333089090884, 0.0570762159768492, 0.057068831054493785, 0.05723145406227559, 0.057119789998978376, 0.0572185319615528, 0.05725004698615521, 0.0576458330033347, 0.05733019101899117, 0.057634240947663784, 0.06349643599241972, 0.059472399996593595, 0.058404899085871875, 0.05745502805802971, 0.058807756984606385, 0.057607864029705524, 0.0577884369995445, 0.057454838999547064, 0.06341447890736163, 0.05902922595851123, 0.05820650700479746, 0.05765951203648001, 0.058651037979871035, 0.05773628002498299, 0.057948081055656075, 0.05737604002933949, 0.05770216602832079, 0.058831953909248114, 0.05756014701910317, 0.05759982904419303, 0.057343236985616386, 0.057257096050307155, 0.057563076028600335, 0.05702406098134816, 0.05840770003851503, 0.057851333054713905, 0.05743941606488079, 0.057614961988292634, 0.05803367600310594, 0.057716854964382946, 0.0577182489214465, 0.058066742960363626, 0.05789369996637106, 0.058273080037906766, 0.058431351906619966, 0.05800734902732074, 0.058412407990545034, 0.05823748093098402, 0.057874600985087454, 0.05778058501891792, 0.05948503501713276, 0.05766935693100095, 0.058152316021732986, 0.05989797809161246, 0.05897246301174164, 0.05796642997302115, 0.058048389037139714, 0.057494464912451804, 0.05845064506866038, 0.05821931501850486, 0.0584703249623999, 0.05784112901892513, 0.058897889917716384, 0.05859595304355025, 0.05868238804396242, 0.058825262007303536, 0.058382604038342834, 0.058403513045050204, 0.05813767004292458, 0.05869630991946906, 0.058103409013710916, 0.05821080401074141, 0.05866501992568374, 0.05839774606283754, 0.05827541102189571, 0.05856403801590204, 0.058133043930865824, 0.05826257902663201, 0.05884905206039548, 0.05852662690449506, 0.058761912980116904, 0.058077594032511115, 0.0578178190626204, 0.05785346298944205, 0.05807224288582802, 0.058088009944185615, 0.05814837198704481, 0.05797428998630494, 0.05817653797566891, 0.0580701349535957, 0.05804738600272685, 0.05823576694820076, 0.058151573059149086, 0.058459748048335314, 0.05837576894555241, 0.05795382894575596, 0.058102600974962115, 0.058023644029162824, 0.058261216967366636, 0.05802778690122068, 0.05887952202465385, 0.05806506203953177, 0.05785234796348959]
[0.0012268388871399854, 0.0012451616137034514, 0.00125136911413971, 0.0012484884090636942, 0.0012302807034839961, 0.00125684286467731, 0.0012641562498174608, 0.001276151136897335, 0.0012724174541124905, 0.0012868291603147306, 0.0012400837969669903, 0.004266143160004338, 0.0013192033194090154, 0.0012469548620918597, 0.0012564887028102848, 0.0012472993852993982, 0.001281199317996983, 0.001290738045513122, 0.0012470278862482783, 0.0012408869092310356, 0.0031745182720690286, 0.003592240209907813, 0.0012893818622065146, 0.0013052668601144539, 0.0013015926978009384, 0.0012977322087038396, 0.0013088550916764625, 0.0013177519323044392, 0.0013273538599267256, 0.001327182117546367, 0.0013309640479598974, 0.001328367209278567, 0.0013306635339895999, 0.0013313964415384934, 0.0013406007675194117, 0.0013332602562556087, 0.0013403311848293902, 0.0014766613021492958, 0.001383079069688223, 0.0013582534671132995, 0.0013361634432099932, 0.0013676222554559624, 0.0013397177681326866, 0.0013439171395242908, 0.0013361590465010946, 0.0014747553234270147, 0.0013727726967095635, 0.0013536396977859874, 0.0013409188845693025, 0.0013639776274388612, 0.0013427041866275113, 0.0013476297919920019, 0.0013343265123102208, 0.0013419108378679254, 0.001368184974633677, 0.0013386080702117017, 0.001339530908004489, 0.001333563650828288, 0.001331560373262957, 0.0013386761867116358, 0.0013261409530546083, 0.0013583186055468612, 0.0013453798384817188, 0.0013358003736018789, 0.001339882836937038, 0.0013496203721652543, 0.0013422524410321615, 0.0013422848586382907, 0.0013503893711712472, 0.0013463651154970015, 0.0013551879078582969, 0.001358868648991162, 0.0013490081169144359, 0.001358428092803373, 0.0013543600216507912, 0.0013459209531415687, 0.0013437345353236726, 0.0013833729073751805, 0.0013411478356046731, 0.0013523794423658834, 0.0013929762346886617, 0.0013714526281800382, 0.001348056511000492, 0.0013499625357474353, 0.0013370805793593442, 0.0013593173271781484, 0.0013539375585698804, 0.0013597749991255792, 0.0013451425353238403, 0.0013697183701794507, 0.0013626965824081454, 0.0013647066986968005, 0.001368029349007059, 0.0013577349776358798, 0.0013582212336058187, 0.0013520388382075484, 0.0013650304632434665, 0.0013512420700863004, 0.001353739628156777, 0.0013643027889693891, 0.001358087117740408, 0.0013552421167882722, 0.0013619543724628382, 0.001351931254206182, 0.0013549436982937676, 0.0013685826060557088, 0.0013610843466161642, 0.0013665561158166721, 0.001350641721686305, 0.0013446004433167536, 0.0013454293718474896, 0.001350517276414605, 0.0013508839521903632, 0.001352287720628949, 0.0013482393020070916, 0.001352942743620207, 0.0013504682547347837, 0.0013499392093657408, 0.0013543201615860642, 0.0013523621641662578, 0.001359529024379891, 0.0013575760219895908, 0.0013477634638547897, 0.001351223278487491, 0.001349387070445647, 0.0013549120224968984, 0.0013494834163074578, 0.001369291209875671, 0.0013503502799891108, 0.0013454034410113858]
[815.1029531931501, 803.1085997148003, 799.1247256309974, 800.9685894881087, 812.8226324026128, 795.6444103748375, 791.0414556305014, 783.6062446578762, 785.9055978586043, 777.1039317724363, 806.3971180381602, 234.4037606086766, 758.0332654468956, 801.9536475622104, 795.8686757496366, 801.7321356732352, 780.5186796098146, 774.7505417355684, 801.9066863119883, 805.8752111581944, 315.00842467926276, 278.37782040351436, 775.5654312436997, 766.1268592326888, 768.2894976973333, 770.5750025259748, 764.0265193293004, 758.8681719868431, 753.3786055025322, 753.4760955404928, 751.3350954391298, 752.803888122997, 751.5047752167646, 751.0910866221419, 745.9342290623597, 750.0411081092655, 746.0842598594684, 677.2033631168431, 723.0244618085518, 736.2396078585415, 748.4114350543855, 731.1960565211789, 746.4258695275879, 744.0934940036349, 748.4138977456535, 678.078583012818, 728.4527164598534, 738.74901987257, 745.7572650423189, 733.1498551612599, 744.7656825377999, 742.0435537580747, 749.4417526551459, 745.2059941544513, 730.8953237611338, 747.044652018159, 746.5299934659281, 749.8704687840668, 750.9986179218624, 747.0066397882448, 754.0676560033975, 736.2043013446013, 743.28451445245, 748.6148527594584, 746.3339125128227, 740.9490999277498, 745.0163392744682, 744.9983463379533, 740.5271556104294, 742.7405749671826, 737.9050493302981, 735.9063002464662, 741.2853840251781, 736.1449643877072, 738.3561121223353, 742.9856840149931, 744.1946111470036, 722.8708865618929, 745.6299547686609, 739.4374453449079, 717.8873372692577, 729.1538763005123, 741.8086644289315, 740.7612978284089, 747.8980814149176, 735.6633951513978, 738.5864980777009, 735.4157861727587, 743.4156409002799, 730.0770886711457, 733.8390753375259, 732.7581823661671, 730.978469669396, 736.5207617625227, 736.257080405959, 739.6237236244926, 732.5843832260616, 740.0598472604784, 738.694486887097, 732.9751196619718, 736.3297883745521, 737.8755335392434, 734.2389878977283, 739.6825814099352, 738.0380463478035, 730.6829676010763, 734.708324642872, 731.7665102997886, 740.3887973721696, 743.7153579492206, 743.2571496687635, 740.4570215161044, 740.2560363372223, 739.4875992328763, 741.7080918137633, 739.1295786281376, 740.4838999317229, 740.7740978720389, 738.3778432633576, 739.446892627692, 735.5488423324543, 736.606999388847, 741.9699575026776, 740.0701393476307, 741.0772060160182, 738.0553005627264, 741.0242970871503, 730.304841503217, 740.548593071765, 743.2714749475189]
Elapsed: 0.06004976611494875~0.015815139014568765
Time per graph: 0.0013908945466354825~0.00036023424742373403
Speed: 737.7926825912704~74.71216364528965
Total Time: 0.0585
best val loss: 0.4247918128967285 test_score: 0.7907

Testing...
Test loss: 0.3809 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.17656972806435078, 0.17082605510950089, 0.24712744180578738, 0.1780299679376185, 0.1740488229552284, 0.175734311924316, 0.17778047500178218, 0.1777336581144482, 0.18057681212667376, 0.18666719703469425, 0.17936126701533794, 0.3143267191480845, 0.1974648729665205, 0.1805724089499563, 0.1768344360170886, 0.17752416373696178, 0.1803921170067042, 0.18702582106925547, 0.1798931659432128, 0.17771824507508427, 0.2790121278958395, 0.274744949885644, 0.19686616503167897, 0.17240559309720993, 0.17288018902763724, 0.1728016920387745, 0.17351212992798537, 0.17437544802669436, 0.17788903298787773, 0.1785081949783489, 0.17777328402735293, 0.17766237200703472, 0.1783968029776588, 0.17820958804804832, 0.1790654050419107, 0.17808897781651467, 0.18188485293649137, 0.18956805195193738, 0.1869267129804939, 0.18285847490187734, 0.17762941296678036, 0.18941969890147448, 0.1798455099342391, 0.1789525639032945, 0.17906951298937201, 0.18317895801737905, 0.18775711115449667, 0.19206294603645802, 0.1827039490453899, 0.18063607497606426, 0.18084824387915432, 0.18003080890048295, 0.1794470709282905, 0.17952579993288964, 0.18015869706869125, 0.18056128302123398, 0.1787099950015545, 0.17811353807337582, 0.17821440193802118, 0.17964479292277247, 0.17932038998696953, 0.1794366870308295, 0.17973413015715778, 0.179946347954683, 0.17941960121970624, 0.18048679910134524, 0.18045106390491128, 0.18189492693636566, 0.18164793401956558, 0.18071850016713142, 0.18278339598327875, 0.1824431250570342, 0.18117405090015382, 0.18259530304931104, 0.18265246006194502, 0.18061433802358806, 0.18139125010930002, 0.18341634003445506, 0.18127139995340258, 0.18108053400646895, 0.18323947000317276, 0.1826013979734853, 0.18040640896651894, 0.18094779085367918, 0.18071050592698157, 0.1809134850045666, 0.1825555469840765, 0.18232021108269691, 0.18177862605080009, 0.18310537794604897, 0.183172516990453, 0.18323128996416926, 0.18366530910134315, 0.1824482571100816, 0.18278960196767002, 0.18221138988155872, 0.18404595903120935, 0.18221187288872898, 0.18248564994428307, 0.18263625702820718, 0.1823295570211485, 0.18247708689887077, 0.1826115440344438, 0.1813623149646446, 0.18249448493588716, 0.18224679003469646, 0.1827891831053421, 0.1829746310831979, 0.18193882994819432, 0.18126013688743114, 0.1831496860831976, 0.18095315899699926, 0.1822556391125545, 0.1824258400592953, 0.18195175402797759, 0.18241074797697365, 0.18186794803477824, 0.18245773506350815, 0.1825074510416016, 0.18164657498709857, 0.18300072196871042, 0.18375594995450228, 0.1818239880958572, 0.182071401970461, 0.18222091905772686, 0.18325145298149437, 0.18354694405570626, 0.18405675201211125, 0.18431233696173877, 0.18321593303699046]
Total Epoch List: [21, 109]
Total Time List: [0.14001657301560044, 0.05845707398839295]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7fc6ce2ad270>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6943;  Loss pred: 0.6943; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6923;  Loss pred: 0.6923; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6915;  Loss pred: 0.6915; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6897;  Loss pred: 0.6897; Loss self: 0.0000; time: 0.09s
Val loss: 0.6931 score: 0.5227 time: 0.05s
Test loss: 0.6931 score: 0.5349 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6870;  Loss pred: 0.6870; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6863;  Loss pred: 0.6863; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6840;  Loss pred: 0.6840; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6798;  Loss pred: 0.6798; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6794;  Loss pred: 0.6794; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6763;  Loss pred: 0.6763; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6716;  Loss pred: 0.6716; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6684;  Loss pred: 0.6684; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6643;  Loss pred: 0.6643; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6633;  Loss pred: 0.6633; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6565;  Loss pred: 0.6565; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6493;  Loss pred: 0.6493; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6480;  Loss pred: 0.6480; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6453;  Loss pred: 0.6453; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.06s
Epoch 22/1000, LR 0.000270
Train loss: 0.6370;  Loss pred: 0.6370; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6300;  Loss pred: 0.6300; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6242;  Loss pred: 0.6242; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6190;  Loss pred: 0.6190; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6094;  Loss pred: 0.6094; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4884 time: 0.06s
Epoch 27/1000, LR 0.000270
Train loss: 0.6031;  Loss pred: 0.6031; Loss self: 0.0000; time: 0.09s
Val loss: 0.6918 score: 0.5227 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4884 time: 0.06s
Epoch 28/1000, LR 0.000270
Train loss: 0.5915;  Loss pred: 0.5915; Loss self: 0.0000; time: 0.09s
Val loss: 0.6915 score: 0.5227 time: 0.06s
Test loss: 0.6914 score: 0.6279 time: 0.06s
Epoch 29/1000, LR 0.000270
Train loss: 0.5852;  Loss pred: 0.5852; Loss self: 0.0000; time: 0.09s
Val loss: 0.6911 score: 0.7273 time: 0.06s
Test loss: 0.6909 score: 0.7674 time: 0.19s
Epoch 30/1000, LR 0.000270
Train loss: 0.5801;  Loss pred: 0.5801; Loss self: 0.0000; time: 0.09s
Val loss: 0.6907 score: 0.8864 time: 0.07s
Test loss: 0.6904 score: 0.8605 time: 0.06s
Epoch 31/1000, LR 0.000270
Train loss: 0.5670;  Loss pred: 0.5670; Loss self: 0.0000; time: 0.09s
Val loss: 0.6903 score: 0.7727 time: 0.06s
Test loss: 0.6899 score: 0.7209 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5576;  Loss pred: 0.5576; Loss self: 0.0000; time: 0.09s
Val loss: 0.6899 score: 0.5682 time: 0.05s
Test loss: 0.6894 score: 0.5581 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5415;  Loss pred: 0.5415; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5359;  Loss pred: 0.5359; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6881 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5238;  Loss pred: 0.5238; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6882 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5151;  Loss pred: 0.5151; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6874 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5001;  Loss pred: 0.5001; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6866 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6855 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4881;  Loss pred: 0.4881; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6857 score: 0.5000 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6845 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4701;  Loss pred: 0.4701; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6833 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4591;  Loss pred: 0.4591; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6836 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6820 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4442;  Loss pred: 0.4442; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6822 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6805 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4358;  Loss pred: 0.4358; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6807 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6788 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4273;  Loss pred: 0.4273; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6792 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6770 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4125;  Loss pred: 0.4125; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6775 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6752 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3928;  Loss pred: 0.3928; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6758 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6731 score: 0.5116 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3747;  Loss pred: 0.3747; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6738 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6710 score: 0.5116 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3673;  Loss pred: 0.3673; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6718 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6686 score: 0.5116 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3491;  Loss pred: 0.3491; Loss self: 0.0000; time: 0.21s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6694 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6660 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3416;  Loss pred: 0.3416; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6668 score: 0.5000 time: 0.06s
Test loss: 0.6631 score: 0.5349 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3314;  Loss pred: 0.3314; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6641 score: 0.5000 time: 0.06s
Test loss: 0.6601 score: 0.5349 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3116;  Loss pred: 0.3116; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6611 score: 0.5000 time: 0.06s
Test loss: 0.6567 score: 0.5349 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3055;  Loss pred: 0.3055; Loss self: 0.0000; time: 0.09s
Val loss: 0.6579 score: 0.5455 time: 0.06s
Test loss: 0.6531 score: 0.5349 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2852;  Loss pred: 0.2852; Loss self: 0.0000; time: 0.09s
Val loss: 0.6544 score: 0.5455 time: 0.06s
Test loss: 0.6493 score: 0.5581 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2817;  Loss pred: 0.2817; Loss self: 0.0000; time: 0.09s
Val loss: 0.6506 score: 0.5455 time: 0.06s
Test loss: 0.6450 score: 0.5581 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2591;  Loss pred: 0.2591; Loss self: 0.0000; time: 0.09s
Val loss: 0.6465 score: 0.5682 time: 0.05s
Test loss: 0.6404 score: 0.5814 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2457;  Loss pred: 0.2457; Loss self: 0.0000; time: 0.09s
Val loss: 0.6420 score: 0.6136 time: 0.06s
Test loss: 0.6354 score: 0.6279 time: 0.17s
Epoch 57/1000, LR 0.000269
Train loss: 0.2375;  Loss pred: 0.2375; Loss self: 0.0000; time: 0.09s
Val loss: 0.6372 score: 0.6364 time: 0.05s
Test loss: 0.6300 score: 0.6512 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2303;  Loss pred: 0.2303; Loss self: 0.0000; time: 0.09s
Val loss: 0.6320 score: 0.7045 time: 0.05s
Test loss: 0.6243 score: 0.6512 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2190;  Loss pred: 0.2190; Loss self: 0.0000; time: 0.09s
Val loss: 0.6261 score: 0.7500 time: 0.05s
Test loss: 0.6178 score: 0.6744 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1941;  Loss pred: 0.1941; Loss self: 0.0000; time: 0.09s
Val loss: 0.6197 score: 0.7500 time: 0.06s
Test loss: 0.6109 score: 0.6977 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1906;  Loss pred: 0.1906; Loss self: 0.0000; time: 0.09s
Val loss: 0.6128 score: 0.7727 time: 0.05s
Test loss: 0.6034 score: 0.6977 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1730;  Loss pred: 0.1730; Loss self: 0.0000; time: 0.09s
Val loss: 0.6056 score: 0.7955 time: 0.06s
Test loss: 0.5954 score: 0.7209 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1737;  Loss pred: 0.1737; Loss self: 0.0000; time: 0.09s
Val loss: 0.5980 score: 0.7955 time: 0.06s
Test loss: 0.5872 score: 0.7209 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1539;  Loss pred: 0.1539; Loss self: 0.0000; time: 0.09s
Val loss: 0.5900 score: 0.7955 time: 0.05s
Test loss: 0.5783 score: 0.7209 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1514;  Loss pred: 0.1514; Loss self: 0.0000; time: 0.09s
Val loss: 0.5815 score: 0.7955 time: 0.06s
Test loss: 0.5690 score: 0.7907 time: 0.15s
Epoch 66/1000, LR 0.000268
Train loss: 0.1345;  Loss pred: 0.1345; Loss self: 0.0000; time: 0.09s
Val loss: 0.5721 score: 0.8409 time: 0.06s
Test loss: 0.5590 score: 0.7907 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1271;  Loss pred: 0.1271; Loss self: 0.0000; time: 0.09s
Val loss: 0.5624 score: 0.8409 time: 0.06s
Test loss: 0.5487 score: 0.7907 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1130;  Loss pred: 0.1130; Loss self: 0.0000; time: 0.09s
Val loss: 0.5521 score: 0.8409 time: 0.06s
Test loss: 0.5378 score: 0.7907 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1068;  Loss pred: 0.1068; Loss self: 0.0000; time: 0.09s
Val loss: 0.5413 score: 0.8409 time: 0.05s
Test loss: 0.5264 score: 0.7907 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1065;  Loss pred: 0.1065; Loss self: 0.0000; time: 0.09s
Val loss: 0.5302 score: 0.8409 time: 0.05s
Test loss: 0.5150 score: 0.7907 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0935;  Loss pred: 0.0935; Loss self: 0.0000; time: 0.09s
Val loss: 0.5190 score: 0.8182 time: 0.06s
Test loss: 0.5038 score: 0.7907 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0903;  Loss pred: 0.0903; Loss self: 0.0000; time: 0.09s
Val loss: 0.5070 score: 0.8182 time: 0.06s
Test loss: 0.4918 score: 0.7907 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0812;  Loss pred: 0.0812; Loss self: 0.0000; time: 0.09s
Val loss: 0.4949 score: 0.8182 time: 0.06s
Test loss: 0.4796 score: 0.8140 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0765;  Loss pred: 0.0765; Loss self: 0.0000; time: 0.09s
Val loss: 0.4826 score: 0.8182 time: 0.06s
Test loss: 0.4674 score: 0.8140 time: 0.07s
Epoch 75/1000, LR 0.000267
Train loss: 0.0694;  Loss pred: 0.0694; Loss self: 0.0000; time: 0.16s
Val loss: 0.4700 score: 0.8182 time: 0.06s
Test loss: 0.4547 score: 0.8372 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0638;  Loss pred: 0.0638; Loss self: 0.0000; time: 0.09s
Val loss: 0.4573 score: 0.7955 time: 0.06s
Test loss: 0.4414 score: 0.8605 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0595;  Loss pred: 0.0595; Loss self: 0.0000; time: 0.09s
Val loss: 0.4452 score: 0.7955 time: 0.06s
Test loss: 0.4287 score: 0.8605 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0561;  Loss pred: 0.0561; Loss self: 0.0000; time: 0.09s
Val loss: 0.4336 score: 0.8409 time: 0.06s
Test loss: 0.4167 score: 0.8605 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0468;  Loss pred: 0.0468; Loss self: 0.0000; time: 0.09s
Val loss: 0.4232 score: 0.8636 time: 0.06s
Test loss: 0.4056 score: 0.8605 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0469;  Loss pred: 0.0469; Loss self: 0.0000; time: 0.09s
Val loss: 0.4135 score: 0.8409 time: 0.06s
Test loss: 0.3957 score: 0.8605 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0393;  Loss pred: 0.0393; Loss self: 0.0000; time: 0.09s
Val loss: 0.4048 score: 0.8409 time: 0.06s
Test loss: 0.3870 score: 0.8605 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0394;  Loss pred: 0.0394; Loss self: 0.0000; time: 0.09s
Val loss: 0.3966 score: 0.8409 time: 0.05s
Test loss: 0.3787 score: 0.8605 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0363;  Loss pred: 0.0363; Loss self: 0.0000; time: 0.10s
Val loss: 0.3895 score: 0.8182 time: 0.15s
Test loss: 0.3717 score: 0.8605 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0338;  Loss pred: 0.0338; Loss self: 0.0000; time: 0.09s
Val loss: 0.3830 score: 0.8182 time: 0.06s
Test loss: 0.3654 score: 0.8605 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0318;  Loss pred: 0.0318; Loss self: 0.0000; time: 0.09s
Val loss: 0.3778 score: 0.8182 time: 0.06s
Test loss: 0.3607 score: 0.8605 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0276;  Loss pred: 0.0276; Loss self: 0.0000; time: 0.08s
Val loss: 0.3733 score: 0.8182 time: 0.06s
Test loss: 0.3569 score: 0.8605 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0276;  Loss pred: 0.0276; Loss self: 0.0000; time: 0.09s
Val loss: 0.3702 score: 0.8182 time: 0.06s
Test loss: 0.3556 score: 0.8605 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0247;  Loss pred: 0.0247; Loss self: 0.0000; time: 0.08s
Val loss: 0.3682 score: 0.8182 time: 0.05s
Test loss: 0.3560 score: 0.8605 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0232;  Loss pred: 0.0232; Loss self: 0.0000; time: 0.08s
Val loss: 0.3669 score: 0.8182 time: 0.05s
Test loss: 0.3568 score: 0.8605 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0221;  Loss pred: 0.0221; Loss self: 0.0000; time: 0.08s
Val loss: 0.3669 score: 0.7955 time: 0.05s
Test loss: 0.3592 score: 0.8605 time: 0.06s
Epoch 91/1000, LR 0.000266
Train loss: 0.0196;  Loss pred: 0.0196; Loss self: 0.0000; time: 0.08s
Val loss: 0.3678 score: 0.7955 time: 0.05s
Test loss: 0.3631 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0213;  Loss pred: 0.0213; Loss self: 0.0000; time: 0.09s
Val loss: 0.3693 score: 0.7955 time: 0.19s
Test loss: 0.3672 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0181;  Loss pred: 0.0181; Loss self: 0.0000; time: 0.08s
Val loss: 0.3721 score: 0.7955 time: 0.06s
Test loss: 0.3733 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0160;  Loss pred: 0.0160; Loss self: 0.0000; time: 0.08s
Val loss: 0.3756 score: 0.7955 time: 0.06s
Test loss: 0.3799 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0149;  Loss pred: 0.0149; Loss self: 0.0000; time: 0.08s
Val loss: 0.3786 score: 0.7955 time: 0.06s
Test loss: 0.3854 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0149;  Loss pred: 0.0149; Loss self: 0.0000; time: 0.08s
Val loss: 0.3819 score: 0.7955 time: 0.06s
Test loss: 0.3907 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0140;  Loss pred: 0.0140; Loss self: 0.0000; time: 0.09s
Val loss: 0.3843 score: 0.7955 time: 0.06s
Test loss: 0.3949 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0132;  Loss pred: 0.0132; Loss self: 0.0000; time: 0.08s
Val loss: 0.3851 score: 0.7955 time: 0.05s
Test loss: 0.3961 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.08s
Val loss: 0.3856 score: 0.7955 time: 0.05s
Test loss: 0.3963 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.07s
Val loss: 0.3868 score: 0.7955 time: 0.05s
Test loss: 0.3979 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.08s
Val loss: 0.3869 score: 0.8182 time: 0.05s
Test loss: 0.3974 score: 0.8605 time: 0.17s
     INFO: Early stopping counter 11 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.08s
Val loss: 0.3881 score: 0.8182 time: 0.05s
Test loss: 0.3995 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.07s
Val loss: 0.3909 score: 0.8182 time: 0.05s
Test loss: 0.4045 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.08s
Val loss: 0.3933 score: 0.8182 time: 0.05s
Test loss: 0.4084 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.08s
Val loss: 0.3975 score: 0.8182 time: 0.05s
Test loss: 0.4156 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.08s
Val loss: 0.4015 score: 0.8182 time: 0.05s
Test loss: 0.4225 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.08s
Val loss: 0.4059 score: 0.8182 time: 0.05s
Test loss: 0.4299 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.08s
Val loss: 0.4088 score: 0.8182 time: 0.05s
Test loss: 0.4346 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.08s
Val loss: 0.4114 score: 0.8182 time: 0.05s
Test loss: 0.4384 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.08s
Val loss: 0.4111 score: 0.8182 time: 0.05s
Test loss: 0.4358 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 089,   Train_Loss: 0.0221,   Val_Loss: 0.3669,   Val_Precision: 0.8421,   Val_Recall: 0.7273,   Val_accuracy: 0.7805,   Val_Score: 0.7955,   Val_Loss: 0.3669,   Test_Precision: 1.0000,   Test_Recall: 0.7143,   Test_accuracy: 0.8333,   Test_Score: 0.8605,   Test_loss: 0.3592


[0.05398091103415936, 0.05478711100295186, 0.05506024102214724, 0.05493348999880254, 0.05413235095329583, 0.05530108604580164, 0.055622874991968274, 0.05615065002348274, 0.05598636798094958, 0.05662048305384815, 0.05456368706654757, 0.18771029904019088, 0.05804494605399668, 0.054866013932041824, 0.05528550292365253, 0.05488117295317352, 0.056372769991867244, 0.056792474002577364, 0.05486922699492425, 0.054599024006165564, 0.13967880397103727, 0.15446632902603596, 0.05544342007488012, 0.056126474984921515, 0.055968486005440354, 0.0558024849742651, 0.05628076894208789, 0.056663333089090884, 0.0570762159768492, 0.057068831054493785, 0.05723145406227559, 0.057119789998978376, 0.0572185319615528, 0.05725004698615521, 0.0576458330033347, 0.05733019101899117, 0.057634240947663784, 0.06349643599241972, 0.059472399996593595, 0.058404899085871875, 0.05745502805802971, 0.058807756984606385, 0.057607864029705524, 0.0577884369995445, 0.057454838999547064, 0.06341447890736163, 0.05902922595851123, 0.05820650700479746, 0.05765951203648001, 0.058651037979871035, 0.05773628002498299, 0.057948081055656075, 0.05737604002933949, 0.05770216602832079, 0.058831953909248114, 0.05756014701910317, 0.05759982904419303, 0.057343236985616386, 0.057257096050307155, 0.057563076028600335, 0.05702406098134816, 0.05840770003851503, 0.057851333054713905, 0.05743941606488079, 0.057614961988292634, 0.05803367600310594, 0.057716854964382946, 0.0577182489214465, 0.058066742960363626, 0.05789369996637106, 0.058273080037906766, 0.058431351906619966, 0.05800734902732074, 0.058412407990545034, 0.05823748093098402, 0.057874600985087454, 0.05778058501891792, 0.05948503501713276, 0.05766935693100095, 0.058152316021732986, 0.05989797809161246, 0.05897246301174164, 0.05796642997302115, 0.058048389037139714, 0.057494464912451804, 0.05845064506866038, 0.05821931501850486, 0.0584703249623999, 0.05784112901892513, 0.058897889917716384, 0.05859595304355025, 0.05868238804396242, 0.058825262007303536, 0.058382604038342834, 0.058403513045050204, 0.05813767004292458, 0.05869630991946906, 0.058103409013710916, 0.05821080401074141, 0.05866501992568374, 0.05839774606283754, 0.05827541102189571, 0.05856403801590204, 0.058133043930865824, 0.05826257902663201, 0.05884905206039548, 0.05852662690449506, 0.058761912980116904, 0.058077594032511115, 0.0578178190626204, 0.05785346298944205, 0.05807224288582802, 0.058088009944185615, 0.05814837198704481, 0.05797428998630494, 0.05817653797566891, 0.0580701349535957, 0.05804738600272685, 0.05823576694820076, 0.058151573059149086, 0.058459748048335314, 0.05837576894555241, 0.05795382894575596, 0.058102600974962115, 0.058023644029162824, 0.058261216967366636, 0.05802778690122068, 0.05887952202465385, 0.05806506203953177, 0.05785234796348959, 0.05820639990270138, 0.05739243293646723, 0.05578262102790177, 0.05580164398998022, 0.05582344997674227, 0.05583070998545736, 0.056226655025966465, 0.05614995106589049, 0.05581804795656353, 0.05597001500427723, 0.05577043106313795, 0.05604783596936613, 0.057538029039278626, 0.056171300006099045, 0.05599302600603551, 0.05638430209364742, 0.057507822988554835, 0.056078416062518954, 0.055738262948580086, 0.056572561035864055, 0.0608657089760527, 0.05690884205978364, 0.05681328207720071, 0.057027839007787406, 0.05782829399686307, 0.060572123038582504, 0.06366023200098425, 0.06250935804564506, 0.1925588600570336, 0.06081485003232956, 0.05802341201342642, 0.055948509951122105, 0.05666594998911023, 0.059095781994983554, 0.05846963101066649, 0.05771425599232316, 0.05792864493560046, 0.05648136790841818, 0.056762946071103215, 0.056594265974126756, 0.05619019304867834, 0.056463452987372875, 0.05681504006497562, 0.05950231500901282, 0.05693954392336309, 0.0563194319838658, 0.05793011200148612, 0.056882967008277774, 0.05665088992100209, 0.0578032520134002, 0.056310607003979385, 0.0562275160336867, 0.058405685937032104, 0.05713984393514693, 0.05631153401918709, 0.17499041405972093, 0.05613718507811427, 0.05588473204988986, 0.0561045000795275, 0.05671553302090615, 0.05784732708707452, 0.057440517004579306, 0.05638957198243588, 0.05615328496787697, 0.15820734901353717, 0.05634849495254457, 0.05604150693397969, 0.05695689900312573, 0.057090622023679316, 0.05665881710592657, 0.05911364092025906, 0.05786296003498137, 0.05843733705114573, 0.07647612399887294, 0.05896228307392448, 0.05749134696088731, 0.057026884984225035, 0.05741744500119239, 0.05900776607450098, 0.05837360501755029, 0.057957550045102835, 0.05823313898872584, 0.05665351508650929, 0.05689328396692872, 0.05653733294457197, 0.05628176196478307, 0.058112683007493615, 0.05530216102488339, 0.05529016093350947, 0.06321067200042307, 0.0659289559116587, 0.0580988060683012, 0.05872559593990445, 0.05867186898831278, 0.05941040406469256, 0.05931994004640728, 0.054613254964351654, 0.055263033020310104, 0.052201322047039866, 0.05278781906235963, 0.17863511096220464, 0.05253256892319769, 0.05279698199592531, 0.053569835028611124, 0.05342635395936668, 0.0535944530274719, 0.05565381492488086, 0.05367277597542852, 0.05349368799943477, 0.053531266981735826]
[0.0012268388871399854, 0.0012451616137034514, 0.00125136911413971, 0.0012484884090636942, 0.0012302807034839961, 0.00125684286467731, 0.0012641562498174608, 0.001276151136897335, 0.0012724174541124905, 0.0012868291603147306, 0.0012400837969669903, 0.004266143160004338, 0.0013192033194090154, 0.0012469548620918597, 0.0012564887028102848, 0.0012472993852993982, 0.001281199317996983, 0.001290738045513122, 0.0012470278862482783, 0.0012408869092310356, 0.0031745182720690286, 0.003592240209907813, 0.0012893818622065146, 0.0013052668601144539, 0.0013015926978009384, 0.0012977322087038396, 0.0013088550916764625, 0.0013177519323044392, 0.0013273538599267256, 0.001327182117546367, 0.0013309640479598974, 0.001328367209278567, 0.0013306635339895999, 0.0013313964415384934, 0.0013406007675194117, 0.0013332602562556087, 0.0013403311848293902, 0.0014766613021492958, 0.001383079069688223, 0.0013582534671132995, 0.0013361634432099932, 0.0013676222554559624, 0.0013397177681326866, 0.0013439171395242908, 0.0013361590465010946, 0.0014747553234270147, 0.0013727726967095635, 0.0013536396977859874, 0.0013409188845693025, 0.0013639776274388612, 0.0013427041866275113, 0.0013476297919920019, 0.0013343265123102208, 0.0013419108378679254, 0.001368184974633677, 0.0013386080702117017, 0.001339530908004489, 0.001333563650828288, 0.001331560373262957, 0.0013386761867116358, 0.0013261409530546083, 0.0013583186055468612, 0.0013453798384817188, 0.0013358003736018789, 0.001339882836937038, 0.0013496203721652543, 0.0013422524410321615, 0.0013422848586382907, 0.0013503893711712472, 0.0013463651154970015, 0.0013551879078582969, 0.001358868648991162, 0.0013490081169144359, 0.001358428092803373, 0.0013543600216507912, 0.0013459209531415687, 0.0013437345353236726, 0.0013833729073751805, 0.0013411478356046731, 0.0013523794423658834, 0.0013929762346886617, 0.0013714526281800382, 0.001348056511000492, 0.0013499625357474353, 0.0013370805793593442, 0.0013593173271781484, 0.0013539375585698804, 0.0013597749991255792, 0.0013451425353238403, 0.0013697183701794507, 0.0013626965824081454, 0.0013647066986968005, 0.001368029349007059, 0.0013577349776358798, 0.0013582212336058187, 0.0013520388382075484, 0.0013650304632434665, 0.0013512420700863004, 0.001353739628156777, 0.0013643027889693891, 0.001358087117740408, 0.0013552421167882722, 0.0013619543724628382, 0.001351931254206182, 0.0013549436982937676, 0.0013685826060557088, 0.0013610843466161642, 0.0013665561158166721, 0.001350641721686305, 0.0013446004433167536, 0.0013454293718474896, 0.001350517276414605, 0.0013508839521903632, 0.001352287720628949, 0.0013482393020070916, 0.001352942743620207, 0.0013504682547347837, 0.0013499392093657408, 0.0013543201615860642, 0.0013523621641662578, 0.001359529024379891, 0.0013575760219895908, 0.0013477634638547897, 0.001351223278487491, 0.001349387070445647, 0.0013549120224968984, 0.0013494834163074578, 0.001369291209875671, 0.0013503502799891108, 0.0013454034410113858, 0.001353637207039567, 0.0013347077427085401, 0.0012972702564628318, 0.0012977126509297727, 0.001298219766900983, 0.0012983886043129618, 0.001307596628510848, 0.0013058128154858253, 0.0012980941385247332, 0.001301628255913424, 0.0012969867689101848, 0.0013034380457992124, 0.001338093698587875, 0.0013063093024674197, 0.0013021633954891979, 0.0013112628393871493, 0.0013373912322919728, 0.0013041492107562548, 0.0012962386732227927, 0.0013156409543224198, 0.001415481604094249, 0.0013234614432507822, 0.001321239118074435, 0.001326228814134591, 0.001344844046438676, 0.0014086540241530815, 0.0014804705116507966, 0.001453706001061513, 0.004478113024582176, 0.0014142988379611525, 0.0013493816747308471, 0.0013011281383981884, 0.001317812790444424, 0.0013743205115112455, 0.001359758860713174, 0.0013421919998214688, 0.0013471777892000106, 0.0013135201839167018, 0.00132006851328147, 0.0013161457203285291, 0.001306748675550659, 0.0013131035578458807, 0.001321280001511061, 0.0013837747676514608, 0.0013241754400782114, 0.0013097542321829254, 0.001347211907011305, 0.001322859697866925, 0.001317462556302374, 0.0013442616747302372, 0.001309549000092544, 0.0013076166519462023, 0.0013582717659774907, 0.0013288335798871378, 0.0013095705585857464, 0.004069544513016766, 0.0013055159320491691, 0.0012996449313927875, 0.001304755815802965, 0.0013189658842071197, 0.0013452866764435934, 0.0013358259768506816, 0.0013113853949403695, 0.001305890348090162, 0.0036792406747334226, 0.0013104301151754551, 0.0013032908589297601, 0.0013245790465843193, 0.001327688884271612, 0.001317646909440153, 0.0013747358353548619, 0.0013456502333716598, 0.001359007838398738, 0.0017785145116016963, 0.0013712158854401043, 0.0013370080688578445, 0.001326206627540117, 0.0013352894186323813, 0.0013722736296395575, 0.001357525698082565, 0.0013478500010489032, 0.001354259046249438, 0.0013175236066630066, 0.0013230996271378773, 0.0013148216963853948, 0.0013088781852275133, 0.0013514577443603166, 0.0012860967680205439, 0.0012858176961281272, 0.0014700156279168156, 0.0015332315328292722, 0.001351135024844214, 0.00136571153348615, 0.001364462069495646, 0.0013816373038300594, 0.0013795334894513322, 0.0012700756968453872, 0.0012851868144258163, 0.0012139842336520898, 0.0012276236991246427, 0.004154304906097782, 0.0012216876493766904, 0.001227836790602914, 0.0012458101169444448, 0.0012424733478922484, 0.0012463826285458582, 0.0012942747656949037, 0.001248204092451826, 0.0012440392558008087, 0.0012449131856217635]
[815.1029531931501, 803.1085997148003, 799.1247256309974, 800.9685894881087, 812.8226324026128, 795.6444103748375, 791.0414556305014, 783.6062446578762, 785.9055978586043, 777.1039317724363, 806.3971180381602, 234.4037606086766, 758.0332654468956, 801.9536475622104, 795.8686757496366, 801.7321356732352, 780.5186796098146, 774.7505417355684, 801.9066863119883, 805.8752111581944, 315.00842467926276, 278.37782040351436, 775.5654312436997, 766.1268592326888, 768.2894976973333, 770.5750025259748, 764.0265193293004, 758.8681719868431, 753.3786055025322, 753.4760955404928, 751.3350954391298, 752.803888122997, 751.5047752167646, 751.0910866221419, 745.9342290623597, 750.0411081092655, 746.0842598594684, 677.2033631168431, 723.0244618085518, 736.2396078585415, 748.4114350543855, 731.1960565211789, 746.4258695275879, 744.0934940036349, 748.4138977456535, 678.078583012818, 728.4527164598534, 738.74901987257, 745.7572650423189, 733.1498551612599, 744.7656825377999, 742.0435537580747, 749.4417526551459, 745.2059941544513, 730.8953237611338, 747.044652018159, 746.5299934659281, 749.8704687840668, 750.9986179218624, 747.0066397882448, 754.0676560033975, 736.2043013446013, 743.28451445245, 748.6148527594584, 746.3339125128227, 740.9490999277498, 745.0163392744682, 744.9983463379533, 740.5271556104294, 742.7405749671826, 737.9050493302981, 735.9063002464662, 741.2853840251781, 736.1449643877072, 738.3561121223353, 742.9856840149931, 744.1946111470036, 722.8708865618929, 745.6299547686609, 739.4374453449079, 717.8873372692577, 729.1538763005123, 741.8086644289315, 740.7612978284089, 747.8980814149176, 735.6633951513978, 738.5864980777009, 735.4157861727587, 743.4156409002799, 730.0770886711457, 733.8390753375259, 732.7581823661671, 730.978469669396, 736.5207617625227, 736.257080405959, 739.6237236244926, 732.5843832260616, 740.0598472604784, 738.694486887097, 732.9751196619718, 736.3297883745521, 737.8755335392434, 734.2389878977283, 739.6825814099352, 738.0380463478035, 730.6829676010763, 734.708324642872, 731.7665102997886, 740.3887973721696, 743.7153579492206, 743.2571496687635, 740.4570215161044, 740.2560363372223, 739.4875992328763, 741.7080918137633, 739.1295786281376, 740.4838999317229, 740.7740978720389, 738.3778432633576, 739.446892627692, 735.5488423324543, 736.606999388847, 741.9699575026776, 740.0701393476307, 741.0772060160182, 738.0553005627264, 741.0242970871503, 730.304841503217, 740.548593071765, 743.2714749475189, 738.750379200215, 749.2276908281708, 770.8494009001824, 770.5866158301915, 770.2856061012907, 770.1854411523789, 764.7618372485761, 765.80654450688, 770.3601536453178, 768.2685094280204, 771.0178885172953, 767.2017885490237, 747.3318206754325, 765.5154855830484, 767.9527803224105, 762.6236098228593, 747.7243575810169, 766.7834261235464, 771.4628645616128, 760.0857944673963, 706.4733283057317, 755.5943583393916, 756.8652686104186, 754.0176999189493, 743.5806424158486, 709.8975212179764, 675.4609376751121, 687.8970020552907, 223.3083431594055, 707.0641459633778, 741.0801693297517, 768.5638105030104, 758.8331265647804, 727.6323038360018, 735.4245145168712, 745.0498886396392, 742.2925229444483, 761.3130062593815, 757.536438403615, 759.7942876343399, 765.2580933962713, 761.5545583019205, 756.8418494614056, 722.6609585439959, 755.1869410453163, 763.5020184919211, 742.2737245682675, 755.9380647943789, 759.0348547032918, 743.902782321513, 763.6216742781916, 764.7501265081333, 736.2296891155227, 752.5396822715251, 763.6091033383775, 245.72774589426888, 765.9806942611386, 769.4409263985143, 766.426934364409, 758.1697237007293, 743.3359874221047, 748.6005043543032, 762.5523388152966, 765.7610774614266, 271.7952122206451, 763.1082256272085, 767.2884323160085, 754.9568314391591, 753.1885005941083, 758.9286574693094, 727.4124775701865, 743.1351588996504, 735.830928818084, 562.2669893761052, 729.2797659495031, 747.9386424752562, 754.0303141561178, 748.9013138621375, 728.7176393986823, 736.6343056433101, 741.9223201556518, 738.4111649609849, 758.9996831501007, 755.8009839086685, 760.5593996122227, 764.0130390179717, 739.9417437748514, 777.546468403866, 777.7152258918309, 680.2648767871381, 652.2172148094945, 740.118479361676, 732.2190488114094, 732.8895557863589, 723.7789521373544, 724.8827285792967, 787.354645462313, 778.0969963084865, 823.7339269157143, 814.5818630847957, 240.71415618342735, 818.5398293174231, 814.4404921349216, 802.6905436060074, 804.8462381075747, 802.3218368878341, 772.6334674099082, 801.1510345521436, 803.8331550528793, 803.2688636843033]
Elapsed: 0.06071644294327901~0.019215450674421847
Time per graph: 0.0014089706615441834~0.0004436378744535874
Speed: 736.5971309653653~87.59884343716035
Total Time: 0.0544
best val loss: 0.3668532371520996 test_score: 0.8605

Testing...
Test loss: 0.6904 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.17656972806435078, 0.17082605510950089, 0.24712744180578738, 0.1780299679376185, 0.1740488229552284, 0.175734311924316, 0.17778047500178218, 0.1777336581144482, 0.18057681212667376, 0.18666719703469425, 0.17936126701533794, 0.3143267191480845, 0.1974648729665205, 0.1805724089499563, 0.1768344360170886, 0.17752416373696178, 0.1803921170067042, 0.18702582106925547, 0.1798931659432128, 0.17771824507508427, 0.2790121278958395, 0.274744949885644, 0.19686616503167897, 0.17240559309720993, 0.17288018902763724, 0.1728016920387745, 0.17351212992798537, 0.17437544802669436, 0.17788903298787773, 0.1785081949783489, 0.17777328402735293, 0.17766237200703472, 0.1783968029776588, 0.17820958804804832, 0.1790654050419107, 0.17808897781651467, 0.18188485293649137, 0.18956805195193738, 0.1869267129804939, 0.18285847490187734, 0.17762941296678036, 0.18941969890147448, 0.1798455099342391, 0.1789525639032945, 0.17906951298937201, 0.18317895801737905, 0.18775711115449667, 0.19206294603645802, 0.1827039490453899, 0.18063607497606426, 0.18084824387915432, 0.18003080890048295, 0.1794470709282905, 0.17952579993288964, 0.18015869706869125, 0.18056128302123398, 0.1787099950015545, 0.17811353807337582, 0.17821440193802118, 0.17964479292277247, 0.17932038998696953, 0.1794366870308295, 0.17973413015715778, 0.179946347954683, 0.17941960121970624, 0.18048679910134524, 0.18045106390491128, 0.18189492693636566, 0.18164793401956558, 0.18071850016713142, 0.18278339598327875, 0.1824431250570342, 0.18117405090015382, 0.18259530304931104, 0.18265246006194502, 0.18061433802358806, 0.18139125010930002, 0.18341634003445506, 0.18127139995340258, 0.18108053400646895, 0.18323947000317276, 0.1826013979734853, 0.18040640896651894, 0.18094779085367918, 0.18071050592698157, 0.1809134850045666, 0.1825555469840765, 0.18232021108269691, 0.18177862605080009, 0.18310537794604897, 0.183172516990453, 0.18323128996416926, 0.18366530910134315, 0.1824482571100816, 0.18278960196767002, 0.18221138988155872, 0.18404595903120935, 0.18221187288872898, 0.18248564994428307, 0.18263625702820718, 0.1823295570211485, 0.18247708689887077, 0.1826115440344438, 0.1813623149646446, 0.18249448493588716, 0.18224679003469646, 0.1827891831053421, 0.1829746310831979, 0.18193882994819432, 0.18126013688743114, 0.1831496860831976, 0.18095315899699926, 0.1822556391125545, 0.1824258400592953, 0.18195175402797759, 0.18241074797697365, 0.18186794803477824, 0.18245773506350815, 0.1825074510416016, 0.18164657498709857, 0.18300072196871042, 0.18375594995450228, 0.1818239880958572, 0.182071401970461, 0.18222091905772686, 0.18325145298149437, 0.18354694405570626, 0.18405675201211125, 0.18431233696173877, 0.18321593303699046, 0.1970625858521089, 0.19596454803831875, 0.19261838705278933, 0.19031128310598433, 0.1911400678800419, 0.19186488003470004, 0.19519677804782987, 0.19161443796474487, 0.19125780405011028, 0.19193352188449353, 0.19547601393423975, 0.19186116510536522, 0.19199729699175805, 0.193474852014333, 0.1912186979316175, 0.19269495899789035, 0.19468711107037961, 0.19446435815189034, 0.19052237994037569, 0.18863481690641493, 0.2744941570563242, 0.20191003801301122, 0.19407184002920985, 0.19305893499404192, 0.19539703894406557, 0.2048372559947893, 0.2138722559902817, 0.20972540602087975, 0.3332973039941862, 0.2099154869792983, 0.20105219690594822, 0.19102356699295342, 0.1923958568368107, 0.19513998099137098, 0.204229790950194, 0.19789297704119235, 0.1960748010315001, 0.3087260469328612, 0.1945380779216066, 0.19420451810583472, 0.1934303231537342, 0.19156958698295057, 0.1932499158428982, 0.2000659090699628, 0.19706776400562376, 0.19420827098656446, 0.19513484195340425, 0.3208464861381799, 0.19393897789996117, 0.19467802601866424, 0.1925140820676461, 0.1930735290516168, 0.19795973994769156, 0.1952348139602691, 0.1922469058772549, 0.3131154349539429, 0.19212860497646034, 0.19168421300128102, 0.19199067691806704, 0.1952535379678011, 0.1932800707872957, 0.19978894607629627, 0.19480854901485145, 0.19143104692921042, 0.30260251904837787, 0.19321372301783413, 0.19342463905923069, 0.19281487597618252, 0.19395104004070163, 0.19384954601991922, 0.19688400602899492, 0.20039769308641553, 0.19888971699401736, 0.21342273813206702, 0.27571478311438113, 0.19594006799161434, 0.19550368282943964, 0.19606870715506375, 0.1970324581488967, 0.2010349741904065, 0.19919471093453467, 0.1941043718252331, 0.2948213591007516, 0.19410448800772429, 0.19291000918019563, 0.19119518098887056, 0.20093448704574257, 0.18733247683849186, 0.18509841384366155, 0.19093878590501845, 0.19845708005595952, 0.3315587898250669, 0.19319548597559333, 0.1945257099578157, 0.1959937270730734, 0.19718678598292172, 0.19020135595928878, 0.1849387378897518, 0.1781268910272047, 0.17235176195390522, 0.2999294681940228, 0.17810902814380825, 0.17347947810776532, 0.17548226192593575, 0.17513439094182104, 0.176684251986444, 0.17818712105508894, 0.18055278586689383, 0.17924523202236742, 0.17765607906039804]
Total Epoch List: [21, 109, 110]
Total Time List: [0.14001657301560044, 0.05845707398839295, 0.05443589994683862]
T-times Epoch Time: 0.19448057665235627 ~ 0.0014452392759902125
T-times Total Epoch: 92.8888888888889 ~ 16.15281957575561
T-times Total Time: 0.06751584420756747 ~ 0.011930531522272301
T-times Inference Elapsed: 0.059788329861752636 ~ 0.0007005564392552773
T-times Time Per Graph: 0.001384828616742272 ~ 1.9237949384631364e-05
T-times Speed: 743.0603828689085 ~ 5.001148645868967
T-times cross validation test micro f1 score:0.7147541272479422 ~ 0.03987234216285683
T-times cross validation test precision:0.7236702868281816 ~ 0.07784459578907442
T-times cross validation test recall:0.7388167388167388 ~ 0.1618425456994946
T-times cross validation test f1_score:0.7147541272479422 ~ 0.11401199572995382
