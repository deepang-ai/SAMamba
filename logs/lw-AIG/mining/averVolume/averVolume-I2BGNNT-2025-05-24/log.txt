Namespace(seed=15, model='I2BGNNT', dataset='mining/averVolume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/mining/averVolume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 436], edge_attr=[436, 2], x=[115, 14887], y=[1, 1], num_nodes=115)
Data(edge_index=[2, 436], edge_attr=[436, 2], x=[115, 14887], y=[1, 1], num_nodes=115)
Data(edge_index=[2, 382], edge_attr=[382, 2], x=[103, 14887], y=[1, 1], num_nodes=115)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7519950ab670>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6933;  Loss pred: 0.6933; Loss self: 0.0000; time: 0.34s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6919;  Loss pred: 0.6919; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6900;  Loss pred: 0.6900; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6900;  Loss pred: 0.6900; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6852;  Loss pred: 0.6852; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6846;  Loss pred: 0.6846; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6814;  Loss pred: 0.6814; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6763;  Loss pred: 0.6763; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6730;  Loss pred: 0.6730; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6699;  Loss pred: 0.6699; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6687;  Loss pred: 0.6687; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6601;  Loss pred: 0.6601; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6582;  Loss pred: 0.6582; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.06s
Epoch 17/1000, LR 0.000270
Train loss: 0.6500;  Loss pred: 0.6500; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6502;  Loss pred: 0.6502; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6384;  Loss pred: 0.6384; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.19s
Epoch 20/1000, LR 0.000270
Train loss: 0.6334;  Loss pred: 0.6334; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6334;  Loss pred: 0.6334; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6308;  Loss pred: 0.6308; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6210;  Loss pred: 0.6210; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6096;  Loss pred: 0.6096; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6045;  Loss pred: 0.6045; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5898;  Loss pred: 0.5898; Loss self: 0.0000; time: 0.07s
Val loss: 0.6921 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.06s
Epoch 27/1000, LR 0.000270
Train loss: 0.5877;  Loss pred: 0.5877; Loss self: 0.0000; time: 0.07s
Val loss: 0.6919 score: 0.5116 time: 0.05s
Test loss: 0.6917 score: 0.6136 time: 0.06s
Epoch 28/1000, LR 0.000270
Train loss: 0.5807;  Loss pred: 0.5807; Loss self: 0.0000; time: 0.08s
Val loss: 0.6916 score: 0.6744 time: 0.16s
Test loss: 0.6914 score: 0.6591 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5737;  Loss pred: 0.5737; Loss self: 0.0000; time: 0.07s
Val loss: 0.6913 score: 0.7442 time: 0.05s
Test loss: 0.6911 score: 0.7500 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5583;  Loss pred: 0.5583; Loss self: 0.0000; time: 0.07s
Val loss: 0.6909 score: 0.7442 time: 0.05s
Test loss: 0.6908 score: 0.8182 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5560;  Loss pred: 0.5560; Loss self: 0.0000; time: 0.07s
Val loss: 0.6905 score: 0.8605 time: 0.05s
Test loss: 0.6904 score: 0.8182 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5378;  Loss pred: 0.5378; Loss self: 0.0000; time: 0.07s
Val loss: 0.6901 score: 0.7674 time: 0.05s
Test loss: 0.6900 score: 0.7955 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5272;  Loss pred: 0.5272; Loss self: 0.0000; time: 0.07s
Val loss: 0.6896 score: 0.7674 time: 0.05s
Test loss: 0.6895 score: 0.7273 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5170;  Loss pred: 0.5170; Loss self: 0.0000; time: 0.07s
Val loss: 0.6890 score: 0.7442 time: 0.05s
Test loss: 0.6890 score: 0.6818 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5149;  Loss pred: 0.5149; Loss self: 0.0000; time: 0.07s
Val loss: 0.6882 score: 0.7442 time: 0.05s
Test loss: 0.6883 score: 0.6364 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5063;  Loss pred: 0.5063; Loss self: 0.0000; time: 0.07s
Val loss: 0.6873 score: 0.7442 time: 0.05s
Test loss: 0.6875 score: 0.6591 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4924;  Loss pred: 0.4924; Loss self: 0.0000; time: 0.07s
Val loss: 0.6864 score: 0.6977 time: 0.05s
Test loss: 0.6867 score: 0.6591 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4797;  Loss pred: 0.4797; Loss self: 0.0000; time: 0.07s
Val loss: 0.6855 score: 0.6279 time: 0.05s
Test loss: 0.6859 score: 0.6591 time: 0.09s
Epoch 39/1000, LR 0.000269
Train loss: 0.4651;  Loss pred: 0.4651; Loss self: 0.0000; time: 0.11s
Val loss: 0.6844 score: 0.6279 time: 0.05s
Test loss: 0.6849 score: 0.6364 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4600;  Loss pred: 0.4600; Loss self: 0.0000; time: 0.07s
Val loss: 0.6833 score: 0.6279 time: 0.05s
Test loss: 0.6840 score: 0.6364 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4483;  Loss pred: 0.4483; Loss self: 0.0000; time: 0.07s
Val loss: 0.6820 score: 0.6512 time: 0.05s
Test loss: 0.6830 score: 0.6364 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4332;  Loss pred: 0.4332; Loss self: 0.0000; time: 0.07s
Val loss: 0.6807 score: 0.6279 time: 0.05s
Test loss: 0.6819 score: 0.6364 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4142;  Loss pred: 0.4142; Loss self: 0.0000; time: 0.07s
Val loss: 0.6792 score: 0.6047 time: 0.05s
Test loss: 0.6806 score: 0.6364 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4021;  Loss pred: 0.4021; Loss self: 0.0000; time: 0.07s
Val loss: 0.6774 score: 0.6279 time: 0.05s
Test loss: 0.6792 score: 0.6364 time: 0.06s
Epoch 45/1000, LR 0.000269
Train loss: 0.3939;  Loss pred: 0.3939; Loss self: 0.0000; time: 0.07s
Val loss: 0.6755 score: 0.6279 time: 0.05s
Test loss: 0.6776 score: 0.6364 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3829;  Loss pred: 0.3829; Loss self: 0.0000; time: 0.07s
Val loss: 0.6734 score: 0.6279 time: 0.05s
Test loss: 0.6759 score: 0.6364 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3694;  Loss pred: 0.3694; Loss self: 0.0000; time: 0.07s
Val loss: 0.6709 score: 0.6279 time: 0.05s
Test loss: 0.6739 score: 0.6364 time: 0.19s
Epoch 48/1000, LR 0.000269
Train loss: 0.3522;  Loss pred: 0.3522; Loss self: 0.0000; time: 0.07s
Val loss: 0.6683 score: 0.6512 time: 0.05s
Test loss: 0.6717 score: 0.6364 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3437;  Loss pred: 0.3437; Loss self: 0.0000; time: 0.07s
Val loss: 0.6653 score: 0.6744 time: 0.05s
Test loss: 0.6691 score: 0.6364 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3285;  Loss pred: 0.3285; Loss self: 0.0000; time: 0.07s
Val loss: 0.6619 score: 0.6977 time: 0.05s
Test loss: 0.6663 score: 0.6818 time: 0.06s
Epoch 51/1000, LR 0.000269
Train loss: 0.3197;  Loss pred: 0.3197; Loss self: 0.0000; time: 0.07s
Val loss: 0.6583 score: 0.6977 time: 0.05s
Test loss: 0.6632 score: 0.6818 time: 0.06s
Epoch 52/1000, LR 0.000269
Train loss: 0.3007;  Loss pred: 0.3007; Loss self: 0.0000; time: 0.07s
Val loss: 0.6542 score: 0.7209 time: 0.05s
Test loss: 0.6597 score: 0.7045 time: 0.06s
Epoch 53/1000, LR 0.000269
Train loss: 0.2915;  Loss pred: 0.2915; Loss self: 0.0000; time: 0.07s
Val loss: 0.6499 score: 0.7209 time: 0.05s
Test loss: 0.6558 score: 0.7045 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2720;  Loss pred: 0.2720; Loss self: 0.0000; time: 0.07s
Val loss: 0.6450 score: 0.7209 time: 0.05s
Test loss: 0.6516 score: 0.6818 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2591;  Loss pred: 0.2591; Loss self: 0.0000; time: 0.07s
Val loss: 0.6398 score: 0.7442 time: 0.05s
Test loss: 0.6470 score: 0.7045 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2570;  Loss pred: 0.2570; Loss self: 0.0000; time: 0.19s
Val loss: 0.6343 score: 0.7674 time: 0.05s
Test loss: 0.6422 score: 0.7045 time: 0.06s
Epoch 57/1000, LR 0.000269
Train loss: 0.2363;  Loss pred: 0.2363; Loss self: 0.0000; time: 0.07s
Val loss: 0.6285 score: 0.7674 time: 0.05s
Test loss: 0.6372 score: 0.7273 time: 0.06s
Epoch 58/1000, LR 0.000269
Train loss: 0.2313;  Loss pred: 0.2313; Loss self: 0.0000; time: 0.07s
Val loss: 0.6222 score: 0.7674 time: 0.05s
Test loss: 0.6318 score: 0.7273 time: 0.06s
Epoch 59/1000, LR 0.000268
Train loss: 0.2186;  Loss pred: 0.2186; Loss self: 0.0000; time: 0.07s
Val loss: 0.6155 score: 0.7674 time: 0.05s
Test loss: 0.6262 score: 0.7273 time: 0.06s
Epoch 60/1000, LR 0.000268
Train loss: 0.2020;  Loss pred: 0.2020; Loss self: 0.0000; time: 0.07s
Val loss: 0.6085 score: 0.7674 time: 0.05s
Test loss: 0.6204 score: 0.7273 time: 0.06s
Epoch 61/1000, LR 0.000268
Train loss: 0.1856;  Loss pred: 0.1856; Loss self: 0.0000; time: 0.07s
Val loss: 0.6012 score: 0.7674 time: 0.05s
Test loss: 0.6145 score: 0.7273 time: 0.06s
Epoch 62/1000, LR 0.000268
Train loss: 0.1721;  Loss pred: 0.1721; Loss self: 0.0000; time: 0.07s
Val loss: 0.5939 score: 0.7674 time: 0.05s
Test loss: 0.6084 score: 0.7273 time: 0.06s
Epoch 63/1000, LR 0.000268
Train loss: 0.1706;  Loss pred: 0.1706; Loss self: 0.0000; time: 0.07s
Val loss: 0.5860 score: 0.7674 time: 0.05s
Test loss: 0.6018 score: 0.7273 time: 0.06s
Epoch 64/1000, LR 0.000268
Train loss: 0.1544;  Loss pred: 0.1544; Loss self: 0.0000; time: 0.07s
Val loss: 0.5779 score: 0.7674 time: 0.05s
Test loss: 0.5948 score: 0.7273 time: 0.06s
Epoch 65/1000, LR 0.000268
Train loss: 0.1406;  Loss pred: 0.1406; Loss self: 0.0000; time: 0.07s
Val loss: 0.5692 score: 0.7674 time: 0.05s
Test loss: 0.5875 score: 0.7273 time: 0.06s
Epoch 66/1000, LR 0.000268
Train loss: 0.1319;  Loss pred: 0.1319; Loss self: 0.0000; time: 0.08s
Val loss: 0.5603 score: 0.7907 time: 0.14s
Test loss: 0.5801 score: 0.7273 time: 0.06s
Epoch 67/1000, LR 0.000268
Train loss: 0.1236;  Loss pred: 0.1236; Loss self: 0.0000; time: 0.07s
Val loss: 0.5512 score: 0.8140 time: 0.05s
Test loss: 0.5725 score: 0.7273 time: 0.06s
Epoch 68/1000, LR 0.000268
Train loss: 0.1139;  Loss pred: 0.1139; Loss self: 0.0000; time: 0.07s
Val loss: 0.5418 score: 0.8140 time: 0.05s
Test loss: 0.5652 score: 0.7273 time: 0.06s
Epoch 69/1000, LR 0.000268
Train loss: 0.1084;  Loss pred: 0.1084; Loss self: 0.0000; time: 0.07s
Val loss: 0.5324 score: 0.8140 time: 0.05s
Test loss: 0.5580 score: 0.7273 time: 0.06s
Epoch 70/1000, LR 0.000268
Train loss: 0.1005;  Loss pred: 0.1005; Loss self: 0.0000; time: 0.07s
Val loss: 0.5229 score: 0.8140 time: 0.05s
Test loss: 0.5509 score: 0.7273 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0913;  Loss pred: 0.0913; Loss self: 0.0000; time: 0.07s
Val loss: 0.5135 score: 0.8140 time: 0.05s
Test loss: 0.5441 score: 0.7273 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0853;  Loss pred: 0.0853; Loss self: 0.0000; time: 0.07s
Val loss: 0.5040 score: 0.8140 time: 0.05s
Test loss: 0.5372 score: 0.7273 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0808;  Loss pred: 0.0808; Loss self: 0.0000; time: 0.07s
Val loss: 0.4946 score: 0.8140 time: 0.05s
Test loss: 0.5306 score: 0.7273 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0700;  Loss pred: 0.0700; Loss self: 0.0000; time: 0.07s
Val loss: 0.4849 score: 0.8140 time: 0.05s
Test loss: 0.5239 score: 0.7273 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0650;  Loss pred: 0.0650; Loss self: 0.0000; time: 0.07s
Val loss: 0.4749 score: 0.8140 time: 0.05s
Test loss: 0.5171 score: 0.7273 time: 0.18s
Epoch 76/1000, LR 0.000267
Train loss: 0.0595;  Loss pred: 0.0595; Loss self: 0.0000; time: 0.07s
Val loss: 0.4646 score: 0.8140 time: 0.05s
Test loss: 0.5104 score: 0.7273 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0532;  Loss pred: 0.0532; Loss self: 0.0000; time: 0.07s
Val loss: 0.4550 score: 0.8140 time: 0.05s
Test loss: 0.5047 score: 0.7273 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0536;  Loss pred: 0.0536; Loss self: 0.0000; time: 0.07s
Val loss: 0.4457 score: 0.8140 time: 0.05s
Test loss: 0.4996 score: 0.7273 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0482;  Loss pred: 0.0482; Loss self: 0.0000; time: 0.07s
Val loss: 0.4354 score: 0.8372 time: 0.05s
Test loss: 0.4937 score: 0.7273 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0416;  Loss pred: 0.0416; Loss self: 0.0000; time: 0.07s
Val loss: 0.4261 score: 0.8372 time: 0.05s
Test loss: 0.4890 score: 0.7273 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0397;  Loss pred: 0.0397; Loss self: 0.0000; time: 0.07s
Val loss: 0.4148 score: 0.8372 time: 0.05s
Test loss: 0.4826 score: 0.7273 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0364;  Loss pred: 0.0364; Loss self: 0.0000; time: 0.07s
Val loss: 0.4042 score: 0.8605 time: 0.05s
Test loss: 0.4768 score: 0.7273 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0319;  Loss pred: 0.0319; Loss self: 0.0000; time: 0.07s
Val loss: 0.3935 score: 0.8837 time: 0.05s
Test loss: 0.4710 score: 0.7273 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0300;  Loss pred: 0.0300; Loss self: 0.0000; time: 0.07s
Val loss: 0.3828 score: 0.8837 time: 0.06s
Test loss: 0.4650 score: 0.7273 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0305;  Loss pred: 0.0305; Loss self: 0.0000; time: 0.07s
Val loss: 0.3710 score: 0.8837 time: 0.05s
Test loss: 0.4575 score: 0.7500 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0270;  Loss pred: 0.0270; Loss self: 0.0000; time: 0.19s
Val loss: 0.3613 score: 0.8837 time: 0.05s
Test loss: 0.4522 score: 0.7727 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0234;  Loss pred: 0.0234; Loss self: 0.0000; time: 0.07s
Val loss: 0.3525 score: 0.8837 time: 0.05s
Test loss: 0.4478 score: 0.7727 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0212;  Loss pred: 0.0212; Loss self: 0.0000; time: 0.07s
Val loss: 0.3446 score: 0.8837 time: 0.05s
Test loss: 0.4448 score: 0.7727 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0237;  Loss pred: 0.0237; Loss self: 0.0000; time: 0.07s
Val loss: 0.3397 score: 0.8837 time: 0.05s
Test loss: 0.4457 score: 0.7727 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0198;  Loss pred: 0.0198; Loss self: 0.0000; time: 0.07s
Val loss: 0.3372 score: 0.8837 time: 0.05s
Test loss: 0.4504 score: 0.7727 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0156;  Loss pred: 0.0156; Loss self: 0.0000; time: 0.07s
Val loss: 0.3360 score: 0.8837 time: 0.05s
Test loss: 0.4569 score: 0.7727 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.07s
Val loss: 0.3320 score: 0.8837 time: 0.05s
Test loss: 0.4589 score: 0.7727 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0157;  Loss pred: 0.0157; Loss self: 0.0000; time: 0.07s
Val loss: 0.3288 score: 0.8837 time: 0.05s
Test loss: 0.4617 score: 0.7727 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.07s
Val loss: 0.3258 score: 0.8837 time: 0.05s
Test loss: 0.4644 score: 0.7727 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.07s
Val loss: 0.3241 score: 0.8837 time: 0.05s
Test loss: 0.4687 score: 0.7727 time: 0.06s
Epoch 96/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.18s
Val loss: 0.3234 score: 0.8837 time: 0.05s
Test loss: 0.4744 score: 0.7727 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.07s
Val loss: 0.3238 score: 0.8837 time: 0.05s
Test loss: 0.4817 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.07s
Val loss: 0.3212 score: 0.8837 time: 0.05s
Test loss: 0.4834 score: 0.7727 time: 0.05s
Epoch 99/1000, LR 0.000265
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.07s
Val loss: 0.3196 score: 0.8837 time: 0.05s
Test loss: 0.4862 score: 0.7727 time: 0.05s
Epoch 100/1000, LR 0.000265
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.07s
Val loss: 0.3190 score: 0.8837 time: 0.05s
Test loss: 0.4907 score: 0.7727 time: 0.05s
Epoch 101/1000, LR 0.000265
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.07s
Val loss: 0.3186 score: 0.8837 time: 0.05s
Test loss: 0.4949 score: 0.7727 time: 0.05s
Epoch 102/1000, LR 0.000264
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.07s
Val loss: 0.3188 score: 0.8837 time: 0.05s
Test loss: 0.4994 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.3195 score: 0.8837 time: 0.05s
Test loss: 0.5044 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.07s
Val loss: 0.3198 score: 0.8605 time: 0.05s
Test loss: 0.5075 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.3210 score: 0.8605 time: 0.05s
Test loss: 0.5123 score: 0.7955 time: 0.17s
     INFO: Early stopping counter 4 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.3227 score: 0.8605 time: 0.05s
Test loss: 0.5183 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.3236 score: 0.8605 time: 0.05s
Test loss: 0.5206 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.3246 score: 0.8605 time: 0.05s
Test loss: 0.5224 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.3256 score: 0.8605 time: 0.05s
Test loss: 0.5220 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.3269 score: 0.8605 time: 0.05s
Test loss: 0.5207 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.07s
Val loss: 0.3290 score: 0.8605 time: 0.05s
Test loss: 0.5218 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.3311 score: 0.8605 time: 0.05s
Test loss: 0.5237 score: 0.7955 time: 0.06s
     INFO: Early stopping counter 11 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.3336 score: 0.8605 time: 0.05s
Test loss: 0.5266 score: 0.7955 time: 0.06s
     INFO: Early stopping counter 12 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.07s
Val loss: 0.3361 score: 0.8605 time: 0.05s
Test loss: 0.5313 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.3388 score: 0.8605 time: 0.05s
Test loss: 0.5364 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.3413 score: 0.8605 time: 0.18s
Test loss: 0.5389 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.3443 score: 0.8605 time: 0.05s
Test loss: 0.5431 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.07s
Val loss: 0.3472 score: 0.8605 time: 0.05s
Test loss: 0.5482 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.07s
Val loss: 0.3503 score: 0.8605 time: 0.05s
Test loss: 0.5547 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.3534 score: 0.8605 time: 0.05s
Test loss: 0.5598 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.3565 score: 0.8605 time: 0.05s
Test loss: 0.5638 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 100,   Train_Loss: 0.0101,   Val_Loss: 0.3186,   Val_Precision: 0.8696,   Val_Recall: 0.9091,   Val_accuracy: 0.8889,   Val_Score: 0.8837,   Val_Loss: 0.3186,   Test_Precision: 0.7143,   Test_Recall: 0.9091,   Test_accuracy: 0.8000,   Test_Score: 0.7727,   Test_loss: 0.4949


[0.05730732099618763, 0.05749989906325936, 0.056766299065202475, 0.05485145200509578, 0.05539480899460614, 0.054776528966613114, 0.05446745501831174, 0.0559593039797619, 0.05866682494524866, 0.05876385304145515, 0.059186495025642216, 0.0586922368966043, 0.05832453502807766, 0.059016642975620925, 0.06654758704826236, 0.0636177510023117, 0.05867426691111177, 0.058607094921171665, 0.1902451820205897, 0.058554779971018434, 0.05854940100107342, 0.058436432969756424, 0.05841857101768255, 0.05909754103049636, 0.0591324899578467, 0.06021022901404649, 0.06345133297145367, 0.05838592897634953, 0.058355937944725156, 0.05834140395745635, 0.05870228598359972, 0.0584486530860886, 0.05866029497701675, 0.05806299194227904, 0.059010858996771276, 0.0592574990587309, 0.0584037370281294, 0.09912319399882108, 0.05813093401957303, 0.05747648107353598, 0.057641441002488136, 0.05756568198557943, 0.05776513495948166, 0.06165052799042314, 0.05814439000096172, 0.05824288504663855, 0.19071419001556933, 0.05913971201516688, 0.0583634520880878, 0.061797049012966454, 0.06152374891098589, 0.060954551910981536, 0.05777961702551693, 0.05760381789878011, 0.05875438405200839, 0.062061788979917765, 0.062043013982474804, 0.06223106198012829, 0.061569219920784235, 0.06178980891127139, 0.061570651014335454, 0.06203197198919952, 0.06252307898830622, 0.06198867398779839, 0.06217550206929445, 0.06023068097420037, 0.06026480894070119, 0.06000987801235169, 0.060286216088570654, 0.058132070931605995, 0.057956268079578876, 0.05908730998635292, 0.059175746981054544, 0.058749857009388506, 0.188875618041493, 0.058534650946967304, 0.05860996199771762, 0.05860977596603334, 0.058371911058202386, 0.05846452200785279, 0.058283181046135724, 0.05939541710540652, 0.05875182000454515, 0.059072459931485355, 0.059738797950558364, 0.05899632803630084, 0.05840311199426651, 0.058197343023493886, 0.0584738259203732, 0.05903155996929854, 0.05873972503468394, 0.058844337007030845, 0.05951786902733147, 0.05858304409775883, 0.06568315892945975, 0.05831865000072867, 0.05829191207885742, 0.0584737058961764, 0.05842914793174714, 0.05818667798303068, 0.0596566490130499, 0.058293186011724174, 0.05835081497207284, 0.058403271017596126, 0.16991736309137195, 0.05954669299535453, 0.05957421404309571, 0.059428779990412295, 0.05977956799324602, 0.05940432602073997, 0.05920866003725678, 0.05990372190717608, 0.06038579496089369, 0.05773629806935787, 0.05561668099835515, 0.056722783017903566, 0.05855152499862015, 0.057646666071377695, 0.058026449056342244, 0.05751632899045944, 0.05834309000056237]
[0.0013024391135497187, 0.0013068158878013492, 0.0012901431605727835, 0.0012466239092067224, 0.001258972931695594, 0.0012449211128775708, 0.0012378967049616304, 0.0012718023631764067, 0.0013333369305738333, 0.001335542114578526, 0.0013451476142191414, 0.001333914474922825, 0.0013255576142744924, 0.0013412873403550211, 0.0015124451601877809, 0.0014458579773252661, 0.0013335060661616312, 0.0013319794300266287, 0.004323754136831584, 0.0013307904538867826, 0.0013306682045698506, 0.001328100749312646, 0.0013276947958564217, 0.0013431259325112808, 0.0013439202263146979, 0.0013684142957737838, 0.0014420757493512197, 0.0013269529312806712, 0.0013262713169255717, 0.001325940999033099, 0.00133414286326363, 0.0013283784792292863, 0.0013331885222049261, 0.0013196134532336146, 0.0013411558862902564, 0.0013467613422438842, 0.0013273576597302135, 0.00225279986360957, 0.0013211575913539325, 0.0013062836607621814, 0.0013100327500565486, 0.0013083109542177144, 0.0013128439763518559, 0.0014011483634187077, 0.0013214634091127664, 0.001323701932878149, 0.004334413409444757, 0.0013440843639810655, 0.0013264420929110863, 0.0014044783866583284, 0.0013982670207042247, 0.0013853307252495804, 0.0013131731142162937, 0.0013091776795177298, 0.001335326910272918, 0.00141049520408904, 0.0014100684996017, 0.0014143423177301884, 0.0013993004527450962, 0.0014043138388925317, 0.001399332977598533, 0.00140981754520908, 0.0014209790679160506, 0.0014088334997226907, 0.001413079592483965, 0.0013688791130500083, 0.0013696547486522998, 0.0013638608639170839, 0.0013701412747402421, 0.0013211834302637726, 0.00131718791089952, 0.0013428934087807481, 0.0013449033404785123, 0.001335224022940648, 0.004292627682761205, 0.0013303329760674387, 0.0013320445908572185, 0.0013320403628643942, 0.0013266343422318723, 0.001328739136542109, 0.0013246177510485393, 0.0013498958433046937, 0.0013352686364669353, 0.001342555907533758, 0.001357699953421781, 0.0013408256371886555, 0.001327343454415148, 0.0013226668868975883, 0.001328950589099391, 0.0013416263629386033, 0.0013349937507882714, 0.0013373712956143374, 0.0013526788415302608, 0.0013314328204036099, 0.0014927990665786308, 0.0013254238636529242, 0.001324816183610396, 0.0013289478612767364, 0.0013279351802669805, 0.0013224244996143336, 0.0013558329321147705, 0.0013248451366300949, 0.001326154885728928, 0.0013273470685817301, 0.0038617582520766355, 0.001353333931712603, 0.001353959410070357, 0.0013506540906911885, 0.0013586265453010458, 0.0013500983186531812, 0.0013456513644831086, 0.0013614482251630927, 0.001372404430929402, 0.0013121885924854062, 0.0012640154772353444, 0.0012891541594978082, 0.001330716477241367, 0.0013101515016222204, 0.0013187829330986874, 0.0013071892952377145, 0.0013259793181945993]
[767.7902096126096, 765.2187345858251, 775.1077791677251, 802.1665496824467, 794.2982528251761, 803.2637487274609, 807.8218449018295, 786.2856910427787, 749.9979765576779, 748.7596153533374, 743.4128339739876, 749.6732502718032, 754.3994989213069, 745.5524032123595, 661.1809977135587, 691.6308625622612, 749.9028503697803, 750.762344715795, 231.28049568812733, 751.4331028445109, 751.5021374717962, 752.9549249313703, 753.1851470088469, 744.5318237064126, 744.0917849284873, 730.7728391090359, 693.4448488228815, 753.6062330672711, 753.993536042157, 754.1813706109238, 749.5449157174687, 752.7975013417797, 750.0814651075196, 757.7976698779286, 745.6254789039323, 742.5220554176782, 753.376448818814, 443.8920723289376, 756.9119736693881, 765.5305122752029, 763.3396951006257, 764.3442843432704, 761.7051363398186, 713.700294778254, 756.7368064102527, 755.457082264496, 230.71172625596435, 744.0009175005084, 753.896461326361, 712.0081088462296, 715.1709832191843, 721.8492896848445, 761.514220154289, 763.8382594243254, 748.880287146776, 708.9708615109004, 709.1854050228542, 707.0424093686548, 714.6428045801291, 712.0915370232475, 714.6261940572223, 709.3116434805734, 703.740134234742, 709.8070852210968, 707.6742211259043, 730.5246975183175, 730.1110013191068, 733.2126219444003, 729.8517448060855, 756.8971704408609, 759.1931202261724, 744.6607403546116, 743.5478594649063, 748.9379930400272, 232.9575434682834, 751.6915073067443, 750.7256189948296, 750.7280018524507, 753.7872103609523, 752.5931708479553, 754.9347720943807, 740.7978956005153, 748.9129697870819, 744.8479384646075, 736.5397615870297, 745.8091285431613, 753.3845115020501, 756.0482612107822, 752.4734239199099, 745.3640056756718, 749.0671768384922, 747.7355041784698, 739.2737797751892, 751.0705644892099, 669.8825196159289, 754.4756265697206, 754.8216970559605, 752.4749684606045, 753.0488045349855, 756.186837351876, 737.5539982202988, 754.8052012657282, 754.0597337168084, 753.3824601492506, 258.9494045781495, 738.915929444354, 738.5745780577249, 740.3820170479448, 736.0374368207408, 740.6867975345461, 743.1345342440312, 734.5119568393477, 728.6481866885207, 762.0855765145068, 791.1295534032548, 775.7024190105792, 751.4748762058191, 763.2705063206866, 758.2749024893302, 765.0001446945358, 754.1595757025533]
Elapsed: 0.06355360401544166~0.02286433217277981
Time per graph: 0.0014444000912600375~0.000519643913017723
Speed: 726.4614840368492~96.9842547602799
Total Time: 0.0589
best val loss: 0.3186129927635193 test_score: 0.7727

Testing...
Test loss: 0.4710 score: 0.7273 time: 0.05s
test Score 0.7273
Epoch Time List: [0.4497484121238813, 0.17500576912425458, 0.1746859138365835, 0.1617481348803267, 0.16408349387347698, 0.16294541710522026, 0.16277886903844774, 0.1638532989891246, 0.28808597498573363, 0.1752547250362113, 0.17579445394221693, 0.17481226287782192, 0.17421284900046885, 0.18196171091403812, 0.18584208597894758, 0.1815277790883556, 0.17541389795951545, 0.17394722800236195, 0.3056220361031592, 0.17414846899919212, 0.17408618400804698, 0.174084032070823, 0.17476797010749578, 0.17941942310426384, 0.18229133100248873, 0.17847433895803988, 0.18263703910633922, 0.28973452001810074, 0.17439992912113667, 0.17430239787790924, 0.17446017998736352, 0.1748259930172935, 0.17431830405257642, 0.17676821094937623, 0.17822308593895286, 0.17580139101482928, 0.1748129321495071, 0.21499356382992119, 0.21386098209768534, 0.1713618190260604, 0.17233720200601965, 0.17204217100515962, 0.17255270795430988, 0.17723889998160303, 0.17364535806700587, 0.17361808300483972, 0.30256906512659043, 0.1725209339056164, 0.17278396105393767, 0.17689552099909633, 0.18247731297742575, 0.18301267293281853, 0.17318782198708504, 0.17109854007139802, 0.1710728551261127, 0.3017923808656633, 0.18360276112798601, 0.1833981249947101, 0.18373266595881432, 0.181936232955195, 0.1831136270193383, 0.1822909329785034, 0.1842925880337134, 0.18374619085807353, 0.18415794696193188, 0.2761290289927274, 0.17964927305001765, 0.17903709888923913, 0.17932408093474805, 0.17198757780715823, 0.17241757502779365, 0.17754943505860865, 0.1756840880261734, 0.17492644593585283, 0.3069283150834963, 0.174490712932311, 0.17439385189209133, 0.17409152700565755, 0.1743353740312159, 0.17431157198734581, 0.17467045411467552, 0.17616693407762796, 0.17549387796316296, 0.18064280599355698, 0.17529696796555072, 0.2988774939440191, 0.17483337805606425, 0.1729841799242422, 0.17436628497671336, 0.17512163403443992, 0.1755683379014954, 0.17511370708234608, 0.17636954109184444, 0.17473127599805593, 0.1806101710535586, 0.2869555309880525, 0.17478194809518754, 0.17438718595076352, 0.17580724915023893, 0.17497969313990325, 0.17623806500341743, 0.17729601997416466, 0.17504422494675964, 0.17531161103397608, 0.2846705538686365, 0.17640321305952966, 0.17740508809220046, 0.1762746429303661, 0.17626275087241083, 0.1761191551340744, 0.1768441180465743, 0.17578295711427927, 0.1791542739374563, 0.17362292308826, 0.16641792992595583, 0.29920201003551483, 0.17350876901764423, 0.17277734901290387, 0.17255216895136982, 0.17220157897099853, 0.1734089150559157]
Total Epoch List: [121]
Total Time List: [0.058929117978550494]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7519951d7a60>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6995;  Loss pred: 0.6995; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.7002;  Loss pred: 0.7002; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6993;  Loss pred: 0.6993; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6972;  Loss pred: 0.6972; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6970;  Loss pred: 0.6970; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6964;  Loss pred: 0.6964; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6957;  Loss pred: 0.6957; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6956 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6942;  Loss pred: 0.6942; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.5000 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6893;  Loss pred: 0.6893; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6887;  Loss pred: 0.6887; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6846;  Loss pred: 0.6846; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6811;  Loss pred: 0.6811; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6807;  Loss pred: 0.6807; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6792;  Loss pred: 0.6792; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6756;  Loss pred: 0.6756; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6739;  Loss pred: 0.6739; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6681;  Loss pred: 0.6681; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6656;  Loss pred: 0.6656; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6611;  Loss pred: 0.6611; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6571;  Loss pred: 0.6571; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6558;  Loss pred: 0.6558; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6503;  Loss pred: 0.6503; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6419;  Loss pred: 0.6419; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6404;  Loss pred: 0.6404; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6338;  Loss pred: 0.6338; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6284;  Loss pred: 0.6284; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.6186;  Loss pred: 0.6186; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.22s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.6110;  Loss pred: 0.6110; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.6021;  Loss pred: 0.6021; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5992;  Loss pred: 0.5992; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5886;  Loss pred: 0.5886; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5789;  Loss pred: 0.5789; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5671;  Loss pred: 0.5671; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5546;  Loss pred: 0.5546; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6906 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5454;  Loss pred: 0.5454; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5333;  Loss pred: 0.5333; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6885 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.5190;  Loss pred: 0.5190; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6887 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6878 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.5086;  Loss pred: 0.5086; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4928;  Loss pred: 0.4928; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6862 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4740;  Loss pred: 0.4740; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6861 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6851 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4631;  Loss pred: 0.4631; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6850 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6840 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4484;  Loss pred: 0.4484; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6838 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6827 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4316;  Loss pred: 0.4316; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6823 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6813 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4141;  Loss pred: 0.4141; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6807 score: 0.5000 time: 0.05s
Test loss: 0.6796 score: 0.5349 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.4011;  Loss pred: 0.4011; Loss self: 0.0000; time: 0.08s
Val loss: 0.6788 score: 0.5682 time: 0.05s
Test loss: 0.6776 score: 0.5814 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3797;  Loss pred: 0.3797; Loss self: 0.0000; time: 0.08s
Val loss: 0.6766 score: 0.5455 time: 0.05s
Test loss: 0.6754 score: 0.6047 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3630;  Loss pred: 0.3630; Loss self: 0.0000; time: 0.08s
Val loss: 0.6741 score: 0.5909 time: 0.05s
Test loss: 0.6729 score: 0.6279 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3552;  Loss pred: 0.3552; Loss self: 0.0000; time: 0.08s
Val loss: 0.6714 score: 0.5909 time: 0.05s
Test loss: 0.6701 score: 0.6279 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3318;  Loss pred: 0.3318; Loss self: 0.0000; time: 0.08s
Val loss: 0.6683 score: 0.6136 time: 0.05s
Test loss: 0.6669 score: 0.6512 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3125;  Loss pred: 0.3125; Loss self: 0.0000; time: 0.08s
Val loss: 0.6648 score: 0.6364 time: 0.05s
Test loss: 0.6633 score: 0.6512 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2981;  Loss pred: 0.2981; Loss self: 0.0000; time: 0.08s
Val loss: 0.6609 score: 0.6591 time: 0.05s
Test loss: 0.6591 score: 0.7209 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2819;  Loss pred: 0.2819; Loss self: 0.0000; time: 0.08s
Val loss: 0.6565 score: 0.7273 time: 0.05s
Test loss: 0.6545 score: 0.8140 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2611;  Loss pred: 0.2611; Loss self: 0.0000; time: 0.08s
Val loss: 0.6517 score: 0.7273 time: 0.05s
Test loss: 0.6494 score: 0.8140 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2488;  Loss pred: 0.2488; Loss self: 0.0000; time: 0.08s
Val loss: 0.6463 score: 0.7727 time: 0.05s
Test loss: 0.6437 score: 0.8372 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2325;  Loss pred: 0.2325; Loss self: 0.0000; time: 0.08s
Val loss: 0.6404 score: 0.7955 time: 0.05s
Test loss: 0.6374 score: 0.7907 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2202;  Loss pred: 0.2202; Loss self: 0.0000; time: 0.08s
Val loss: 0.6338 score: 0.8182 time: 0.05s
Test loss: 0.6305 score: 0.7907 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2041;  Loss pred: 0.2041; Loss self: 0.0000; time: 0.08s
Val loss: 0.6268 score: 0.8182 time: 0.05s
Test loss: 0.6230 score: 0.8140 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1932;  Loss pred: 0.1932; Loss self: 0.0000; time: 0.08s
Val loss: 0.6192 score: 0.8182 time: 0.05s
Test loss: 0.6150 score: 0.8372 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1807;  Loss pred: 0.1807; Loss self: 0.0000; time: 0.08s
Val loss: 0.6114 score: 0.8182 time: 0.05s
Test loss: 0.6066 score: 0.8605 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1696;  Loss pred: 0.1696; Loss self: 0.0000; time: 0.08s
Val loss: 0.6032 score: 0.8182 time: 0.05s
Test loss: 0.5976 score: 0.8372 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1616;  Loss pred: 0.1616; Loss self: 0.0000; time: 0.08s
Val loss: 0.5947 score: 0.8182 time: 0.05s
Test loss: 0.5881 score: 0.8372 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1478;  Loss pred: 0.1478; Loss self: 0.0000; time: 0.08s
Val loss: 0.5860 score: 0.8182 time: 0.05s
Test loss: 0.5781 score: 0.8372 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1363;  Loss pred: 0.1363; Loss self: 0.0000; time: 0.08s
Val loss: 0.5772 score: 0.8182 time: 0.05s
Test loss: 0.5681 score: 0.8372 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1303;  Loss pred: 0.1303; Loss self: 0.0000; time: 0.08s
Val loss: 0.5682 score: 0.8182 time: 0.05s
Test loss: 0.5574 score: 0.8372 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1214;  Loss pred: 0.1214; Loss self: 0.0000; time: 0.08s
Val loss: 0.5591 score: 0.8182 time: 0.05s
Test loss: 0.5465 score: 0.8372 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1143;  Loss pred: 0.1143; Loss self: 0.0000; time: 0.08s
Val loss: 0.5500 score: 0.8182 time: 0.05s
Test loss: 0.5353 score: 0.8837 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1053;  Loss pred: 0.1053; Loss self: 0.0000; time: 0.08s
Val loss: 0.5411 score: 0.8182 time: 0.05s
Test loss: 0.5241 score: 0.8837 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0963;  Loss pred: 0.0963; Loss self: 0.0000; time: 0.08s
Val loss: 0.5320 score: 0.8409 time: 0.05s
Test loss: 0.5127 score: 0.8837 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0864;  Loss pred: 0.0864; Loss self: 0.0000; time: 0.08s
Val loss: 0.5230 score: 0.8409 time: 0.05s
Test loss: 0.5009 score: 0.8837 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0853;  Loss pred: 0.0853; Loss self: 0.0000; time: 0.08s
Val loss: 0.5142 score: 0.8409 time: 0.05s
Test loss: 0.4893 score: 0.8837 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0804;  Loss pred: 0.0804; Loss self: 0.0000; time: 0.08s
Val loss: 0.5057 score: 0.8182 time: 0.05s
Test loss: 0.4778 score: 0.8837 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0721;  Loss pred: 0.0721; Loss self: 0.0000; time: 0.07s
Val loss: 0.4975 score: 0.8182 time: 0.05s
Test loss: 0.4664 score: 0.8837 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0679;  Loss pred: 0.0679; Loss self: 0.0000; time: 0.08s
Val loss: 0.4897 score: 0.8182 time: 0.05s
Test loss: 0.4552 score: 0.8837 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0593;  Loss pred: 0.0593; Loss self: 0.0000; time: 0.08s
Val loss: 0.4820 score: 0.8182 time: 0.05s
Test loss: 0.4437 score: 0.8837 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.08s
Val loss: 0.4746 score: 0.8182 time: 0.05s
Test loss: 0.4322 score: 0.8605 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0554;  Loss pred: 0.0554; Loss self: 0.0000; time: 0.08s
Val loss: 0.4676 score: 0.8182 time: 0.05s
Test loss: 0.4207 score: 0.8837 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0481;  Loss pred: 0.0481; Loss self: 0.0000; time: 0.08s
Val loss: 0.4609 score: 0.8182 time: 0.05s
Test loss: 0.4092 score: 0.8837 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0448;  Loss pred: 0.0448; Loss self: 0.0000; time: 0.08s
Val loss: 0.4551 score: 0.8182 time: 0.05s
Test loss: 0.3981 score: 0.8837 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0420;  Loss pred: 0.0420; Loss self: 0.0000; time: 0.08s
Val loss: 0.4496 score: 0.8182 time: 0.05s
Test loss: 0.3871 score: 0.8837 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0430;  Loss pred: 0.0430; Loss self: 0.0000; time: 0.08s
Val loss: 0.4445 score: 0.8182 time: 0.05s
Test loss: 0.3763 score: 0.8605 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0347;  Loss pred: 0.0347; Loss self: 0.0000; time: 0.08s
Val loss: 0.4399 score: 0.7955 time: 0.05s
Test loss: 0.3658 score: 0.8605 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0372;  Loss pred: 0.0372; Loss self: 0.0000; time: 0.08s
Val loss: 0.4363 score: 0.7955 time: 0.05s
Test loss: 0.3559 score: 0.8605 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0320;  Loss pred: 0.0320; Loss self: 0.0000; time: 0.08s
Val loss: 0.4334 score: 0.7955 time: 0.05s
Test loss: 0.3464 score: 0.8605 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0285;  Loss pred: 0.0285; Loss self: 0.0000; time: 0.08s
Val loss: 0.4317 score: 0.7955 time: 0.05s
Test loss: 0.3374 score: 0.8605 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0294;  Loss pred: 0.0294; Loss self: 0.0000; time: 0.08s
Val loss: 0.4310 score: 0.8182 time: 0.05s
Test loss: 0.3293 score: 0.8605 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0282;  Loss pred: 0.0282; Loss self: 0.0000; time: 0.08s
Val loss: 0.4314 score: 0.8182 time: 0.05s
Test loss: 0.3218 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0244;  Loss pred: 0.0244; Loss self: 0.0000; time: 0.08s
Val loss: 0.4330 score: 0.8182 time: 0.05s
Test loss: 0.3153 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.08s
Val loss: 0.4360 score: 0.8182 time: 0.05s
Test loss: 0.3100 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0222;  Loss pred: 0.0222; Loss self: 0.0000; time: 0.08s
Val loss: 0.4405 score: 0.8409 time: 0.05s
Test loss: 0.3058 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0194;  Loss pred: 0.0194; Loss self: 0.0000; time: 0.08s
Val loss: 0.4456 score: 0.8409 time: 0.05s
Test loss: 0.3023 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0194;  Loss pred: 0.0194; Loss self: 0.0000; time: 0.08s
Val loss: 0.4519 score: 0.8409 time: 0.05s
Test loss: 0.3000 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0172;  Loss pred: 0.0172; Loss self: 0.0000; time: 0.08s
Val loss: 0.4594 score: 0.8409 time: 0.05s
Test loss: 0.2992 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0174;  Loss pred: 0.0174; Loss self: 0.0000; time: 0.08s
Val loss: 0.4671 score: 0.8409 time: 0.05s
Test loss: 0.2989 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.08s
Val loss: 0.4755 score: 0.8409 time: 0.05s
Test loss: 0.2996 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.08s
Val loss: 0.4850 score: 0.8409 time: 0.05s
Test loss: 0.3014 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.08s
Val loss: 0.4947 score: 0.8409 time: 0.05s
Test loss: 0.3038 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.08s
Val loss: 0.5047 score: 0.8409 time: 0.05s
Test loss: 0.3066 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.08s
Val loss: 0.5148 score: 0.8409 time: 0.05s
Test loss: 0.3099 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.08s
Val loss: 0.5258 score: 0.8409 time: 0.05s
Test loss: 0.3138 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.08s
Val loss: 0.5365 score: 0.8409 time: 0.05s
Test loss: 0.3175 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.08s
Val loss: 0.5482 score: 0.8409 time: 0.05s
Test loss: 0.3220 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.08s
Val loss: 0.5602 score: 0.8409 time: 0.05s
Test loss: 0.3278 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.08s
Val loss: 0.5715 score: 0.8409 time: 0.05s
Test loss: 0.3331 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.08s
Val loss: 0.5819 score: 0.8409 time: 0.05s
Test loss: 0.3375 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.08s
Val loss: 0.5925 score: 0.8409 time: 0.05s
Test loss: 0.3421 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 085,   Train_Loss: 0.0294,   Val_Loss: 0.4310,   Val_Precision: 0.8889,   Val_Recall: 0.7273,   Val_accuracy: 0.8000,   Val_Score: 0.8182,   Val_Loss: 0.4310,   Test_Precision: 0.9444,   Test_Recall: 0.7727,   Test_accuracy: 0.8500,   Test_Score: 0.8605,   Test_loss: 0.3293


[0.05730732099618763, 0.05749989906325936, 0.056766299065202475, 0.05485145200509578, 0.05539480899460614, 0.054776528966613114, 0.05446745501831174, 0.0559593039797619, 0.05866682494524866, 0.05876385304145515, 0.059186495025642216, 0.0586922368966043, 0.05832453502807766, 0.059016642975620925, 0.06654758704826236, 0.0636177510023117, 0.05867426691111177, 0.058607094921171665, 0.1902451820205897, 0.058554779971018434, 0.05854940100107342, 0.058436432969756424, 0.05841857101768255, 0.05909754103049636, 0.0591324899578467, 0.06021022901404649, 0.06345133297145367, 0.05838592897634953, 0.058355937944725156, 0.05834140395745635, 0.05870228598359972, 0.0584486530860886, 0.05866029497701675, 0.05806299194227904, 0.059010858996771276, 0.0592574990587309, 0.0584037370281294, 0.09912319399882108, 0.05813093401957303, 0.05747648107353598, 0.057641441002488136, 0.05756568198557943, 0.05776513495948166, 0.06165052799042314, 0.05814439000096172, 0.05824288504663855, 0.19071419001556933, 0.05913971201516688, 0.0583634520880878, 0.061797049012966454, 0.06152374891098589, 0.060954551910981536, 0.05777961702551693, 0.05760381789878011, 0.05875438405200839, 0.062061788979917765, 0.062043013982474804, 0.06223106198012829, 0.061569219920784235, 0.06178980891127139, 0.061570651014335454, 0.06203197198919952, 0.06252307898830622, 0.06198867398779839, 0.06217550206929445, 0.06023068097420037, 0.06026480894070119, 0.06000987801235169, 0.060286216088570654, 0.058132070931605995, 0.057956268079578876, 0.05908730998635292, 0.059175746981054544, 0.058749857009388506, 0.188875618041493, 0.058534650946967304, 0.05860996199771762, 0.05860977596603334, 0.058371911058202386, 0.05846452200785279, 0.058283181046135724, 0.05939541710540652, 0.05875182000454515, 0.059072459931485355, 0.059738797950558364, 0.05899632803630084, 0.05840311199426651, 0.058197343023493886, 0.0584738259203732, 0.05903155996929854, 0.05873972503468394, 0.058844337007030845, 0.05951786902733147, 0.05858304409775883, 0.06568315892945975, 0.05831865000072867, 0.05829191207885742, 0.0584737058961764, 0.05842914793174714, 0.05818667798303068, 0.0596566490130499, 0.058293186011724174, 0.05835081497207284, 0.058403271017596126, 0.16991736309137195, 0.05954669299535453, 0.05957421404309571, 0.059428779990412295, 0.05977956799324602, 0.05940432602073997, 0.05920866003725678, 0.05990372190717608, 0.06038579496089369, 0.05773629806935787, 0.05561668099835515, 0.056722783017903566, 0.05855152499862015, 0.057646666071377695, 0.058026449056342244, 0.05751632899045944, 0.05834309000056237, 0.05661140300799161, 0.05707906698808074, 0.056989800999872386, 0.057843430899083614, 0.05729635199531913, 0.0572393499314785, 0.05777145503088832, 0.05623934301547706, 0.057726540020667017, 0.057247034972533584, 0.05212230095639825, 0.052938009961508214, 0.053593463031575084, 0.053366951062344015, 0.05361244594678283, 0.05375275295227766, 0.05308440199587494, 0.053988214931450784, 0.0572830120800063, 0.0571114479098469, 0.05690802296157926, 0.057823774055577815, 0.056862303987145424, 0.056717499042861164, 0.05714067502412945, 0.057401231955736876, 0.05711308098398149, 0.05729323101695627, 0.05192135600373149, 0.053307060967199504, 0.053429001942276955, 0.05356530798599124, 0.053301507025025785, 0.054276716080494225, 0.05359681893605739, 0.05316086101811379, 0.052860556985251606, 0.05375208903569728, 0.05356933595612645, 0.053589363931678236, 0.05399233405478299, 0.053924391977488995, 0.053861393011175096, 0.05386607290711254, 0.05388354405295104, 0.053742605028674006, 0.053448221064172685, 0.053446345031261444, 0.0539183949586004, 0.05333071597851813, 0.05310347198974341, 0.05348976003006101, 0.05350809602532536, 0.05324956204276532, 0.053206500015221536, 0.05290713894646615, 0.05302607303019613, 0.05262739199679345, 0.052668177988380194, 0.053010044968687, 0.05320415901951492, 0.05338794901035726, 0.053427139995619655, 0.05356872593984008, 0.052916300017386675, 0.05300115002319217, 0.05293309094849974, 0.05273770296480507, 0.05265451793093234, 0.0528975510969758, 0.052902344963513315, 0.05299536790698767, 0.05295053205918521, 0.053133761044591665, 0.05376970104407519, 0.05281242809724063, 0.05247244401834905, 0.053077787975780666, 0.05316869996022433, 0.05295836599543691, 0.05312728707212955, 0.05275405792053789, 0.05289411393459886, 0.052643663017079234, 0.053560793050564826, 0.05324664094951004, 0.05294132907874882, 0.05275194603018463, 0.05345002794638276, 0.05360709200613201, 0.05355453898664564, 0.05332413001451641, 0.05334508896339685, 0.05389601201750338, 0.05350380891468376, 0.05362024891655892, 0.05404740700032562, 0.05430054699536413, 0.054088869015686214, 0.054426281014457345, 0.054302314994856715, 0.053532791091129184, 0.05363594996742904, 0.053719872958026826, 0.05428614793345332, 0.05412541201803833]
[0.0013024391135497187, 0.0013068158878013492, 0.0012901431605727835, 0.0012466239092067224, 0.001258972931695594, 0.0012449211128775708, 0.0012378967049616304, 0.0012718023631764067, 0.0013333369305738333, 0.001335542114578526, 0.0013451476142191414, 0.001333914474922825, 0.0013255576142744924, 0.0013412873403550211, 0.0015124451601877809, 0.0014458579773252661, 0.0013335060661616312, 0.0013319794300266287, 0.004323754136831584, 0.0013307904538867826, 0.0013306682045698506, 0.001328100749312646, 0.0013276947958564217, 0.0013431259325112808, 0.0013439202263146979, 0.0013684142957737838, 0.0014420757493512197, 0.0013269529312806712, 0.0013262713169255717, 0.001325940999033099, 0.00133414286326363, 0.0013283784792292863, 0.0013331885222049261, 0.0013196134532336146, 0.0013411558862902564, 0.0013467613422438842, 0.0013273576597302135, 0.00225279986360957, 0.0013211575913539325, 0.0013062836607621814, 0.0013100327500565486, 0.0013083109542177144, 0.0013128439763518559, 0.0014011483634187077, 0.0013214634091127664, 0.001323701932878149, 0.004334413409444757, 0.0013440843639810655, 0.0013264420929110863, 0.0014044783866583284, 0.0013982670207042247, 0.0013853307252495804, 0.0013131731142162937, 0.0013091776795177298, 0.001335326910272918, 0.00141049520408904, 0.0014100684996017, 0.0014143423177301884, 0.0013993004527450962, 0.0014043138388925317, 0.001399332977598533, 0.00140981754520908, 0.0014209790679160506, 0.0014088334997226907, 0.001413079592483965, 0.0013688791130500083, 0.0013696547486522998, 0.0013638608639170839, 0.0013701412747402421, 0.0013211834302637726, 0.00131718791089952, 0.0013428934087807481, 0.0013449033404785123, 0.001335224022940648, 0.004292627682761205, 0.0013303329760674387, 0.0013320445908572185, 0.0013320403628643942, 0.0013266343422318723, 0.001328739136542109, 0.0013246177510485393, 0.0013498958433046937, 0.0013352686364669353, 0.001342555907533758, 0.001357699953421781, 0.0013408256371886555, 0.001327343454415148, 0.0013226668868975883, 0.001328950589099391, 0.0013416263629386033, 0.0013349937507882714, 0.0013373712956143374, 0.0013526788415302608, 0.0013314328204036099, 0.0014927990665786308, 0.0013254238636529242, 0.001324816183610396, 0.0013289478612767364, 0.0013279351802669805, 0.0013224244996143336, 0.0013558329321147705, 0.0013248451366300949, 0.001326154885728928, 0.0013273470685817301, 0.0038617582520766355, 0.001353333931712603, 0.001353959410070357, 0.0013506540906911885, 0.0013586265453010458, 0.0013500983186531812, 0.0013456513644831086, 0.0013614482251630927, 0.001372404430929402, 0.0013121885924854062, 0.0012640154772353444, 0.0012891541594978082, 0.001330716477241367, 0.0013101515016222204, 0.0013187829330986874, 0.0013071892952377145, 0.0013259793181945993, 0.001316544255999805, 0.0013274201625135056, 0.0013253442092993578, 0.001345196067420549, 0.001332473302216724, 0.0013311476728250814, 0.0013435222100206586, 0.0013078916980343502, 0.001342477674899233, 0.0013313263947100833, 0.0012121465338697267, 0.0012311165107327493, 0.001246359605385467, 0.001241091885170791, 0.0012468010685298331, 0.001250064022145992, 0.0012345209766482545, 0.0012555398821267624, 0.0013321630716280535, 0.001328173207205742, 0.0013234423944553317, 0.0013447389315250655, 0.001322379162491754, 0.001319011605647934, 0.0013288529075378942, 0.0013349123710636483, 0.001328211185673988, 0.0013324007213245644, 0.001207473395435616, 0.0012396990922604535, 0.0012425349288901618, 0.0012457048368835172, 0.001239569930814553, 0.0012622492111742842, 0.0012464376496757533, 0.0012362990934445069, 0.0012293152787267816, 0.0012500485822255181, 0.0012457985106075918, 0.0012462642774808891, 0.0012556356756926277, 0.001254055627383465, 0.001252590535143607, 0.0012526993699328497, 0.0012531056756500242, 0.0012498280239226513, 0.0012429818852133182, 0.001242938256540964, 0.0012539161618279164, 0.0012402492088027471, 0.0012349644648777538, 0.0012439479076758373, 0.0012443743261703571, 0.0012383619079712866, 0.0012373604654702683, 0.0012303985801503756, 0.0012331644890743287, 0.0012238928371347314, 0.0012248413485669812, 0.0012327917434578372, 0.0012373060237096493, 0.0012415802095431922, 0.0012424916278051083, 0.0012457843241823275, 0.001230611628311318, 0.001232584884260283, 0.0012310021150813892, 0.0012264582084838388, 0.0012245236728123802, 0.001230175606906414, 0.0012302870921747282, 0.0012324504164415737, 0.0012314077223066328, 0.0012356688615021317, 0.0012504581638157022, 0.00122819600226141, 0.0012202893957755593, 0.0012343671622274573, 0.0012364813944238217, 0.0012315899068706256, 0.0012355183040030128, 0.0012268385562915788, 0.001230095672897648, 0.001224271232955331, 0.0012455998383852284, 0.001238293975570001, 0.0012311936995057866, 0.0012267894425624331, 0.0012430239057298316, 0.0012466765582821396, 0.0012454543950382708, 0.001240096046849219, 0.001240583464265043, 0.0012533956283140321, 0.001244274625922878, 0.0012469825329432308, 0.0012569164418680377, 0.0012628034184968403, 0.0012578806747834002, 0.0012657274654524963, 0.0012628445347641097, 0.0012449486300262602, 0.0012473476736611405, 0.001249299371116903, 0.0012624685565919378, 0.0012587305120474032]
[767.7902096126096, 765.2187345858251, 775.1077791677251, 802.1665496824467, 794.2982528251761, 803.2637487274609, 807.8218449018295, 786.2856910427787, 749.9979765576779, 748.7596153533374, 743.4128339739876, 749.6732502718032, 754.3994989213069, 745.5524032123595, 661.1809977135587, 691.6308625622612, 749.9028503697803, 750.762344715795, 231.28049568812733, 751.4331028445109, 751.5021374717962, 752.9549249313703, 753.1851470088469, 744.5318237064126, 744.0917849284873, 730.7728391090359, 693.4448488228815, 753.6062330672711, 753.993536042157, 754.1813706109238, 749.5449157174687, 752.7975013417797, 750.0814651075196, 757.7976698779286, 745.6254789039323, 742.5220554176782, 753.376448818814, 443.8920723289376, 756.9119736693881, 765.5305122752029, 763.3396951006257, 764.3442843432704, 761.7051363398186, 713.700294778254, 756.7368064102527, 755.457082264496, 230.71172625596435, 744.0009175005084, 753.896461326361, 712.0081088462296, 715.1709832191843, 721.8492896848445, 761.514220154289, 763.8382594243254, 748.880287146776, 708.9708615109004, 709.1854050228542, 707.0424093686548, 714.6428045801291, 712.0915370232475, 714.6261940572223, 709.3116434805734, 703.740134234742, 709.8070852210968, 707.6742211259043, 730.5246975183175, 730.1110013191068, 733.2126219444003, 729.8517448060855, 756.8971704408609, 759.1931202261724, 744.6607403546116, 743.5478594649063, 748.9379930400272, 232.9575434682834, 751.6915073067443, 750.7256189948296, 750.7280018524507, 753.7872103609523, 752.5931708479553, 754.9347720943807, 740.7978956005153, 748.9129697870819, 744.8479384646075, 736.5397615870297, 745.8091285431613, 753.3845115020501, 756.0482612107822, 752.4734239199099, 745.3640056756718, 749.0671768384922, 747.7355041784698, 739.2737797751892, 751.0705644892099, 669.8825196159289, 754.4756265697206, 754.8216970559605, 752.4749684606045, 753.0488045349855, 756.186837351876, 737.5539982202988, 754.8052012657282, 754.0597337168084, 753.3824601492506, 258.9494045781495, 738.915929444354, 738.5745780577249, 740.3820170479448, 736.0374368207408, 740.6867975345461, 743.1345342440312, 734.5119568393477, 728.6481866885207, 762.0855765145068, 791.1295534032548, 775.7024190105792, 751.4748762058191, 763.2705063206866, 758.2749024893302, 765.0001446945358, 754.1595757025533, 759.5642876741609, 753.3409754048585, 754.520971218978, 743.3860566642362, 750.4840797458261, 751.2314526890243, 744.312220923109, 764.5893016240677, 744.8913443384156, 751.130604766358, 824.9827657449484, 812.2708056322056, 802.3366576380062, 805.742114623839, 802.0525689628668, 799.9590279250612, 810.0307883913136, 796.4701195362247, 750.6588504798344, 752.9138478134456, 755.6052338882148, 743.6387662740619, 756.2127628476115, 758.1434429523257, 752.5287368733725, 749.1128419187601, 752.8923192229853, 750.5249614439426, 828.1755968952289, 806.647360027191, 804.8063493017495, 802.7583825569649, 806.7314115492253, 792.2365814510504, 802.2864202314001, 808.8657553034811, 813.4609707574069, 799.9689085840605, 802.6980217790493, 802.398029109307, 796.4093561202654, 797.4127926736859, 798.3454863686577, 798.2761259420163, 798.0172936981309, 800.1100798343816, 804.5169538640395, 804.5451934056249, 797.5014841041956, 806.2895689853593, 809.7398981427273, 803.8921837718882, 803.6167083883553, 807.5183785636813, 808.1719336490538, 812.7447610332767, 810.9218266175076, 817.064999204596, 816.4322678769481, 811.1670160891218, 808.2074934071958, 805.425209192022, 804.8343969661385, 802.7071625390307, 812.6040555721303, 811.3031506143569, 812.3462890507574, 815.3559518641986, 816.6440732854812, 812.8920736078904, 812.8184115403022, 811.3916687109227, 812.0787143731993, 809.2783035613257, 799.7068825945818, 814.2022919458742, 819.4777431171942, 810.1317262810736, 808.7464999552074, 811.9585865565612, 809.3769204066455, 815.1031730065167, 812.9448969155154, 816.812462044092, 802.8260515001195, 807.5626787570283, 812.2198809183396, 815.1358051396896, 804.4897571079761, 802.1326729508348, 802.9198049995815, 806.38915230861, 806.0723270984662, 797.8326853948903, 803.6810999487354, 801.9358520120709, 795.5978350587834, 791.8888920892656, 794.9879667021629, 790.0594932910782, 791.8631094102117, 803.2459941571298, 801.7010983512397, 800.4486539571188, 792.0989356752951, 794.4512271919413]
Elapsed: 0.05912924663159619~0.017382794611431815
Time per graph: 0.001357193584092805~0.0003914621093907306
Speed: 758.8325316417852~80.26260917942277
Total Time: 0.0549
best val loss: 0.4309574365615845 test_score: 0.8605

Testing...
Test loss: 0.5127 score: 0.8837 time: 0.05s
test Score 0.8837
Epoch Time List: [0.4497484121238813, 0.17500576912425458, 0.1746859138365835, 0.1617481348803267, 0.16408349387347698, 0.16294541710522026, 0.16277886903844774, 0.1638532989891246, 0.28808597498573363, 0.1752547250362113, 0.17579445394221693, 0.17481226287782192, 0.17421284900046885, 0.18196171091403812, 0.18584208597894758, 0.1815277790883556, 0.17541389795951545, 0.17394722800236195, 0.3056220361031592, 0.17414846899919212, 0.17408618400804698, 0.174084032070823, 0.17476797010749578, 0.17941942310426384, 0.18229133100248873, 0.17847433895803988, 0.18263703910633922, 0.28973452001810074, 0.17439992912113667, 0.17430239787790924, 0.17446017998736352, 0.1748259930172935, 0.17431830405257642, 0.17676821094937623, 0.17822308593895286, 0.17580139101482928, 0.1748129321495071, 0.21499356382992119, 0.21386098209768534, 0.1713618190260604, 0.17233720200601965, 0.17204217100515962, 0.17255270795430988, 0.17723889998160303, 0.17364535806700587, 0.17361808300483972, 0.30256906512659043, 0.1725209339056164, 0.17278396105393767, 0.17689552099909633, 0.18247731297742575, 0.18301267293281853, 0.17318782198708504, 0.17109854007139802, 0.1710728551261127, 0.3017923808656633, 0.18360276112798601, 0.1833981249947101, 0.18373266595881432, 0.181936232955195, 0.1831136270193383, 0.1822909329785034, 0.1842925880337134, 0.18374619085807353, 0.18415794696193188, 0.2761290289927274, 0.17964927305001765, 0.17903709888923913, 0.17932408093474805, 0.17198757780715823, 0.17241757502779365, 0.17754943505860865, 0.1756840880261734, 0.17492644593585283, 0.3069283150834963, 0.174490712932311, 0.17439385189209133, 0.17409152700565755, 0.1743353740312159, 0.17431157198734581, 0.17467045411467552, 0.17616693407762796, 0.17549387796316296, 0.18064280599355698, 0.17529696796555072, 0.2988774939440191, 0.17483337805606425, 0.1729841799242422, 0.17436628497671336, 0.17512163403443992, 0.1755683379014954, 0.17511370708234608, 0.17636954109184444, 0.17473127599805593, 0.1806101710535586, 0.2869555309880525, 0.17478194809518754, 0.17438718595076352, 0.17580724915023893, 0.17497969313990325, 0.17623806500341743, 0.17729601997416466, 0.17504422494675964, 0.17531161103397608, 0.2846705538686365, 0.17640321305952966, 0.17740508809220046, 0.1762746429303661, 0.17626275087241083, 0.1761191551340744, 0.1768441180465743, 0.17578295711427927, 0.1791542739374563, 0.17362292308826, 0.16641792992595583, 0.29920201003551483, 0.17350876901764423, 0.17277734901290387, 0.17255216895136982, 0.17220157897099853, 0.1734089150559157, 0.18009253893978894, 0.18349338695406914, 0.18464720097836107, 0.18318252707831562, 0.1838246489642188, 0.1844765490386635, 0.1842448191018775, 0.26354038598947227, 0.18338398693595082, 0.1833485719980672, 0.17360830609686673, 0.1714617528486997, 0.17217264289502054, 0.17259969701990485, 0.17783643899019808, 0.1740520551102236, 0.17225102300290018, 0.17390445189084858, 0.24021248414646834, 0.18460961314849555, 0.18364034895785153, 0.18475888087414205, 0.18425799580290914, 0.1831792639568448, 0.18663030001334846, 0.18552171683404595, 0.18368813197594136, 0.35749211604706943, 0.17925400601234287, 0.17269261495675892, 0.17309088597539812, 0.17384633992332965, 0.1742021661484614, 0.1759963878430426, 0.17593789694365114, 0.17370032612234354, 0.17368518188595772, 0.1746882990701124, 0.1725415049586445, 0.17438281001523137, 0.1741254790686071, 0.17493315902538598, 0.17426745500415564, 0.1744421770563349, 0.17471645900513977, 0.17362894618418068, 0.17349079600535333, 0.17417762195691466, 0.1739480938995257, 0.17319432401563972, 0.17299175809603184, 0.17413851513992995, 0.17396112903952599, 0.1735866900999099, 0.174949791864492, 0.17296557710506022, 0.1735988218570128, 0.17248812119942158, 0.17346073384396732, 0.1731215538457036, 0.17481584998313338, 0.173820111900568, 0.17427817091811448, 0.174389234976843, 0.17136561393272132, 0.17152526997961104, 0.17161162896081805, 0.17148769786581397, 0.17299269698560238, 0.1716937009477988, 0.17228421894833446, 0.1719197699567303, 0.17101113009266555, 0.17246231599710882, 0.1731880500447005, 0.17233180499169976, 0.17216328089125454, 0.1715853608911857, 0.17147721396759152, 0.17182502523064613, 0.17209833313245326, 0.17166500084567815, 0.17207445995882154, 0.17218930600211024, 0.17330174602102488, 0.1743263640673831, 0.1740252070594579, 0.17437928298022598, 0.17323049600236118, 0.17529787099920213, 0.1740633340086788, 0.17509862990118563, 0.173545490950346, 0.17545237101148814, 0.17437664594035596, 0.17574808397330344, 0.1755438850959763, 0.17588551284279674, 0.17599884094670415, 0.17688694992102683, 0.1763339788885787, 0.1754699550801888, 0.1759794200770557, 0.1761265560053289, 0.17635473411064595, 0.17555084300693125]
Total Epoch List: [121, 106]
Total Time List: [0.058929117978550494, 0.05487964896019548]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x751995066170>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 3/1000, LR 0.000030
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 4/1000, LR 0.000060
Train loss: 0.6906;  Loss pred: 0.6906; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 5/1000, LR 0.000090
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 6/1000, LR 0.000120
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 7/1000, LR 0.000150
Train loss: 0.6877;  Loss pred: 0.6877; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 8/1000, LR 0.000180
Train loss: 0.6868;  Loss pred: 0.6868; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.04s
Epoch 9/1000, LR 0.000210
Train loss: 0.6841;  Loss pred: 0.6841; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.04s
Epoch 10/1000, LR 0.000240
Train loss: 0.6800;  Loss pred: 0.6800; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.04s
Epoch 11/1000, LR 0.000270
Train loss: 0.6787;  Loss pred: 0.6787; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.04s
Epoch 12/1000, LR 0.000270
Train loss: 0.6780;  Loss pred: 0.6780; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 13/1000, LR 0.000270
Train loss: 0.6720;  Loss pred: 0.6720; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 14/1000, LR 0.000270
Train loss: 0.6682;  Loss pred: 0.6682; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 15/1000, LR 0.000270
Train loss: 0.6668;  Loss pred: 0.6668; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.04s
Epoch 16/1000, LR 0.000270
Train loss: 0.6600;  Loss pred: 0.6600; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.04s
Epoch 17/1000, LR 0.000270
Train loss: 0.6591;  Loss pred: 0.6591; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.04s
Epoch 18/1000, LR 0.000270
Train loss: 0.6539;  Loss pred: 0.6539; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.04s
Epoch 19/1000, LR 0.000270
Train loss: 0.6486;  Loss pred: 0.6486; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.04s
Epoch 20/1000, LR 0.000270
Train loss: 0.6445;  Loss pred: 0.6445; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.04s
Epoch 21/1000, LR 0.000270
Train loss: 0.6370;  Loss pred: 0.6370; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.04s
Epoch 22/1000, LR 0.000270
Train loss: 0.6334;  Loss pred: 0.6334; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.04s
Epoch 23/1000, LR 0.000270
Train loss: 0.6233;  Loss pred: 0.6233; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.04s
Epoch 24/1000, LR 0.000270
Train loss: 0.6191;  Loss pred: 0.6191; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.04s
Epoch 25/1000, LR 0.000270
Train loss: 0.6128;  Loss pred: 0.6128; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.04s
Epoch 26/1000, LR 0.000270
Train loss: 0.6036;  Loss pred: 0.6036; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.04s
Epoch 27/1000, LR 0.000270
Train loss: 0.5972;  Loss pred: 0.5972; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.04s
Epoch 28/1000, LR 0.000270
Train loss: 0.5897;  Loss pred: 0.5897; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5116 time: 0.04s
Epoch 29/1000, LR 0.000270
Train loss: 0.5827;  Loss pred: 0.5827; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5116 time: 0.04s
Epoch 30/1000, LR 0.000270
Train loss: 0.5684;  Loss pred: 0.5684; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5116 time: 0.04s
Epoch 31/1000, LR 0.000270
Train loss: 0.5631;  Loss pred: 0.5631; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5116 time: 0.04s
Epoch 32/1000, LR 0.000270
Train loss: 0.5486;  Loss pred: 0.5486; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5116 time: 0.04s
Epoch 33/1000, LR 0.000270
Train loss: 0.5462;  Loss pred: 0.5462; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5116 time: 0.04s
Epoch 34/1000, LR 0.000270
Train loss: 0.5313;  Loss pred: 0.5313; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6883 score: 0.5116 time: 0.04s
Epoch 35/1000, LR 0.000270
Train loss: 0.5231;  Loss pred: 0.5231; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6887 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5116 time: 0.04s
Epoch 36/1000, LR 0.000270
Train loss: 0.5141;  Loss pred: 0.5141; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6882 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.5116 time: 0.04s
Epoch 37/1000, LR 0.000270
Train loss: 0.5001;  Loss pred: 0.5001; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6877 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.5116 time: 0.04s
Epoch 38/1000, LR 0.000270
Train loss: 0.4940;  Loss pred: 0.4940; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6856 score: 0.5116 time: 0.04s
Epoch 39/1000, LR 0.000269
Train loss: 0.4794;  Loss pred: 0.4794; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6846 score: 0.5116 time: 0.04s
Epoch 40/1000, LR 0.000269
Train loss: 0.4653;  Loss pred: 0.4653; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6854 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6836 score: 0.5116 time: 0.04s
Epoch 41/1000, LR 0.000269
Train loss: 0.4506;  Loss pred: 0.4506; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6844 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6825 score: 0.5116 time: 0.04s
Epoch 42/1000, LR 0.000269
Train loss: 0.4379;  Loss pred: 0.4379; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6834 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6814 score: 0.5116 time: 0.04s
Epoch 43/1000, LR 0.000269
Train loss: 0.4259;  Loss pred: 0.4259; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6802 score: 0.5116 time: 0.04s
Epoch 44/1000, LR 0.000269
Train loss: 0.4118;  Loss pred: 0.4118; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6813 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6790 score: 0.5116 time: 0.04s
Epoch 45/1000, LR 0.000269
Train loss: 0.3988;  Loss pred: 0.3988; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6802 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6777 score: 0.5116 time: 0.04s
Epoch 46/1000, LR 0.000269
Train loss: 0.3832;  Loss pred: 0.3832; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6790 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6764 score: 0.5116 time: 0.04s
Epoch 47/1000, LR 0.000269
Train loss: 0.3731;  Loss pred: 0.3731; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6779 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6750 score: 0.5116 time: 0.04s
Epoch 48/1000, LR 0.000269
Train loss: 0.3539;  Loss pred: 0.3539; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6767 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6736 score: 0.5116 time: 0.04s
Epoch 49/1000, LR 0.000269
Train loss: 0.3411;  Loss pred: 0.3411; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6753 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6718 score: 0.5116 time: 0.04s
Epoch 50/1000, LR 0.000269
Train loss: 0.3278;  Loss pred: 0.3278; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6738 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6699 score: 0.5116 time: 0.04s
Epoch 51/1000, LR 0.000269
Train loss: 0.3070;  Loss pred: 0.3070; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6722 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6680 score: 0.5116 time: 0.04s
Epoch 52/1000, LR 0.000269
Train loss: 0.2978;  Loss pred: 0.2978; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6704 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6658 score: 0.5116 time: 0.04s
Epoch 53/1000, LR 0.000269
Train loss: 0.2821;  Loss pred: 0.2821; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6685 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6635 score: 0.5116 time: 0.04s
Epoch 54/1000, LR 0.000269
Train loss: 0.2726;  Loss pred: 0.2726; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6664 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6609 score: 0.5116 time: 0.04s
Epoch 55/1000, LR 0.000269
Train loss: 0.2681;  Loss pred: 0.2681; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6644 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6583 score: 0.5116 time: 0.04s
Epoch 56/1000, LR 0.000269
Train loss: 0.2502;  Loss pred: 0.2502; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6624 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6555 score: 0.5116 time: 0.04s
Epoch 57/1000, LR 0.000269
Train loss: 0.2377;  Loss pred: 0.2377; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6605 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6527 score: 0.5116 time: 0.18s
Epoch 58/1000, LR 0.000269
Train loss: 0.2225;  Loss pred: 0.2225; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6585 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6497 score: 0.5116 time: 0.04s
Epoch 59/1000, LR 0.000268
Train loss: 0.2095;  Loss pred: 0.2095; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6561 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6463 score: 0.5116 time: 0.04s
Epoch 60/1000, LR 0.000268
Train loss: 0.1922;  Loss pred: 0.1922; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6541 score: 0.5000 time: 0.06s
Test loss: 0.6429 score: 0.5349 time: 0.04s
Epoch 61/1000, LR 0.000268
Train loss: 0.1897;  Loss pred: 0.1897; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6524 score: 0.5000 time: 0.06s
Test loss: 0.6397 score: 0.5581 time: 0.04s
Epoch 62/1000, LR 0.000268
Train loss: 0.1715;  Loss pred: 0.1715; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6510 score: 0.5000 time: 0.06s
Test loss: 0.6365 score: 0.5581 time: 0.04s
Epoch 63/1000, LR 0.000268
Train loss: 0.1594;  Loss pred: 0.1594; Loss self: 0.0000; time: 0.07s
Val loss: 0.6488 score: 0.5227 time: 0.06s
Test loss: 0.6327 score: 0.5581 time: 0.04s
Epoch 64/1000, LR 0.000268
Train loss: 0.1477;  Loss pred: 0.1477; Loss self: 0.0000; time: 0.07s
Val loss: 0.6472 score: 0.5227 time: 0.06s
Test loss: 0.6290 score: 0.5581 time: 0.04s
Epoch 65/1000, LR 0.000268
Train loss: 0.1400;  Loss pred: 0.1400; Loss self: 0.0000; time: 0.07s
Val loss: 0.6454 score: 0.5227 time: 0.06s
Test loss: 0.6250 score: 0.5581 time: 0.04s
Epoch 66/1000, LR 0.000268
Train loss: 0.1334;  Loss pred: 0.1334; Loss self: 0.0000; time: 0.07s
Val loss: 0.6432 score: 0.5227 time: 0.06s
Test loss: 0.6205 score: 0.5814 time: 0.04s
Epoch 67/1000, LR 0.000268
Train loss: 0.1255;  Loss pred: 0.1255; Loss self: 0.0000; time: 0.08s
Val loss: 0.6401 score: 0.5227 time: 0.14s
Test loss: 0.6153 score: 0.6047 time: 0.04s
Epoch 68/1000, LR 0.000268
Train loss: 0.1149;  Loss pred: 0.1149; Loss self: 0.0000; time: 0.07s
Val loss: 0.6361 score: 0.5227 time: 0.06s
Test loss: 0.6091 score: 0.6279 time: 0.04s
Epoch 69/1000, LR 0.000268
Train loss: 0.1053;  Loss pred: 0.1053; Loss self: 0.0000; time: 0.07s
Val loss: 0.6328 score: 0.5227 time: 0.06s
Test loss: 0.6033 score: 0.6512 time: 0.04s
Epoch 70/1000, LR 0.000268
Train loss: 0.0951;  Loss pred: 0.0951; Loss self: 0.0000; time: 0.07s
Val loss: 0.6299 score: 0.5455 time: 0.06s
Test loss: 0.5977 score: 0.6512 time: 0.04s
Epoch 71/1000, LR 0.000268
Train loss: 0.0871;  Loss pred: 0.0871; Loss self: 0.0000; time: 0.07s
Val loss: 0.6257 score: 0.5909 time: 0.06s
Test loss: 0.5911 score: 0.6512 time: 0.04s
Epoch 72/1000, LR 0.000267
Train loss: 0.0839;  Loss pred: 0.0839; Loss self: 0.0000; time: 0.07s
Val loss: 0.6218 score: 0.5909 time: 0.06s
Test loss: 0.5846 score: 0.6744 time: 0.04s
Epoch 73/1000, LR 0.000267
Train loss: 0.0767;  Loss pred: 0.0767; Loss self: 0.0000; time: 0.07s
Val loss: 0.6175 score: 0.5909 time: 0.06s
Test loss: 0.5779 score: 0.7209 time: 0.04s
Epoch 74/1000, LR 0.000267
Train loss: 0.0662;  Loss pred: 0.0662; Loss self: 0.0000; time: 0.07s
Val loss: 0.6136 score: 0.5909 time: 0.06s
Test loss: 0.5714 score: 0.7209 time: 0.04s
Epoch 75/1000, LR 0.000267
Train loss: 0.0647;  Loss pred: 0.0647; Loss self: 0.0000; time: 0.07s
Val loss: 0.6080 score: 0.5909 time: 0.06s
Test loss: 0.5638 score: 0.7209 time: 0.04s
Epoch 76/1000, LR 0.000267
Train loss: 0.0609;  Loss pred: 0.0609; Loss self: 0.0000; time: 0.07s
Val loss: 0.6023 score: 0.5909 time: 0.06s
Test loss: 0.5564 score: 0.7209 time: 0.04s
Epoch 77/1000, LR 0.000267
Train loss: 0.0558;  Loss pred: 0.0558; Loss self: 0.0000; time: 0.07s
Val loss: 0.5944 score: 0.5909 time: 0.06s
Test loss: 0.5477 score: 0.7209 time: 0.04s
Epoch 78/1000, LR 0.000267
Train loss: 0.0492;  Loss pred: 0.0492; Loss self: 0.0000; time: 0.07s
Val loss: 0.5864 score: 0.6136 time: 0.19s
Test loss: 0.5394 score: 0.7209 time: 0.04s
Epoch 79/1000, LR 0.000267
Train loss: 0.0461;  Loss pred: 0.0461; Loss self: 0.0000; time: 0.07s
Val loss: 0.5778 score: 0.6136 time: 0.06s
Test loss: 0.5312 score: 0.7442 time: 0.04s
Epoch 80/1000, LR 0.000267
Train loss: 0.0435;  Loss pred: 0.0435; Loss self: 0.0000; time: 0.07s
Val loss: 0.5675 score: 0.6136 time: 0.06s
Test loss: 0.5224 score: 0.7442 time: 0.04s
Epoch 81/1000, LR 0.000267
Train loss: 0.0385;  Loss pred: 0.0385; Loss self: 0.0000; time: 0.07s
Val loss: 0.5563 score: 0.6136 time: 0.06s
Test loss: 0.5137 score: 0.7674 time: 0.04s
Epoch 82/1000, LR 0.000267
Train loss: 0.0351;  Loss pred: 0.0351; Loss self: 0.0000; time: 0.07s
Val loss: 0.5457 score: 0.6364 time: 0.06s
Test loss: 0.5060 score: 0.7907 time: 0.04s
Epoch 83/1000, LR 0.000266
Train loss: 0.0338;  Loss pred: 0.0338; Loss self: 0.0000; time: 0.07s
Val loss: 0.5346 score: 0.6591 time: 0.06s
Test loss: 0.4987 score: 0.7907 time: 0.04s
Epoch 84/1000, LR 0.000266
Train loss: 0.0324;  Loss pred: 0.0324; Loss self: 0.0000; time: 0.07s
Val loss: 0.5233 score: 0.6818 time: 0.06s
Test loss: 0.4922 score: 0.7674 time: 0.04s
Epoch 85/1000, LR 0.000266
Train loss: 0.0270;  Loss pred: 0.0270; Loss self: 0.0000; time: 0.07s
Val loss: 0.5118 score: 0.6818 time: 0.06s
Test loss: 0.4862 score: 0.7674 time: 0.04s
Epoch 86/1000, LR 0.000266
Train loss: 0.0254;  Loss pred: 0.0254; Loss self: 0.0000; time: 0.07s
Val loss: 0.5016 score: 0.6818 time: 0.06s
Test loss: 0.4818 score: 0.7907 time: 0.04s
Epoch 87/1000, LR 0.000266
Train loss: 0.0251;  Loss pred: 0.0251; Loss self: 0.0000; time: 0.07s
Val loss: 0.4899 score: 0.6818 time: 0.06s
Test loss: 0.4772 score: 0.7907 time: 0.04s
Epoch 88/1000, LR 0.000266
Train loss: 0.0231;  Loss pred: 0.0231; Loss self: 0.0000; time: 0.07s
Val loss: 0.4771 score: 0.6818 time: 0.20s
Test loss: 0.4728 score: 0.7907 time: 0.06s
Epoch 89/1000, LR 0.000266
Train loss: 0.0198;  Loss pred: 0.0198; Loss self: 0.0000; time: 0.09s
Val loss: 0.4651 score: 0.7045 time: 0.06s
Test loss: 0.4695 score: 0.7907 time: 0.04s
Epoch 90/1000, LR 0.000266
Train loss: 0.0204;  Loss pred: 0.0204; Loss self: 0.0000; time: 0.07s
Val loss: 0.4544 score: 0.7045 time: 0.05s
Test loss: 0.4676 score: 0.8140 time: 0.04s
Epoch 91/1000, LR 0.000266
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.07s
Val loss: 0.4429 score: 0.7273 time: 0.05s
Test loss: 0.4662 score: 0.8140 time: 0.04s
Epoch 92/1000, LR 0.000266
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.07s
Val loss: 0.4324 score: 0.7273 time: 0.05s
Test loss: 0.4661 score: 0.8140 time: 0.04s
Epoch 93/1000, LR 0.000265
Train loss: 0.0163;  Loss pred: 0.0163; Loss self: 0.0000; time: 0.07s
Val loss: 0.4208 score: 0.7273 time: 0.05s
Test loss: 0.4666 score: 0.8140 time: 0.04s
Epoch 94/1000, LR 0.000265
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.07s
Val loss: 0.4092 score: 0.7500 time: 0.05s
Test loss: 0.4675 score: 0.8140 time: 0.04s
Epoch 95/1000, LR 0.000265
Train loss: 0.0147;  Loss pred: 0.0147; Loss self: 0.0000; time: 0.07s
Val loss: 0.3986 score: 0.8409 time: 0.05s
Test loss: 0.4696 score: 0.8372 time: 0.04s
Epoch 96/1000, LR 0.000265
Train loss: 0.0128;  Loss pred: 0.0128; Loss self: 0.0000; time: 0.07s
Val loss: 0.3888 score: 0.8409 time: 0.05s
Test loss: 0.4726 score: 0.8372 time: 0.04s
Epoch 97/1000, LR 0.000265
Train loss: 0.0118;  Loss pred: 0.0118; Loss self: 0.0000; time: 0.07s
Val loss: 0.3798 score: 0.8409 time: 0.05s
Test loss: 0.4763 score: 0.8605 time: 0.04s
Epoch 98/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.07s
Val loss: 0.3696 score: 0.8409 time: 0.05s
Test loss: 0.4799 score: 0.8605 time: 0.04s
Epoch 99/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.07s
Val loss: 0.3607 score: 0.8409 time: 0.05s
Test loss: 0.4840 score: 0.8605 time: 0.04s
Epoch 100/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.07s
Val loss: 0.3519 score: 0.8182 time: 0.17s
Test loss: 0.4888 score: 0.8605 time: 0.05s
Epoch 101/1000, LR 0.000265
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.07s
Val loss: 0.3433 score: 0.8182 time: 0.06s
Test loss: 0.4939 score: 0.8605 time: 0.04s
Epoch 102/1000, LR 0.000264
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.07s
Val loss: 0.3359 score: 0.8182 time: 0.06s
Test loss: 0.4990 score: 0.8605 time: 0.04s
Epoch 103/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.3283 score: 0.8182 time: 0.06s
Test loss: 0.5044 score: 0.8605 time: 0.04s
Epoch 104/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.3207 score: 0.8182 time: 0.06s
Test loss: 0.5099 score: 0.8605 time: 0.04s
Epoch 105/1000, LR 0.000264
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.07s
Val loss: 0.3141 score: 0.8182 time: 0.06s
Test loss: 0.5156 score: 0.8372 time: 0.04s
Epoch 106/1000, LR 0.000264
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.07s
Val loss: 0.3079 score: 0.8182 time: 0.06s
Test loss: 0.5216 score: 0.8372 time: 0.04s
Epoch 107/1000, LR 0.000264
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.07s
Val loss: 0.3020 score: 0.8409 time: 0.06s
Test loss: 0.5277 score: 0.8372 time: 0.04s
Epoch 108/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.2973 score: 0.8409 time: 0.06s
Test loss: 0.5338 score: 0.8372 time: 0.04s
Epoch 109/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.07s
Val loss: 0.2929 score: 0.8409 time: 0.06s
Test loss: 0.5404 score: 0.8372 time: 0.04s
Epoch 110/1000, LR 0.000263
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.07s
Val loss: 0.2898 score: 0.8409 time: 0.06s
Test loss: 0.5467 score: 0.8372 time: 0.04s
Epoch 111/1000, LR 0.000263
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.19s
Val loss: 0.2873 score: 0.8636 time: 0.07s
Test loss: 0.5534 score: 0.8372 time: 0.05s
Epoch 112/1000, LR 0.000263
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.08s
Val loss: 0.2852 score: 0.8636 time: 0.06s
Test loss: 0.5600 score: 0.8372 time: 0.04s
Epoch 113/1000, LR 0.000263
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.07s
Val loss: 0.2833 score: 0.8636 time: 0.06s
Test loss: 0.5660 score: 0.8372 time: 0.04s
Epoch 114/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.2812 score: 0.8636 time: 0.06s
Test loss: 0.5717 score: 0.8372 time: 0.05s
Epoch 115/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.2794 score: 0.8636 time: 0.06s
Test loss: 0.5774 score: 0.8372 time: 0.04s
Epoch 116/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.2779 score: 0.8636 time: 0.06s
Test loss: 0.5834 score: 0.8372 time: 0.04s
Epoch 117/1000, LR 0.000262
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.07s
Val loss: 0.2752 score: 0.8409 time: 0.06s
Test loss: 0.5886 score: 0.8372 time: 0.04s
Epoch 118/1000, LR 0.000262
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.07s
Val loss: 0.2734 score: 0.8636 time: 0.06s
Test loss: 0.5941 score: 0.8372 time: 0.05s
Epoch 119/1000, LR 0.000262
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.08s
Val loss: 0.2708 score: 0.8636 time: 0.07s
Test loss: 0.5987 score: 0.8372 time: 0.05s
Epoch 120/1000, LR 0.000262
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.16s
Val loss: 0.2688 score: 0.8636 time: 0.06s
Test loss: 0.6030 score: 0.8372 time: 0.05s
Epoch 121/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.2668 score: 0.8636 time: 0.06s
Test loss: 0.6076 score: 0.8372 time: 0.04s
Epoch 122/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.2659 score: 0.8636 time: 0.06s
Test loss: 0.6120 score: 0.8372 time: 0.04s
Epoch 123/1000, LR 0.000262
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.07s
Val loss: 0.2650 score: 0.8636 time: 0.06s
Test loss: 0.6158 score: 0.8605 time: 0.04s
Epoch 124/1000, LR 0.000261
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.07s
Val loss: 0.2636 score: 0.8636 time: 0.06s
Test loss: 0.6200 score: 0.8605 time: 0.04s
Epoch 125/1000, LR 0.000261
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.2628 score: 0.8636 time: 0.06s
Test loss: 0.6237 score: 0.8605 time: 0.04s
Epoch 126/1000, LR 0.000261
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.07s
Val loss: 0.2632 score: 0.8636 time: 0.06s
Test loss: 0.6291 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 1 of 20
Epoch 127/1000, LR 0.000261
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.07s
Val loss: 0.2630 score: 0.8636 time: 0.06s
Test loss: 0.6347 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 2 of 20
Epoch 128/1000, LR 0.000261
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.07s
Val loss: 0.2633 score: 0.8636 time: 0.06s
Test loss: 0.6403 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 3 of 20
Epoch 129/1000, LR 0.000261
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.07s
Val loss: 0.2634 score: 0.8636 time: 0.06s
Test loss: 0.6452 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 4 of 20
Epoch 130/1000, LR 0.000260
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.07s
Val loss: 0.2641 score: 0.8636 time: 0.06s
Test loss: 0.6500 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 5 of 20
Epoch 131/1000, LR 0.000260
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.09s
Val loss: 0.2640 score: 0.8636 time: 0.12s
Test loss: 0.6545 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 6 of 20
Epoch 132/1000, LR 0.000260
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.07s
Val loss: 0.2642 score: 0.8636 time: 0.06s
Test loss: 0.6585 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 7 of 20
Epoch 133/1000, LR 0.000260
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.07s
Val loss: 0.2648 score: 0.8636 time: 0.06s
Test loss: 0.6621 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 8 of 20
Epoch 134/1000, LR 0.000260
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.07s
Val loss: 0.2649 score: 0.8636 time: 0.06s
Test loss: 0.6658 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 9 of 20
Epoch 135/1000, LR 0.000260
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.07s
Val loss: 0.2645 score: 0.8636 time: 0.06s
Test loss: 0.6694 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 10 of 20
Epoch 136/1000, LR 0.000260
Train loss: 0.0028;  Loss pred: 0.0028; Loss self: 0.0000; time: 0.07s
Val loss: 0.2646 score: 0.8636 time: 0.06s
Test loss: 0.6728 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 11 of 20
Epoch 137/1000, LR 0.000259
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.07s
Val loss: 0.2643 score: 0.8636 time: 0.06s
Test loss: 0.6762 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 12 of 20
Epoch 138/1000, LR 0.000259
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.07s
Val loss: 0.2643 score: 0.8636 time: 0.06s
Test loss: 0.6785 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 13 of 20
Epoch 139/1000, LR 0.000259
Train loss: 0.0029;  Loss pred: 0.0029; Loss self: 0.0000; time: 0.07s
Val loss: 0.2640 score: 0.8636 time: 0.06s
Test loss: 0.6808 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 14 of 20
Epoch 140/1000, LR 0.000259
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.07s
Val loss: 0.2641 score: 0.8636 time: 0.06s
Test loss: 0.6830 score: 0.8605 time: 0.17s
     INFO: Early stopping counter 15 of 20
Epoch 141/1000, LR 0.000259
Train loss: 0.0027;  Loss pred: 0.0027; Loss self: 0.0000; time: 0.07s
Val loss: 0.2644 score: 0.8636 time: 0.06s
Test loss: 0.6858 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 16 of 20
Epoch 142/1000, LR 0.000259
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.07s
Val loss: 0.2658 score: 0.8636 time: 0.06s
Test loss: 0.6890 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 17 of 20
Epoch 143/1000, LR 0.000258
Train loss: 0.0026;  Loss pred: 0.0026; Loss self: 0.0000; time: 0.07s
Val loss: 0.2665 score: 0.8636 time: 0.06s
Test loss: 0.6921 score: 0.8605 time: 0.04s
     INFO: Early stopping counter 18 of 20
Epoch 144/1000, LR 0.000258
Train loss: 0.0023;  Loss pred: 0.0023; Loss self: 0.0000; time: 0.07s
Val loss: 0.2674 score: 0.8636 time: 0.06s
Test loss: 0.6948 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 19 of 20
Epoch 145/1000, LR 0.000258
Train loss: 0.0024;  Loss pred: 0.0024; Loss self: 0.0000; time: 0.07s
Val loss: 0.2683 score: 0.8636 time: 0.06s
Test loss: 0.6976 score: 0.8372 time: 0.04s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 124,   Train_Loss: 0.0043,   Val_Loss: 0.2628,   Val_Precision: 0.9000,   Val_Recall: 0.8182,   Val_accuracy: 0.8571,   Val_Score: 0.8636,   Val_Loss: 0.2628,   Test_Precision: 0.8571,   Test_Recall: 0.8571,   Test_accuracy: 0.8571,   Test_Score: 0.8605,   Test_loss: 0.6237


[0.05730732099618763, 0.05749989906325936, 0.056766299065202475, 0.05485145200509578, 0.05539480899460614, 0.054776528966613114, 0.05446745501831174, 0.0559593039797619, 0.05866682494524866, 0.05876385304145515, 0.059186495025642216, 0.0586922368966043, 0.05832453502807766, 0.059016642975620925, 0.06654758704826236, 0.0636177510023117, 0.05867426691111177, 0.058607094921171665, 0.1902451820205897, 0.058554779971018434, 0.05854940100107342, 0.058436432969756424, 0.05841857101768255, 0.05909754103049636, 0.0591324899578467, 0.06021022901404649, 0.06345133297145367, 0.05838592897634953, 0.058355937944725156, 0.05834140395745635, 0.05870228598359972, 0.0584486530860886, 0.05866029497701675, 0.05806299194227904, 0.059010858996771276, 0.0592574990587309, 0.0584037370281294, 0.09912319399882108, 0.05813093401957303, 0.05747648107353598, 0.057641441002488136, 0.05756568198557943, 0.05776513495948166, 0.06165052799042314, 0.05814439000096172, 0.05824288504663855, 0.19071419001556933, 0.05913971201516688, 0.0583634520880878, 0.061797049012966454, 0.06152374891098589, 0.060954551910981536, 0.05777961702551693, 0.05760381789878011, 0.05875438405200839, 0.062061788979917765, 0.062043013982474804, 0.06223106198012829, 0.061569219920784235, 0.06178980891127139, 0.061570651014335454, 0.06203197198919952, 0.06252307898830622, 0.06198867398779839, 0.06217550206929445, 0.06023068097420037, 0.06026480894070119, 0.06000987801235169, 0.060286216088570654, 0.058132070931605995, 0.057956268079578876, 0.05908730998635292, 0.059175746981054544, 0.058749857009388506, 0.188875618041493, 0.058534650946967304, 0.05860996199771762, 0.05860977596603334, 0.058371911058202386, 0.05846452200785279, 0.058283181046135724, 0.05939541710540652, 0.05875182000454515, 0.059072459931485355, 0.059738797950558364, 0.05899632803630084, 0.05840311199426651, 0.058197343023493886, 0.0584738259203732, 0.05903155996929854, 0.05873972503468394, 0.058844337007030845, 0.05951786902733147, 0.05858304409775883, 0.06568315892945975, 0.05831865000072867, 0.05829191207885742, 0.0584737058961764, 0.05842914793174714, 0.05818667798303068, 0.0596566490130499, 0.058293186011724174, 0.05835081497207284, 0.058403271017596126, 0.16991736309137195, 0.05954669299535453, 0.05957421404309571, 0.059428779990412295, 0.05977956799324602, 0.05940432602073997, 0.05920866003725678, 0.05990372190717608, 0.06038579496089369, 0.05773629806935787, 0.05561668099835515, 0.056722783017903566, 0.05855152499862015, 0.057646666071377695, 0.058026449056342244, 0.05751632899045944, 0.05834309000056237, 0.05661140300799161, 0.05707906698808074, 0.056989800999872386, 0.057843430899083614, 0.05729635199531913, 0.0572393499314785, 0.05777145503088832, 0.05623934301547706, 0.057726540020667017, 0.057247034972533584, 0.05212230095639825, 0.052938009961508214, 0.053593463031575084, 0.053366951062344015, 0.05361244594678283, 0.05375275295227766, 0.05308440199587494, 0.053988214931450784, 0.0572830120800063, 0.0571114479098469, 0.05690802296157926, 0.057823774055577815, 0.056862303987145424, 0.056717499042861164, 0.05714067502412945, 0.057401231955736876, 0.05711308098398149, 0.05729323101695627, 0.05192135600373149, 0.053307060967199504, 0.053429001942276955, 0.05356530798599124, 0.053301507025025785, 0.054276716080494225, 0.05359681893605739, 0.05316086101811379, 0.052860556985251606, 0.05375208903569728, 0.05356933595612645, 0.053589363931678236, 0.05399233405478299, 0.053924391977488995, 0.053861393011175096, 0.05386607290711254, 0.05388354405295104, 0.053742605028674006, 0.053448221064172685, 0.053446345031261444, 0.0539183949586004, 0.05333071597851813, 0.05310347198974341, 0.05348976003006101, 0.05350809602532536, 0.05324956204276532, 0.053206500015221536, 0.05290713894646615, 0.05302607303019613, 0.05262739199679345, 0.052668177988380194, 0.053010044968687, 0.05320415901951492, 0.05338794901035726, 0.053427139995619655, 0.05356872593984008, 0.052916300017386675, 0.05300115002319217, 0.05293309094849974, 0.05273770296480507, 0.05265451793093234, 0.0528975510969758, 0.052902344963513315, 0.05299536790698767, 0.05295053205918521, 0.053133761044591665, 0.05376970104407519, 0.05281242809724063, 0.05247244401834905, 0.053077787975780666, 0.05316869996022433, 0.05295836599543691, 0.05312728707212955, 0.05275405792053789, 0.05289411393459886, 0.052643663017079234, 0.053560793050564826, 0.05324664094951004, 0.05294132907874882, 0.05275194603018463, 0.05345002794638276, 0.05360709200613201, 0.05355453898664564, 0.05332413001451641, 0.05334508896339685, 0.05389601201750338, 0.05350380891468376, 0.05362024891655892, 0.05404740700032562, 0.05430054699536413, 0.054088869015686214, 0.054426281014457345, 0.054302314994856715, 0.053532791091129184, 0.05363594996742904, 0.053719872958026826, 0.05428614793345332, 0.05412541201803833, 0.05641131103038788, 0.046326470910571516, 0.04641908407211304, 0.04620649793650955, 0.046023971983231604, 0.0462153929984197, 0.04627376701682806, 0.046302314032800496, 0.04638551699463278, 0.046073195058852434, 0.04630031296983361, 0.046432782895863056, 0.04623432189691812, 0.04622380901128054, 0.04604454489890486, 0.04650119389407337, 0.04668920102994889, 0.04633974004536867, 0.04656223999336362, 0.04638683295343071, 0.045985625009052455, 0.046373183955438435, 0.0463846679776907, 0.04625475499778986, 0.04621604806743562, 0.04625083110295236, 0.046086519956588745, 0.04607335606124252, 0.04621800791937858, 0.04642287909518927, 0.04625083308201283, 0.046104674926027656, 0.046287457924336195, 0.04630429297685623, 0.046404268010519445, 0.04634858702775091, 0.046303996932692826, 0.04652679490391165, 0.046528859063982964, 0.046380952931940556, 0.046382487984374166, 0.046226639999076724, 0.04641460406128317, 0.04627343500033021, 0.04632009600754827, 0.046222827048040926, 0.04621889290865511, 0.046339703956618905, 0.04604402696713805, 0.04644849896430969, 0.046387848909944296, 0.04636989696882665, 0.046477572061121464, 0.0465921979630366, 0.04628270899411291, 0.04636767506599426, 0.18394516699481755, 0.0461069910088554, 0.04605328489560634, 0.0461462460225448, 0.046229258994571865, 0.04623870400246233, 0.047187129966914654, 0.04607258795294911, 0.04608152399305254, 0.047031905967742205, 0.046710555092431605, 0.04657527094241232, 0.046645753900520504, 0.04655702202580869, 0.04681834299117327, 0.04682747402694076, 0.047012928989715874, 0.047144528944045305, 0.04710094991605729, 0.04666039301082492, 0.046543973963707685, 0.04602561006322503, 0.04573721205815673, 0.04570491495542228, 0.04569728998467326, 0.04566771595273167, 0.045920726959593594, 0.04602766199968755, 0.04588341491762549, 0.045722009032033384, 0.04934928007423878, 0.06831214495468885, 0.04216767300385982, 0.04229596210643649, 0.04212116193957627, 0.04226136999204755, 0.042594778002239764, 0.04226284800097346, 0.04294160706922412, 0.04240344499703497, 0.04216588498093188, 0.04202843504026532, 0.04281253495719284, 0.0500008650124073, 0.04544994002208114, 0.04568243399262428, 0.04567931895144284, 0.04569692793302238, 0.04579845303669572, 0.04581076093018055, 0.045918766991235316, 0.04589048703201115, 0.04581778100691736, 0.0464137609815225, 0.05588971299584955, 0.046479369048029184, 0.046193844988010824, 0.05710768105927855, 0.04602234193589538, 0.0459415529621765, 0.0456791459582746, 0.05661312898155302, 0.06021509307902306, 0.05106555297970772, 0.04555107105989009, 0.045788784977048635, 0.04564377304632217, 0.04552501591388136, 0.04592190799303353, 0.04551212105434388, 0.045600989018566906, 0.04538972198497504, 0.04562886105850339, 0.04579719004686922, 0.04540356190409511, 0.04549416096415371, 0.04556333692744374, 0.04573331493884325, 0.045756005914881825, 0.04611162992659956, 0.045692105079069734, 0.04551190207712352, 0.045698447967879474, 0.1766122110420838, 0.04516944696661085, 0.04525811306666583, 0.04527746303938329, 0.045284127932973206, 0.045120359980501235]
[0.0013024391135497187, 0.0013068158878013492, 0.0012901431605727835, 0.0012466239092067224, 0.001258972931695594, 0.0012449211128775708, 0.0012378967049616304, 0.0012718023631764067, 0.0013333369305738333, 0.001335542114578526, 0.0013451476142191414, 0.001333914474922825, 0.0013255576142744924, 0.0013412873403550211, 0.0015124451601877809, 0.0014458579773252661, 0.0013335060661616312, 0.0013319794300266287, 0.004323754136831584, 0.0013307904538867826, 0.0013306682045698506, 0.001328100749312646, 0.0013276947958564217, 0.0013431259325112808, 0.0013439202263146979, 0.0013684142957737838, 0.0014420757493512197, 0.0013269529312806712, 0.0013262713169255717, 0.001325940999033099, 0.00133414286326363, 0.0013283784792292863, 0.0013331885222049261, 0.0013196134532336146, 0.0013411558862902564, 0.0013467613422438842, 0.0013273576597302135, 0.00225279986360957, 0.0013211575913539325, 0.0013062836607621814, 0.0013100327500565486, 0.0013083109542177144, 0.0013128439763518559, 0.0014011483634187077, 0.0013214634091127664, 0.001323701932878149, 0.004334413409444757, 0.0013440843639810655, 0.0013264420929110863, 0.0014044783866583284, 0.0013982670207042247, 0.0013853307252495804, 0.0013131731142162937, 0.0013091776795177298, 0.001335326910272918, 0.00141049520408904, 0.0014100684996017, 0.0014143423177301884, 0.0013993004527450962, 0.0014043138388925317, 0.001399332977598533, 0.00140981754520908, 0.0014209790679160506, 0.0014088334997226907, 0.001413079592483965, 0.0013688791130500083, 0.0013696547486522998, 0.0013638608639170839, 0.0013701412747402421, 0.0013211834302637726, 0.00131718791089952, 0.0013428934087807481, 0.0013449033404785123, 0.001335224022940648, 0.004292627682761205, 0.0013303329760674387, 0.0013320445908572185, 0.0013320403628643942, 0.0013266343422318723, 0.001328739136542109, 0.0013246177510485393, 0.0013498958433046937, 0.0013352686364669353, 0.001342555907533758, 0.001357699953421781, 0.0013408256371886555, 0.001327343454415148, 0.0013226668868975883, 0.001328950589099391, 0.0013416263629386033, 0.0013349937507882714, 0.0013373712956143374, 0.0013526788415302608, 0.0013314328204036099, 0.0014927990665786308, 0.0013254238636529242, 0.001324816183610396, 0.0013289478612767364, 0.0013279351802669805, 0.0013224244996143336, 0.0013558329321147705, 0.0013248451366300949, 0.001326154885728928, 0.0013273470685817301, 0.0038617582520766355, 0.001353333931712603, 0.001353959410070357, 0.0013506540906911885, 0.0013586265453010458, 0.0013500983186531812, 0.0013456513644831086, 0.0013614482251630927, 0.001372404430929402, 0.0013121885924854062, 0.0012640154772353444, 0.0012891541594978082, 0.001330716477241367, 0.0013101515016222204, 0.0013187829330986874, 0.0013071892952377145, 0.0013259793181945993, 0.001316544255999805, 0.0013274201625135056, 0.0013253442092993578, 0.001345196067420549, 0.001332473302216724, 0.0013311476728250814, 0.0013435222100206586, 0.0013078916980343502, 0.001342477674899233, 0.0013313263947100833, 0.0012121465338697267, 0.0012311165107327493, 0.001246359605385467, 0.001241091885170791, 0.0012468010685298331, 0.001250064022145992, 0.0012345209766482545, 0.0012555398821267624, 0.0013321630716280535, 0.001328173207205742, 0.0013234423944553317, 0.0013447389315250655, 0.001322379162491754, 0.001319011605647934, 0.0013288529075378942, 0.0013349123710636483, 0.001328211185673988, 0.0013324007213245644, 0.001207473395435616, 0.0012396990922604535, 0.0012425349288901618, 0.0012457048368835172, 0.001239569930814553, 0.0012622492111742842, 0.0012464376496757533, 0.0012362990934445069, 0.0012293152787267816, 0.0012500485822255181, 0.0012457985106075918, 0.0012462642774808891, 0.0012556356756926277, 0.001254055627383465, 0.001252590535143607, 0.0012526993699328497, 0.0012531056756500242, 0.0012498280239226513, 0.0012429818852133182, 0.001242938256540964, 0.0012539161618279164, 0.0012402492088027471, 0.0012349644648777538, 0.0012439479076758373, 0.0012443743261703571, 0.0012383619079712866, 0.0012373604654702683, 0.0012303985801503756, 0.0012331644890743287, 0.0012238928371347314, 0.0012248413485669812, 0.0012327917434578372, 0.0012373060237096493, 0.0012415802095431922, 0.0012424916278051083, 0.0012457843241823275, 0.001230611628311318, 0.001232584884260283, 0.0012310021150813892, 0.0012264582084838388, 0.0012245236728123802, 0.001230175606906414, 0.0012302870921747282, 0.0012324504164415737, 0.0012314077223066328, 0.0012356688615021317, 0.0012504581638157022, 0.00122819600226141, 0.0012202893957755593, 0.0012343671622274573, 0.0012364813944238217, 0.0012315899068706256, 0.0012355183040030128, 0.0012268385562915788, 0.001230095672897648, 0.001224271232955331, 0.0012455998383852284, 0.001238293975570001, 0.0012311936995057866, 0.0012267894425624331, 0.0012430239057298316, 0.0012466765582821396, 0.0012454543950382708, 0.001240096046849219, 0.001240583464265043, 0.0012533956283140321, 0.001244274625922878, 0.0012469825329432308, 0.0012569164418680377, 0.0012628034184968403, 0.0012578806747834002, 0.0012657274654524963, 0.0012628445347641097, 0.0012449486300262602, 0.0012473476736611405, 0.001249299371116903, 0.0012624685565919378, 0.0012587305120474032, 0.001311890954195067, 0.0010773597886179422, 0.0010795135830723962, 0.0010745697194537104, 0.0010703249298425954, 0.0010747765813585977, 0.00107613411667042, 0.0010767980007628023, 0.001078732953363553, 0.0010714696525314519, 0.001076751464414735, 0.0010798321603689082, 0.0010752167883004214, 0.0010749723025879196, 0.0010708033697419735, 0.0010814231138156598, 0.001085795372789509, 0.0010776683731481087, 0.0010828427905433399, 0.0010787635570565282, 0.0010694331397454058, 0.0010784461384985683, 0.0010787132087835046, 0.0010756919766927873, 0.0010747918155217587, 0.0010756007233244736, 0.0010717795338741568, 0.001071473396773082, 0.0010748373934739205, 0.0010796018394230063, 0.0010756007693491357, 0.0010722017424657595, 0.0010764525098682835, 0.0010768440227175867, 0.0010791690235004523, 0.0010778741169244397, 0.0010768371379696006, 0.0010820184861374802, 0.001082066489860069, 0.0010786268123707107, 0.0010786625112645155, 0.0010750381395134123, 0.0010794093967740272, 0.0010761263953565166, 0.001077211535059262, 0.0010749494662335099, 0.0010748579746198861, 0.0010776675338748582, 0.001070791324817164, 0.0010801976503327835, 0.001078787183952193, 0.001078369696949457, 0.0010808737688632899, 0.001083539487512479, 0.0010763420696305328, 0.0010783180247905643, 0.004277794581274827, 0.0010722556048571024, 0.0010710066254792172, 0.0010731685121522048, 0.0010750990463853922, 0.0010753186977316821, 0.0010973751155096431, 0.0010714555337895141, 0.0010716633486756405, 0.0010937652550637722, 0.0010862919788937582, 0.001083145835870054, 0.0010847849744307094, 0.0010827214424606673, 0.0010887986742133318, 0.0010890110238823433, 0.0010933239299933924, 0.0010963843940475651, 0.001095370928280402, 0.0010851254188563935, 0.0010824179991559928, 0.0010703630247261636, 0.001063656094375738, 0.001062904998963309, 0.0010627276740621688, 0.0010620399058774807, 0.0010679238827812465, 0.0010704107441787804, 0.0010670561608750113, 0.0010633025356286832, 0.001147657676145088, 0.0015886545338299732, 0.000980643558229298, 0.0009836270257310813, 0.000979561905571541, 0.0009828225579545942, 0.000990576232610227, 0.0009828569302551967, 0.0009986420248656771, 0.0009861266278380224, 0.0009806019763007414, 0.0009774054660526819, 0.000995640347841694, 0.0011628108142420304, 0.001056975349350724, 0.0010623821858749833, 0.00106230974305681, 0.0010627192542563345, 0.0010650803031789701, 0.0010653665332600129, 0.0010678783021217516, 0.0010672206286514222, 0.001065529790858543, 0.001079389790267965, 0.0012997607673453384, 0.0010809155592564927, 0.001074275464837461, 0.0013280856060297337, 0.001070287021765009, 0.0010684082084227093, 0.0010623057199598744, 0.0013165843949198377, 0.0014003510018377457, 0.0011875709995280864, 0.0010593272339509323, 0.0010648554645825265, 0.0010614830941005156, 0.0010587213003228223, 0.0010679513486751982, 0.0010584214198684624, 0.0010604881167108583, 0.0010555749298831404, 0.0010611363036861254, 0.00106505093132254, 0.0010558967884673283, 0.0010580037433524118, 0.0010596124866847382, 0.0010635654636940292, 0.0010640931608112052, 0.001072363486665106, 0.0010626070948620869, 0.0010584163273749656, 0.0010627546039041738, 0.004107260721908926, 0.0010504522550374615, 0.0010525142573643215, 0.001052964256729844, 0.0010531192542551908, 0.001049310697220959]
[767.7902096126096, 765.2187345858251, 775.1077791677251, 802.1665496824467, 794.2982528251761, 803.2637487274609, 807.8218449018295, 786.2856910427787, 749.9979765576779, 748.7596153533374, 743.4128339739876, 749.6732502718032, 754.3994989213069, 745.5524032123595, 661.1809977135587, 691.6308625622612, 749.9028503697803, 750.762344715795, 231.28049568812733, 751.4331028445109, 751.5021374717962, 752.9549249313703, 753.1851470088469, 744.5318237064126, 744.0917849284873, 730.7728391090359, 693.4448488228815, 753.6062330672711, 753.993536042157, 754.1813706109238, 749.5449157174687, 752.7975013417797, 750.0814651075196, 757.7976698779286, 745.6254789039323, 742.5220554176782, 753.376448818814, 443.8920723289376, 756.9119736693881, 765.5305122752029, 763.3396951006257, 764.3442843432704, 761.7051363398186, 713.700294778254, 756.7368064102527, 755.457082264496, 230.71172625596435, 744.0009175005084, 753.896461326361, 712.0081088462296, 715.1709832191843, 721.8492896848445, 761.514220154289, 763.8382594243254, 748.880287146776, 708.9708615109004, 709.1854050228542, 707.0424093686548, 714.6428045801291, 712.0915370232475, 714.6261940572223, 709.3116434805734, 703.740134234742, 709.8070852210968, 707.6742211259043, 730.5246975183175, 730.1110013191068, 733.2126219444003, 729.8517448060855, 756.8971704408609, 759.1931202261724, 744.6607403546116, 743.5478594649063, 748.9379930400272, 232.9575434682834, 751.6915073067443, 750.7256189948296, 750.7280018524507, 753.7872103609523, 752.5931708479553, 754.9347720943807, 740.7978956005153, 748.9129697870819, 744.8479384646075, 736.5397615870297, 745.8091285431613, 753.3845115020501, 756.0482612107822, 752.4734239199099, 745.3640056756718, 749.0671768384922, 747.7355041784698, 739.2737797751892, 751.0705644892099, 669.8825196159289, 754.4756265697206, 754.8216970559605, 752.4749684606045, 753.0488045349855, 756.186837351876, 737.5539982202988, 754.8052012657282, 754.0597337168084, 753.3824601492506, 258.9494045781495, 738.915929444354, 738.5745780577249, 740.3820170479448, 736.0374368207408, 740.6867975345461, 743.1345342440312, 734.5119568393477, 728.6481866885207, 762.0855765145068, 791.1295534032548, 775.7024190105792, 751.4748762058191, 763.2705063206866, 758.2749024893302, 765.0001446945358, 754.1595757025533, 759.5642876741609, 753.3409754048585, 754.520971218978, 743.3860566642362, 750.4840797458261, 751.2314526890243, 744.312220923109, 764.5893016240677, 744.8913443384156, 751.130604766358, 824.9827657449484, 812.2708056322056, 802.3366576380062, 805.742114623839, 802.0525689628668, 799.9590279250612, 810.0307883913136, 796.4701195362247, 750.6588504798344, 752.9138478134456, 755.6052338882148, 743.6387662740619, 756.2127628476115, 758.1434429523257, 752.5287368733725, 749.1128419187601, 752.8923192229853, 750.5249614439426, 828.1755968952289, 806.647360027191, 804.8063493017495, 802.7583825569649, 806.7314115492253, 792.2365814510504, 802.2864202314001, 808.8657553034811, 813.4609707574069, 799.9689085840605, 802.6980217790493, 802.398029109307, 796.4093561202654, 797.4127926736859, 798.3454863686577, 798.2761259420163, 798.0172936981309, 800.1100798343816, 804.5169538640395, 804.5451934056249, 797.5014841041956, 806.2895689853593, 809.7398981427273, 803.8921837718882, 803.6167083883553, 807.5183785636813, 808.1719336490538, 812.7447610332767, 810.9218266175076, 817.064999204596, 816.4322678769481, 811.1670160891218, 808.2074934071958, 805.425209192022, 804.8343969661385, 802.7071625390307, 812.6040555721303, 811.3031506143569, 812.3462890507574, 815.3559518641986, 816.6440732854812, 812.8920736078904, 812.8184115403022, 811.3916687109227, 812.0787143731993, 809.2783035613257, 799.7068825945818, 814.2022919458742, 819.4777431171942, 810.1317262810736, 808.7464999552074, 811.9585865565612, 809.3769204066455, 815.1031730065167, 812.9448969155154, 816.812462044092, 802.8260515001195, 807.5626787570283, 812.2198809183396, 815.1358051396896, 804.4897571079761, 802.1326729508348, 802.9198049995815, 806.38915230861, 806.0723270984662, 797.8326853948903, 803.6810999487354, 801.9358520120709, 795.5978350587834, 791.8888920892656, 794.9879667021629, 790.0594932910782, 791.8631094102117, 803.2459941571298, 801.7010983512397, 800.4486539571188, 792.0989356752951, 794.4512271919413, 762.258476439886, 928.1950287775444, 926.3431379472844, 930.605043019805, 934.2957191019202, 930.425929764794, 929.252204264297, 928.6792873794354, 927.0134901153626, 933.2975485002324, 928.7194241649319, 926.0698437230885, 930.0450019764709, 930.2565262310211, 933.8782714523633, 924.7074408014372, 920.9838474729426, 927.9292451338977, 923.4950897149421, 926.9871914551513, 935.0748193926967, 927.2600311706041, 927.0304580099917, 929.6341533330924, 930.4127418522899, 929.7130229786325, 933.0277061601506, 933.2942871112473, 930.3732881565994, 926.2674103393992, 929.7129831964671, 932.6603011297893, 928.9773499830119, 928.6395976608954, 926.6389029184185, 927.7521227185207, 928.645534909319, 924.1986276683085, 924.1576274386969, 927.1047117789544, 927.0740287689247, 930.1995559456373, 926.432550048801, 929.2588717412733, 928.3227736184477, 930.2762887113907, 930.3554735718837, 927.9299677929453, 933.88877629425, 925.7565036286863, 926.9668891842485, 927.3257611270486, 925.1774155382257, 922.9012984988082, 929.0726695680138, 927.370197854408, 233.76531551498428, 932.6134510001169, 933.7010399469326, 931.8201090288536, 930.146857968218, 929.9568603330695, 911.2654240711298, 933.3098467121722, 933.1288610698482, 914.2729624755677, 920.5628131567031, 923.2367118844475, 921.8416769874563, 923.5985921986834, 918.44344017273, 918.2643500108774, 914.6420128260099, 912.0888672158684, 912.9327556372865, 921.5524607781223, 923.8575123286406, 934.2624669381074, 940.1535000717522, 940.8178538771926, 940.9748371166447, 941.5842045725938, 936.3963257340506, 934.2208170445828, 937.1577960619958, 940.4661105305694, 871.3399655539612, 629.4634728351996, 1019.7385090721984, 1016.6455107887562, 1020.8645255723108, 1017.4776635989662, 1009.5134196435753, 1017.4420805481343, 1001.3598217384307, 1014.0685503974205, 1019.7817505655419, 1023.1168483623973, 1004.3787419500995, 859.9851220439867, 946.0958579727306, 941.2808434625576, 941.3450328738273, 940.9822923550737, 938.8963414451254, 938.6440898795724, 936.4362942978754, 937.0133720743718, 938.5002733656626, 926.4493781729618, 769.3723530695754, 925.1416462983007, 930.8599448943954, 752.9635103790226, 934.3288105567246, 935.971843080745, 941.3485978761106, 759.5411307156551, 714.1066766029757, 842.0549174721992, 943.9953660686492, 939.0945844392573, 942.0781221648986, 944.5356390724195, 936.3722432117413, 944.8032524930167, 942.9620042339895, 947.3510327786081, 942.3860031234885, 938.9222342242712, 947.0622611245325, 945.1762399548606, 943.7412380149929, 940.2336143247353, 939.7673407069507, 932.5196283117155, 941.0816141123051, 944.8077983454327, 940.9509931327174, 243.4712738506728, 951.9709203388188, 950.1058945312282, 949.6998531608914, 949.5600768473662, 953.0065810330957]
Elapsed: 0.054911218844579474~0.017630706098531762
Time per graph: 0.0012660790822168729~0.000399795488968152
Speed: 821.345451511571~116.33211688169418
Total Time: 0.0462
best val loss: 0.2627885043621063 test_score: 0.8605

Testing...
Test loss: 0.5534 score: 0.8372 time: 0.04s
test Score 0.8372
Epoch Time List: [0.4497484121238813, 0.17500576912425458, 0.1746859138365835, 0.1617481348803267, 0.16408349387347698, 0.16294541710522026, 0.16277886903844774, 0.1638532989891246, 0.28808597498573363, 0.1752547250362113, 0.17579445394221693, 0.17481226287782192, 0.17421284900046885, 0.18196171091403812, 0.18584208597894758, 0.1815277790883556, 0.17541389795951545, 0.17394722800236195, 0.3056220361031592, 0.17414846899919212, 0.17408618400804698, 0.174084032070823, 0.17476797010749578, 0.17941942310426384, 0.18229133100248873, 0.17847433895803988, 0.18263703910633922, 0.28973452001810074, 0.17439992912113667, 0.17430239787790924, 0.17446017998736352, 0.1748259930172935, 0.17431830405257642, 0.17676821094937623, 0.17822308593895286, 0.17580139101482928, 0.1748129321495071, 0.21499356382992119, 0.21386098209768534, 0.1713618190260604, 0.17233720200601965, 0.17204217100515962, 0.17255270795430988, 0.17723889998160303, 0.17364535806700587, 0.17361808300483972, 0.30256906512659043, 0.1725209339056164, 0.17278396105393767, 0.17689552099909633, 0.18247731297742575, 0.18301267293281853, 0.17318782198708504, 0.17109854007139802, 0.1710728551261127, 0.3017923808656633, 0.18360276112798601, 0.1833981249947101, 0.18373266595881432, 0.181936232955195, 0.1831136270193383, 0.1822909329785034, 0.1842925880337134, 0.18374619085807353, 0.18415794696193188, 0.2761290289927274, 0.17964927305001765, 0.17903709888923913, 0.17932408093474805, 0.17198757780715823, 0.17241757502779365, 0.17754943505860865, 0.1756840880261734, 0.17492644593585283, 0.3069283150834963, 0.174490712932311, 0.17439385189209133, 0.17409152700565755, 0.1743353740312159, 0.17431157198734581, 0.17467045411467552, 0.17616693407762796, 0.17549387796316296, 0.18064280599355698, 0.17529696796555072, 0.2988774939440191, 0.17483337805606425, 0.1729841799242422, 0.17436628497671336, 0.17512163403443992, 0.1755683379014954, 0.17511370708234608, 0.17636954109184444, 0.17473127599805593, 0.1806101710535586, 0.2869555309880525, 0.17478194809518754, 0.17438718595076352, 0.17580724915023893, 0.17497969313990325, 0.17623806500341743, 0.17729601997416466, 0.17504422494675964, 0.17531161103397608, 0.2846705538686365, 0.17640321305952966, 0.17740508809220046, 0.1762746429303661, 0.17626275087241083, 0.1761191551340744, 0.1768441180465743, 0.17578295711427927, 0.1791542739374563, 0.17362292308826, 0.16641792992595583, 0.29920201003551483, 0.17350876901764423, 0.17277734901290387, 0.17255216895136982, 0.17220157897099853, 0.1734089150559157, 0.18009253893978894, 0.18349338695406914, 0.18464720097836107, 0.18318252707831562, 0.1838246489642188, 0.1844765490386635, 0.1842448191018775, 0.26354038598947227, 0.18338398693595082, 0.1833485719980672, 0.17360830609686673, 0.1714617528486997, 0.17217264289502054, 0.17259969701990485, 0.17783643899019808, 0.1740520551102236, 0.17225102300290018, 0.17390445189084858, 0.24021248414646834, 0.18460961314849555, 0.18364034895785153, 0.18475888087414205, 0.18425799580290914, 0.1831792639568448, 0.18663030001334846, 0.18552171683404595, 0.18368813197594136, 0.35749211604706943, 0.17925400601234287, 0.17269261495675892, 0.17309088597539812, 0.17384633992332965, 0.1742021661484614, 0.1759963878430426, 0.17593789694365114, 0.17370032612234354, 0.17368518188595772, 0.1746882990701124, 0.1725415049586445, 0.17438281001523137, 0.1741254790686071, 0.17493315902538598, 0.17426745500415564, 0.1744421770563349, 0.17471645900513977, 0.17362894618418068, 0.17349079600535333, 0.17417762195691466, 0.1739480938995257, 0.17319432401563972, 0.17299175809603184, 0.17413851513992995, 0.17396112903952599, 0.1735866900999099, 0.174949791864492, 0.17296557710506022, 0.1735988218570128, 0.17248812119942158, 0.17346073384396732, 0.1731215538457036, 0.17481584998313338, 0.173820111900568, 0.17427817091811448, 0.174389234976843, 0.17136561393272132, 0.17152526997961104, 0.17161162896081805, 0.17148769786581397, 0.17299269698560238, 0.1716937009477988, 0.17228421894833446, 0.1719197699567303, 0.17101113009266555, 0.17246231599710882, 0.1731880500447005, 0.17233180499169976, 0.17216328089125454, 0.1715853608911857, 0.17147721396759152, 0.17182502523064613, 0.17209833313245326, 0.17166500084567815, 0.17207445995882154, 0.17218930600211024, 0.17330174602102488, 0.1743263640673831, 0.1740252070594579, 0.17437928298022598, 0.17323049600236118, 0.17529787099920213, 0.1740633340086788, 0.17509862990118563, 0.173545490950346, 0.17545237101148814, 0.17437664594035596, 0.17574808397330344, 0.1755438850959763, 0.17588551284279674, 0.17599884094670415, 0.17688694992102683, 0.1763339788885787, 0.1754699550801888, 0.1759794200770557, 0.1761265560053289, 0.17635473411064595, 0.17555084300693125, 0.1917026110459119, 0.18119415594264865, 0.17028257390484214, 0.1703747968422249, 0.17006461415439844, 0.1699547239113599, 0.17021470901090652, 0.17138842307031155, 0.17057459987699986, 0.17016652191523463, 0.17037937510758638, 0.17065068194642663, 0.17055444116704166, 0.17030223296023905, 0.1698304358869791, 0.17037067282944918, 0.17182533896993846, 0.17118913994636387, 0.17154402320738882, 0.17116615397389978, 0.17067768494598567, 0.1702606569742784, 0.17078402114566416, 0.17029913293663412, 0.1701495690504089, 0.17012141295708716, 0.17015119676943868, 0.17032129794824868, 0.17038913490250707, 0.17015049594920129, 0.16966539493296295, 0.16981638001743704, 0.16993559792172164, 0.1703172610141337, 0.1708175130188465, 0.17029821791220456, 0.1701392710674554, 0.17058234906289726, 0.17084029910620302, 0.17257614096160978, 0.17094543389976025, 0.17050184996332973, 0.17130726692266762, 0.17043041007127613, 0.17037566390354186, 0.1703707359265536, 0.1700944300973788, 0.1701964340172708, 0.17012631706893444, 0.17071499093435705, 0.17057602806016803, 0.17056055914144963, 0.17238276195712388, 0.17149939516093582, 0.16983337490819395, 0.16935875301714987, 0.307670617941767, 0.16840946406591684, 0.16814664215780795, 0.16812492697499692, 0.16818732710089535, 0.16876125300768763, 0.17142100702039897, 0.17005493200849742, 0.16965112218167633, 0.1695495540043339, 0.2606560610001907, 0.16758861194830388, 0.167876488994807, 0.17039545904845, 0.17193777405191213, 0.17091691412497312, 0.17305769689846784, 0.17272629006765783, 0.17158841295167804, 0.1720363131025806, 0.17092058912385255, 0.3036684200633317, 0.16529157815966755, 0.16669284901581705, 0.16644185211043805, 0.16708472999744117, 0.16691062587779015, 0.16841998999007046, 0.16775904188398272, 0.1685734208440408, 0.1740879559656605, 0.3336355809587985, 0.18932769598904997, 0.15526127396151423, 0.15481055702548474, 0.15575528994668275, 0.15610890102107078, 0.15696104092057794, 0.156124962028116, 0.1585124790435657, 0.15741166088264436, 0.1561645601177588, 0.1566339711425826, 0.28447166294790804, 0.16700945794582367, 0.166462488938123, 0.1667922749184072, 0.1664274699287489, 0.166616155882366, 0.1676928779343143, 0.16865762195084244, 0.16949895804282278, 0.16770921903662384, 0.16976107598748058, 0.3099398629274219, 0.17754962702747434, 0.1666145019698888, 0.18193093605805188, 0.1698202039115131, 0.16625501797534525, 0.16670437611173838, 0.1847478401614353, 0.19581157097127289, 0.27003863907884806, 0.1667820200091228, 0.16599669097922742, 0.16634265088941902, 0.16556610516272485, 0.16710469708777964, 0.16649776208214462, 0.16783540416508913, 0.1671100949170068, 0.17325716011691839, 0.16970700200181454, 0.246513047022745, 0.16627529298420995, 0.16621005698107183, 0.16710943111684173, 0.16710935800801963, 0.1675715009914711, 0.1684259349713102, 0.1675057850079611, 0.1674053301103413, 0.29900799808092415, 0.16582321701571345, 0.1658536980394274, 0.16681008785963058, 0.16650506504811347, 0.16659076290670782]
Total Epoch List: [121, 106, 145]
Total Time List: [0.058929117978550494, 0.05487964896019548, 0.046244047000072896]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x75199505ac50>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6971;  Loss pred: 0.6971; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.04s
Epoch 2/1000, LR 0.000000
Train loss: 0.6980;  Loss pred: 0.6980; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.04s
Epoch 3/1000, LR 0.000030
Train loss: 0.6966;  Loss pred: 0.6966; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.04s
Epoch 4/1000, LR 0.000060
Train loss: 0.6962;  Loss pred: 0.6962; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.04s
Epoch 5/1000, LR 0.000090
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6930;  Loss pred: 0.6930; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.04s
Epoch 7/1000, LR 0.000150
Train loss: 0.6895;  Loss pred: 0.6895; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6903;  Loss pred: 0.6903; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.04s
Epoch 9/1000, LR 0.000210
Train loss: 0.6868;  Loss pred: 0.6868; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.04s
Epoch 10/1000, LR 0.000240
Train loss: 0.6804;  Loss pred: 0.6804; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.04s
Epoch 11/1000, LR 0.000270
Train loss: 0.6803;  Loss pred: 0.6803; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.04s
Epoch 12/1000, LR 0.000270
Train loss: 0.6731;  Loss pred: 0.6731; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.04s
Epoch 13/1000, LR 0.000270
Train loss: 0.6719;  Loss pred: 0.6719; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.04s
Epoch 14/1000, LR 0.000270
Train loss: 0.6661;  Loss pred: 0.6661; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.04s
Epoch 15/1000, LR 0.000270
Train loss: 0.6626;  Loss pred: 0.6626; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.04s
Epoch 16/1000, LR 0.000270
Train loss: 0.6570;  Loss pred: 0.6570; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.04s
Epoch 17/1000, LR 0.000270
Train loss: 0.6534;  Loss pred: 0.6534; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.13s
Epoch 18/1000, LR 0.000270
Train loss: 0.6472;  Loss pred: 0.6472; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.04s
Epoch 19/1000, LR 0.000270
Train loss: 0.6426;  Loss pred: 0.6426; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.04s
Epoch 20/1000, LR 0.000270
Train loss: 0.6366;  Loss pred: 0.6366; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.04s
Epoch 21/1000, LR 0.000270
Train loss: 0.6298;  Loss pred: 0.6298; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4884 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.04s
Epoch 22/1000, LR 0.000270
Train loss: 0.6219;  Loss pred: 0.6219; Loss self: 0.0000; time: 0.06s
Val loss: 0.6927 score: 0.8140 time: 0.04s
Test loss: 0.6927 score: 0.8636 time: 0.04s
Epoch 23/1000, LR 0.000270
Train loss: 0.6143;  Loss pred: 0.6143; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.04s
Test loss: 0.6926 score: 0.5455 time: 0.04s
Epoch 24/1000, LR 0.000270
Train loss: 0.6093;  Loss pred: 0.6093; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.04s
Epoch 25/1000, LR 0.000270
Train loss: 0.6007;  Loss pred: 0.6007; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.04s
Epoch 26/1000, LR 0.000270
Train loss: 0.5915;  Loss pred: 0.5915; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.04s
Epoch 27/1000, LR 0.000270
Train loss: 0.5801;  Loss pred: 0.5801; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.04s
Epoch 28/1000, LR 0.000270
Train loss: 0.5693;  Loss pred: 0.5693; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.04s
Epoch 29/1000, LR 0.000270
Train loss: 0.5607;  Loss pred: 0.5607; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5116 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.04s
Epoch 30/1000, LR 0.000270
Train loss: 0.5479;  Loss pred: 0.5479; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5000 time: 0.04s
Epoch 31/1000, LR 0.000270
Train loss: 0.5384;  Loss pred: 0.5384; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5000 time: 0.04s
Epoch 32/1000, LR 0.000270
Train loss: 0.5279;  Loss pred: 0.5279; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5000 time: 0.04s
Epoch 33/1000, LR 0.000270
Train loss: 0.5090;  Loss pred: 0.5090; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5000 time: 0.04s
Epoch 34/1000, LR 0.000270
Train loss: 0.4992;  Loss pred: 0.4992; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5000 time: 0.04s
Epoch 35/1000, LR 0.000270
Train loss: 0.4901;  Loss pred: 0.4901; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.5000 time: 0.04s
Epoch 36/1000, LR 0.000270
Train loss: 0.4768;  Loss pred: 0.4768; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.5000 time: 0.04s
Epoch 37/1000, LR 0.000270
Train loss: 0.4594;  Loss pred: 0.4594; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6877 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5000 time: 0.04s
Epoch 38/1000, LR 0.000270
Train loss: 0.4502;  Loss pred: 0.4502; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6883 score: 0.5000 time: 0.04s
Epoch 39/1000, LR 0.000269
Train loss: 0.4390;  Loss pred: 0.4390; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6864 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5000 time: 0.04s
Epoch 40/1000, LR 0.000269
Train loss: 0.4207;  Loss pred: 0.4207; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6857 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.5000 time: 0.04s
Epoch 41/1000, LR 0.000269
Train loss: 0.4029;  Loss pred: 0.4029; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6848 score: 0.5116 time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6863 score: 0.5000 time: 0.04s
Epoch 42/1000, LR 0.000269
Train loss: 0.3970;  Loss pred: 0.3970; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6839 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6855 score: 0.5000 time: 0.04s
Epoch 43/1000, LR 0.000269
Train loss: 0.3733;  Loss pred: 0.3733; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6828 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6846 score: 0.5000 time: 0.04s
Epoch 44/1000, LR 0.000269
Train loss: 0.3586;  Loss pred: 0.3586; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6815 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6836 score: 0.5000 time: 0.04s
Epoch 45/1000, LR 0.000269
Train loss: 0.3445;  Loss pred: 0.3445; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6801 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6824 score: 0.5000 time: 0.04s
Epoch 46/1000, LR 0.000269
Train loss: 0.3256;  Loss pred: 0.3256; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6785 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6810 score: 0.5000 time: 0.04s
Epoch 47/1000, LR 0.000269
Train loss: 0.3158;  Loss pred: 0.3158; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6766 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6794 score: 0.5000 time: 0.04s
Epoch 48/1000, LR 0.000269
Train loss: 0.2981;  Loss pred: 0.2981; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6746 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6776 score: 0.5000 time: 0.04s
Epoch 49/1000, LR 0.000269
Train loss: 0.2771;  Loss pred: 0.2771; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6721 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6755 score: 0.5000 time: 0.04s
Epoch 50/1000, LR 0.000269
Train loss: 0.2699;  Loss pred: 0.2699; Loss self: 0.0000; time: 0.06s
Val loss: 0.6694 score: 0.5349 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6732 score: 0.5000 time: 0.04s
Epoch 51/1000, LR 0.000269
Train loss: 0.2476;  Loss pred: 0.2476; Loss self: 0.0000; time: 0.06s
Val loss: 0.6664 score: 0.5349 time: 0.04s
Test loss: 0.6705 score: 0.5227 time: 0.04s
Epoch 52/1000, LR 0.000269
Train loss: 0.2405;  Loss pred: 0.2405; Loss self: 0.0000; time: 0.07s
Val loss: 0.6629 score: 0.5349 time: 0.13s
Test loss: 0.6675 score: 0.5455 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2205;  Loss pred: 0.2205; Loss self: 0.0000; time: 0.06s
Val loss: 0.6589 score: 0.5581 time: 0.05s
Test loss: 0.6639 score: 0.5682 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2107;  Loss pred: 0.2107; Loss self: 0.0000; time: 0.06s
Val loss: 0.6545 score: 0.5581 time: 0.05s
Test loss: 0.6598 score: 0.5909 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2054;  Loss pred: 0.2054; Loss self: 0.0000; time: 0.06s
Val loss: 0.6493 score: 0.5814 time: 0.05s
Test loss: 0.6551 score: 0.5909 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1854;  Loss pred: 0.1854; Loss self: 0.0000; time: 0.06s
Val loss: 0.6436 score: 0.5814 time: 0.05s
Test loss: 0.6497 score: 0.5909 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1718;  Loss pred: 0.1718; Loss self: 0.0000; time: 0.06s
Val loss: 0.6374 score: 0.5581 time: 0.05s
Test loss: 0.6439 score: 0.5909 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1686;  Loss pred: 0.1686; Loss self: 0.0000; time: 0.06s
Val loss: 0.6306 score: 0.5581 time: 0.05s
Test loss: 0.6376 score: 0.5909 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1486;  Loss pred: 0.1486; Loss self: 0.0000; time: 0.07s
Val loss: 0.6235 score: 0.5814 time: 0.05s
Test loss: 0.6310 score: 0.5909 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1423;  Loss pred: 0.1423; Loss self: 0.0000; time: 0.07s
Val loss: 0.6158 score: 0.6279 time: 0.05s
Test loss: 0.6238 score: 0.5909 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1332;  Loss pred: 0.1332; Loss self: 0.0000; time: 0.06s
Val loss: 0.6075 score: 0.6512 time: 0.05s
Test loss: 0.6161 score: 0.5909 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1222;  Loss pred: 0.1222; Loss self: 0.0000; time: 0.07s
Val loss: 0.5986 score: 0.6744 time: 0.05s
Test loss: 0.6078 score: 0.5909 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1161;  Loss pred: 0.1161; Loss self: 0.0000; time: 0.18s
Val loss: 0.5891 score: 0.6512 time: 0.05s
Test loss: 0.5986 score: 0.5909 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1091;  Loss pred: 0.1091; Loss self: 0.0000; time: 0.07s
Val loss: 0.5794 score: 0.6744 time: 0.05s
Test loss: 0.5895 score: 0.5909 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1011;  Loss pred: 0.1011; Loss self: 0.0000; time: 0.06s
Val loss: 0.5693 score: 0.6744 time: 0.05s
Test loss: 0.5797 score: 0.6591 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0901;  Loss pred: 0.0901; Loss self: 0.0000; time: 0.06s
Val loss: 0.5584 score: 0.6977 time: 0.05s
Test loss: 0.5692 score: 0.6591 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0815;  Loss pred: 0.0815; Loss self: 0.0000; time: 0.06s
Val loss: 0.5473 score: 0.7209 time: 0.05s
Test loss: 0.5583 score: 0.6591 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0759;  Loss pred: 0.0759; Loss self: 0.0000; time: 0.06s
Val loss: 0.5355 score: 0.7442 time: 0.05s
Test loss: 0.5467 score: 0.7273 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0734;  Loss pred: 0.0734; Loss self: 0.0000; time: 0.06s
Val loss: 0.5236 score: 0.7442 time: 0.05s
Test loss: 0.5345 score: 0.7500 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0650;  Loss pred: 0.0650; Loss self: 0.0000; time: 0.06s
Val loss: 0.5118 score: 0.7674 time: 0.05s
Test loss: 0.5223 score: 0.7727 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0634;  Loss pred: 0.0634; Loss self: 0.0000; time: 0.07s
Val loss: 0.4997 score: 0.7674 time: 0.05s
Test loss: 0.5096 score: 0.7727 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.07s
Val loss: 0.4880 score: 0.7674 time: 0.04s
Test loss: 0.4971 score: 0.7727 time: 0.04s
Epoch 73/1000, LR 0.000267
Train loss: 0.0535;  Loss pred: 0.0535; Loss self: 0.0000; time: 0.06s
Val loss: 0.4762 score: 0.7674 time: 0.04s
Test loss: 0.4841 score: 0.8182 time: 0.04s
Epoch 74/1000, LR 0.000267
Train loss: 0.0528;  Loss pred: 0.0528; Loss self: 0.0000; time: 0.06s
Val loss: 0.4650 score: 0.7907 time: 0.04s
Test loss: 0.4713 score: 0.8182 time: 0.04s
Epoch 75/1000, LR 0.000267
Train loss: 0.0433;  Loss pred: 0.0433; Loss self: 0.0000; time: 0.06s
Val loss: 0.4544 score: 0.8140 time: 0.04s
Test loss: 0.4590 score: 0.8182 time: 0.18s
Epoch 76/1000, LR 0.000267
Train loss: 0.0439;  Loss pred: 0.0439; Loss self: 0.0000; time: 0.06s
Val loss: 0.4443 score: 0.8605 time: 0.04s
Test loss: 0.4467 score: 0.8182 time: 0.04s
Epoch 77/1000, LR 0.000267
Train loss: 0.0400;  Loss pred: 0.0400; Loss self: 0.0000; time: 0.06s
Val loss: 0.4348 score: 0.8837 time: 0.04s
Test loss: 0.4345 score: 0.8409 time: 0.04s
Epoch 78/1000, LR 0.000267
Train loss: 0.0385;  Loss pred: 0.0385; Loss self: 0.0000; time: 0.06s
Val loss: 0.4260 score: 0.8837 time: 0.04s
Test loss: 0.4228 score: 0.8636 time: 0.04s
Epoch 79/1000, LR 0.000267
Train loss: 0.0334;  Loss pred: 0.0334; Loss self: 0.0000; time: 0.06s
Val loss: 0.4177 score: 0.8372 time: 0.04s
Test loss: 0.4110 score: 0.8864 time: 0.04s
Epoch 80/1000, LR 0.000267
Train loss: 0.0295;  Loss pred: 0.0295; Loss self: 0.0000; time: 0.06s
Val loss: 0.4103 score: 0.8372 time: 0.04s
Test loss: 0.3997 score: 0.8864 time: 0.04s
Epoch 81/1000, LR 0.000267
Train loss: 0.0288;  Loss pred: 0.0288; Loss self: 0.0000; time: 0.06s
Val loss: 0.4040 score: 0.8372 time: 0.04s
Test loss: 0.3885 score: 0.8409 time: 0.04s
Epoch 82/1000, LR 0.000267
Train loss: 0.0282;  Loss pred: 0.0282; Loss self: 0.0000; time: 0.06s
Val loss: 0.3989 score: 0.8837 time: 0.04s
Test loss: 0.3782 score: 0.8182 time: 0.04s
Epoch 83/1000, LR 0.000266
Train loss: 0.0237;  Loss pred: 0.0237; Loss self: 0.0000; time: 0.06s
Val loss: 0.3952 score: 0.8837 time: 0.04s
Test loss: 0.3686 score: 0.8182 time: 0.04s
Epoch 84/1000, LR 0.000266
Train loss: 0.0220;  Loss pred: 0.0220; Loss self: 0.0000; time: 0.06s
Val loss: 0.3926 score: 0.8837 time: 0.04s
Test loss: 0.3601 score: 0.8182 time: 0.04s
Epoch 85/1000, LR 0.000266
Train loss: 0.0210;  Loss pred: 0.0210; Loss self: 0.0000; time: 0.06s
Val loss: 0.3917 score: 0.8837 time: 0.05s
Test loss: 0.3526 score: 0.8409 time: 0.04s
Epoch 86/1000, LR 0.000266
Train loss: 0.0193;  Loss pred: 0.0193; Loss self: 0.0000; time: 0.06s
Val loss: 0.3923 score: 0.8837 time: 0.04s
Test loss: 0.3462 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 1 of 20
Epoch 87/1000, LR 0.000266
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.06s
Val loss: 0.3943 score: 0.8605 time: 0.04s
Test loss: 0.3410 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 2 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0162;  Loss pred: 0.0162; Loss self: 0.0000; time: 0.06s
Val loss: 0.3974 score: 0.8605 time: 0.04s
Test loss: 0.3368 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 3 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.07s
Val loss: 0.4027 score: 0.8605 time: 0.14s
Test loss: 0.3339 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 4 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.06s
Val loss: 0.4086 score: 0.8605 time: 0.04s
Test loss: 0.3318 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 5 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0135;  Loss pred: 0.0135; Loss self: 0.0000; time: 0.06s
Val loss: 0.4154 score: 0.8605 time: 0.04s
Test loss: 0.3305 score: 0.8182 time: 0.04s
     INFO: Early stopping counter 6 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.06s
Val loss: 0.4232 score: 0.8605 time: 0.04s
Test loss: 0.3300 score: 0.8182 time: 0.04s
     INFO: Early stopping counter 7 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.06s
Val loss: 0.4319 score: 0.8605 time: 0.04s
Test loss: 0.3303 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 8 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0131;  Loss pred: 0.0131; Loss self: 0.0000; time: 0.06s
Val loss: 0.4407 score: 0.8605 time: 0.04s
Test loss: 0.3310 score: 0.8409 time: 0.04s
     INFO: Early stopping counter 9 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.06s
Val loss: 0.4501 score: 0.8605 time: 0.04s
Test loss: 0.3322 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 10 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.06s
Val loss: 0.4609 score: 0.8372 time: 0.04s
Test loss: 0.3345 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 11 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.06s
Val loss: 0.4721 score: 0.8372 time: 0.04s
Test loss: 0.3372 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 12 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.06s
Val loss: 0.4830 score: 0.8372 time: 0.04s
Test loss: 0.3399 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 13 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0088;  Loss pred: 0.0088; Loss self: 0.0000; time: 0.06s
Val loss: 0.4938 score: 0.8372 time: 0.04s
Test loss: 0.3428 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 14 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.06s
Val loss: 0.5052 score: 0.8372 time: 0.04s
Test loss: 0.3462 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 15 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.06s
Val loss: 0.5157 score: 0.8372 time: 0.04s
Test loss: 0.3494 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 16 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.06s
Val loss: 0.5263 score: 0.8372 time: 0.04s
Test loss: 0.3528 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 17 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.06s
Val loss: 0.5376 score: 0.8372 time: 0.04s
Test loss: 0.3566 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 18 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.06s
Val loss: 0.5499 score: 0.8372 time: 0.04s
Test loss: 0.3614 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 19 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.06s
Val loss: 0.5610 score: 0.8372 time: 0.04s
Test loss: 0.3656 score: 0.8636 time: 0.04s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 084,   Train_Loss: 0.0210,   Val_Loss: 0.3917,   Val_Precision: 1.0000,   Val_Recall: 0.7727,   Val_accuracy: 0.8718,   Val_Score: 0.8837,   Val_Loss: 0.3917,   Test_Precision: 0.8947,   Test_Recall: 0.7727,   Test_accuracy: 0.8293,   Test_Score: 0.8409,   Test_loss: 0.3526


[0.04603887104894966, 0.04531975497957319, 0.045436262036673725, 0.045277690049260855, 0.05188795307185501, 0.04977476701606065, 0.05062086891848594, 0.04895159904845059, 0.04871337302029133, 0.049147495068609715, 0.04894814605358988, 0.04890310298651457, 0.04866041196510196, 0.048744780011475086, 0.048637880012393, 0.04863415192812681, 0.13580167898908257, 0.04968568799085915, 0.04544687899760902, 0.044942502048797905, 0.04581856809090823, 0.04493385704699904, 0.0454160759691149, 0.04486890695989132, 0.04761497594881803, 0.04491375607904047, 0.04537022300064564, 0.04559711995534599, 0.04563709406647831, 0.04592725797556341, 0.04565979598555714, 0.045745317940600216, 0.04551674390677363, 0.04593586490955204, 0.04566017002798617, 0.045911313965916634, 0.04565657302737236, 0.046216204995289445, 0.04536561400163919, 0.046377010992728174, 0.04530785093083978, 0.04541709797922522, 0.04524559690617025, 0.04559773893561214, 0.0454745190218091, 0.04535398003645241, 0.0458511000033468, 0.04557407496031374, 0.04595678602345288, 0.045510448049753904, 0.046168806962668896, 0.05095513793639839, 0.0517409211024642, 0.05119840404950082, 0.05180897889658809, 0.051216849009506404, 0.05164223804604262, 0.051630544010549784, 0.05164410104043782, 0.05123320105485618, 0.05138012103270739, 0.05167271103709936, 0.05128790799062699, 0.051237000967375934, 0.051252032979391515, 0.0511227180249989, 0.05105035298038274, 0.051640974008478224, 0.05156421195715666, 0.05130526295397431, 0.05184876103885472, 0.046360087930224836, 0.046323130023665726, 0.046210753032937646, 0.18437502905726433, 0.04642786306794733, 0.04655216203536838, 0.046291395905427635, 0.046259031048975885, 0.04634515300858766, 0.04650445294100791, 0.04664714995305985, 0.04666853207163513, 0.046863732975907624, 0.0466115860035643, 0.046417257050052285, 0.04639109305571765, 0.0474632759578526, 0.04948582698125392, 0.04612089798320085, 0.04577147506643087, 0.04611521202605218, 0.04600039392244071, 0.04592650302220136, 0.04606425005476922, 0.04575316503178328, 0.045600996003486216, 0.04581351508386433, 0.04605697898659855, 0.04580971598625183, 0.04568676196504384, 0.04572781908791512, 0.04571362107526511, 0.04569762200117111, 0.04578396596480161]
[0.0010463379783852195, 0.001029994431353936, 0.0010326423190153118, 0.001029038410210474, 0.0011792716607239774, 0.0011312447049104694, 0.0011504742936019532, 0.0011125363420102406, 0.0011071221140975301, 0.0011169885242865844, 0.0011124578648543154, 0.001111434158784422, 0.0011059184537523172, 0.0011078359093517065, 0.0011054063639180226, 0.0011053216347301548, 0.0030864017952064223, 0.0011292201816104352, 0.0010328836135820231, 0.0010214205011090432, 0.001041331092975187, 0.0010212240237954327, 0.0010321835447526114, 0.0010197478854520755, 0.0010821585442913188, 0.0010207671836145562, 0.0010311414318328555, 0.001036298180803318, 0.0010372066833290526, 0.001043801317626441, 0.0010377226360353895, 0.001039666316831823, 0.0010344714524266733, 0.0010439969297625464, 0.0010377311369996858, 0.0010434389537708325, 0.0010376493869857354, 0.0010503682953474874, 0.001031036681855436, 0.0010540229771074585, 0.0010297238847918131, 0.0010322067722551185, 0.0010283090205947783, 0.0010363122485366396, 0.0010335117959502068, 0.0010307722735557366, 0.0010420704546215181, 0.0010357744309162213, 0.001044472409623929, 0.0010343283647671342, 0.001049291067333384, 0.001158071316736327, 0.0011759300250560045, 0.0011636000920341096, 0.0011774767931042747, 0.0011640192956706, 0.0011736872283191506, 0.0011734214547852223, 0.0011737295691008594, 0.0011643909330649133, 0.0011677300234706227, 0.0011743797962977128, 0.0011656342725142497, 0.0011644772947130894, 0.0011648189313498071, 0.0011618799551136115, 0.0011602352950086986, 0.001173658500192687, 0.0011719139081171968, 0.001166028703499416, 0.0011783809327012436, 0.0010536383620505644, 0.0010527984096287664, 0.0010502443871122193, 0.00419034156948328, 0.001055178706089712, 0.0010580036826220087, 0.0010520771796688098, 0.001051341614749452, 0.0010532989320133559, 0.0010569193850229071, 0.0010601624989331785, 0.0010606484561735256, 0.0010650848403615369, 0.0010593542273537341, 0.001054937660228461, 0.0010543430239935828, 0.0010787108172239227, 0.001124677885937589, 0.0010482022268909284, 0.001040260796964338, 0.001048073000592095, 0.0010454634982372888, 0.0010437841595954853, 0.0010469147739720277, 0.0010398446598132564, 0.0010363862728065049, 0.0010412162519060075, 0.0010467495224226943, 0.0010411299087784507, 0.001038335499205542, 0.0010392686156344346, 0.0010389459335287525, 0.0010385823182084343, 0.0010405446810182184]
[955.7141388896813, 970.8790354191448, 968.3895203457879, 971.7810239906063, 847.9810321110242, 883.9820382444517, 869.2067311379536, 898.8470418800891, 903.2427292947258, 895.2643453868029, 898.9104500878848, 899.738407440799, 904.2258012849483, 902.6607564880155, 904.6446923424446, 904.7140385016826, 324.00188515737915, 885.5668861442521, 968.163292408151, 979.0287143387221, 960.3093643760315, 979.2170735304949, 968.8199401005517, 980.6345414059665, 924.0790134451855, 979.6553181294298, 969.7990684192551, 964.9732273242241, 964.1279950013119, 958.0367289379905, 963.6486333385686, 961.8470694013649, 966.6772317923227, 957.8572230355569, 963.6407392489206, 958.3694344418993, 963.7166585766479, 952.0470147751134, 969.8975968540877, 948.7459208377857, 971.1341212622036, 968.7981389767917, 972.470317747087, 964.9601280039722, 967.574829739223, 970.1463899008604, 959.6280132164401, 965.461175861837, 957.4211733941908, 966.8109606808832, 953.024409653415, 863.5046784667778, 850.3907364321055, 859.40178833424, 849.2736382206067, 859.0922880053226, 852.015746505234, 852.2087234062337, 851.9850111351069, 858.8180924492405, 856.3623268226756, 851.5132865471177, 857.9020225984091, 858.7543995405988, 858.5025303814277, 860.6741131894453, 861.894138457926, 852.0366016484554, 853.3050022476526, 857.6118212174875, 848.6220136875986, 949.0922464647407, 949.8494591691261, 952.1593376467619, 238.64403018661605, 947.7067668526087, 945.1762942088628, 950.500609009309, 951.1656211176543, 949.3980954566466, 946.1459541479851, 943.2516251105667, 942.8194555693547, 938.8923418162217, 943.9713121247453, 947.92331120631, 948.4579280586072, 927.0325132861037, 889.1434716584196, 954.0143822877567, 961.2974005347256, 954.132011257864, 956.5135479967088, 958.0524774274656, 955.1875901091437, 961.6821037284434, 964.8912053727112, 960.4152818105184, 955.3383866710606, 960.4949311016259, 963.0798530582134, 962.2151433770925, 962.5139939703372, 962.8509772099825, 961.035136926034]
Elapsed: 0.04957568700358804~0.01593046504246461
Time per graph: 0.0011267201591724553~0.00036205602369237757
Speed: 917.5179596907443~99.04206189463615
Total Time: 0.0463
best val loss: 0.3917003870010376 test_score: 0.8409

Testing...
Test loss: 0.4345 score: 0.8409 time: 0.04s
test Score 0.8409
Epoch Time List: [0.1432942870305851, 0.14036314107943326, 0.13979205617215484, 0.13932356401346624, 0.26668625499587506, 0.1699229449732229, 0.16859722894150764, 0.15600306983105838, 0.14918672805652022, 0.1496791070094332, 0.15158983587753028, 0.15158415911719203, 0.15155321301426739, 0.15072564594447613, 0.15023660904262215, 0.15057733887806535, 0.2478686940157786, 0.1504229160491377, 0.14629875414539129, 0.1366298081120476, 0.13993832911364734, 0.13715384097304195, 0.13791213603690267, 0.13838580111041665, 0.14186061907093972, 0.1390799260698259, 0.1389242239529267, 0.1391562249045819, 0.2647453990066424, 0.14096523204352707, 0.1417489618761465, 0.1400142170023173, 0.14081558701582253, 0.14076597604434937, 0.14154638606123626, 0.1406630000565201, 0.14209710201248527, 0.14184328191913664, 0.14118854596745223, 0.14120627602096647, 0.25800302193965763, 0.140222345944494, 0.14039525296539068, 0.14079322305042297, 0.1404133450705558, 0.14077112183440477, 0.14117405307479203, 0.14302920398768038, 0.14263540401589125, 0.14298490690998733, 0.14168563403654844, 0.2448293229099363, 0.15668226010166109, 0.15519304701592773, 0.155481543042697, 0.15481070091482252, 0.15636858891230077, 0.15644996403716505, 0.15784975001588464, 0.15707467205356807, 0.15690392581745982, 0.15718578605446965, 0.27035847201477736, 0.15776781202293932, 0.15576338698156178, 0.15646942204330117, 0.15643437195103616, 0.15655857103411108, 0.15756203001365066, 0.15685152797959745, 0.15932622901163995, 0.1526066279038787, 0.14445405919104815, 0.1436726360116154, 0.281222294899635, 0.1447669049957767, 0.14356797188520432, 0.143094326951541, 0.14395324501674622, 0.14344280899967998, 0.14335207093972713, 0.14404569496400654, 0.14386266586370766, 0.1446724410634488, 0.14816017192788422, 0.14414047205355018, 0.14438948791939765, 0.1450497719924897, 0.2526191350771114, 0.14797119400463998, 0.1422548268456012, 0.1421396000077948, 0.14309560495894402, 0.14260410889983177, 0.14320108981337398, 0.14286064787302166, 0.14248181390576065, 0.14221386902499944, 0.1427740149665624, 0.14273661992046982, 0.1425549859413877, 0.14364551298785955, 0.14304766990244389, 0.14330813894048333, 0.14287108497228473]
Total Epoch List: [105]
Total Time List: [0.046314112027175725]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7519951d5300>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6950;  Loss pred: 0.6950; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6959;  Loss pred: 0.6959; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6984;  Loss pred: 0.6984; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6975;  Loss pred: 0.6975; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6965;  Loss pred: 0.6965; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6937;  Loss pred: 0.6937; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6907;  Loss pred: 0.6907; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6849;  Loss pred: 0.6849; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6814;  Loss pred: 0.6814; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6771;  Loss pred: 0.6771; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6762;  Loss pred: 0.6762; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6735;  Loss pred: 0.6735; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6701;  Loss pred: 0.6701; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6687;  Loss pred: 0.6687; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6628;  Loss pred: 0.6628; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6597;  Loss pred: 0.6597; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6580;  Loss pred: 0.6580; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6519;  Loss pred: 0.6519; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6459;  Loss pred: 0.6459; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6442;  Loss pred: 0.6442; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6397;  Loss pred: 0.6397; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6357;  Loss pred: 0.6357; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6266;  Loss pred: 0.6266; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6205;  Loss pred: 0.6205; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6194;  Loss pred: 0.6194; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.6100;  Loss pred: 0.6100; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.6018;  Loss pred: 0.6018; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5958;  Loss pred: 0.5958; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5899;  Loss pred: 0.5899; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5849;  Loss pred: 0.5849; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5759;  Loss pred: 0.5759; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5690;  Loss pred: 0.5690; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6885 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5567;  Loss pred: 0.5567; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5500;  Loss pred: 0.5500; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5411;  Loss pred: 0.5411; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6861 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.5323;  Loss pred: 0.5323; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6852 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.5215;  Loss pred: 0.5215; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6841 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.5106;  Loss pred: 0.5106; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6829 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4955;  Loss pred: 0.4955; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6817 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4892;  Loss pred: 0.4892; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5000 time: 0.05s
Test loss: 0.6802 score: 0.5349 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4800;  Loss pred: 0.4800; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.5000 time: 0.05s
Test loss: 0.6786 score: 0.5349 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4639;  Loss pred: 0.4639; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6853 score: 0.5000 time: 0.06s
Test loss: 0.6769 score: 0.5581 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4567;  Loss pred: 0.4567; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6841 score: 0.5000 time: 0.06s
Test loss: 0.6748 score: 0.5581 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.4442;  Loss pred: 0.4442; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6827 score: 0.5000 time: 0.06s
Test loss: 0.6724 score: 0.5581 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.4306;  Loss pred: 0.4306; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6811 score: 0.5000 time: 0.05s
Test loss: 0.6698 score: 0.5581 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.4266;  Loss pred: 0.4266; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6793 score: 0.5000 time: 0.05s
Test loss: 0.6668 score: 0.5814 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.4122;  Loss pred: 0.4122; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6774 score: 0.5000 time: 0.06s
Test loss: 0.6636 score: 0.5814 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3945;  Loss pred: 0.3945; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6754 score: 0.5000 time: 0.05s
Test loss: 0.6602 score: 0.5814 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3829;  Loss pred: 0.3829; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6731 score: 0.5000 time: 0.05s
Test loss: 0.6565 score: 0.5814 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3715;  Loss pred: 0.3715; Loss self: 0.0000; time: 0.09s
Val loss: 0.6705 score: 0.5227 time: 0.05s
Test loss: 0.6524 score: 0.5814 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.3560;  Loss pred: 0.3560; Loss self: 0.0000; time: 0.09s
Val loss: 0.6678 score: 0.5227 time: 0.06s
Test loss: 0.6480 score: 0.6047 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.3429;  Loss pred: 0.3429; Loss self: 0.0000; time: 0.09s
Val loss: 0.6647 score: 0.5227 time: 0.05s
Test loss: 0.6432 score: 0.6047 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.3266;  Loss pred: 0.3266; Loss self: 0.0000; time: 0.09s
Val loss: 0.6611 score: 0.5227 time: 0.05s
Test loss: 0.6378 score: 0.6047 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.3168;  Loss pred: 0.3168; Loss self: 0.0000; time: 0.09s
Val loss: 0.6572 score: 0.5682 time: 0.05s
Test loss: 0.6321 score: 0.6279 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.3006;  Loss pred: 0.3006; Loss self: 0.0000; time: 0.09s
Val loss: 0.6528 score: 0.5682 time: 0.05s
Test loss: 0.6259 score: 0.6279 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2915;  Loss pred: 0.2915; Loss self: 0.0000; time: 0.09s
Val loss: 0.6481 score: 0.5682 time: 0.06s
Test loss: 0.6193 score: 0.6279 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2784;  Loss pred: 0.2784; Loss self: 0.0000; time: 0.09s
Val loss: 0.6435 score: 0.5682 time: 0.05s
Test loss: 0.6126 score: 0.6279 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2689;  Loss pred: 0.2689; Loss self: 0.0000; time: 0.09s
Val loss: 0.6387 score: 0.5682 time: 0.05s
Test loss: 0.6057 score: 0.6279 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.2445;  Loss pred: 0.2445; Loss self: 0.0000; time: 0.09s
Val loss: 0.6338 score: 0.5682 time: 0.05s
Test loss: 0.5984 score: 0.6279 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.2323;  Loss pred: 0.2323; Loss self: 0.0000; time: 0.09s
Val loss: 0.6288 score: 0.5682 time: 0.06s
Test loss: 0.5910 score: 0.6512 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.2273;  Loss pred: 0.2273; Loss self: 0.0000; time: 0.09s
Val loss: 0.6234 score: 0.5909 time: 0.05s
Test loss: 0.5832 score: 0.6512 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.2120;  Loss pred: 0.2120; Loss self: 0.0000; time: 0.09s
Val loss: 0.6180 score: 0.5909 time: 0.05s
Test loss: 0.5752 score: 0.6512 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.2036;  Loss pred: 0.2036; Loss self: 0.0000; time: 0.09s
Val loss: 0.6118 score: 0.5909 time: 0.05s
Test loss: 0.5666 score: 0.6744 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1862;  Loss pred: 0.1862; Loss self: 0.0000; time: 0.09s
Val loss: 0.6045 score: 0.5909 time: 0.05s
Test loss: 0.5569 score: 0.6744 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1800;  Loss pred: 0.1800; Loss self: 0.0000; time: 0.09s
Val loss: 0.5964 score: 0.6136 time: 0.06s
Test loss: 0.5468 score: 0.6744 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1757;  Loss pred: 0.1757; Loss self: 0.0000; time: 0.09s
Val loss: 0.5876 score: 0.6364 time: 0.05s
Test loss: 0.5360 score: 0.6744 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1551;  Loss pred: 0.1551; Loss self: 0.0000; time: 0.09s
Val loss: 0.5790 score: 0.6364 time: 0.06s
Test loss: 0.5253 score: 0.6977 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1439;  Loss pred: 0.1439; Loss self: 0.0000; time: 0.09s
Val loss: 0.5698 score: 0.6364 time: 0.05s
Test loss: 0.5141 score: 0.6977 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.1306;  Loss pred: 0.1306; Loss self: 0.0000; time: 0.09s
Val loss: 0.5596 score: 0.6364 time: 0.05s
Test loss: 0.5021 score: 0.6977 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.1230;  Loss pred: 0.1230; Loss self: 0.0000; time: 0.09s
Val loss: 0.5505 score: 0.6818 time: 0.06s
Test loss: 0.4908 score: 0.7209 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.1150;  Loss pred: 0.1150; Loss self: 0.0000; time: 0.09s
Val loss: 0.5408 score: 0.6818 time: 0.06s
Test loss: 0.4790 score: 0.7442 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.1053;  Loss pred: 0.1053; Loss self: 0.0000; time: 0.09s
Val loss: 0.5314 score: 0.6818 time: 0.06s
Test loss: 0.4675 score: 0.7674 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0956;  Loss pred: 0.0956; Loss self: 0.0000; time: 0.09s
Val loss: 0.5218 score: 0.7045 time: 0.05s
Test loss: 0.4560 score: 0.7674 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0896;  Loss pred: 0.0896; Loss self: 0.0000; time: 0.09s
Val loss: 0.5118 score: 0.7045 time: 0.06s
Test loss: 0.4447 score: 0.7674 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0790;  Loss pred: 0.0790; Loss self: 0.0000; time: 0.09s
Val loss: 0.5013 score: 0.7273 time: 0.07s
Test loss: 0.4335 score: 0.8140 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0761;  Loss pred: 0.0761; Loss self: 0.0000; time: 0.09s
Val loss: 0.4896 score: 0.7273 time: 0.05s
Test loss: 0.4221 score: 0.7907 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0712;  Loss pred: 0.0712; Loss self: 0.0000; time: 0.09s
Val loss: 0.4768 score: 0.7273 time: 0.05s
Test loss: 0.4105 score: 0.8140 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0656;  Loss pred: 0.0656; Loss self: 0.0000; time: 0.09s
Val loss: 0.4622 score: 0.7500 time: 0.05s
Test loss: 0.3988 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0607;  Loss pred: 0.0607; Loss self: 0.0000; time: 0.09s
Val loss: 0.4469 score: 0.8182 time: 0.05s
Test loss: 0.3871 score: 0.8140 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0548;  Loss pred: 0.0548; Loss self: 0.0000; time: 0.09s
Val loss: 0.4326 score: 0.8182 time: 0.05s
Test loss: 0.3767 score: 0.8140 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0514;  Loss pred: 0.0514; Loss self: 0.0000; time: 0.09s
Val loss: 0.4214 score: 0.8182 time: 0.05s
Test loss: 0.3687 score: 0.8140 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0452;  Loss pred: 0.0452; Loss self: 0.0000; time: 0.09s
Val loss: 0.4115 score: 0.8409 time: 0.05s
Test loss: 0.3617 score: 0.7907 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0444;  Loss pred: 0.0444; Loss self: 0.0000; time: 0.09s
Val loss: 0.4036 score: 0.8636 time: 0.05s
Test loss: 0.3563 score: 0.7907 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0355;  Loss pred: 0.0355; Loss self: 0.0000; time: 0.09s
Val loss: 0.3965 score: 0.8409 time: 0.05s
Test loss: 0.3517 score: 0.7907 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0376;  Loss pred: 0.0376; Loss self: 0.0000; time: 0.09s
Val loss: 0.3897 score: 0.8636 time: 0.05s
Test loss: 0.3477 score: 0.7907 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0310;  Loss pred: 0.0310; Loss self: 0.0000; time: 0.09s
Val loss: 0.3847 score: 0.8636 time: 0.05s
Test loss: 0.3449 score: 0.7907 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0328;  Loss pred: 0.0328; Loss self: 0.0000; time: 0.09s
Val loss: 0.3812 score: 0.8409 time: 0.05s
Test loss: 0.3431 score: 0.7907 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0252;  Loss pred: 0.0252; Loss self: 0.0000; time: 0.09s
Val loss: 0.3787 score: 0.8409 time: 0.05s
Test loss: 0.3424 score: 0.7907 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0247;  Loss pred: 0.0247; Loss self: 0.0000; time: 0.10s
Val loss: 0.3777 score: 0.8409 time: 0.06s
Test loss: 0.3431 score: 0.7907 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0233;  Loss pred: 0.0233; Loss self: 0.0000; time: 0.09s
Val loss: 0.3780 score: 0.8409 time: 0.05s
Test loss: 0.3447 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0270;  Loss pred: 0.0270; Loss self: 0.0000; time: 0.09s
Val loss: 0.3789 score: 0.8409 time: 0.05s
Test loss: 0.3474 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0212;  Loss pred: 0.0212; Loss self: 0.0000; time: 0.09s
Val loss: 0.3800 score: 0.8409 time: 0.05s
Test loss: 0.3501 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0185;  Loss pred: 0.0185; Loss self: 0.0000; time: 0.09s
Val loss: 0.3819 score: 0.8409 time: 0.05s
Test loss: 0.3532 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0176;  Loss pred: 0.0176; Loss self: 0.0000; time: 0.09s
Val loss: 0.3842 score: 0.8409 time: 0.05s
Test loss: 0.3563 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0154;  Loss pred: 0.0154; Loss self: 0.0000; time: 0.09s
Val loss: 0.3878 score: 0.8409 time: 0.05s
Test loss: 0.3600 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.09s
Val loss: 0.3921 score: 0.8182 time: 0.05s
Test loss: 0.3641 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.09s
Val loss: 0.3962 score: 0.8182 time: 0.05s
Test loss: 0.3686 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0127;  Loss pred: 0.0127; Loss self: 0.0000; time: 0.09s
Val loss: 0.4009 score: 0.8182 time: 0.05s
Test loss: 0.3737 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.09s
Val loss: 0.4060 score: 0.8182 time: 0.05s
Test loss: 0.3793 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.09s
Val loss: 0.4121 score: 0.8182 time: 0.05s
Test loss: 0.3857 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.09s
Val loss: 0.4187 score: 0.8182 time: 0.05s
Test loss: 0.3924 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.09s
Val loss: 0.4263 score: 0.8409 time: 0.05s
Test loss: 0.3997 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.09s
Val loss: 0.4345 score: 0.8409 time: 0.06s
Test loss: 0.4070 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.09s
Val loss: 0.4430 score: 0.8409 time: 0.05s
Test loss: 0.4144 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.09s
Val loss: 0.4521 score: 0.8409 time: 0.05s
Test loss: 0.4220 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.09s
Val loss: 0.4606 score: 0.8409 time: 0.06s
Test loss: 0.4293 score: 0.8605 time: 0.07s
     INFO: Early stopping counter 17 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.17s
Val loss: 0.4695 score: 0.8409 time: 0.06s
Test loss: 0.4368 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0088;  Loss pred: 0.0088; Loss self: 0.0000; time: 0.09s
Val loss: 0.4793 score: 0.8409 time: 0.05s
Test loss: 0.4450 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.09s
Val loss: 0.4891 score: 0.8409 time: 0.05s
Test loss: 0.4531 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 090,   Train_Loss: 0.0247,   Val_Loss: 0.3777,   Val_Precision: 0.8261,   Val_Recall: 0.8636,   Val_accuracy: 0.8444,   Val_Score: 0.8409,   Val_Loss: 0.3777,   Test_Precision: 0.7826,   Test_Recall: 0.8182,   Test_accuracy: 0.8000,   Test_Score: 0.7907,   Test_loss: 0.3431


[0.04603887104894966, 0.04531975497957319, 0.045436262036673725, 0.045277690049260855, 0.05188795307185501, 0.04977476701606065, 0.05062086891848594, 0.04895159904845059, 0.04871337302029133, 0.049147495068609715, 0.04894814605358988, 0.04890310298651457, 0.04866041196510196, 0.048744780011475086, 0.048637880012393, 0.04863415192812681, 0.13580167898908257, 0.04968568799085915, 0.04544687899760902, 0.044942502048797905, 0.04581856809090823, 0.04493385704699904, 0.0454160759691149, 0.04486890695989132, 0.04761497594881803, 0.04491375607904047, 0.04537022300064564, 0.04559711995534599, 0.04563709406647831, 0.04592725797556341, 0.04565979598555714, 0.045745317940600216, 0.04551674390677363, 0.04593586490955204, 0.04566017002798617, 0.045911313965916634, 0.04565657302737236, 0.046216204995289445, 0.04536561400163919, 0.046377010992728174, 0.04530785093083978, 0.04541709797922522, 0.04524559690617025, 0.04559773893561214, 0.0454745190218091, 0.04535398003645241, 0.0458511000033468, 0.04557407496031374, 0.04595678602345288, 0.045510448049753904, 0.046168806962668896, 0.05095513793639839, 0.0517409211024642, 0.05119840404950082, 0.05180897889658809, 0.051216849009506404, 0.05164223804604262, 0.051630544010549784, 0.05164410104043782, 0.05123320105485618, 0.05138012103270739, 0.05167271103709936, 0.05128790799062699, 0.051237000967375934, 0.051252032979391515, 0.0511227180249989, 0.05105035298038274, 0.051640974008478224, 0.05156421195715666, 0.05130526295397431, 0.05184876103885472, 0.046360087930224836, 0.046323130023665726, 0.046210753032937646, 0.18437502905726433, 0.04642786306794733, 0.04655216203536838, 0.046291395905427635, 0.046259031048975885, 0.04634515300858766, 0.04650445294100791, 0.04664714995305985, 0.04666853207163513, 0.046863732975907624, 0.0466115860035643, 0.046417257050052285, 0.04639109305571765, 0.0474632759578526, 0.04948582698125392, 0.04612089798320085, 0.04577147506643087, 0.04611521202605218, 0.04600039392244071, 0.04592650302220136, 0.04606425005476922, 0.04575316503178328, 0.045600996003486216, 0.04581351508386433, 0.04605697898659855, 0.04580971598625183, 0.04568676196504384, 0.04572781908791512, 0.04571362107526511, 0.04569762200117111, 0.04578396596480161, 0.05427002301439643, 0.054678395041264594, 0.053951427922584116, 0.05429313506465405, 0.05414056696463376, 0.05431559099815786, 0.05399782699532807, 0.05579635198228061, 0.05411732604261488, 0.054122180910781026, 0.05425903107970953, 0.05449509702157229, 0.05459102592431009, 0.05566567706409842, 0.05443651101086289, 0.054609881015494466, 0.05455723393242806, 0.05532359890639782, 0.053833379060961306, 0.054734503966756165, 0.05437062494456768, 0.05494065803941339, 0.05467644799500704, 0.05439502897206694, 0.054421275039203465, 0.05449082097038627, 0.05471732700243592, 0.05621752294246107, 0.054971735924482346, 0.05504911905154586, 0.05557770899031311, 0.05513217707630247, 0.055825826013460755, 0.05460464803036302, 0.055139434058219194, 0.054826186038553715, 0.05476402898784727, 0.055302098975516856, 0.0546957979677245, 0.05488111590966582, 0.055712758912704885, 0.05506840790621936, 0.05477859894745052, 0.05533361900597811, 0.05514979606959969, 0.05485264502931386, 0.055341411964036524, 0.055403567967005074, 0.05616716097574681, 0.05452691705431789, 0.05419914296362549, 0.05490294506307691, 0.05463848204817623, 0.05435321596451104, 0.05421894590836018, 0.054064844036474824, 0.055187580990605056, 0.05570408096536994, 0.054975951090455055, 0.05443777795881033, 0.05525268102064729, 0.05467230000067502, 0.055318634025752544, 0.05449303507339209, 0.0545534030534327, 0.054293190012685955, 0.05486851104069501, 0.05457523395307362, 0.056507686036638916, 0.0545509799849242, 0.05481948598753661, 0.05622927797958255, 0.054723022039979696, 0.055243083043023944, 0.054749066941440105, 0.057024682057090104, 0.05650514201261103, 0.054566791048273444, 0.05404413992073387, 0.05388060596305877, 0.053581760032102466, 0.054739487008191645, 0.054204241023398936, 0.054293949040584266, 0.05414890497922897, 0.05393583292607218, 0.05506580194924027, 0.05431053799111396, 0.054357149987481534, 0.05465516296681017, 0.05750069208443165, 0.05386938899755478, 0.054316228022798896, 0.0538183799944818, 0.05395873705856502, 0.055404093000106514, 0.05473593494389206, 0.055982529069297016, 0.05493068799842149, 0.05486664897762239, 0.05438952904660255, 0.054824552964419127, 0.05415028193965554, 0.05376949708443135, 0.056696817046031356, 0.054995290003716946, 0.054195367032662034, 0.07739867805503309, 0.05876512895338237, 0.05501946492586285, 0.05563526402693242]
[0.0010463379783852195, 0.001029994431353936, 0.0010326423190153118, 0.001029038410210474, 0.0011792716607239774, 0.0011312447049104694, 0.0011504742936019532, 0.0011125363420102406, 0.0011071221140975301, 0.0011169885242865844, 0.0011124578648543154, 0.001111434158784422, 0.0011059184537523172, 0.0011078359093517065, 0.0011054063639180226, 0.0011053216347301548, 0.0030864017952064223, 0.0011292201816104352, 0.0010328836135820231, 0.0010214205011090432, 0.001041331092975187, 0.0010212240237954327, 0.0010321835447526114, 0.0010197478854520755, 0.0010821585442913188, 0.0010207671836145562, 0.0010311414318328555, 0.001036298180803318, 0.0010372066833290526, 0.001043801317626441, 0.0010377226360353895, 0.001039666316831823, 0.0010344714524266733, 0.0010439969297625464, 0.0010377311369996858, 0.0010434389537708325, 0.0010376493869857354, 0.0010503682953474874, 0.001031036681855436, 0.0010540229771074585, 0.0010297238847918131, 0.0010322067722551185, 0.0010283090205947783, 0.0010363122485366396, 0.0010335117959502068, 0.0010307722735557366, 0.0010420704546215181, 0.0010357744309162213, 0.001044472409623929, 0.0010343283647671342, 0.001049291067333384, 0.001158071316736327, 0.0011759300250560045, 0.0011636000920341096, 0.0011774767931042747, 0.0011640192956706, 0.0011736872283191506, 0.0011734214547852223, 0.0011737295691008594, 0.0011643909330649133, 0.0011677300234706227, 0.0011743797962977128, 0.0011656342725142497, 0.0011644772947130894, 0.0011648189313498071, 0.0011618799551136115, 0.0011602352950086986, 0.001173658500192687, 0.0011719139081171968, 0.001166028703499416, 0.0011783809327012436, 0.0010536383620505644, 0.0010527984096287664, 0.0010502443871122193, 0.00419034156948328, 0.001055178706089712, 0.0010580036826220087, 0.0010520771796688098, 0.001051341614749452, 0.0010532989320133559, 0.0010569193850229071, 0.0010601624989331785, 0.0010606484561735256, 0.0010650848403615369, 0.0010593542273537341, 0.001054937660228461, 0.0010543430239935828, 0.0010787108172239227, 0.001124677885937589, 0.0010482022268909284, 0.001040260796964338, 0.001048073000592095, 0.0010454634982372888, 0.0010437841595954853, 0.0010469147739720277, 0.0010398446598132564, 0.0010363862728065049, 0.0010412162519060075, 0.0010467495224226943, 0.0010411299087784507, 0.001038335499205542, 0.0010392686156344346, 0.0010389459335287525, 0.0010385823182084343, 0.0010405446810182184, 0.0012620935584743355, 0.0012715905823549906, 0.0012546843702926538, 0.0012626310480152105, 0.0012590829526659014, 0.001263153279026927, 0.0012557634184960015, 0.00129758958098327, 0.0012585424661073227, 0.0012586553700181635, 0.0012618379320862682, 0.0012673278377109834, 0.001269558742425816, 0.0012945506293976375, 0.0012659653723456484, 0.0012699972329184759, 0.0012687728821494898, 0.0012865953234046004, 0.0012519390479293327, 0.0012728954410873526, 0.00126443313824576, 0.001277689721846823, 0.001271545302209466, 0.0012650006737689986, 0.0012656110474233363, 0.0012672283946601457, 0.0012724959768008353, 0.0013073842544758388, 0.0012784124633600546, 0.0012802120709661828, 0.0012925048602398397, 0.0012821436529372667, 0.0012982750235688548, 0.0012698755355898378, 0.001282312419958586, 0.0012750275822919468, 0.0012735820694848201, 0.0012860953250120198, 0.0012719953015749884, 0.001276305021155019, 0.001295645556109416, 0.0012806606489818456, 0.0012739209057546633, 0.0012868283489762351, 0.0012825533969674347, 0.0012756429076584619, 0.0012870095805589889, 0.001288455069000118, 0.0013062130459476002, 0.0012680678384725092, 0.0012604451852005927, 0.0012768126758855097, 0.0012706623732134006, 0.0012640282782444426, 0.001260905718799074, 0.0012573219543366239, 0.0012834321160605827, 0.0012954437433806963, 0.001278510490475699, 0.001265994836251403, 0.0012849460702476112, 0.0012714488372250006, 0.0012864798610640127, 0.0012672798854277232, 0.0012686837919402955, 0.0012626323258764175, 0.0012760118846673258, 0.001269191487280782, 0.0013141322334102074, 0.001268627441509865, 0.0012748717671520141, 0.0013076576274321523, 0.0012726284195344116, 0.0012847228614656732, 0.0012732341149172119, 0.001326155396676514, 0.0013140730700607216, 0.001268995140657522, 0.0012568404632728807, 0.001253037347978111, 0.001246087442607034, 0.0012730113257718987, 0.0012605637447302078, 0.001262649977688006, 0.0012592768599820692, 0.001254321695955167, 0.001280600045331169, 0.0012630357672352083, 0.0012641197671507333, 0.0012710503015537248, 0.0013372253973123638, 0.0012527764883152274, 0.0012631680935534628, 0.0012515902324298092, 0.0012548543501991866, 0.0012884672790722444, 0.0012729287196253968, 0.001301919280681326, 0.0012774578604284068, 0.0012759685808749392, 0.0012648727685256407, 0.0012749896038237007, 0.0012593088823175708, 0.001250453420568171, 0.0013185306289774735, 0.00127896023264458, 0.0012603573728526055, 0.0017999692570937927, 0.0013666309058926133, 0.0012795224401363453, 0.0012938433494635445]
[955.7141388896813, 970.8790354191448, 968.3895203457879, 971.7810239906063, 847.9810321110242, 883.9820382444517, 869.2067311379536, 898.8470418800891, 903.2427292947258, 895.2643453868029, 898.9104500878848, 899.738407440799, 904.2258012849483, 902.6607564880155, 904.6446923424446, 904.7140385016826, 324.00188515737915, 885.5668861442521, 968.163292408151, 979.0287143387221, 960.3093643760315, 979.2170735304949, 968.8199401005517, 980.6345414059665, 924.0790134451855, 979.6553181294298, 969.7990684192551, 964.9732273242241, 964.1279950013119, 958.0367289379905, 963.6486333385686, 961.8470694013649, 966.6772317923227, 957.8572230355569, 963.6407392489206, 958.3694344418993, 963.7166585766479, 952.0470147751134, 969.8975968540877, 948.7459208377857, 971.1341212622036, 968.7981389767917, 972.470317747087, 964.9601280039722, 967.574829739223, 970.1463899008604, 959.6280132164401, 965.461175861837, 957.4211733941908, 966.8109606808832, 953.024409653415, 863.5046784667778, 850.3907364321055, 859.40178833424, 849.2736382206067, 859.0922880053226, 852.015746505234, 852.2087234062337, 851.9850111351069, 858.8180924492405, 856.3623268226756, 851.5132865471177, 857.9020225984091, 858.7543995405988, 858.5025303814277, 860.6741131894453, 861.894138457926, 852.0366016484554, 853.3050022476526, 857.6118212174875, 848.6220136875986, 949.0922464647407, 949.8494591691261, 952.1593376467619, 238.64403018661605, 947.7067668526087, 945.1762942088628, 950.500609009309, 951.1656211176543, 949.3980954566466, 946.1459541479851, 943.2516251105667, 942.8194555693547, 938.8923418162217, 943.9713121247453, 947.92331120631, 948.4579280586072, 927.0325132861037, 889.1434716584196, 954.0143822877567, 961.2974005347256, 954.132011257864, 956.5135479967088, 958.0524774274656, 955.1875901091437, 961.6821037284434, 964.8912053727112, 960.4152818105184, 955.3383866710606, 960.4949311016259, 963.0798530582134, 962.2151433770925, 962.5139939703372, 962.8509772099825, 961.035136926034, 792.3342871734773, 786.4166453230538, 797.013196049259, 791.9969983091635, 794.2288455916778, 791.6695595093197, 796.3283412075155, 770.6597021550015, 794.569930638101, 794.4986561218653, 792.49480030026, 789.0618119824271, 787.6752501339519, 772.4688222238988, 789.9110211420289, 787.4032904008636, 788.1631252284108, 777.2451693309367, 798.7609314159249, 785.6104812079178, 790.8682315835005, 782.6626315460694, 786.4446498778906, 790.5134129459046, 790.1321674110737, 789.1237319285187, 785.8571015006949, 764.8860666452829, 782.2201587206821, 781.1205835961965, 773.6914813724089, 779.9438056017335, 770.2528215100984, 787.4787504552683, 779.8411560517338, 784.2967586649644, 785.1869337360508, 777.547340816789, 786.1664258993701, 783.5117651539355, 771.816022742219, 780.8469798732574, 784.9780904628501, 777.1044217323719, 779.694632881933, 783.9184414356012, 776.9949929709679, 776.1232999580122, 765.5718974040286, 788.6013426573309, 793.3704787335561, 783.2002445515108, 786.9911166654618, 791.1215415123934, 793.080707852155, 795.3412382173907, 779.1608044447568, 771.9362613078958, 782.1601836273766, 789.8926372883077, 778.2427785527982, 786.5043175331766, 777.3149275519378, 789.0916690928833, 788.21847205175, 791.9961967597184, 783.6917602540309, 787.903173021181, 760.9584291262486, 788.2534834733226, 784.3926156070889, 764.7261630429215, 785.7753171706223, 778.3779910782878, 785.4015127964286, 754.0594431890154, 760.9926896635902, 788.0250821779003, 795.6459305868827, 798.0608092915909, 802.5118990909853, 785.5389655654819, 793.2958600312792, 791.9851246749038, 794.1065477962003, 797.2436442937385, 780.88393300142, 791.7432157831959, 791.0642851934458, 786.7509246310752, 747.8170860423832, 798.2269856810858, 791.6602747516087, 798.9835443654928, 796.905234333584, 776.1159450785943, 785.5899427693678, 768.0967743842581, 782.804686539438, 783.7183571669876, 790.5933504803164, 784.320120729608, 794.0863548581098, 799.7099160603904, 758.4200002813014, 781.885139565475, 793.4257549005084, 555.5650442689156, 731.7264637351745, 781.5415881986723, 772.8910925844474]
Elapsed: 0.0523937051082073~0.011555930646441902
Time per graph: 0.0012057207888307138~0.0002665808163257009
Speed: 847.8629109405999~98.29486958890452
Total Time: 0.0565
best val loss: 0.3777494728565216 test_score: 0.7907

Testing...
Test loss: 0.3563 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.1432942870305851, 0.14036314107943326, 0.13979205617215484, 0.13932356401346624, 0.26668625499587506, 0.1699229449732229, 0.16859722894150764, 0.15600306983105838, 0.14918672805652022, 0.1496791070094332, 0.15158983587753028, 0.15158415911719203, 0.15155321301426739, 0.15072564594447613, 0.15023660904262215, 0.15057733887806535, 0.2478686940157786, 0.1504229160491377, 0.14629875414539129, 0.1366298081120476, 0.13993832911364734, 0.13715384097304195, 0.13791213603690267, 0.13838580111041665, 0.14186061907093972, 0.1390799260698259, 0.1389242239529267, 0.1391562249045819, 0.2647453990066424, 0.14096523204352707, 0.1417489618761465, 0.1400142170023173, 0.14081558701582253, 0.14076597604434937, 0.14154638606123626, 0.1406630000565201, 0.14209710201248527, 0.14184328191913664, 0.14118854596745223, 0.14120627602096647, 0.25800302193965763, 0.140222345944494, 0.14039525296539068, 0.14079322305042297, 0.1404133450705558, 0.14077112183440477, 0.14117405307479203, 0.14302920398768038, 0.14263540401589125, 0.14298490690998733, 0.14168563403654844, 0.2448293229099363, 0.15668226010166109, 0.15519304701592773, 0.155481543042697, 0.15481070091482252, 0.15636858891230077, 0.15644996403716505, 0.15784975001588464, 0.15707467205356807, 0.15690392581745982, 0.15718578605446965, 0.27035847201477736, 0.15776781202293932, 0.15576338698156178, 0.15646942204330117, 0.15643437195103616, 0.15655857103411108, 0.15756203001365066, 0.15685152797959745, 0.15932622901163995, 0.1526066279038787, 0.14445405919104815, 0.1436726360116154, 0.281222294899635, 0.1447669049957767, 0.14356797188520432, 0.143094326951541, 0.14395324501674622, 0.14344280899967998, 0.14335207093972713, 0.14404569496400654, 0.14386266586370766, 0.1446724410634488, 0.14816017192788422, 0.14414047205355018, 0.14438948791939765, 0.1450497719924897, 0.2526191350771114, 0.14797119400463998, 0.1422548268456012, 0.1421396000077948, 0.14309560495894402, 0.14260410889983177, 0.14320108981337398, 0.14286064787302166, 0.14248181390576065, 0.14221386902499944, 0.1427740149665624, 0.14273661992046982, 0.1425549859413877, 0.14364551298785955, 0.14304766990244389, 0.14330813894048333, 0.14287108497228473, 0.19296458922326565, 0.19141573808155954, 0.1913488069549203, 0.19232721417210996, 0.18942318810150027, 0.18984032701700926, 0.18974886811338365, 0.19251513516064733, 0.1930980869801715, 0.1903783471789211, 0.1912754689110443, 0.19212455092929304, 0.19196328800171614, 0.19196114293299615, 0.19324807997327298, 0.19064971420448273, 0.19290993479080498, 0.19219327007886022, 0.19154480088036507, 0.19327064091339707, 0.19169521098956466, 0.19329654693137854, 0.19369282585103065, 0.19133529998362064, 0.1904131950577721, 0.19038791896309704, 0.19333893503062427, 0.19624623202253133, 0.19331318605691195, 0.19337158207781613, 0.19376336818095297, 0.19329706602729857, 0.19566123897675425, 0.19323072908446193, 0.19387935288250446, 0.19273148197680712, 0.19490221911109984, 0.1939528229413554, 0.19442672014702111, 0.19345603801775724, 0.1941496409708634, 0.19315528811421245, 0.19518552685622126, 0.19444803905207664, 0.19305989902932197, 0.19450389011763036, 0.1931855210568756, 0.19430228194687515, 0.20865894097369164, 0.19942016107961535, 0.19286035897675902, 0.19378110591787845, 0.19495135894976556, 0.19194402208086103, 0.19245772494468838, 0.19171166012529284, 0.1939940438605845, 0.19508907303679734, 0.19386564590968192, 0.19249209691770375, 0.19468683283776045, 0.19390334805939347, 0.19387701514642686, 0.19370856508612633, 0.19277013186365366, 0.19319322693627328, 0.19367021403741091, 0.19392271002288908, 0.19709108490496874, 0.19446576898917556, 0.19313244184013456, 0.19539557001553476, 0.19319444196298718, 0.19626560586038977, 0.1960435250075534, 0.19984027394093573, 0.21223694120999426, 0.19610605901107192, 0.19158310710918158, 0.19084747903980315, 0.19126932590734214, 0.19284595421049744, 0.19204526988323778, 0.19212874583899975, 0.19061351800337434, 0.19279787701088935, 0.19579379505012184, 0.19357831892557442, 0.19290158292278647, 0.19351998111233115, 0.21453267999459058, 0.19166327104903758, 0.19204864709172398, 0.19136380206327885, 0.19139174604788423, 0.19223357702139765, 0.19278979999944568, 0.19462794612627476, 0.1930378678953275, 0.19445954193361104, 0.1933903059689328, 0.1925246660830453, 0.19225246796850115, 0.19098057108931243, 0.1961999370250851, 0.1931395309511572, 0.1907774859573692, 0.21239996200893074, 0.28571108100004494, 0.1922277050325647, 0.19301416212692857]
Total Epoch List: [105, 111]
Total Time List: [0.046314112027175725, 0.056494776043109596]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7519951d7190>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6965;  Loss pred: 0.6965; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7014 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7044 score: 0.4884 time: 0.06s
Epoch 2/1000, LR 0.000000
Train loss: 0.6995;  Loss pred: 0.6995; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7014 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7044 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6964;  Loss pred: 0.6964; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7014 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7044 score: 0.4884 time: 0.06s
Epoch 4/1000, LR 0.000060
Train loss: 0.6983;  Loss pred: 0.6983; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7014 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7044 score: 0.4884 time: 0.06s
Epoch 5/1000, LR 0.000090
Train loss: 0.6929;  Loss pred: 0.6929; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7014 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7043 score: 0.4884 time: 0.06s
Epoch 6/1000, LR 0.000120
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7013 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7042 score: 0.4884 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6888;  Loss pred: 0.6888; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7011 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7041 score: 0.4884 time: 0.06s
Epoch 8/1000, LR 0.000180
Train loss: 0.6857;  Loss pred: 0.6857; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7009 score: 0.5000 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7039 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6810;  Loss pred: 0.6810; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7007 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7036 score: 0.4884 time: 0.06s
Epoch 10/1000, LR 0.000240
Train loss: 0.6771;  Loss pred: 0.6771; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7005 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7033 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6724;  Loss pred: 0.6724; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.7002 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7030 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6662;  Loss pred: 0.6662; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6999 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7027 score: 0.4884 time: 0.06s
Epoch 13/1000, LR 0.000270
Train loss: 0.6647;  Loss pred: 0.6647; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6996 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7023 score: 0.4884 time: 0.06s
Epoch 14/1000, LR 0.000270
Train loss: 0.6555;  Loss pred: 0.6555; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6993 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7020 score: 0.4884 time: 0.06s
Epoch 15/1000, LR 0.000270
Train loss: 0.6515;  Loss pred: 0.6515; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6990 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7017 score: 0.4884 time: 0.06s
Epoch 16/1000, LR 0.000270
Train loss: 0.6432;  Loss pred: 0.6432; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6988 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7014 score: 0.4884 time: 0.06s
Epoch 17/1000, LR 0.000270
Train loss: 0.6390;  Loss pred: 0.6390; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6986 score: 0.5000 time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7012 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6358;  Loss pred: 0.6358; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6983 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7010 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6260;  Loss pred: 0.6260; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6981 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7008 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6225;  Loss pred: 0.6225; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6979 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7006 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6068;  Loss pred: 0.6068; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6977 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7004 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6048;  Loss pred: 0.6048; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7002 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.5942;  Loss pred: 0.5942; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7000 score: 0.4884 time: 0.06s
Epoch 24/1000, LR 0.000270
Train loss: 0.5844;  Loss pred: 0.5844; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6998 score: 0.4884 time: 0.06s
Epoch 25/1000, LR 0.000270
Train loss: 0.5811;  Loss pred: 0.5811; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6967 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6995 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5676;  Loss pred: 0.5676; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6993 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5607;  Loss pred: 0.5607; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.5000 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6991 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5458;  Loss pred: 0.5458; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6989 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5424;  Loss pred: 0.5424; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6987 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5237;  Loss pred: 0.5237; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6984 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5162;  Loss pred: 0.5162; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.4992;  Loss pred: 0.4992; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6979 score: 0.4884 time: 0.06s
Epoch 33/1000, LR 0.000270
Train loss: 0.5003;  Loss pred: 0.5003; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.4884 time: 0.06s
Epoch 34/1000, LR 0.000270
Train loss: 0.4744;  Loss pred: 0.4744; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6973 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4709;  Loss pred: 0.4709; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.4884 time: 0.06s
Epoch 36/1000, LR 0.000270
Train loss: 0.4592;  Loss pred: 0.4592; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4884 time: 0.06s
Epoch 37/1000, LR 0.000270
Train loss: 0.4365;  Loss pred: 0.4365; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4884 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4300;  Loss pred: 0.4300; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4273;  Loss pred: 0.4273; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4039;  Loss pred: 0.4039; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6869 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3993;  Loss pred: 0.3993; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6856 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.06s
Epoch 42/1000, LR 0.000269
Train loss: 0.3755;  Loss pred: 0.3755; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6844 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.4884 time: 0.06s
Epoch 43/1000, LR 0.000269
Train loss: 0.3636;  Loss pred: 0.3636; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6829 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.4884 time: 0.06s
Epoch 44/1000, LR 0.000269
Train loss: 0.3534;  Loss pred: 0.3534; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6814 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.4884 time: 0.06s
Epoch 45/1000, LR 0.000269
Train loss: 0.3319;  Loss pred: 0.3319; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6798 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.4884 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3221;  Loss pred: 0.3221; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6782 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.4884 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3017;  Loss pred: 0.3017; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6762 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6866 score: 0.4884 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2877;  Loss pred: 0.2877; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6740 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6850 score: 0.4884 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2892;  Loss pred: 0.2892; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6716 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6833 score: 0.4884 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2657;  Loss pred: 0.2657; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6692 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6816 score: 0.4884 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2529;  Loss pred: 0.2529; Loss self: 0.0000; time: 0.08s
Val loss: 0.6667 score: 0.5227 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6798 score: 0.4884 time: 0.06s
Epoch 52/1000, LR 0.000269
Train loss: 0.2466;  Loss pred: 0.2466; Loss self: 0.0000; time: 0.08s
Val loss: 0.6637 score: 0.5227 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6776 score: 0.4884 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2272;  Loss pred: 0.2272; Loss self: 0.0000; time: 0.08s
Val loss: 0.6604 score: 0.5227 time: 0.06s
Test loss: 0.6750 score: 0.5116 time: 0.06s
Epoch 54/1000, LR 0.000269
Train loss: 0.2127;  Loss pred: 0.2127; Loss self: 0.0000; time: 0.08s
Val loss: 0.6568 score: 0.5227 time: 0.09s
Test loss: 0.6723 score: 0.5116 time: 0.10s
Epoch 55/1000, LR 0.000269
Train loss: 0.2039;  Loss pred: 0.2039; Loss self: 0.0000; time: 0.08s
Val loss: 0.6529 score: 0.5227 time: 0.06s
Test loss: 0.6693 score: 0.5116 time: 0.06s
Epoch 56/1000, LR 0.000269
Train loss: 0.1844;  Loss pred: 0.1844; Loss self: 0.0000; time: 0.08s
Val loss: 0.6484 score: 0.5455 time: 0.06s
Test loss: 0.6659 score: 0.5116 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1752;  Loss pred: 0.1752; Loss self: 0.0000; time: 0.08s
Val loss: 0.6435 score: 0.5909 time: 0.06s
Test loss: 0.6620 score: 0.5116 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1644;  Loss pred: 0.1644; Loss self: 0.0000; time: 0.08s
Val loss: 0.6375 score: 0.5909 time: 0.06s
Test loss: 0.6572 score: 0.5116 time: 0.06s
Epoch 59/1000, LR 0.000268
Train loss: 0.1544;  Loss pred: 0.1544; Loss self: 0.0000; time: 0.08s
Val loss: 0.6309 score: 0.5909 time: 0.05s
Test loss: 0.6519 score: 0.5349 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1426;  Loss pred: 0.1426; Loss self: 0.0000; time: 0.08s
Val loss: 0.6238 score: 0.5909 time: 0.06s
Test loss: 0.6464 score: 0.5349 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1378;  Loss pred: 0.1378; Loss self: 0.0000; time: 0.08s
Val loss: 0.6158 score: 0.5909 time: 0.05s
Test loss: 0.6402 score: 0.5349 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1215;  Loss pred: 0.1215; Loss self: 0.0000; time: 0.08s
Val loss: 0.6069 score: 0.5909 time: 0.05s
Test loss: 0.6332 score: 0.5349 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1116;  Loss pred: 0.1116; Loss self: 0.0000; time: 0.08s
Val loss: 0.5974 score: 0.6136 time: 0.05s
Test loss: 0.6257 score: 0.5814 time: 0.13s
Epoch 64/1000, LR 0.000268
Train loss: 0.1058;  Loss pred: 0.1058; Loss self: 0.0000; time: 0.08s
Val loss: 0.5875 score: 0.6364 time: 0.06s
Test loss: 0.6182 score: 0.5814 time: 0.06s
Epoch 65/1000, LR 0.000268
Train loss: 0.0982;  Loss pred: 0.0982; Loss self: 0.0000; time: 0.08s
Val loss: 0.5777 score: 0.6364 time: 0.06s
Test loss: 0.6107 score: 0.5814 time: 0.06s
Epoch 66/1000, LR 0.000268
Train loss: 0.0918;  Loss pred: 0.0918; Loss self: 0.0000; time: 0.08s
Val loss: 0.5669 score: 0.6591 time: 0.06s
Test loss: 0.6023 score: 0.6279 time: 0.06s
Epoch 67/1000, LR 0.000268
Train loss: 0.0798;  Loss pred: 0.0798; Loss self: 0.0000; time: 0.08s
Val loss: 0.5558 score: 0.7045 time: 0.06s
Test loss: 0.5937 score: 0.6512 time: 0.06s
Epoch 68/1000, LR 0.000268
Train loss: 0.0754;  Loss pred: 0.0754; Loss self: 0.0000; time: 0.08s
Val loss: 0.5437 score: 0.7045 time: 0.06s
Test loss: 0.5840 score: 0.6744 time: 0.06s
Epoch 69/1000, LR 0.000268
Train loss: 0.0646;  Loss pred: 0.0646; Loss self: 0.0000; time: 0.08s
Val loss: 0.5320 score: 0.7273 time: 0.06s
Test loss: 0.5746 score: 0.6744 time: 0.06s
Epoch 70/1000, LR 0.000268
Train loss: 0.0642;  Loss pred: 0.0642; Loss self: 0.0000; time: 0.08s
Val loss: 0.5201 score: 0.7500 time: 0.05s
Test loss: 0.5653 score: 0.6744 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0607;  Loss pred: 0.0607; Loss self: 0.0000; time: 0.08s
Val loss: 0.5077 score: 0.7500 time: 0.06s
Test loss: 0.5552 score: 0.6512 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.0515;  Loss pred: 0.0515; Loss self: 0.0000; time: 0.08s
Val loss: 0.4952 score: 0.7500 time: 0.06s
Test loss: 0.5450 score: 0.6512 time: 0.16s
Epoch 73/1000, LR 0.000267
Train loss: 0.0518;  Loss pred: 0.0518; Loss self: 0.0000; time: 0.08s
Val loss: 0.4831 score: 0.7500 time: 0.06s
Test loss: 0.5348 score: 0.6977 time: 0.06s
Epoch 74/1000, LR 0.000267
Train loss: 0.0439;  Loss pred: 0.0439; Loss self: 0.0000; time: 0.08s
Val loss: 0.4705 score: 0.7727 time: 0.06s
Test loss: 0.5239 score: 0.7442 time: 0.06s
Epoch 75/1000, LR 0.000267
Train loss: 0.0423;  Loss pred: 0.0423; Loss self: 0.0000; time: 0.08s
Val loss: 0.4575 score: 0.8182 time: 0.05s
Test loss: 0.5126 score: 0.7674 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0381;  Loss pred: 0.0381; Loss self: 0.0000; time: 0.08s
Val loss: 0.4455 score: 0.8182 time: 0.05s
Test loss: 0.5022 score: 0.8372 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0361;  Loss pred: 0.0361; Loss self: 0.0000; time: 0.08s
Val loss: 0.4333 score: 0.8409 time: 0.05s
Test loss: 0.4914 score: 0.8372 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0327;  Loss pred: 0.0327; Loss self: 0.0000; time: 0.08s
Val loss: 0.4212 score: 0.8409 time: 0.05s
Test loss: 0.4806 score: 0.8372 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0332;  Loss pred: 0.0332; Loss self: 0.0000; time: 0.08s
Val loss: 0.4101 score: 0.8409 time: 0.05s
Test loss: 0.4711 score: 0.8140 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0286;  Loss pred: 0.0286; Loss self: 0.0000; time: 0.08s
Val loss: 0.3987 score: 0.8409 time: 0.05s
Test loss: 0.4607 score: 0.7907 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0281;  Loss pred: 0.0281; Loss self: 0.0000; time: 0.08s
Val loss: 0.3882 score: 0.8864 time: 0.05s
Test loss: 0.4516 score: 0.7907 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0275;  Loss pred: 0.0275; Loss self: 0.0000; time: 0.08s
Val loss: 0.3782 score: 0.8409 time: 0.17s
Test loss: 0.4426 score: 0.7907 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.08s
Val loss: 0.3700 score: 0.8409 time: 0.05s
Test loss: 0.4358 score: 0.7907 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0211;  Loss pred: 0.0211; Loss self: 0.0000; time: 0.08s
Val loss: 0.3627 score: 0.8409 time: 0.05s
Test loss: 0.4295 score: 0.7907 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.08s
Val loss: 0.3567 score: 0.8409 time: 0.05s
Test loss: 0.4249 score: 0.7907 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0196;  Loss pred: 0.0196; Loss self: 0.0000; time: 0.08s
Val loss: 0.3516 score: 0.8409 time: 0.05s
Test loss: 0.4217 score: 0.7674 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.08s
Val loss: 0.3477 score: 0.8636 time: 0.05s
Test loss: 0.4195 score: 0.7674 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0152;  Loss pred: 0.0152; Loss self: 0.0000; time: 0.08s
Val loss: 0.3446 score: 0.8636 time: 0.05s
Test loss: 0.4184 score: 0.7674 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.08s
Val loss: 0.3424 score: 0.8636 time: 0.05s
Test loss: 0.4181 score: 0.7674 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.08s
Val loss: 0.3412 score: 0.8636 time: 0.05s
Test loss: 0.4183 score: 0.7442 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0133;  Loss pred: 0.0133; Loss self: 0.0000; time: 0.09s
Val loss: 0.3409 score: 0.8636 time: 0.16s
Test loss: 0.4198 score: 0.7442 time: 0.06s
Epoch 92/1000, LR 0.000266
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.08s
Val loss: 0.3415 score: 0.8636 time: 0.06s
Test loss: 0.4219 score: 0.7442 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.08s
Val loss: 0.3431 score: 0.8636 time: 0.06s
Test loss: 0.4250 score: 0.7442 time: 0.06s
     INFO: Early stopping counter 2 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.08s
Val loss: 0.3455 score: 0.8636 time: 0.06s
Test loss: 0.4290 score: 0.7442 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.08s
Val loss: 0.3484 score: 0.8409 time: 0.06s
Test loss: 0.4337 score: 0.7674 time: 0.06s
     INFO: Early stopping counter 4 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.08s
Val loss: 0.3525 score: 0.8409 time: 0.06s
Test loss: 0.4392 score: 0.7907 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.08s
Val loss: 0.3568 score: 0.8409 time: 0.06s
Test loss: 0.4453 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.08s
Val loss: 0.3618 score: 0.8409 time: 0.06s
Test loss: 0.4522 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.08s
Val loss: 0.3673 score: 0.8409 time: 0.05s
Test loss: 0.4594 score: 0.8140 time: 0.08s
     INFO: Early stopping counter 8 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.15s
Val loss: 0.3731 score: 0.8409 time: 0.06s
Test loss: 0.4669 score: 0.8140 time: 0.06s
     INFO: Early stopping counter 9 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.08s
Val loss: 0.3791 score: 0.8409 time: 0.05s
Test loss: 0.4747 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.08s
Val loss: 0.3843 score: 0.8409 time: 0.05s
Test loss: 0.4829 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.08s
Val loss: 0.3892 score: 0.8409 time: 0.05s
Test loss: 0.4907 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.08s
Val loss: 0.3938 score: 0.8409 time: 0.05s
Test loss: 0.4985 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.08s
Val loss: 0.3981 score: 0.8409 time: 0.05s
Test loss: 0.5061 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.08s
Val loss: 0.4026 score: 0.8409 time: 0.05s
Test loss: 0.5138 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.08s
Val loss: 0.4072 score: 0.8409 time: 0.05s
Test loss: 0.5214 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.08s
Val loss: 0.4124 score: 0.8409 time: 0.18s
Test loss: 0.5292 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.08s
Val loss: 0.4175 score: 0.8409 time: 0.05s
Test loss: 0.5370 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.08s
Val loss: 0.4223 score: 0.8409 time: 0.05s
Test loss: 0.5447 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.08s
Val loss: 0.4270 score: 0.8409 time: 0.05s
Test loss: 0.5519 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 090,   Train_Loss: 0.0133,   Val_Loss: 0.3409,   Val_Precision: 0.9000,   Val_Recall: 0.8182,   Val_accuracy: 0.8571,   Val_Score: 0.8636,   Val_Loss: 0.3409,   Test_Precision: 0.7273,   Test_Recall: 0.7619,   Test_accuracy: 0.7442,   Test_Score: 0.7442,   Test_loss: 0.4198


[0.04603887104894966, 0.04531975497957319, 0.045436262036673725, 0.045277690049260855, 0.05188795307185501, 0.04977476701606065, 0.05062086891848594, 0.04895159904845059, 0.04871337302029133, 0.049147495068609715, 0.04894814605358988, 0.04890310298651457, 0.04866041196510196, 0.048744780011475086, 0.048637880012393, 0.04863415192812681, 0.13580167898908257, 0.04968568799085915, 0.04544687899760902, 0.044942502048797905, 0.04581856809090823, 0.04493385704699904, 0.0454160759691149, 0.04486890695989132, 0.04761497594881803, 0.04491375607904047, 0.04537022300064564, 0.04559711995534599, 0.04563709406647831, 0.04592725797556341, 0.04565979598555714, 0.045745317940600216, 0.04551674390677363, 0.04593586490955204, 0.04566017002798617, 0.045911313965916634, 0.04565657302737236, 0.046216204995289445, 0.04536561400163919, 0.046377010992728174, 0.04530785093083978, 0.04541709797922522, 0.04524559690617025, 0.04559773893561214, 0.0454745190218091, 0.04535398003645241, 0.0458511000033468, 0.04557407496031374, 0.04595678602345288, 0.045510448049753904, 0.046168806962668896, 0.05095513793639839, 0.0517409211024642, 0.05119840404950082, 0.05180897889658809, 0.051216849009506404, 0.05164223804604262, 0.051630544010549784, 0.05164410104043782, 0.05123320105485618, 0.05138012103270739, 0.05167271103709936, 0.05128790799062699, 0.051237000967375934, 0.051252032979391515, 0.0511227180249989, 0.05105035298038274, 0.051640974008478224, 0.05156421195715666, 0.05130526295397431, 0.05184876103885472, 0.046360087930224836, 0.046323130023665726, 0.046210753032937646, 0.18437502905726433, 0.04642786306794733, 0.04655216203536838, 0.046291395905427635, 0.046259031048975885, 0.04634515300858766, 0.04650445294100791, 0.04664714995305985, 0.04666853207163513, 0.046863732975907624, 0.0466115860035643, 0.046417257050052285, 0.04639109305571765, 0.0474632759578526, 0.04948582698125392, 0.04612089798320085, 0.04577147506643087, 0.04611521202605218, 0.04600039392244071, 0.04592650302220136, 0.04606425005476922, 0.04575316503178328, 0.045600996003486216, 0.04581351508386433, 0.04605697898659855, 0.04580971598625183, 0.04568676196504384, 0.04572781908791512, 0.04571362107526511, 0.04569762200117111, 0.04578396596480161, 0.05427002301439643, 0.054678395041264594, 0.053951427922584116, 0.05429313506465405, 0.05414056696463376, 0.05431559099815786, 0.05399782699532807, 0.05579635198228061, 0.05411732604261488, 0.054122180910781026, 0.05425903107970953, 0.05449509702157229, 0.05459102592431009, 0.05566567706409842, 0.05443651101086289, 0.054609881015494466, 0.05455723393242806, 0.05532359890639782, 0.053833379060961306, 0.054734503966756165, 0.05437062494456768, 0.05494065803941339, 0.05467644799500704, 0.05439502897206694, 0.054421275039203465, 0.05449082097038627, 0.05471732700243592, 0.05621752294246107, 0.054971735924482346, 0.05504911905154586, 0.05557770899031311, 0.05513217707630247, 0.055825826013460755, 0.05460464803036302, 0.055139434058219194, 0.054826186038553715, 0.05476402898784727, 0.055302098975516856, 0.0546957979677245, 0.05488111590966582, 0.055712758912704885, 0.05506840790621936, 0.05477859894745052, 0.05533361900597811, 0.05514979606959969, 0.05485264502931386, 0.055341411964036524, 0.055403567967005074, 0.05616716097574681, 0.05452691705431789, 0.05419914296362549, 0.05490294506307691, 0.05463848204817623, 0.05435321596451104, 0.05421894590836018, 0.054064844036474824, 0.055187580990605056, 0.05570408096536994, 0.054975951090455055, 0.05443777795881033, 0.05525268102064729, 0.05467230000067502, 0.055318634025752544, 0.05449303507339209, 0.0545534030534327, 0.054293190012685955, 0.05486851104069501, 0.05457523395307362, 0.056507686036638916, 0.0545509799849242, 0.05481948598753661, 0.05622927797958255, 0.054723022039979696, 0.055243083043023944, 0.054749066941440105, 0.057024682057090104, 0.05650514201261103, 0.054566791048273444, 0.05404413992073387, 0.05388060596305877, 0.053581760032102466, 0.054739487008191645, 0.054204241023398936, 0.054293949040584266, 0.05414890497922897, 0.05393583292607218, 0.05506580194924027, 0.05431053799111396, 0.054357149987481534, 0.05465516296681017, 0.05750069208443165, 0.05386938899755478, 0.054316228022798896, 0.0538183799944818, 0.05395873705856502, 0.055404093000106514, 0.05473593494389206, 0.055982529069297016, 0.05493068799842149, 0.05486664897762239, 0.05438952904660255, 0.054824552964419127, 0.05415028193965554, 0.05376949708443135, 0.056696817046031356, 0.054995290003716946, 0.054195367032662034, 0.07739867805503309, 0.05876512895338237, 0.05501946492586285, 0.05563526402693242, 0.060232687974348664, 0.05938104703091085, 0.06013967108447105, 0.06270116998348385, 0.06102686398662627, 0.06005512899719179, 0.06028239103034139, 0.06001379305962473, 0.06020113604608923, 0.05955995002295822, 0.05881887301802635, 0.060190560994669795, 0.06250169198028743, 0.060773618053644896, 0.06031740491744131, 0.061579509056173265, 0.0590745530789718, 0.05896745796781033, 0.05898024805355817, 0.05896474909968674, 0.05882080504670739, 0.05966193799395114, 0.06114464602433145, 0.06116508389823139, 0.05974137701559812, 0.059968390967696905, 0.058799449005164206, 0.05907266307622194, 0.058506377041339874, 0.05862976098433137, 0.05879540403839201, 0.061093099997378886, 0.06099193007685244, 0.05987624905537814, 0.06034341000486165, 0.0604699719697237, 0.05961194692645222, 0.059192906017415226, 0.05889749003108591, 0.059422187972813845, 0.06185666099190712, 0.060402951086871326, 0.06018154392950237, 0.06076015206053853, 0.05960757995489985, 0.05945729301311076, 0.05931037000846118, 0.059510366059839725, 0.05989178200252354, 0.05962565296795219, 0.061042481916956604, 0.06000897998455912, 0.06032312905881554, 0.1081005830783397, 0.06103703402914107, 0.059644419932737947, 0.05979660409502685, 0.06016674207057804, 0.05900088790804148, 0.05965069402009249, 0.058822707971557975, 0.058531717979349196, 0.14105388103052974, 0.06562971603125334, 0.06568066403269768, 0.06608046195469797, 0.06545825395733118, 0.06542328197974712, 0.0654217799892649, 0.0586859870236367, 0.06236343097407371, 0.16490074596367776, 0.06311286089476198, 0.06284581101499498, 0.057209588936530054, 0.057266533956862986, 0.05750184110365808, 0.0596373820444569, 0.05777911806944758, 0.0573508320376277, 0.0570508090313524, 0.057820342015475035, 0.058562745922245085, 0.05783544306177646, 0.05733036401215941, 0.05806404002942145, 0.059236172935925424, 0.05905551603063941, 0.05806360801216215, 0.05767243599984795, 0.061971107963472605, 0.06184296100400388, 0.0625591209391132, 0.061781442956998944, 0.061731052002869546, 0.0633740620687604, 0.06270331400446594, 0.05925519799347967, 0.08333007001783699, 0.06426708598155528, 0.058284113998524845, 0.05827024800237268, 0.05860733496956527, 0.05998366896528751, 0.05941574298776686, 0.058199007995426655, 0.058077782043255866, 0.058249639929272234, 0.058307986008003354, 0.058548939996398985, 0.0583524729590863]
[0.0010463379783852195, 0.001029994431353936, 0.0010326423190153118, 0.001029038410210474, 0.0011792716607239774, 0.0011312447049104694, 0.0011504742936019532, 0.0011125363420102406, 0.0011071221140975301, 0.0011169885242865844, 0.0011124578648543154, 0.001111434158784422, 0.0011059184537523172, 0.0011078359093517065, 0.0011054063639180226, 0.0011053216347301548, 0.0030864017952064223, 0.0011292201816104352, 0.0010328836135820231, 0.0010214205011090432, 0.001041331092975187, 0.0010212240237954327, 0.0010321835447526114, 0.0010197478854520755, 0.0010821585442913188, 0.0010207671836145562, 0.0010311414318328555, 0.001036298180803318, 0.0010372066833290526, 0.001043801317626441, 0.0010377226360353895, 0.001039666316831823, 0.0010344714524266733, 0.0010439969297625464, 0.0010377311369996858, 0.0010434389537708325, 0.0010376493869857354, 0.0010503682953474874, 0.001031036681855436, 0.0010540229771074585, 0.0010297238847918131, 0.0010322067722551185, 0.0010283090205947783, 0.0010363122485366396, 0.0010335117959502068, 0.0010307722735557366, 0.0010420704546215181, 0.0010357744309162213, 0.001044472409623929, 0.0010343283647671342, 0.001049291067333384, 0.001158071316736327, 0.0011759300250560045, 0.0011636000920341096, 0.0011774767931042747, 0.0011640192956706, 0.0011736872283191506, 0.0011734214547852223, 0.0011737295691008594, 0.0011643909330649133, 0.0011677300234706227, 0.0011743797962977128, 0.0011656342725142497, 0.0011644772947130894, 0.0011648189313498071, 0.0011618799551136115, 0.0011602352950086986, 0.001173658500192687, 0.0011719139081171968, 0.001166028703499416, 0.0011783809327012436, 0.0010536383620505644, 0.0010527984096287664, 0.0010502443871122193, 0.00419034156948328, 0.001055178706089712, 0.0010580036826220087, 0.0010520771796688098, 0.001051341614749452, 0.0010532989320133559, 0.0010569193850229071, 0.0010601624989331785, 0.0010606484561735256, 0.0010650848403615369, 0.0010593542273537341, 0.001054937660228461, 0.0010543430239935828, 0.0010787108172239227, 0.001124677885937589, 0.0010482022268909284, 0.001040260796964338, 0.001048073000592095, 0.0010454634982372888, 0.0010437841595954853, 0.0010469147739720277, 0.0010398446598132564, 0.0010363862728065049, 0.0010412162519060075, 0.0010467495224226943, 0.0010411299087784507, 0.001038335499205542, 0.0010392686156344346, 0.0010389459335287525, 0.0010385823182084343, 0.0010405446810182184, 0.0012620935584743355, 0.0012715905823549906, 0.0012546843702926538, 0.0012626310480152105, 0.0012590829526659014, 0.001263153279026927, 0.0012557634184960015, 0.00129758958098327, 0.0012585424661073227, 0.0012586553700181635, 0.0012618379320862682, 0.0012673278377109834, 0.001269558742425816, 0.0012945506293976375, 0.0012659653723456484, 0.0012699972329184759, 0.0012687728821494898, 0.0012865953234046004, 0.0012519390479293327, 0.0012728954410873526, 0.00126443313824576, 0.001277689721846823, 0.001271545302209466, 0.0012650006737689986, 0.0012656110474233363, 0.0012672283946601457, 0.0012724959768008353, 0.0013073842544758388, 0.0012784124633600546, 0.0012802120709661828, 0.0012925048602398397, 0.0012821436529372667, 0.0012982750235688548, 0.0012698755355898378, 0.001282312419958586, 0.0012750275822919468, 0.0012735820694848201, 0.0012860953250120198, 0.0012719953015749884, 0.001276305021155019, 0.001295645556109416, 0.0012806606489818456, 0.0012739209057546633, 0.0012868283489762351, 0.0012825533969674347, 0.0012756429076584619, 0.0012870095805589889, 0.001288455069000118, 0.0013062130459476002, 0.0012680678384725092, 0.0012604451852005927, 0.0012768126758855097, 0.0012706623732134006, 0.0012640282782444426, 0.001260905718799074, 0.0012573219543366239, 0.0012834321160605827, 0.0012954437433806963, 0.001278510490475699, 0.001265994836251403, 0.0012849460702476112, 0.0012714488372250006, 0.0012864798610640127, 0.0012672798854277232, 0.0012686837919402955, 0.0012626323258764175, 0.0012760118846673258, 0.001269191487280782, 0.0013141322334102074, 0.001268627441509865, 0.0012748717671520141, 0.0013076576274321523, 0.0012726284195344116, 0.0012847228614656732, 0.0012732341149172119, 0.001326155396676514, 0.0013140730700607216, 0.001268995140657522, 0.0012568404632728807, 0.001253037347978111, 0.001246087442607034, 0.0012730113257718987, 0.0012605637447302078, 0.001262649977688006, 0.0012592768599820692, 0.001254321695955167, 0.001280600045331169, 0.0012630357672352083, 0.0012641197671507333, 0.0012710503015537248, 0.0013372253973123638, 0.0012527764883152274, 0.0012631680935534628, 0.0012515902324298092, 0.0012548543501991866, 0.0012884672790722444, 0.0012729287196253968, 0.001301919280681326, 0.0012774578604284068, 0.0012759685808749392, 0.0012648727685256407, 0.0012749896038237007, 0.0012593088823175708, 0.001250453420568171, 0.0013185306289774735, 0.00127896023264458, 0.0012603573728526055, 0.0017999692570937927, 0.0013666309058926133, 0.0012795224401363453, 0.0012938433494635445, 0.001400760185449969, 0.0013809545821142058, 0.001398597001964443, 0.00145816674380195, 0.00141922939503782, 0.0013966309069114368, 0.0014019160704730556, 0.0013956696060377844, 0.0014000264196764938, 0.001385115116812982, 0.001367880767861078, 0.0013997804882481348, 0.0014535277204718007, 0.001413339954735928, 0.0014027303469172398, 0.0014320816059575179, 0.001373826815790042, 0.0013713362318095426, 0.0013716336756641435, 0.001371273234876436, 0.0013679256987606371, 0.001387486930091887, 0.0014219685121937547, 0.0014224438115867765, 0.0013893343491999562, 0.0013946137434348118, 0.0013674290466317257, 0.0013737828622377196, 0.0013606134195660437, 0.0013634828135891015, 0.0013673349776370234, 0.0014207697673809044, 0.001418416978531452, 0.0013924709082646079, 0.0014033351163921315, 0.0014062784179005511, 0.0013863243471267958, 0.0013765792097073309, 0.00136970907049037, 0.001381911348204973, 0.0014385269998117936, 0.0014047197927179378, 0.0013995707890581946, 0.0014130267921055471, 0.0013862227896488336, 0.0013827277444909479, 0.0013793109304293296, 0.0013839620013916215, 0.0013928321395935707, 0.001386643092277958, 0.001419592602719921, 0.0013955576740595143, 0.0014028634664840823, 0.0025139670483334815, 0.0014194659076544435, 0.0013870795333194871, 0.0013906186998843453, 0.0013992265597808846, 0.0013721136722800343, 0.0013872254423277323, 0.0013679699528269297, 0.0013612027437057952, 0.003280322814663482, 0.0015262724658431008, 0.0015274573030859926, 0.0015367549291790226, 0.001522284975751888, 0.0015214716739476073, 0.001521436743936393, 0.0013647903958985278, 0.0014503123482342722, 0.0038349010689227385, 0.0014677409510409764, 0.0014615304887208135, 0.0013304555566634895, 0.00133177985946193, 0.0013372521186897227, 0.0013869158614989976, 0.001343700420219711, 0.0013337402799448303, 0.0013267630007291256, 0.0013446591166389544, 0.0013619243237731416, 0.0013450103037622432, 0.0013332642793525444, 0.0013503265123121267, 0.0013775854171145447, 0.0013733840937358002, 0.0013503164653991197, 0.0013412194418569291, 0.0014411885572900606, 0.0014382083954419507, 0.0014548632776537954, 0.001436777743186022, 0.00143560586053185, 0.0014738153969479162, 0.001458216604755022, 0.0013780278603134806, 0.0019379086050659764, 0.0014945833949198903, 0.001355444511593601, 0.0013551220465668065, 0.001362961278361983, 0.0013949690457043607, 0.0013817614648317874, 0.0013534653022192246, 0.0013506460940292061, 0.0013546427890528427, 0.0013559996746047292, 0.001361603255730209, 0.001357034254862472]
[955.7141388896813, 970.8790354191448, 968.3895203457879, 971.7810239906063, 847.9810321110242, 883.9820382444517, 869.2067311379536, 898.8470418800891, 903.2427292947258, 895.2643453868029, 898.9104500878848, 899.738407440799, 904.2258012849483, 902.6607564880155, 904.6446923424446, 904.7140385016826, 324.00188515737915, 885.5668861442521, 968.163292408151, 979.0287143387221, 960.3093643760315, 979.2170735304949, 968.8199401005517, 980.6345414059665, 924.0790134451855, 979.6553181294298, 969.7990684192551, 964.9732273242241, 964.1279950013119, 958.0367289379905, 963.6486333385686, 961.8470694013649, 966.6772317923227, 957.8572230355569, 963.6407392489206, 958.3694344418993, 963.7166585766479, 952.0470147751134, 969.8975968540877, 948.7459208377857, 971.1341212622036, 968.7981389767917, 972.470317747087, 964.9601280039722, 967.574829739223, 970.1463899008604, 959.6280132164401, 965.461175861837, 957.4211733941908, 966.8109606808832, 953.024409653415, 863.5046784667778, 850.3907364321055, 859.40178833424, 849.2736382206067, 859.0922880053226, 852.015746505234, 852.2087234062337, 851.9850111351069, 858.8180924492405, 856.3623268226756, 851.5132865471177, 857.9020225984091, 858.7543995405988, 858.5025303814277, 860.6741131894453, 861.894138457926, 852.0366016484554, 853.3050022476526, 857.6118212174875, 848.6220136875986, 949.0922464647407, 949.8494591691261, 952.1593376467619, 238.64403018661605, 947.7067668526087, 945.1762942088628, 950.500609009309, 951.1656211176543, 949.3980954566466, 946.1459541479851, 943.2516251105667, 942.8194555693547, 938.8923418162217, 943.9713121247453, 947.92331120631, 948.4579280586072, 927.0325132861037, 889.1434716584196, 954.0143822877567, 961.2974005347256, 954.132011257864, 956.5135479967088, 958.0524774274656, 955.1875901091437, 961.6821037284434, 964.8912053727112, 960.4152818105184, 955.3383866710606, 960.4949311016259, 963.0798530582134, 962.2151433770925, 962.5139939703372, 962.8509772099825, 961.035136926034, 792.3342871734773, 786.4166453230538, 797.013196049259, 791.9969983091635, 794.2288455916778, 791.6695595093197, 796.3283412075155, 770.6597021550015, 794.569930638101, 794.4986561218653, 792.49480030026, 789.0618119824271, 787.6752501339519, 772.4688222238988, 789.9110211420289, 787.4032904008636, 788.1631252284108, 777.2451693309367, 798.7609314159249, 785.6104812079178, 790.8682315835005, 782.6626315460694, 786.4446498778906, 790.5134129459046, 790.1321674110737, 789.1237319285187, 785.8571015006949, 764.8860666452829, 782.2201587206821, 781.1205835961965, 773.6914813724089, 779.9438056017335, 770.2528215100984, 787.4787504552683, 779.8411560517338, 784.2967586649644, 785.1869337360508, 777.547340816789, 786.1664258993701, 783.5117651539355, 771.816022742219, 780.8469798732574, 784.9780904628501, 777.1044217323719, 779.694632881933, 783.9184414356012, 776.9949929709679, 776.1232999580122, 765.5718974040286, 788.6013426573309, 793.3704787335561, 783.2002445515108, 786.9911166654618, 791.1215415123934, 793.080707852155, 795.3412382173907, 779.1608044447568, 771.9362613078958, 782.1601836273766, 789.8926372883077, 778.2427785527982, 786.5043175331766, 777.3149275519378, 789.0916690928833, 788.21847205175, 791.9961967597184, 783.6917602540309, 787.903173021181, 760.9584291262486, 788.2534834733226, 784.3926156070889, 764.7261630429215, 785.7753171706223, 778.3779910782878, 785.4015127964286, 754.0594431890154, 760.9926896635902, 788.0250821779003, 795.6459305868827, 798.0608092915909, 802.5118990909853, 785.5389655654819, 793.2958600312792, 791.9851246749038, 794.1065477962003, 797.2436442937385, 780.88393300142, 791.7432157831959, 791.0642851934458, 786.7509246310752, 747.8170860423832, 798.2269856810858, 791.6602747516087, 798.9835443654928, 796.905234333584, 776.1159450785943, 785.5899427693678, 768.0967743842581, 782.804686539438, 783.7183571669876, 790.5933504803164, 784.320120729608, 794.0863548581098, 799.7099160603904, 758.4200002813014, 781.885139565475, 793.4257549005084, 555.5650442689156, 731.7264637351745, 781.5415881986723, 772.8910925844474, 713.8980750504185, 724.1367768004549, 715.0022476777934, 685.7926257409017, 704.6077283181917, 716.008785894219, 713.3094634278392, 716.5019540970984, 714.2722351132999, 721.9616534840114, 731.0578695858674, 714.3977276405163, 687.981375185201, 707.543855000436, 712.8953916179868, 698.2842289433502, 727.893784359518, 729.2157654731058, 729.0576323272328, 729.2492659860812, 731.033857252639, 720.7275097962721, 703.2504527524601, 703.0154666597844, 719.7691474164205, 717.0444180028568, 731.2993697649007, 727.9170729871573, 734.9626173163438, 733.4159184358882, 731.3496812084499, 703.8438056318121, 705.0113014265684, 718.14785792995, 712.588168228074, 711.0967410656215, 721.331917795813, 726.4384010365856, 730.0820455558418, 723.6354208241687, 695.155530713593, 711.8857477370193, 714.5047666170029, 707.7006646915045, 721.3847640272355, 723.2081687694425, 724.9996921932143, 722.5631910373735, 717.9616061213238, 721.166106526528, 704.4274519915172, 716.5594217909438, 712.8277440328842, 397.77768792272116, 704.4903259793128, 720.9391934483033, 719.1043814405543, 714.6805447693886, 728.8025913613302, 720.8633647332931, 731.010208180001, 734.6444198882219, 304.84804590873375, 655.1910110280394, 654.6827842451987, 650.7218431596169, 656.9072256041148, 657.2583749820343, 657.2734646941109, 732.7132452024889, 689.5066440118785, 260.7629198322213, 681.3191382926005, 684.2142587632487, 751.6222507332717, 750.8748483431964, 747.8021429345935, 721.0242724596043, 744.2135054452748, 749.7711623745553, 753.7141143146498, 743.6829064153837, 734.255187710835, 743.4887280809779, 750.0388448759888, 740.5616277856589, 725.9078003994659, 728.1284271174699, 740.5671378704732, 745.5901463935626, 693.8717317325571, 695.30952758255, 687.3498117380922, 696.0018727618391, 696.5700179222794, 678.5110279556534, 685.769176361833, 725.6747332905991, 516.0202072408646, 669.0827714258127, 737.7653540566529, 737.9409128008019, 733.696559011425, 716.8617849115575, 723.71391549969, 738.8442085366643, 740.386400568361, 738.2019880674177, 737.4633038105247, 734.4283261600413, 736.9010741009957]
Elapsed: 0.055788820278004886~0.013133190229297261
Time per graph: 0.001289000683748986~0.0003064046734200015
Speed: 799.0247177812504~112.82720638424665
Total Time: 0.0594
best val loss: 0.34088775515556335 test_score: 0.7442

Testing...
Test loss: 0.4516 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.1432942870305851, 0.14036314107943326, 0.13979205617215484, 0.13932356401346624, 0.26668625499587506, 0.1699229449732229, 0.16859722894150764, 0.15600306983105838, 0.14918672805652022, 0.1496791070094332, 0.15158983587753028, 0.15158415911719203, 0.15155321301426739, 0.15072564594447613, 0.15023660904262215, 0.15057733887806535, 0.2478686940157786, 0.1504229160491377, 0.14629875414539129, 0.1366298081120476, 0.13993832911364734, 0.13715384097304195, 0.13791213603690267, 0.13838580111041665, 0.14186061907093972, 0.1390799260698259, 0.1389242239529267, 0.1391562249045819, 0.2647453990066424, 0.14096523204352707, 0.1417489618761465, 0.1400142170023173, 0.14081558701582253, 0.14076597604434937, 0.14154638606123626, 0.1406630000565201, 0.14209710201248527, 0.14184328191913664, 0.14118854596745223, 0.14120627602096647, 0.25800302193965763, 0.140222345944494, 0.14039525296539068, 0.14079322305042297, 0.1404133450705558, 0.14077112183440477, 0.14117405307479203, 0.14302920398768038, 0.14263540401589125, 0.14298490690998733, 0.14168563403654844, 0.2448293229099363, 0.15668226010166109, 0.15519304701592773, 0.155481543042697, 0.15481070091482252, 0.15636858891230077, 0.15644996403716505, 0.15784975001588464, 0.15707467205356807, 0.15690392581745982, 0.15718578605446965, 0.27035847201477736, 0.15776781202293932, 0.15576338698156178, 0.15646942204330117, 0.15643437195103616, 0.15655857103411108, 0.15756203001365066, 0.15685152797959745, 0.15932622901163995, 0.1526066279038787, 0.14445405919104815, 0.1436726360116154, 0.281222294899635, 0.1447669049957767, 0.14356797188520432, 0.143094326951541, 0.14395324501674622, 0.14344280899967998, 0.14335207093972713, 0.14404569496400654, 0.14386266586370766, 0.1446724410634488, 0.14816017192788422, 0.14414047205355018, 0.14438948791939765, 0.1450497719924897, 0.2526191350771114, 0.14797119400463998, 0.1422548268456012, 0.1421396000077948, 0.14309560495894402, 0.14260410889983177, 0.14320108981337398, 0.14286064787302166, 0.14248181390576065, 0.14221386902499944, 0.1427740149665624, 0.14273661992046982, 0.1425549859413877, 0.14364551298785955, 0.14304766990244389, 0.14330813894048333, 0.14287108497228473, 0.19296458922326565, 0.19141573808155954, 0.1913488069549203, 0.19232721417210996, 0.18942318810150027, 0.18984032701700926, 0.18974886811338365, 0.19251513516064733, 0.1930980869801715, 0.1903783471789211, 0.1912754689110443, 0.19212455092929304, 0.19196328800171614, 0.19196114293299615, 0.19324807997327298, 0.19064971420448273, 0.19290993479080498, 0.19219327007886022, 0.19154480088036507, 0.19327064091339707, 0.19169521098956466, 0.19329654693137854, 0.19369282585103065, 0.19133529998362064, 0.1904131950577721, 0.19038791896309704, 0.19333893503062427, 0.19624623202253133, 0.19331318605691195, 0.19337158207781613, 0.19376336818095297, 0.19329706602729857, 0.19566123897675425, 0.19323072908446193, 0.19387935288250446, 0.19273148197680712, 0.19490221911109984, 0.1939528229413554, 0.19442672014702111, 0.19345603801775724, 0.1941496409708634, 0.19315528811421245, 0.19518552685622126, 0.19444803905207664, 0.19305989902932197, 0.19450389011763036, 0.1931855210568756, 0.19430228194687515, 0.20865894097369164, 0.19942016107961535, 0.19286035897675902, 0.19378110591787845, 0.19495135894976556, 0.19194402208086103, 0.19245772494468838, 0.19171166012529284, 0.1939940438605845, 0.19508907303679734, 0.19386564590968192, 0.19249209691770375, 0.19468683283776045, 0.19390334805939347, 0.19387701514642686, 0.19370856508612633, 0.19277013186365366, 0.19319322693627328, 0.19367021403741091, 0.19392271002288908, 0.19709108490496874, 0.19446576898917556, 0.19313244184013456, 0.19539557001553476, 0.19319444196298718, 0.19626560586038977, 0.1960435250075534, 0.19984027394093573, 0.21223694120999426, 0.19610605901107192, 0.19158310710918158, 0.19084747903980315, 0.19126932590734214, 0.19284595421049744, 0.19204526988323778, 0.19212874583899975, 0.19061351800337434, 0.19279787701088935, 0.19579379505012184, 0.19357831892557442, 0.19290158292278647, 0.19351998111233115, 0.21453267999459058, 0.19166327104903758, 0.19204864709172398, 0.19136380206327885, 0.19139174604788423, 0.19223357702139765, 0.19278979999944568, 0.19462794612627476, 0.1930378678953275, 0.19445954193361104, 0.1933903059689328, 0.1925246660830453, 0.19225246796850115, 0.19098057108931243, 0.1961999370250851, 0.1931395309511572, 0.1907774859573692, 0.21239996200893074, 0.28571108100004494, 0.1922277050325647, 0.19301416212692857, 0.19298928196076304, 0.18641934206243604, 0.1895946889417246, 0.19255852920468897, 0.19332114094868302, 0.19176623597741127, 0.1906991290161386, 0.31519764417316765, 0.1893484469037503, 0.18796923803165555, 0.18742568092420697, 0.18878013908397406, 0.19053531403187662, 0.1962762790499255, 0.19258447107858956, 0.19137885910458863, 0.23540693789254874, 0.18804614210966974, 0.1869448518846184, 0.18552831397391856, 0.185389197897166, 0.18777741910889745, 0.18949626688845456, 0.19785477092955261, 0.19147911004256457, 0.18830874899867922, 0.3121632297988981, 0.18639249296393245, 0.18488588009495288, 0.18538703897502273, 0.18480146094225347, 0.18713906209450215, 0.1963536221301183, 0.19309478206560016, 0.19010731694288552, 0.3121619449229911, 0.18993608304299414, 0.1873873269651085, 0.1861840079072863, 0.18720860895700753, 0.19024015008471906, 0.19160768389701843, 0.19133709697052836, 0.18902985996101052, 0.23939442506525666, 0.18838681001216173, 0.18700077815447003, 0.18727727909572423, 0.18777261988725513, 0.18808833393268287, 0.19399904692545533, 0.19155075610615313, 0.19119621103163809, 0.27578558295499533, 0.1986374561674893, 0.18943251390010118, 0.1891955480678007, 0.18887031881604344, 0.1863153560552746, 0.19011975300963968, 0.18541524501051754, 0.185185651993379, 0.26603096106555313, 0.20518749405164272, 0.20269713609013706, 0.20290571404621005, 0.20315612584818155, 0.20354705397039652, 0.20495506701990962, 0.18698104412760586, 0.1939208081457764, 0.2972781998105347, 0.1969585728365928, 0.19549795996863395, 0.18101075512822717, 0.1796806249767542, 0.18105417501647025, 0.18418580619618297, 0.18376865005120635, 0.18216571386437863, 0.18207055109087378, 0.2991005019284785, 0.18245479394681752, 0.18253243784420192, 0.18152288196142763, 0.18222687300294638, 0.18262023106217384, 0.18736604694277048, 0.1849392750300467, 0.181324427947402, 0.3055027030641213, 0.19294364820234478, 0.1944566909223795, 0.19449445290956646, 0.19335519103333354, 0.19854912802111357, 0.19822179700713605, 0.1855722740292549, 0.20613390009384602, 0.26712541992310435, 0.18734275200404227, 0.1829489030642435, 0.1835950668901205, 0.18545704102143645, 0.18988629197701812, 0.18520497693680227, 0.18271187297068536, 0.3153112130239606, 0.18431221903301775, 0.18475698796100914, 0.18443793896585703]
Total Epoch List: [105, 111, 111]
Total Time List: [0.046314112027175725, 0.056494776043109596, 0.05938867898657918]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x751995067f40>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6967;  Loss pred: 0.6967; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6965;  Loss pred: 0.6965; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6968;  Loss pred: 0.6968; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6942;  Loss pred: 0.6942; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6923;  Loss pred: 0.6923; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6932;  Loss pred: 0.6932; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.18s
Epoch 7/1000, LR 0.000150
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6858;  Loss pred: 0.6858; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6865;  Loss pred: 0.6865; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6840;  Loss pred: 0.6840; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6830;  Loss pred: 0.6830; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6794;  Loss pred: 0.6794; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6768;  Loss pred: 0.6768; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6735;  Loss pred: 0.6735; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.10s
Epoch 16/1000, LR 0.000270
Train loss: 0.6719;  Loss pred: 0.6719; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6677;  Loss pred: 0.6677; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6646;  Loss pred: 0.6646; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6625;  Loss pred: 0.6625; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6582;  Loss pred: 0.6582; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6562;  Loss pred: 0.6562; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6447;  Loss pred: 0.6447; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.06s
Epoch 23/1000, LR 0.000270
Train loss: 0.6456;  Loss pred: 0.6456; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6375;  Loss pred: 0.6375; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6305;  Loss pred: 0.6305; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.21s
     INFO: Early stopping counter 1 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.6251;  Loss pred: 0.6251; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.6208;  Loss pred: 0.6208; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.6176;  Loss pred: 0.6176; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.6103;  Loss pred: 0.6103; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.6001;  Loss pred: 0.6001; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.5881;  Loss pred: 0.5881; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.5854;  Loss pred: 0.5854; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 33/1000, LR 0.000270
Train loss: 0.5792;  Loss pred: 0.5792; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 9 of 20
Epoch 34/1000, LR 0.000270
Train loss: 0.5693;  Loss pred: 0.5693; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 35/1000, LR 0.000270
Train loss: 0.5555;  Loss pred: 0.5555; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6982 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 36/1000, LR 0.000270
Train loss: 0.5475;  Loss pred: 0.5475; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6989 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 37/1000, LR 0.000270
Train loss: 0.5352;  Loss pred: 0.5352; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6997 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 38/1000, LR 0.000270
Train loss: 0.5297;  Loss pred: 0.5297; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7004 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 39/1000, LR 0.000269
Train loss: 0.5225;  Loss pred: 0.5225; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7013 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 40/1000, LR 0.000269
Train loss: 0.5143;  Loss pred: 0.5143; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7023 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 41/1000, LR 0.000269
Train loss: 0.4922;  Loss pred: 0.4922; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7033 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 42/1000, LR 0.000269
Train loss: 0.4865;  Loss pred: 0.4865; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6962 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7043 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 43/1000, LR 0.000269
Train loss: 0.4722;  Loss pred: 0.4722; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6966 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7055 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 44/1000, LR 0.000269
Train loss: 0.4615;  Loss pred: 0.4615; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7066 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 023,   Train_Loss: 0.6375,   Val_Loss: 0.6924,   Val_Precision: 0.5116,   Val_Recall: 1.0000,   Val_accuracy: 0.6769,   Val_Score: 0.5116,   Val_Loss: 0.6924,   Test_Precision: 0.5000,   Test_Recall: 1.0000,   Test_accuracy: 0.6667,   Test_Score: 0.5000,   Test_loss: 0.6939


[0.05800415598787367, 0.058512003044597805, 0.05870127701200545, 0.05802062607835978, 0.05822777608409524, 0.1804224189836532, 0.058711144025437534, 0.05841985298320651, 0.058423498063348234, 0.05784128000959754, 0.05764588201418519, 0.060179866035468876, 0.05910740094259381, 0.058139464003033936, 0.1082148200366646, 0.05838016397319734, 0.058313607005402446, 0.057841603993438184, 0.05735980800818652, 0.05757914506830275, 0.057832763995975256, 0.06019897304940969, 0.05891126103233546, 0.058204802917316556, 0.21417489694431424, 0.05827821302227676, 0.05896499496884644, 0.05775154801085591, 0.05825548304710537, 0.0669071659212932, 0.059020153945311904, 0.05874746502377093, 0.0684967270353809, 0.059260001056827605, 0.05880200199317187, 0.05818869103677571, 0.05824083695188165, 0.05844106199219823, 0.05847687099594623, 0.05833870905917138, 0.05811601900495589, 0.057844653027132154, 0.057873972109518945, 0.05817619292065501]
[0.0013182762724516745, 0.0013298182510135864, 0.001334119932091033, 0.0013186505926899952, 0.0013233585473658009, 0.004100509522355755, 0.0013343441823963076, 0.0013277239314365115, 0.0013278067741670054, 0.0013145745456726713, 0.0013101336821405725, 0.001367724228078838, 0.0013433500214225867, 0.0013213514546144077, 0.0024594277281060136, 0.0013268219084817577, 0.001325309250122783, 0.0013145819089417769, 0.0013036320001860572, 0.001308616933370517, 0.0013143809999085286, 0.0013681584783956748, 0.0013388922961894423, 0.0013228364299390125, 0.00486761129418896, 0.001324504841415381, 0.0013401135220192373, 0.001312535182064907, 0.0013239882510705766, 0.0015206174073021182, 0.0013413671351207251, 0.0013351696596311574, 0.0015567437962586569, 0.001346818205836991, 0.0013364091362084516, 0.0013224702508358116, 0.0013236553852700374, 0.0013282059543681416, 0.0013290197953624142, 0.0013258797513448042, 0.0013208186137489974, 0.0013146512051620944, 0.0013153175479436125, 0.0013221862027421594]
[758.5663346122755, 751.9824601879247, 749.5577990748178, 758.3510033238142, 755.653108517371, 243.8721321211558, 749.4318281540606, 753.1686191104988, 753.1216284292166, 760.702390968857, 763.2808877687519, 731.1415411604145, 744.4076257511915, 756.8009226521922, 406.5986524312679, 753.6806511917412, 754.5408740694712, 760.6981301035767, 767.0876442564143, 764.165566331445, 760.8144062258909, 730.9094785368845, 746.8860660757049, 755.9513613078402, 205.43957591556614, 754.9991277732051, 746.2054397400857, 761.884339303408, 755.2937113991761, 657.6276157289306, 745.5080520591392, 748.9684871031682, 642.3664590174141, 742.4907056246258, 748.2738428720388, 756.1606768605889, 755.4836486356237, 752.8952845838755, 752.4342402494517, 754.2162092646237, 757.1062291146933, 760.6580331523764, 760.2726821089062, 756.3231244782629]
Elapsed: 0.06626248300943355~0.029811972040150757
Time per graph: 0.0015059655229416715~0.0006775448190943353
Speed: 716.954059030635~121.12111234177215
Total Time: 0.0586
best val loss: 0.6923786401748657 test_score: 0.5000

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
test Score 0.5000
Epoch Time List: [0.1856738510541618, 0.1862029180629179, 0.19305652589537203, 0.1889084989670664, 0.1868659380124882, 0.3102270000381395, 0.18933938501868397, 0.189542090985924, 0.186469912994653, 0.1853916710242629, 0.1862830490572378, 0.1932960341218859, 0.19206689798738807, 0.18918248394038528, 0.2362229758873582, 0.2208525639725849, 0.18797700700815767, 0.186904042144306, 0.18599635211285204, 0.18527241703122854, 0.18653369590174407, 0.19251902389805764, 0.19295163196511567, 0.18765260884538293, 0.3443980098236352, 0.18791651108767837, 0.18825460004154593, 0.18604540615342557, 0.18588442797772586, 0.19530170690268278, 0.1946106778923422, 0.1881941210012883, 0.20537291502114385, 0.1955945799127221, 0.1877030119067058, 0.1875283649424091, 0.1863435439299792, 0.18721118790563196, 0.18756949715316296, 0.18703683197963983, 0.18684160115662962, 0.18492654198780656, 0.1857901078183204, 0.18678808596450835]
Total Epoch List: [44]
Total Time List: [0.058590776985511184]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x75199505b5b0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.06s
Epoch 2/1000, LR 0.000000
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6918;  Loss pred: 0.6918; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6915;  Loss pred: 0.6915; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6914;  Loss pred: 0.6914; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6879;  Loss pred: 0.6879; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6865;  Loss pred: 0.6865; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6849;  Loss pred: 0.6849; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6798;  Loss pred: 0.6798; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6789;  Loss pred: 0.6789; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6734;  Loss pred: 0.6734; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.06s
Epoch 13/1000, LR 0.000270
Train loss: 0.6711;  Loss pred: 0.6711; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.06s
Epoch 14/1000, LR 0.000270
Train loss: 0.6686;  Loss pred: 0.6686; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.06s
Epoch 15/1000, LR 0.000270
Train loss: 0.6635;  Loss pred: 0.6635; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6571;  Loss pred: 0.6571; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6513;  Loss pred: 0.6513; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6507;  Loss pred: 0.6507; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 4 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6451;  Loss pred: 0.6451; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6380;  Loss pred: 0.6380; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6341;  Loss pred: 0.6341; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 22/1000, LR 0.000270
Train loss: 0.6308;  Loss pred: 0.6308; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.6201;  Loss pred: 0.6201; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.6164;  Loss pred: 0.6164; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 25/1000, LR 0.000270
Train loss: 0.6080;  Loss pred: 0.6080; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.6005;  Loss pred: 0.6005; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5929;  Loss pred: 0.5929; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 13 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5842;  Loss pred: 0.5842; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5738;  Loss pred: 0.5738; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 15 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.5644;  Loss pred: 0.5644; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 31/1000, LR 0.000270
Train loss: 0.5559;  Loss pred: 0.5559; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 32/1000, LR 0.000270
Train loss: 0.5463;  Loss pred: 0.5463; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 33/1000, LR 0.000270
Train loss: 0.5417;  Loss pred: 0.5417; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 34/1000, LR 0.000270
Train loss: 0.5304;  Loss pred: 0.5304; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 013,   Train_Loss: 0.6686,   Val_Loss: 0.6931,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.5000,   Val_Loss: 0.6931,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.4884,   Test_loss: 0.6932


[0.05800415598787367, 0.058512003044597805, 0.05870127701200545, 0.05802062607835978, 0.05822777608409524, 0.1804224189836532, 0.058711144025437534, 0.05841985298320651, 0.058423498063348234, 0.05784128000959754, 0.05764588201418519, 0.060179866035468876, 0.05910740094259381, 0.058139464003033936, 0.1082148200366646, 0.05838016397319734, 0.058313607005402446, 0.057841603993438184, 0.05735980800818652, 0.05757914506830275, 0.057832763995975256, 0.06019897304940969, 0.05891126103233546, 0.058204802917316556, 0.21417489694431424, 0.05827821302227676, 0.05896499496884644, 0.05775154801085591, 0.05825548304710537, 0.0669071659212932, 0.059020153945311904, 0.05874746502377093, 0.0684967270353809, 0.059260001056827605, 0.05880200199317187, 0.05818869103677571, 0.05824083695188165, 0.05844106199219823, 0.05847687099594623, 0.05833870905917138, 0.05811601900495589, 0.057844653027132154, 0.057873972109518945, 0.05817619292065501, 0.06073241902049631, 0.058410294936038554, 0.05866438092198223, 0.05883046705275774, 0.0590703230118379, 0.05951271706726402, 0.05895102594513446, 0.05958915699739009, 0.05904288298916072, 0.05969656293746084, 0.059244973002932966, 0.06468180904630572, 0.0615662009222433, 0.06034798896871507, 0.060085405013523996, 0.0599951590411365, 0.06080928898882121, 0.060220331070013344, 0.06005481805186719, 0.060208896989934146, 0.05980050109792501, 0.059642967069521546, 0.059514219989068806, 0.05932000104803592, 0.05957155500072986, 0.06003113090991974, 0.06025307101663202, 0.05991861701477319, 0.06026463501621038, 0.05988152790814638, 0.05983215500600636, 0.0599083979614079, 0.05985294107813388, 0.05975878203753382]
[0.0013182762724516745, 0.0013298182510135864, 0.001334119932091033, 0.0013186505926899952, 0.0013233585473658009, 0.004100509522355755, 0.0013343441823963076, 0.0013277239314365115, 0.0013278067741670054, 0.0013145745456726713, 0.0013101336821405725, 0.001367724228078838, 0.0013433500214225867, 0.0013213514546144077, 0.0024594277281060136, 0.0013268219084817577, 0.001325309250122783, 0.0013145819089417769, 0.0013036320001860572, 0.001308616933370517, 0.0013143809999085286, 0.0013681584783956748, 0.0013388922961894423, 0.0013228364299390125, 0.00486761129418896, 0.001324504841415381, 0.0013401135220192373, 0.001312535182064907, 0.0013239882510705766, 0.0015206174073021182, 0.0013413671351207251, 0.0013351696596311574, 0.0015567437962586569, 0.001346818205836991, 0.0013364091362084516, 0.0013224702508358116, 0.0013236553852700374, 0.0013282059543681416, 0.0013290197953624142, 0.0013258797513448042, 0.0013208186137489974, 0.0013146512051620944, 0.0013153175479436125, 0.0013221862027421594, 0.0014123818376859606, 0.0013583789520008967, 0.0013642879284181913, 0.0013681503965757614, 0.0013737284421357651, 0.001384016675982884, 0.001370954091747313, 0.0013857943487765138, 0.001373090302073505, 0.0013882921613362987, 0.0013777900698356503, 0.0015042281173559468, 0.0014317721144707744, 0.0014034416039236063, 0.0013973350003145116, 0.0013952362567706163, 0.001414169511367935, 0.0014004728155817057, 0.0013966236756248183, 0.0014002069067426545, 0.001390709327858721, 0.0013870457458028266, 0.001384051627652763, 0.0013795349080938585, 0.0013853850000169734, 0.0013960728118585985, 0.0014012342096891167, 0.001393456209645888, 0.0014015031399118693, 0.001392593672282474, 0.0013914454652559618, 0.0013932185572420443, 0.0013919288622821833, 0.0013897391171519492]
[758.5663346122755, 751.9824601879247, 749.5577990748178, 758.3510033238142, 755.653108517371, 243.8721321211558, 749.4318281540606, 753.1686191104988, 753.1216284292166, 760.702390968857, 763.2808877687519, 731.1415411604145, 744.4076257511915, 756.8009226521922, 406.5986524312679, 753.6806511917412, 754.5408740694712, 760.6981301035767, 767.0876442564143, 764.165566331445, 760.8144062258909, 730.9094785368845, 746.8860660757049, 755.9513613078402, 205.43957591556614, 754.9991277732051, 746.2054397400857, 761.884339303408, 755.2937113991761, 657.6276157289306, 745.5080520591392, 748.9684871031682, 642.3664590174141, 742.4907056246258, 748.2738428720388, 756.1606768605889, 755.4836486356237, 752.8952845838755, 752.4342402494517, 754.2162092646237, 757.1062291146933, 760.6580331523764, 760.2726821089062, 756.3231244782629, 708.023831316321, 736.1715952142786, 732.9831036176058, 730.9137961022584, 727.9459093423723, 722.534646694074, 729.4190272450893, 721.6077918652772, 728.2842202657022, 720.309476527946, 725.799976275983, 664.7927853906543, 698.4351698801103, 712.5340998900822, 715.6480012129664, 716.7244938965235, 707.1288073752161, 714.0445632888891, 716.0124931668671, 714.180165220247, 719.0575197620215, 720.9567550500627, 722.5164004148583, 724.8819831472968, 721.8210100352958, 716.2950180719407, 713.6565701046251, 717.6400615087322, 713.5196286915797, 718.0845496454042, 718.6771059087437, 717.7624750990665, 718.4275196078747, 719.5595113198957]
Elapsed: 0.06349762636595048~0.022620989915818047
Time per graph: 0.0014569327291397449~0.000512177113806544
Speed: 717.3375469167153~91.30847311502572
Total Time: 0.0603
best val loss: 0.6931155920028687 test_score: 0.4884

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
test Score 0.5116
Epoch Time List: [0.1856738510541618, 0.1862029180629179, 0.19305652589537203, 0.1889084989670664, 0.1868659380124882, 0.3102270000381395, 0.18933938501868397, 0.189542090985924, 0.186469912994653, 0.1853916710242629, 0.1862830490572378, 0.1932960341218859, 0.19206689798738807, 0.18918248394038528, 0.2362229758873582, 0.2208525639725849, 0.18797700700815767, 0.186904042144306, 0.18599635211285204, 0.18527241703122854, 0.18653369590174407, 0.19251902389805764, 0.19295163196511567, 0.18765260884538293, 0.3443980098236352, 0.18791651108767837, 0.18825460004154593, 0.18604540615342557, 0.18588442797772586, 0.19530170690268278, 0.1946106778923422, 0.1881941210012883, 0.20537291502114385, 0.1955945799127221, 0.1877030119067058, 0.1875283649424091, 0.1863435439299792, 0.18721118790563196, 0.18756949715316296, 0.18703683197963983, 0.18684160115662962, 0.18492654198780656, 0.1857901078183204, 0.18678808596450835, 0.1864428239641711, 0.1814088320825249, 0.1806389291305095, 0.18156528798863292, 0.1828158990247175, 0.1831885069841519, 0.1814076198497787, 0.18302469106856734, 0.18277277401648462, 0.18398755101952702, 0.18369761703070253, 0.18888245790731162, 0.19788471492938697, 0.18714205001015216, 0.1876390939578414, 0.18632332200650126, 0.1894892459968105, 0.18767285195644945, 0.18672366603277624, 0.18703760707285255, 0.18602745793759823, 0.18596952012740076, 0.18576310796197504, 0.18638291279785335, 0.18673631304409355, 0.18760008399840444, 0.18642998696304858, 0.18582127895206213, 0.18552431708667427, 0.187324594007805, 0.18532386317383498, 0.18675955396611243, 0.18612024409230798, 0.18595322989858687]
Total Epoch List: [44, 34]
Total Time List: [0.058590776985511184, 0.06027041294146329]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7519952286d0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6963;  Loss pred: 0.6963; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6938;  Loss pred: 0.6938; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6898;  Loss pred: 0.6898; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6891;  Loss pred: 0.6891; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6860;  Loss pred: 0.6860; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6824;  Loss pred: 0.6824; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6781;  Loss pred: 0.6781; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6778;  Loss pred: 0.6778; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6732;  Loss pred: 0.6732; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6729;  Loss pred: 0.6729; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6681;  Loss pred: 0.6681; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6650;  Loss pred: 0.6650; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6630;  Loss pred: 0.6630; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6613;  Loss pred: 0.6613; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6548;  Loss pred: 0.6548; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6516;  Loss pred: 0.6516; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6454;  Loss pred: 0.6454; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6934,   Val_Loss: 0.6934,   Val_Precision: 0.5000,   Val_Recall: 1.0000,   Val_accuracy: 0.6667,   Val_Score: 0.5000,   Val_Loss: 0.6934,   Test_Precision: 0.4884,   Test_Recall: 1.0000,   Test_accuracy: 0.6562,   Test_Score: 0.4884,   Test_loss: 0.6939


[0.05800415598787367, 0.058512003044597805, 0.05870127701200545, 0.05802062607835978, 0.05822777608409524, 0.1804224189836532, 0.058711144025437534, 0.05841985298320651, 0.058423498063348234, 0.05784128000959754, 0.05764588201418519, 0.060179866035468876, 0.05910740094259381, 0.058139464003033936, 0.1082148200366646, 0.05838016397319734, 0.058313607005402446, 0.057841603993438184, 0.05735980800818652, 0.05757914506830275, 0.057832763995975256, 0.06019897304940969, 0.05891126103233546, 0.058204802917316556, 0.21417489694431424, 0.05827821302227676, 0.05896499496884644, 0.05775154801085591, 0.05825548304710537, 0.0669071659212932, 0.059020153945311904, 0.05874746502377093, 0.0684967270353809, 0.059260001056827605, 0.05880200199317187, 0.05818869103677571, 0.05824083695188165, 0.05844106199219823, 0.05847687099594623, 0.05833870905917138, 0.05811601900495589, 0.057844653027132154, 0.057873972109518945, 0.05817619292065501, 0.06073241902049631, 0.058410294936038554, 0.05866438092198223, 0.05883046705275774, 0.0590703230118379, 0.05951271706726402, 0.05895102594513446, 0.05958915699739009, 0.05904288298916072, 0.05969656293746084, 0.059244973002932966, 0.06468180904630572, 0.0615662009222433, 0.06034798896871507, 0.060085405013523996, 0.0599951590411365, 0.06080928898882121, 0.060220331070013344, 0.06005481805186719, 0.060208896989934146, 0.05980050109792501, 0.059642967069521546, 0.059514219989068806, 0.05932000104803592, 0.05957155500072986, 0.06003113090991974, 0.06025307101663202, 0.05991861701477319, 0.06026463501621038, 0.05988152790814638, 0.05983215500600636, 0.0599083979614079, 0.05985294107813388, 0.05975878203753382, 0.057020301930606365, 0.05631980602629483, 0.056205408996902406, 0.05602420901414007, 0.05625699402298778, 0.056738707004114985, 0.05626085796393454, 0.056101721012964845, 0.05637732602190226, 0.0563986930064857, 0.05636304500512779, 0.05658415996003896, 0.05604339891579002, 0.056338079972192645, 0.05611861601937562, 0.056563302990980446, 0.06438848201651126, 0.06200755899772048, 0.05559460504446179, 0.057358416030183434, 0.055536653962917626]
[0.0013182762724516745, 0.0013298182510135864, 0.001334119932091033, 0.0013186505926899952, 0.0013233585473658009, 0.004100509522355755, 0.0013343441823963076, 0.0013277239314365115, 0.0013278067741670054, 0.0013145745456726713, 0.0013101336821405725, 0.001367724228078838, 0.0013433500214225867, 0.0013213514546144077, 0.0024594277281060136, 0.0013268219084817577, 0.001325309250122783, 0.0013145819089417769, 0.0013036320001860572, 0.001308616933370517, 0.0013143809999085286, 0.0013681584783956748, 0.0013388922961894423, 0.0013228364299390125, 0.00486761129418896, 0.001324504841415381, 0.0013401135220192373, 0.001312535182064907, 0.0013239882510705766, 0.0015206174073021182, 0.0013413671351207251, 0.0013351696596311574, 0.0015567437962586569, 0.001346818205836991, 0.0013364091362084516, 0.0013224702508358116, 0.0013236553852700374, 0.0013282059543681416, 0.0013290197953624142, 0.0013258797513448042, 0.0013208186137489974, 0.0013146512051620944, 0.0013153175479436125, 0.0013221862027421594, 0.0014123818376859606, 0.0013583789520008967, 0.0013642879284181913, 0.0013681503965757614, 0.0013737284421357651, 0.001384016675982884, 0.001370954091747313, 0.0013857943487765138, 0.001373090302073505, 0.0013882921613362987, 0.0013777900698356503, 0.0015042281173559468, 0.0014317721144707744, 0.0014034416039236063, 0.0013973350003145116, 0.0013952362567706163, 0.001414169511367935, 0.0014004728155817057, 0.0013966236756248183, 0.0014002069067426545, 0.001390709327858721, 0.0013870457458028266, 0.001384051627652763, 0.0013795349080938585, 0.0013853850000169734, 0.0013960728118585985, 0.0014012342096891167, 0.001393456209645888, 0.0014015031399118693, 0.001392593672282474, 0.0013914454652559618, 0.0013932185572420443, 0.0013919288622821833, 0.0013897391171519492, 0.0013260535332699154, 0.0013097629308440658, 0.001307102534811684, 0.0013028885817241876, 0.0013083021865811111, 0.0013195048140491857, 0.0013083920456728963, 0.0013046911863480197, 0.0013111006051605178, 0.0013115975117787373, 0.0013107684884913439, 0.0013159106967450922, 0.0013033348585067446, 0.0013101879063300615, 0.0013050840934738517, 0.0013154256509530337, 0.0014974065585235178, 0.0014420362557609413, 0.0012928977917316695, 0.0013339166518647311, 0.001291550092160875]
[758.5663346122755, 751.9824601879247, 749.5577990748178, 758.3510033238142, 755.653108517371, 243.8721321211558, 749.4318281540606, 753.1686191104988, 753.1216284292166, 760.702390968857, 763.2808877687519, 731.1415411604145, 744.4076257511915, 756.8009226521922, 406.5986524312679, 753.6806511917412, 754.5408740694712, 760.6981301035767, 767.0876442564143, 764.165566331445, 760.8144062258909, 730.9094785368845, 746.8860660757049, 755.9513613078402, 205.43957591556614, 754.9991277732051, 746.2054397400857, 761.884339303408, 755.2937113991761, 657.6276157289306, 745.5080520591392, 748.9684871031682, 642.3664590174141, 742.4907056246258, 748.2738428720388, 756.1606768605889, 755.4836486356237, 752.8952845838755, 752.4342402494517, 754.2162092646237, 757.1062291146933, 760.6580331523764, 760.2726821089062, 756.3231244782629, 708.023831316321, 736.1715952142786, 732.9831036176058, 730.9137961022584, 727.9459093423723, 722.534646694074, 729.4190272450893, 721.6077918652772, 728.2842202657022, 720.309476527946, 725.799976275983, 664.7927853906543, 698.4351698801103, 712.5340998900822, 715.6480012129664, 716.7244938965235, 707.1288073752161, 714.0445632888891, 716.0124931668671, 714.180165220247, 719.0575197620215, 720.9567550500627, 722.5164004148583, 724.8819831472968, 721.8210100352958, 716.2950180719407, 713.6565701046251, 717.6400615087322, 713.5196286915797, 718.0845496454042, 718.6771059087437, 717.7624750990665, 718.4275196078747, 719.5595113198957, 754.1173677461572, 763.4969477686763, 765.0509224542751, 767.525338718252, 764.3494066254109, 757.8600618600882, 764.2969118523703, 766.464900249012, 762.7179760759627, 762.4290157762186, 762.911230152451, 759.9299880102062, 767.26252925186, 763.2492981873706, 766.2341492019999, 760.2102021315261, 667.8213036451679, 693.4638404582378, 773.4563446509018, 749.6720268107181, 774.2634266139174]
Elapsed: 0.0621153050551492~0.0202777483967991
Time per graph: 0.001428976442905881~0.00045834897321944164
Speed: 725.4455742196421~83.35249305096565
Total Time: 0.0560
best val loss: 0.6933771371841431 test_score: 0.4884

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
test Score 0.4884
Epoch Time List: [0.1856738510541618, 0.1862029180629179, 0.19305652589537203, 0.1889084989670664, 0.1868659380124882, 0.3102270000381395, 0.18933938501868397, 0.189542090985924, 0.186469912994653, 0.1853916710242629, 0.1862830490572378, 0.1932960341218859, 0.19206689798738807, 0.18918248394038528, 0.2362229758873582, 0.2208525639725849, 0.18797700700815767, 0.186904042144306, 0.18599635211285204, 0.18527241703122854, 0.18653369590174407, 0.19251902389805764, 0.19295163196511567, 0.18765260884538293, 0.3443980098236352, 0.18791651108767837, 0.18825460004154593, 0.18604540615342557, 0.18588442797772586, 0.19530170690268278, 0.1946106778923422, 0.1881941210012883, 0.20537291502114385, 0.1955945799127221, 0.1877030119067058, 0.1875283649424091, 0.1863435439299792, 0.18721118790563196, 0.18756949715316296, 0.18703683197963983, 0.18684160115662962, 0.18492654198780656, 0.1857901078183204, 0.18678808596450835, 0.1864428239641711, 0.1814088320825249, 0.1806389291305095, 0.18156528798863292, 0.1828158990247175, 0.1831885069841519, 0.1814076198497787, 0.18302469106856734, 0.18277277401648462, 0.18398755101952702, 0.18369761703070253, 0.18888245790731162, 0.19788471492938697, 0.18714205001015216, 0.1876390939578414, 0.18632332200650126, 0.1894892459968105, 0.18767285195644945, 0.18672366603277624, 0.18703760707285255, 0.18602745793759823, 0.18596952012740076, 0.18576310796197504, 0.18638291279785335, 0.18673631304409355, 0.18760008399840444, 0.18642998696304858, 0.18582127895206213, 0.18552431708667427, 0.187324594007805, 0.18532386317383498, 0.18675955396611243, 0.18612024409230798, 0.18595322989858687, 0.19004269212018698, 0.18805407406762242, 0.18770617514383048, 0.18771513691172004, 0.1885534047614783, 0.18774462293367833, 0.18741995992604643, 0.18774182710330933, 0.18801068712491542, 0.18801405897829682, 0.18918285297695547, 0.18918305286206305, 0.18757242895662785, 0.18951078213285655, 0.18812773714307696, 0.18718603590968996, 0.19474512292072177, 0.2122558089904487, 0.19687375705689192, 0.19314152095466852, 0.18669864302501082]
Total Epoch List: [44, 34, 21]
Total Time List: [0.058590776985511184, 0.06027041294146329, 0.05603993497788906]
T-times Epoch Time: 0.1856205996466592 ~ 0.004405363566703064
T-times Total Epoch: 88.66666666666667 ~ 39.83577398380617
T-times Total Time: 0.05523905621117189 ~ 0.0021842666551340983
T-times Inference Elapsed: 0.057605114725911184 ~ 0.003209247956915728
T-times Time Per Graph: 0.00132801873629058 ~ 7.199858261551701e-05
T-times Speed: 781.9385811708212 ~ 40.972744309312425
T-times cross validation test micro f1 score:0.6892793181115643 ~ 0.15138427990319672
T-times cross validation test precision:0.6565403748807151 ~ 0.23177761554847298
T-times cross validation test recall:0.7657527657527656 ~ 0.07450307733853356
T-times cross validation test f1_score:0.6892793181115643 ~ 0.17651963453343722
