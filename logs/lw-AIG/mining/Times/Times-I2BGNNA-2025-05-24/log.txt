Namespace(seed=15, model='I2BGNNA', dataset='mining/Times', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/mining/Times/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 72], edge_attr=[72, 2], x=[25, 14887], y=[1, 1], num_nodes=25)
Data(edge_index=[2, 72], edge_attr=[72, 2], x=[25, 14887], y=[1, 1], num_nodes=25)
Data(edge_index=[2, 72], edge_attr=[72, 2], x=[25, 14887], y=[1, 1], num_nodes=25)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a81b3520>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7031;  Loss pred: 0.7031; Loss self: 0.0000; time: 0.29s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6983 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7013 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.7040;  Loss pred: 0.7040; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6982 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7011 score: 0.5000 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.7014;  Loss pred: 0.7014; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6981 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7010 score: 0.5000 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.7027;  Loss pred: 0.7027; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6979 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7008 score: 0.5000 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.7005;  Loss pred: 0.7005; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6977 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7005 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6991;  Loss pred: 0.6991; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7003 score: 0.5000 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6954;  Loss pred: 0.6954; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6973 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7000 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6970 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6997 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6888;  Loss pred: 0.6888; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6994 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6870;  Loss pred: 0.6870; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6966 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6992 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6789;  Loss pred: 0.6789; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6964 score: 0.5116 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6989 score: 0.5000 time: 0.04s
Epoch 12/1000, LR 0.000270
Train loss: 0.6795;  Loss pred: 0.6795; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6986 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6755;  Loss pred: 0.6755; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6959 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6983 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6683;  Loss pred: 0.6683; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6957 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6981 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6634;  Loss pred: 0.6634; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6978 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6574;  Loss pred: 0.6574; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6976 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6526;  Loss pred: 0.6526; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6499;  Loss pred: 0.6499; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6973 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6429;  Loss pred: 0.6429; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6374;  Loss pred: 0.6374; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6316;  Loss pred: 0.6316; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.19s
Epoch 22/1000, LR 0.000270
Train loss: 0.6258;  Loss pred: 0.6258; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6186;  Loss pred: 0.6186; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6187;  Loss pred: 0.6187; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6055;  Loss pred: 0.6055; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6006;  Loss pred: 0.6006; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5967;  Loss pred: 0.5967; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5854;  Loss pred: 0.5854; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5733;  Loss pred: 0.5733; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5659;  Loss pred: 0.5659; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5702;  Loss pred: 0.5702; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5533;  Loss pred: 0.5533; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5485;  Loss pred: 0.5485; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5301;  Loss pred: 0.5301; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5197;  Loss pred: 0.5197; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5030;  Loss pred: 0.5030; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4935;  Loss pred: 0.4935; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4801;  Loss pred: 0.4801; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4789;  Loss pred: 0.4789; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.5000 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4521;  Loss pred: 0.4521; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.5000 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4482;  Loss pred: 0.4482; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.5000 time: 0.04s
Epoch 42/1000, LR 0.000269
Train loss: 0.4312;  Loss pred: 0.4312; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.5000 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4128;  Loss pred: 0.4128; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5116 time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3975;  Loss pred: 0.3975; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.5000 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3917;  Loss pred: 0.3917; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3748;  Loss pred: 0.3748; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3566;  Loss pred: 0.3566; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3445;  Loss pred: 0.3445; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3305;  Loss pred: 0.3305; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3106;  Loss pred: 0.3106; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6866 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5000 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3019;  Loss pred: 0.3019; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6853 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5000 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2833;  Loss pred: 0.2833; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6836 score: 0.5116 time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.5000 time: 0.06s
Epoch 53/1000, LR 0.000269
Train loss: 0.2722;  Loss pred: 0.2722; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6820 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.5000 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2612;  Loss pred: 0.2612; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6806 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6862 score: 0.5000 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2336;  Loss pred: 0.2336; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6851 score: 0.5000 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2275;  Loss pred: 0.2275; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6773 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6838 score: 0.5000 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2137;  Loss pred: 0.2137; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6754 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6823 score: 0.5000 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1961;  Loss pred: 0.1961; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6732 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6805 score: 0.5000 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1899;  Loss pred: 0.1899; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6708 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6786 score: 0.5000 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1797;  Loss pred: 0.1797; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6681 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6764 score: 0.5000 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1605;  Loss pred: 0.1605; Loss self: 0.0000; time: 0.06s
Val loss: 0.6647 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6736 score: 0.5000 time: 0.12s
Epoch 62/1000, LR 0.000268
Train loss: 0.1609;  Loss pred: 0.1609; Loss self: 0.0000; time: 0.08s
Val loss: 0.6610 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6706 score: 0.5000 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1414;  Loss pred: 0.1414; Loss self: 0.0000; time: 0.07s
Val loss: 0.6570 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6673 score: 0.5000 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1297;  Loss pred: 0.1297; Loss self: 0.0000; time: 0.07s
Val loss: 0.6522 score: 0.5349 time: 0.05s
Test loss: 0.6632 score: 0.5227 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1245;  Loss pred: 0.1245; Loss self: 0.0000; time: 0.07s
Val loss: 0.6465 score: 0.5349 time: 0.05s
Test loss: 0.6583 score: 0.5455 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1141;  Loss pred: 0.1141; Loss self: 0.0000; time: 0.07s
Val loss: 0.6404 score: 0.5349 time: 0.05s
Test loss: 0.6531 score: 0.5455 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1089;  Loss pred: 0.1089; Loss self: 0.0000; time: 0.07s
Val loss: 0.6336 score: 0.5349 time: 0.05s
Test loss: 0.6470 score: 0.5682 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0969;  Loss pred: 0.0969; Loss self: 0.0000; time: 0.07s
Val loss: 0.6253 score: 0.5349 time: 0.05s
Test loss: 0.6396 score: 0.5682 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0862;  Loss pred: 0.0862; Loss self: 0.0000; time: 0.07s
Val loss: 0.6161 score: 0.5349 time: 0.05s
Test loss: 0.6315 score: 0.5682 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0799;  Loss pred: 0.0799; Loss self: 0.0000; time: 0.07s
Val loss: 0.6057 score: 0.5581 time: 0.05s
Test loss: 0.6224 score: 0.5909 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0726;  Loss pred: 0.0726; Loss self: 0.0000; time: 0.07s
Val loss: 0.5947 score: 0.5581 time: 0.05s
Test loss: 0.6130 score: 0.5909 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0712;  Loss pred: 0.0712; Loss self: 0.0000; time: 0.07s
Val loss: 0.5837 score: 0.5581 time: 0.05s
Test loss: 0.6037 score: 0.5909 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0674;  Loss pred: 0.0674; Loss self: 0.0000; time: 0.07s
Val loss: 0.5722 score: 0.6047 time: 0.05s
Test loss: 0.5941 score: 0.6136 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0577;  Loss pred: 0.0577; Loss self: 0.0000; time: 0.07s
Val loss: 0.5600 score: 0.6047 time: 0.05s
Test loss: 0.5840 score: 0.6136 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0558;  Loss pred: 0.0558; Loss self: 0.0000; time: 0.07s
Val loss: 0.5480 score: 0.6279 time: 0.05s
Test loss: 0.5743 score: 0.6364 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0499;  Loss pred: 0.0499; Loss self: 0.0000; time: 0.07s
Val loss: 0.5353 score: 0.6512 time: 0.05s
Test loss: 0.5641 score: 0.6591 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0475;  Loss pred: 0.0475; Loss self: 0.0000; time: 0.07s
Val loss: 0.5213 score: 0.6744 time: 0.05s
Test loss: 0.5529 score: 0.6591 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0404;  Loss pred: 0.0404; Loss self: 0.0000; time: 0.07s
Val loss: 0.5067 score: 0.6744 time: 0.05s
Test loss: 0.5411 score: 0.6591 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0368;  Loss pred: 0.0368; Loss self: 0.0000; time: 0.07s
Val loss: 0.4919 score: 0.7209 time: 0.05s
Test loss: 0.5294 score: 0.6818 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0379;  Loss pred: 0.0379; Loss self: 0.0000; time: 0.07s
Val loss: 0.4759 score: 0.7209 time: 0.05s
Test loss: 0.5169 score: 0.7045 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0349;  Loss pred: 0.0349; Loss self: 0.0000; time: 0.07s
Val loss: 0.4598 score: 0.7442 time: 0.05s
Test loss: 0.5043 score: 0.7045 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0297;  Loss pred: 0.0297; Loss self: 0.0000; time: 0.08s
Val loss: 0.4432 score: 0.7674 time: 0.06s
Test loss: 0.4914 score: 0.7273 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0272;  Loss pred: 0.0272; Loss self: 0.0000; time: 0.07s
Val loss: 0.4270 score: 0.7674 time: 0.05s
Test loss: 0.4790 score: 0.7500 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0248;  Loss pred: 0.0248; Loss self: 0.0000; time: 0.07s
Val loss: 0.4114 score: 0.7907 time: 0.05s
Test loss: 0.4673 score: 0.7727 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0232;  Loss pred: 0.0232; Loss self: 0.0000; time: 0.07s
Val loss: 0.3965 score: 0.7907 time: 0.05s
Test loss: 0.4565 score: 0.7727 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0218;  Loss pred: 0.0218; Loss self: 0.0000; time: 0.07s
Val loss: 0.3825 score: 0.8372 time: 0.05s
Test loss: 0.4465 score: 0.7727 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0176;  Loss pred: 0.0176; Loss self: 0.0000; time: 0.07s
Val loss: 0.3685 score: 0.8605 time: 0.05s
Test loss: 0.4367 score: 0.7955 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0184;  Loss pred: 0.0184; Loss self: 0.0000; time: 0.07s
Val loss: 0.3560 score: 0.9070 time: 0.05s
Test loss: 0.4284 score: 0.7727 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.07s
Val loss: 0.3454 score: 0.9070 time: 0.05s
Test loss: 0.4222 score: 0.7727 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0168;  Loss pred: 0.0168; Loss self: 0.0000; time: 0.07s
Val loss: 0.3350 score: 0.9070 time: 0.05s
Test loss: 0.4163 score: 0.7727 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.07s
Val loss: 0.3254 score: 0.9070 time: 0.05s
Test loss: 0.4110 score: 0.7727 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.07s
Val loss: 0.3166 score: 0.9070 time: 0.05s
Test loss: 0.4063 score: 0.7727 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0131;  Loss pred: 0.0131; Loss self: 0.0000; time: 0.07s
Val loss: 0.3081 score: 0.9070 time: 0.05s
Test loss: 0.4021 score: 0.7727 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.07s
Val loss: 0.3000 score: 0.9070 time: 0.05s
Test loss: 0.3982 score: 0.7955 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.07s
Val loss: 0.2928 score: 0.9070 time: 0.05s
Test loss: 0.3952 score: 0.7955 time: 0.05s
Epoch 96/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.2861 score: 0.8837 time: 0.05s
Test loss: 0.3927 score: 0.7955 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.07s
Val loss: 0.2806 score: 0.8837 time: 0.05s
Test loss: 0.3911 score: 0.7955 time: 0.05s
Epoch 98/1000, LR 0.000265
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.07s
Val loss: 0.2763 score: 0.8837 time: 0.06s
Test loss: 0.3908 score: 0.7955 time: 0.05s
Epoch 99/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.2726 score: 0.8837 time: 0.05s
Test loss: 0.3909 score: 0.8182 time: 0.05s
Epoch 100/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.07s
Val loss: 0.2696 score: 0.8837 time: 0.05s
Test loss: 0.3915 score: 0.8182 time: 0.05s
Epoch 101/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.2672 score: 0.8837 time: 0.05s
Test loss: 0.3928 score: 0.8409 time: 0.05s
Epoch 102/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.2646 score: 0.8837 time: 0.05s
Test loss: 0.3934 score: 0.8409 time: 0.05s
Epoch 103/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.2632 score: 0.8837 time: 0.05s
Test loss: 0.3951 score: 0.8409 time: 0.05s
Epoch 104/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.2617 score: 0.8837 time: 0.06s
Test loss: 0.3962 score: 0.8636 time: 0.06s
Epoch 105/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.2610 score: 0.8837 time: 0.06s
Test loss: 0.3979 score: 0.8636 time: 0.05s
Epoch 106/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.2606 score: 0.8837 time: 0.05s
Test loss: 0.3995 score: 0.8636 time: 0.05s
Epoch 107/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.2608 score: 0.8837 time: 0.05s
Test loss: 0.4018 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.2613 score: 0.9070 time: 0.05s
Test loss: 0.4044 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.2618 score: 0.9070 time: 0.05s
Test loss: 0.4066 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.2626 score: 0.9070 time: 0.05s
Test loss: 0.4087 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.2634 score: 0.9070 time: 0.05s
Test loss: 0.4109 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.2645 score: 0.8837 time: 0.05s
Test loss: 0.4136 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.2657 score: 0.8837 time: 0.05s
Test loss: 0.4163 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.2668 score: 0.8837 time: 0.05s
Test loss: 0.4184 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.2682 score: 0.8837 time: 0.05s
Test loss: 0.4209 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.07s
Val loss: 0.2695 score: 0.8837 time: 0.05s
Test loss: 0.4238 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.2707 score: 0.8837 time: 0.05s
Test loss: 0.4261 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.07s
Val loss: 0.2718 score: 0.8837 time: 0.05s
Test loss: 0.4282 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.2728 score: 0.8837 time: 0.05s
Test loss: 0.4302 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.07s
Val loss: 0.2738 score: 0.8837 time: 0.05s
Test loss: 0.4323 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.07s
Val loss: 0.2749 score: 0.8837 time: 0.06s
Test loss: 0.4343 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 122/1000, LR 0.000262
Train loss: 0.0034;  Loss pred: 0.0034; Loss self: 0.0000; time: 0.07s
Val loss: 0.2759 score: 0.8837 time: 0.05s
Test loss: 0.4364 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 123/1000, LR 0.000262
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.07s
Val loss: 0.2769 score: 0.8837 time: 0.05s
Test loss: 0.4386 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 124/1000, LR 0.000261
Train loss: 0.0032;  Loss pred: 0.0032; Loss self: 0.0000; time: 0.07s
Val loss: 0.2777 score: 0.8837 time: 0.05s
Test loss: 0.4397 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 125/1000, LR 0.000261
Train loss: 0.0035;  Loss pred: 0.0035; Loss self: 0.0000; time: 0.07s
Val loss: 0.2787 score: 0.8837 time: 0.06s
Test loss: 0.4412 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 126/1000, LR 0.000261
Train loss: 0.0031;  Loss pred: 0.0031; Loss self: 0.0000; time: 0.07s
Val loss: 0.2797 score: 0.8837 time: 0.06s
Test loss: 0.4431 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 105,   Train_Loss: 0.0068,   Val_Loss: 0.2606,   Val_Precision: 0.8400,   Val_Recall: 0.9545,   Val_accuracy: 0.8936,   Val_Score: 0.8837,   Val_Loss: 0.2606,   Test_Precision: 0.8333,   Test_Recall: 0.9091,   Test_accuracy: 0.8696,   Test_Score: 0.8636,   Test_loss: 0.3995


[0.05345530004706234, 0.05335202196147293, 0.05365341296419501, 0.06008344900328666, 0.054768183967098594, 0.05438750598113984, 0.05662208399735391, 0.05469117406755686, 0.054770804941654205, 0.05451968603301793, 0.04907143593300134, 0.05006279796361923, 0.049990538973361254, 0.0503107929835096, 0.05122050305362791, 0.05069822701625526, 0.051311152055859566, 0.05095531593542546, 0.05093483906239271, 0.05086309590842575, 0.1941265920177102, 0.05480933899525553, 0.05512766202446073, 0.054957903921604156, 0.054851212073117495, 0.05539399909321219, 0.055130888940766454, 0.056992194964550436, 0.051255083992145956, 0.051183989038690925, 0.051951918983832, 0.05120980297215283, 0.05206560296937823, 0.050571169005706906, 0.05065702192950994, 0.05125729902647436, 0.05194280599243939, 0.05092356808017939, 0.05305691703688353, 0.050835956004448235, 0.049705796991474926, 0.051686970982700586, 0.05454093299340457, 0.05443206196650863, 0.054367152974009514, 0.054409870062954724, 0.05434901197440922, 0.052142050000838935, 0.050861751078628004, 0.05138757801614702, 0.05094680702313781, 0.06103980902116746, 0.05074983707163483, 0.051034083939157426, 0.050911087077111006, 0.051480274996720254, 0.05213106097653508, 0.051546753966249526, 0.051608129986561835, 0.053958500968292356, 0.1263940860517323, 0.05564287700690329, 0.056148070958442986, 0.055469280923716724, 0.05586373002734035, 0.05594266694970429, 0.05644234106875956, 0.05590913200285286, 0.055834177997894585, 0.05589120404329151, 0.05648133601062, 0.056412779027596116, 0.055959837045520544, 0.05606647697277367, 0.05628147698007524, 0.056167342932894826, 0.05666964501142502, 0.056592431967146695, 0.05629748501814902, 0.05594882206059992, 0.056260338984429836, 0.05682837695349008, 0.05616825202014297, 0.0567413599928841, 0.05667519092094153, 0.05660115904174745, 0.05620737397111952, 0.05662684596609324, 0.05659314803779125, 0.05679090099874884, 0.0564849249785766, 0.05666331702377647, 0.05672156298533082, 0.05680249095894396, 0.05664221302140504, 0.05665295396465808, 0.05651035706978291, 0.05760233209002763, 0.05642682500183582, 0.05640399095136672, 0.05594621901400387, 0.055827262927778065, 0.056796840974129736, 0.06165442802011967, 0.05938215204514563, 0.05587540194392204, 0.056064456002786756, 0.05588026705663651, 0.056068286998197436, 0.05568802997004241, 0.05491437599994242, 0.054884094977751374, 0.05439047503750771, 0.05141773400828242, 0.0510263399919495, 0.05666929704602808, 0.05252925003878772, 0.052746000001206994, 0.05292037990875542, 0.052703340887092054, 0.05580456601455808, 0.05226187803782523, 0.05538289900869131, 0.05243772896938026, 0.05734907102305442, 0.055093011003918946]
[0.0012148931828877803, 0.0012125459536698393, 0.0012193957491862502, 0.0013655329318928786, 0.0012447314537976954, 0.0012360796813895417, 0.001286865545394407, 0.0012429812288081105, 0.001244791021401232, 0.0012390837734776803, 0.0011152599075682122, 0.001137790862809528, 0.0011361486130309377, 0.0011434271132615818, 0.001164102342127907, 0.0011522324321876195, 0.001166162546724081, 0.0011580753621687604, 0.0011576099786907434, 0.0011559794524642216, 0.004411968000402505, 0.0012456667953467165, 0.0012529014096468347, 0.001249043270945549, 0.0012466184562072158, 0.0012589545248457316, 0.001252974748653783, 0.0012952771582852372, 0.0011648882725487717, 0.0011632724781520665, 0.0011807254314507272, 0.0011638591584580188, 0.00118330915839496, 0.0011493447501297023, 0.0011512959529434077, 0.0011649386142380536, 0.0011805183180099862, 0.001157353820004077, 0.001205839023565535, 0.0011553626364647325, 0.0011296772043517028, 0.0011747038859704678, 0.001239566658941013, 0.0012370923174206507, 0.0012356171130456707, 0.0012365879559762436, 0.0012352048176002097, 0.0011850465909281577, 0.0011559488881506365, 0.0011678995003669777, 0.0011578819777985866, 0.001387268386844715, 0.0011534053879917008, 0.0011598655440717596, 0.001157070160843432, 0.0011700062499254602, 0.0011847968403757973, 0.0011715171355965801, 0.0011729120451491326, 0.00122632956746119, 0.0028725928648120976, 0.0012646108410659838, 0.001276092521782795, 0.0012606654755390164, 0.0012696302278940989, 0.0012714242488569157, 0.0012827804788354445, 0.0012706620909739286, 0.0012689585908612405, 0.0012702546373475343, 0.0012836667275140908, 0.0012821086142635481, 0.001271814478307285, 0.0012742381130175834, 0.001279124476819892, 0.0012765305212021551, 0.0012879464775323868, 0.0012861916356169704, 0.0012794882958670232, 0.0012715641377409074, 0.0012786440678279507, 0.001291554021670229, 0.0012765511822759765, 0.0012895763634746386, 0.0012880725209304894, 0.001286389978221533, 0.0012774403175254438, 0.0012869737719566647, 0.0012862079099498012, 0.00129070229542611, 0.00128374829496765, 0.0012878026596312834, 0.0012891264314847913, 0.0012909657036123629, 0.001287323023213751, 0.0012875671355604109, 0.0012843262970405208, 0.0013091439111369916, 0.0012824278409508142, 0.0012819088852583345, 0.0012715049775909972, 0.0012688014301767742, 0.001290837294866585, 0.0014012370004572651, 0.0013495943646624007, 0.001269895498725501, 0.0012741921818815172, 0.0012700060694690117, 0.0012742792499590325, 0.001265637044773691, 0.0012480539999986913, 0.001247365794948895, 0.0012361471599433571, 0.0011685848638246005, 0.0011596895452715796, 0.0012879385692279109, 0.00119384659179063, 0.001198772727300159, 0.0012027359070171688, 0.0011978032019793648, 0.0012682855912399564, 0.0011877699554051187, 0.0012587022501975298, 0.001191766567485915, 0.0013033879777966913, 0.0012521138864527034]
[823.1176321386683, 824.7110115484227, 820.0783057242396, 732.3148176395987, 803.3861416042668, 809.0093341521865, 777.0819597889796, 804.5173787209127, 803.3476967678668, 807.0479344534916, 896.6519761124268, 878.8961422406898, 880.1665455826858, 874.563833935631, 859.0310008070785, 867.880448479833, 857.5133910869839, 863.5016620397413, 863.8488078091723, 865.0672794125212, 226.65622232726298, 802.7828980716001, 798.1473979519888, 800.6127756030272, 802.1700585457863, 794.309866055358, 798.1006808592246, 772.0355397325603, 858.4514271158412, 859.6438227340894, 846.9369536415637, 859.2104918647428, 845.0876872755719, 870.0609628983392, 868.586393831574, 858.4143299722842, 847.0855426332664, 864.0400046344316, 829.2980907543601, 865.5291147893416, 885.2086207881641, 851.2783620987699, 806.7335409410902, 808.3471103312723, 809.3121966683526, 808.6768071507977, 809.5823346470004, 843.8486787399434, 865.0901525584459, 856.2380578857853, 863.6458803005481, 720.8410495639268, 866.997857311202, 862.1688997583767, 864.2518265885125, 854.6962890700017, 844.0265587497829, 853.5940018416912, 852.5788477795475, 815.4414820725974, 348.1175533955843, 790.7570989641886, 783.6422382625724, 793.2318441356816, 787.6309007376682, 786.5195279223738, 779.5566088656392, 786.9912914719339, 788.0477796531574, 787.2437309799058, 779.0183998432124, 779.9651206418317, 786.2782009927618, 784.7826789859964, 781.7847427063236, 783.3733572294564, 776.4297798429702, 777.4891177241346, 781.5624443226089, 786.4330003649088, 782.0784729394733, 774.2610709436734, 783.360678274638, 775.4484560383821, 776.3538028725363, 777.3692402225689, 782.8154366828823, 777.0166119855256, 777.4792801880907, 774.7720009050281, 778.9689021750169, 776.5164891694776, 775.7191037098037, 774.6139166995789, 776.8058070642903, 776.6585309470112, 778.6183326653863, 763.8579620566695, 779.7709688356288, 780.0866438323162, 786.469591251312, 788.1453915611336, 774.6909730426989, 713.6551487533303, 740.9633784667949, 787.466371054646, 784.8109682507742, 787.3978117428203, 784.7573442258825, 790.1159373687661, 801.2473819250197, 801.6894515220938, 808.9651721125356, 855.735882738676, 862.2997457184259, 776.4345473398446, 837.6285587079636, 834.1864785764445, 831.4377197568155, 834.8616854150199, 788.4659471864982, 841.9138701474604, 794.4690651367857, 839.0904958087093, 767.23125963648, 798.6493966879054]
Elapsed: 0.05606226724505957~0.01413301340389973
Time per graph: 0.0012741424373877172~0.0003212048500886303
Speed: 802.5845937743583~76.06492149336182
Total Time: 0.0557
best val loss: 0.26060670614242554 test_score: 0.8636

Testing...
Test loss: 0.4284 score: 0.7727 time: 0.05s
test Score 0.7727
Epoch Time List: [0.3953267310280353, 0.163774271029979, 0.16709847911261022, 0.1736071859486401, 0.1814392131054774, 0.17101437400560826, 0.1733871620381251, 0.17446275218389928, 0.17270455602556467, 0.17102167394477874, 0.2935880918521434, 0.15724992391187698, 0.15791298111435026, 0.15764300292357802, 0.1570837430190295, 0.16603583109099418, 0.15952609106898308, 0.1637241590069607, 0.16027185996063054, 0.15876670693978667, 0.3022761069005355, 0.17059148696716875, 0.17146894102916121, 0.17133061808999628, 0.1715478270780295, 0.17143540608230978, 0.17244740691967309, 0.17668951803352684, 0.16205942211672664, 0.15910033194813877, 0.15972990600857884, 0.25787733390461653, 0.16039869410451502, 0.15845292690210044, 0.15986342704854906, 0.1595118959667161, 0.162252196110785, 0.1670778290135786, 0.16112114395946264, 0.1626806070562452, 0.1562420369591564, 0.15684873389545828, 0.2660882141208276, 0.16956370207481086, 0.16908078989945352, 0.1685571379493922, 0.1697788309538737, 0.1640570560703054, 0.16036046296358109, 0.1591018739854917, 0.1599582409253344, 0.3199528199620545, 0.16118808602914214, 0.15849063196219504, 0.1584856059635058, 0.1603177699726075, 0.1609952028375119, 0.16985826008021832, 0.16151070012710989, 0.16181473701726645, 0.23664692603051662, 0.18400501902215183, 0.17375044291839004, 0.17305170197505504, 0.17360578197985888, 0.17322358500678092, 0.1751155350357294, 0.17329018318559974, 0.17410216596908867, 0.17390741605777293, 0.174434743123129, 0.17468408297281712, 0.17369513399899006, 0.17433397902641445, 0.17421403003390878, 0.17464080592617393, 0.1757492240285501, 0.17472369596362114, 0.17495227011386305, 0.17503687797579914, 0.1759612428722903, 0.18441417592111975, 0.17763835401274264, 0.17552517796866596, 0.17531463806517422, 0.17493232595734298, 0.1752824359573424, 0.17558589403051883, 0.17490696697495878, 0.17560751910787076, 0.17532307701185346, 0.1759726230520755, 0.17597887199372053, 0.17627642897423357, 0.17544958391226828, 0.17584756296128035, 0.17585248604882509, 0.17708558193407953, 0.17690792202483863, 0.17702344001736492, 0.1755319320363924, 0.17599504010286182, 0.17674084706231952, 0.18992511206306517, 0.18810730299446732, 0.17615708091761917, 0.17605788097716868, 0.17570833396166563, 0.17640605696942657, 0.17477357399184257, 0.17384687601588666, 0.1709499468561262, 0.16963975399266928, 0.1682941319886595, 0.1609153610188514, 0.16731517994776368, 0.17130087595432997, 0.16767897410318255, 0.168310169945471, 0.16708453197497874, 0.1761298921192065, 0.16863204597029835, 0.17145734908990562, 0.16655033791903406, 0.182291125995107, 0.17497949593234807]
Total Epoch List: [126]
Total Time List: [0.055701536941342056]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a82e7a60>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6990;  Loss pred: 0.6990; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6996;  Loss pred: 0.6996; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6965;  Loss pred: 0.6965; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6970;  Loss pred: 0.6970; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6950;  Loss pred: 0.6950; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6878;  Loss pred: 0.6878; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6864;  Loss pred: 0.6864; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6833;  Loss pred: 0.6833; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6792;  Loss pred: 0.6792; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6759;  Loss pred: 0.6759; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6691;  Loss pred: 0.6691; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6662;  Loss pred: 0.6662; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6611;  Loss pred: 0.6611; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6555;  Loss pred: 0.6555; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6522;  Loss pred: 0.6522; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6487;  Loss pred: 0.6487; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6356;  Loss pred: 0.6356; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6343;  Loss pred: 0.6343; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6261;  Loss pred: 0.6261; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6141;  Loss pred: 0.6141; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6054;  Loss pred: 0.6054; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5956;  Loss pred: 0.5956; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5886;  Loss pred: 0.5886; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5815;  Loss pred: 0.5815; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5661;  Loss pred: 0.5661; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5525;  Loss pred: 0.5525; Loss self: 0.0000; time: 0.08s
Val loss: 0.6909 score: 0.4545 time: 0.05s
Test loss: 0.6911 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5433;  Loss pred: 0.5433; Loss self: 0.0000; time: 0.07s
Val loss: 0.6905 score: 0.5909 time: 0.05s
Test loss: 0.6908 score: 0.5581 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5324;  Loss pred: 0.5324; Loss self: 0.0000; time: 0.07s
Val loss: 0.6901 score: 0.6591 time: 0.05s
Test loss: 0.6905 score: 0.5581 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5175;  Loss pred: 0.5175; Loss self: 0.0000; time: 0.08s
Val loss: 0.6896 score: 0.7727 time: 0.05s
Test loss: 0.6901 score: 0.6744 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5031;  Loss pred: 0.5031; Loss self: 0.0000; time: 0.08s
Val loss: 0.6890 score: 0.7955 time: 0.05s
Test loss: 0.6897 score: 0.8140 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.4864;  Loss pred: 0.4864; Loss self: 0.0000; time: 0.08s
Val loss: 0.6883 score: 0.8182 time: 0.05s
Test loss: 0.6892 score: 0.8372 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4796;  Loss pred: 0.4796; Loss self: 0.0000; time: 0.08s
Val loss: 0.6876 score: 0.8409 time: 0.05s
Test loss: 0.6886 score: 0.8140 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4550;  Loss pred: 0.4550; Loss self: 0.0000; time: 0.08s
Val loss: 0.6867 score: 0.8182 time: 0.05s
Test loss: 0.6880 score: 0.8140 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4431;  Loss pred: 0.4431; Loss self: 0.0000; time: 0.08s
Val loss: 0.6857 score: 0.8182 time: 0.05s
Test loss: 0.6872 score: 0.8140 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4215;  Loss pred: 0.4215; Loss self: 0.0000; time: 0.08s
Val loss: 0.6846 score: 0.8182 time: 0.05s
Test loss: 0.6863 score: 0.7907 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4056;  Loss pred: 0.4056; Loss self: 0.0000; time: 0.08s
Val loss: 0.6832 score: 0.8182 time: 0.05s
Test loss: 0.6852 score: 0.7907 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.3910;  Loss pred: 0.3910; Loss self: 0.0000; time: 0.08s
Val loss: 0.6818 score: 0.8182 time: 0.05s
Test loss: 0.6841 score: 0.8140 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.3771;  Loss pred: 0.3771; Loss self: 0.0000; time: 0.08s
Val loss: 0.6801 score: 0.8182 time: 0.05s
Test loss: 0.6828 score: 0.8140 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3656;  Loss pred: 0.3656; Loss self: 0.0000; time: 0.08s
Val loss: 0.6782 score: 0.8182 time: 0.05s
Test loss: 0.6813 score: 0.8372 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3450;  Loss pred: 0.3450; Loss self: 0.0000; time: 0.08s
Val loss: 0.6761 score: 0.8182 time: 0.05s
Test loss: 0.6795 score: 0.8372 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3302;  Loss pred: 0.3302; Loss self: 0.0000; time: 0.08s
Val loss: 0.6737 score: 0.8182 time: 0.05s
Test loss: 0.6777 score: 0.8372 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3171;  Loss pred: 0.3171; Loss self: 0.0000; time: 0.08s
Val loss: 0.6711 score: 0.8182 time: 0.05s
Test loss: 0.6756 score: 0.8372 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.2908;  Loss pred: 0.2908; Loss self: 0.0000; time: 0.08s
Val loss: 0.6683 score: 0.8409 time: 0.05s
Test loss: 0.6733 score: 0.8372 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.2860;  Loss pred: 0.2860; Loss self: 0.0000; time: 0.07s
Val loss: 0.6652 score: 0.8182 time: 0.05s
Test loss: 0.6709 score: 0.8372 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2637;  Loss pred: 0.2637; Loss self: 0.0000; time: 0.08s
Val loss: 0.6617 score: 0.8182 time: 0.05s
Test loss: 0.6683 score: 0.8372 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2559;  Loss pred: 0.2559; Loss self: 0.0000; time: 0.08s
Val loss: 0.6579 score: 0.8182 time: 0.05s
Test loss: 0.6654 score: 0.8372 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2417;  Loss pred: 0.2417; Loss self: 0.0000; time: 0.08s
Val loss: 0.6537 score: 0.8409 time: 0.05s
Test loss: 0.6622 score: 0.8140 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2216;  Loss pred: 0.2216; Loss self: 0.0000; time: 0.07s
Val loss: 0.6490 score: 0.8636 time: 0.05s
Test loss: 0.6587 score: 0.8140 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2196;  Loss pred: 0.2196; Loss self: 0.0000; time: 0.08s
Val loss: 0.6440 score: 0.8409 time: 0.05s
Test loss: 0.6550 score: 0.8140 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2035;  Loss pred: 0.2035; Loss self: 0.0000; time: 0.08s
Val loss: 0.6385 score: 0.8409 time: 0.05s
Test loss: 0.6509 score: 0.8140 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.1892;  Loss pred: 0.1892; Loss self: 0.0000; time: 0.07s
Val loss: 0.6325 score: 0.8409 time: 0.05s
Test loss: 0.6466 score: 0.8140 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.1700;  Loss pred: 0.1700; Loss self: 0.0000; time: 0.07s
Val loss: 0.6261 score: 0.8409 time: 0.05s
Test loss: 0.6420 score: 0.8140 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1663;  Loss pred: 0.1663; Loss self: 0.0000; time: 0.08s
Val loss: 0.6192 score: 0.8864 time: 0.05s
Test loss: 0.6371 score: 0.8140 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1503;  Loss pred: 0.1503; Loss self: 0.0000; time: 0.08s
Val loss: 0.6119 score: 0.8864 time: 0.05s
Test loss: 0.6322 score: 0.7907 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1402;  Loss pred: 0.1402; Loss self: 0.0000; time: 0.08s
Val loss: 0.6039 score: 0.8864 time: 0.05s
Test loss: 0.6269 score: 0.7907 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1341;  Loss pred: 0.1341; Loss self: 0.0000; time: 0.08s
Val loss: 0.5956 score: 0.8864 time: 0.05s
Test loss: 0.6215 score: 0.7907 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1190;  Loss pred: 0.1190; Loss self: 0.0000; time: 0.08s
Val loss: 0.5871 score: 0.8864 time: 0.05s
Test loss: 0.6160 score: 0.7674 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1158;  Loss pred: 0.1158; Loss self: 0.0000; time: 0.08s
Val loss: 0.5780 score: 0.8864 time: 0.05s
Test loss: 0.6103 score: 0.7674 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1033;  Loss pred: 0.1033; Loss self: 0.0000; time: 0.08s
Val loss: 0.5687 score: 0.8864 time: 0.05s
Test loss: 0.6046 score: 0.7674 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.0972;  Loss pred: 0.0972; Loss self: 0.0000; time: 0.08s
Val loss: 0.5592 score: 0.9091 time: 0.05s
Test loss: 0.5988 score: 0.7674 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.0934;  Loss pred: 0.0934; Loss self: 0.0000; time: 0.08s
Val loss: 0.5494 score: 0.9091 time: 0.05s
Test loss: 0.5932 score: 0.7674 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0865;  Loss pred: 0.0865; Loss self: 0.0000; time: 0.08s
Val loss: 0.5397 score: 0.9091 time: 0.05s
Test loss: 0.5877 score: 0.7674 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0779;  Loss pred: 0.0779; Loss self: 0.0000; time: 0.07s
Val loss: 0.5295 score: 0.9091 time: 0.05s
Test loss: 0.5822 score: 0.7674 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0724;  Loss pred: 0.0724; Loss self: 0.0000; time: 0.07s
Val loss: 0.5194 score: 0.9091 time: 0.05s
Test loss: 0.5768 score: 0.7674 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0663;  Loss pred: 0.0663; Loss self: 0.0000; time: 0.08s
Val loss: 0.5094 score: 0.9091 time: 0.05s
Test loss: 0.5716 score: 0.7674 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0603;  Loss pred: 0.0603; Loss self: 0.0000; time: 0.08s
Val loss: 0.4993 score: 0.9091 time: 0.05s
Test loss: 0.5665 score: 0.7674 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0546;  Loss pred: 0.0546; Loss self: 0.0000; time: 0.08s
Val loss: 0.4893 score: 0.9091 time: 0.05s
Test loss: 0.5617 score: 0.7674 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0548;  Loss pred: 0.0548; Loss self: 0.0000; time: 0.08s
Val loss: 0.4796 score: 0.9091 time: 0.05s
Test loss: 0.5575 score: 0.7674 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0456;  Loss pred: 0.0456; Loss self: 0.0000; time: 0.08s
Val loss: 0.4701 score: 0.9091 time: 0.05s
Test loss: 0.5538 score: 0.7674 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0431;  Loss pred: 0.0431; Loss self: 0.0000; time: 0.08s
Val loss: 0.4608 score: 0.9091 time: 0.05s
Test loss: 0.5506 score: 0.7674 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0395;  Loss pred: 0.0395; Loss self: 0.0000; time: 0.08s
Val loss: 0.4517 score: 0.9091 time: 0.05s
Test loss: 0.5481 score: 0.7674 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0363;  Loss pred: 0.0363; Loss self: 0.0000; time: 0.08s
Val loss: 0.4431 score: 0.9091 time: 0.05s
Test loss: 0.5464 score: 0.7674 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0349;  Loss pred: 0.0349; Loss self: 0.0000; time: 0.07s
Val loss: 0.4353 score: 0.9091 time: 0.05s
Test loss: 0.5457 score: 0.7674 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0321;  Loss pred: 0.0321; Loss self: 0.0000; time: 0.07s
Val loss: 0.4287 score: 0.9091 time: 0.05s
Test loss: 0.5461 score: 0.7674 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0298;  Loss pred: 0.0298; Loss self: 0.0000; time: 0.17s
Val loss: 0.4228 score: 0.9091 time: 0.06s
Test loss: 0.5476 score: 0.7674 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0265;  Loss pred: 0.0265; Loss self: 0.0000; time: 0.08s
Val loss: 0.4182 score: 0.9091 time: 0.05s
Test loss: 0.5502 score: 0.7674 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0257;  Loss pred: 0.0257; Loss self: 0.0000; time: 0.08s
Val loss: 0.4145 score: 0.9091 time: 0.05s
Test loss: 0.5543 score: 0.7674 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0214;  Loss pred: 0.0214; Loss self: 0.0000; time: 0.08s
Val loss: 0.4116 score: 0.9091 time: 0.05s
Test loss: 0.5594 score: 0.7674 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0285;  Loss pred: 0.0285; Loss self: 0.0000; time: 0.08s
Val loss: 0.4117 score: 0.9091 time: 0.05s
Test loss: 0.5671 score: 0.7674 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 82/1000, LR 0.000267
Train loss: 0.0189;  Loss pred: 0.0189; Loss self: 0.0000; time: 0.08s
Val loss: 0.4129 score: 0.9318 time: 0.05s
Test loss: 0.5767 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 83/1000, LR 0.000266
Train loss: 0.0176;  Loss pred: 0.0176; Loss self: 0.0000; time: 0.08s
Val loss: 0.4153 score: 0.9318 time: 0.05s
Test loss: 0.5877 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 84/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.08s
Val loss: 0.4192 score: 0.9318 time: 0.05s
Test loss: 0.6010 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 85/1000, LR 0.000266
Train loss: 0.0155;  Loss pred: 0.0155; Loss self: 0.0000; time: 0.08s
Val loss: 0.4245 score: 0.9318 time: 0.05s
Test loss: 0.6161 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 86/1000, LR 0.000266
Train loss: 0.0153;  Loss pred: 0.0153; Loss self: 0.0000; time: 0.07s
Val loss: 0.4305 score: 0.9318 time: 0.05s
Test loss: 0.6326 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 87/1000, LR 0.000266
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.07s
Val loss: 0.4373 score: 0.9318 time: 0.05s
Test loss: 0.6504 score: 0.8140 time: 0.18s
     INFO: Early stopping counter 7 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.07s
Val loss: 0.4453 score: 0.9318 time: 0.05s
Test loss: 0.6701 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.07s
Val loss: 0.4536 score: 0.9091 time: 0.05s
Test loss: 0.6902 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.07s
Val loss: 0.4634 score: 0.9091 time: 0.05s
Test loss: 0.7130 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.07s
Val loss: 0.4737 score: 0.9091 time: 0.05s
Test loss: 0.7364 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.07s
Val loss: 0.4855 score: 0.9091 time: 0.05s
Test loss: 0.7619 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.4976 score: 0.9091 time: 0.05s
Test loss: 0.7882 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.08s
Val loss: 0.5106 score: 0.9091 time: 0.05s
Test loss: 0.8153 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.08s
Val loss: 0.5235 score: 0.8864 time: 0.05s
Test loss: 0.8422 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.07s
Val loss: 0.5370 score: 0.8864 time: 0.05s
Test loss: 0.8698 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.07s
Val loss: 0.5504 score: 0.8864 time: 0.05s
Test loss: 0.8971 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.07s
Val loss: 0.5647 score: 0.8864 time: 0.17s
Test loss: 0.9246 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.5791 score: 0.8864 time: 0.05s
Test loss: 0.9524 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.07s
Val loss: 0.5935 score: 0.8864 time: 0.05s
Test loss: 0.9801 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 079,   Train_Loss: 0.0214,   Val_Loss: 0.4116,   Val_Precision: 0.9500,   Val_Recall: 0.8636,   Val_accuracy: 0.9048,   Val_Score: 0.9091,   Val_Loss: 0.4116,   Test_Precision: 0.8000,   Test_Recall: 0.7273,   Test_accuracy: 0.7619,   Test_Score: 0.7674,   Test_loss: 0.5594


[0.05345530004706234, 0.05335202196147293, 0.05365341296419501, 0.06008344900328666, 0.054768183967098594, 0.05438750598113984, 0.05662208399735391, 0.05469117406755686, 0.054770804941654205, 0.05451968603301793, 0.04907143593300134, 0.05006279796361923, 0.049990538973361254, 0.0503107929835096, 0.05122050305362791, 0.05069822701625526, 0.051311152055859566, 0.05095531593542546, 0.05093483906239271, 0.05086309590842575, 0.1941265920177102, 0.05480933899525553, 0.05512766202446073, 0.054957903921604156, 0.054851212073117495, 0.05539399909321219, 0.055130888940766454, 0.056992194964550436, 0.051255083992145956, 0.051183989038690925, 0.051951918983832, 0.05120980297215283, 0.05206560296937823, 0.050571169005706906, 0.05065702192950994, 0.05125729902647436, 0.05194280599243939, 0.05092356808017939, 0.05305691703688353, 0.050835956004448235, 0.049705796991474926, 0.051686970982700586, 0.05454093299340457, 0.05443206196650863, 0.054367152974009514, 0.054409870062954724, 0.05434901197440922, 0.052142050000838935, 0.050861751078628004, 0.05138757801614702, 0.05094680702313781, 0.06103980902116746, 0.05074983707163483, 0.051034083939157426, 0.050911087077111006, 0.051480274996720254, 0.05213106097653508, 0.051546753966249526, 0.051608129986561835, 0.053958500968292356, 0.1263940860517323, 0.05564287700690329, 0.056148070958442986, 0.055469280923716724, 0.05586373002734035, 0.05594266694970429, 0.05644234106875956, 0.05590913200285286, 0.055834177997894585, 0.05589120404329151, 0.05648133601062, 0.056412779027596116, 0.055959837045520544, 0.05606647697277367, 0.05628147698007524, 0.056167342932894826, 0.05666964501142502, 0.056592431967146695, 0.05629748501814902, 0.05594882206059992, 0.056260338984429836, 0.05682837695349008, 0.05616825202014297, 0.0567413599928841, 0.05667519092094153, 0.05660115904174745, 0.05620737397111952, 0.05662684596609324, 0.05659314803779125, 0.05679090099874884, 0.0564849249785766, 0.05666331702377647, 0.05672156298533082, 0.05680249095894396, 0.05664221302140504, 0.05665295396465808, 0.05651035706978291, 0.05760233209002763, 0.05642682500183582, 0.05640399095136672, 0.05594621901400387, 0.055827262927778065, 0.056796840974129736, 0.06165442802011967, 0.05938215204514563, 0.05587540194392204, 0.056064456002786756, 0.05588026705663651, 0.056068286998197436, 0.05568802997004241, 0.05491437599994242, 0.054884094977751374, 0.05439047503750771, 0.05141773400828242, 0.0510263399919495, 0.05666929704602808, 0.05252925003878772, 0.052746000001206994, 0.05292037990875542, 0.052703340887092054, 0.05580456601455808, 0.05226187803782523, 0.05538289900869131, 0.05243772896938026, 0.05734907102305442, 0.055093011003918946, 0.05248277494683862, 0.056450773030519485, 0.051222498062998056, 0.05089607404079288, 0.0511907699983567, 0.051289271912537515, 0.0509510770207271, 0.0516568940365687, 0.05103855091147125, 0.05121682200115174, 0.0510492060566321, 0.05116502207238227, 0.05136828601825982, 0.05122433602809906, 0.05129758990369737, 0.05121032509487122, 0.05150953703559935, 0.051129239960573614, 0.051041424041613936, 0.051270741969347, 0.05104426003526896, 0.05117748596239835, 0.05333370203152299, 0.052010343060828745, 0.0517622260376811, 0.05141227494459599, 0.05136370798572898, 0.05165653699077666, 0.0518578999908641, 0.05132656393107027, 0.05150009808130562, 0.05199860199354589, 0.051817158004269004, 0.05151762207970023, 0.051609761896543205, 0.05147554993163794, 0.051673120935447514, 0.051828259020112455, 0.05152061500120908, 0.05159398098476231, 0.05197094497270882, 0.05180623091291636, 0.051481657079420984, 0.05170691502280533, 0.051680649048648775, 0.051991541986353695, 0.0516959959641099, 0.05132833600509912, 0.05138985300436616, 0.051892952993512154, 0.051826025010086596, 0.051372457994148135, 0.05123475508298725, 0.05129888898227364, 0.051586132030934095, 0.051700882031582296, 0.05136635806411505, 0.051626501022838056, 0.05170828499831259, 0.05197981698438525, 0.0517648640088737, 0.05157715210225433, 0.051666715065948665, 0.05201004899572581, 0.05172837304417044, 0.05153766099829227, 0.05137514299713075, 0.051417614915408194, 0.051785113057121634, 0.05193048296496272, 0.05168169899843633, 0.05202770000323653, 0.05748359102290124, 0.052154879085719585, 0.05124111601617187, 0.051987468963488936, 0.05620144703425467, 0.056442364933900535, 0.05600157391745597, 0.05598656996153295, 0.05602732195984572, 0.05515524290967733, 0.05658190802205354, 0.056060618022456765, 0.05044250295031816, 0.05018106393981725, 0.18094239302445203, 0.050411809934303164, 0.05007177102379501, 0.05006312299519777, 0.050296109984628856, 0.05072527995798737, 0.05161823192611337, 0.050740630947984755, 0.05074835999403149, 0.050216907053254545, 0.050311626051552594, 0.050363183952867985, 0.05008712492417544, 0.050270589999854565]
[0.0012148931828877803, 0.0012125459536698393, 0.0012193957491862502, 0.0013655329318928786, 0.0012447314537976954, 0.0012360796813895417, 0.001286865545394407, 0.0012429812288081105, 0.001244791021401232, 0.0012390837734776803, 0.0011152599075682122, 0.001137790862809528, 0.0011361486130309377, 0.0011434271132615818, 0.001164102342127907, 0.0011522324321876195, 0.001166162546724081, 0.0011580753621687604, 0.0011576099786907434, 0.0011559794524642216, 0.004411968000402505, 0.0012456667953467165, 0.0012529014096468347, 0.001249043270945549, 0.0012466184562072158, 0.0012589545248457316, 0.001252974748653783, 0.0012952771582852372, 0.0011648882725487717, 0.0011632724781520665, 0.0011807254314507272, 0.0011638591584580188, 0.00118330915839496, 0.0011493447501297023, 0.0011512959529434077, 0.0011649386142380536, 0.0011805183180099862, 0.001157353820004077, 0.001205839023565535, 0.0011553626364647325, 0.0011296772043517028, 0.0011747038859704678, 0.001239566658941013, 0.0012370923174206507, 0.0012356171130456707, 0.0012365879559762436, 0.0012352048176002097, 0.0011850465909281577, 0.0011559488881506365, 0.0011678995003669777, 0.0011578819777985866, 0.001387268386844715, 0.0011534053879917008, 0.0011598655440717596, 0.001157070160843432, 0.0011700062499254602, 0.0011847968403757973, 0.0011715171355965801, 0.0011729120451491326, 0.00122632956746119, 0.0028725928648120976, 0.0012646108410659838, 0.001276092521782795, 0.0012606654755390164, 0.0012696302278940989, 0.0012714242488569157, 0.0012827804788354445, 0.0012706620909739286, 0.0012689585908612405, 0.0012702546373475343, 0.0012836667275140908, 0.0012821086142635481, 0.001271814478307285, 0.0012742381130175834, 0.001279124476819892, 0.0012765305212021551, 0.0012879464775323868, 0.0012861916356169704, 0.0012794882958670232, 0.0012715641377409074, 0.0012786440678279507, 0.001291554021670229, 0.0012765511822759765, 0.0012895763634746386, 0.0012880725209304894, 0.001286389978221533, 0.0012774403175254438, 0.0012869737719566647, 0.0012862079099498012, 0.00129070229542611, 0.00128374829496765, 0.0012878026596312834, 0.0012891264314847913, 0.0012909657036123629, 0.001287323023213751, 0.0012875671355604109, 0.0012843262970405208, 0.0013091439111369916, 0.0012824278409508142, 0.0012819088852583345, 0.0012715049775909972, 0.0012688014301767742, 0.001290837294866585, 0.0014012370004572651, 0.0013495943646624007, 0.001269895498725501, 0.0012741921818815172, 0.0012700060694690117, 0.0012742792499590325, 0.001265637044773691, 0.0012480539999986913, 0.001247365794948895, 0.0012361471599433571, 0.0011685848638246005, 0.0011596895452715796, 0.0012879385692279109, 0.00119384659179063, 0.001198772727300159, 0.0012027359070171688, 0.0011978032019793648, 0.0012682855912399564, 0.0011877699554051187, 0.0012587022501975298, 0.001191766567485915, 0.0013033879777966913, 0.0012521138864527034, 0.0012205296499264795, 0.00131280867512836, 0.0011912208851860013, 0.0011836296288556484, 0.0011904830232175978, 0.0011927737654078491, 0.001184908767923886, 0.0012013231171295047, 0.0011869430444528197, 0.0011910888837477149, 0.0011871908385263279, 0.001189884234241448, 0.0011946113027502285, 0.0011912636285604432, 0.0011929672070627297, 0.0011909377929039818, 0.0011978962101302174, 0.001189052092106363, 0.0011870098614328822, 0.0011923428364964419, 0.0011870758147736968, 0.0011901740921487988, 0.0012403186518958834, 0.0012095428618797382, 0.0012037726985507232, 0.0011956343010371161, 0.0011945048368774182, 0.001201314813738992, 0.0012059976742061418, 0.001193641021652797, 0.001197676699565247, 0.0012092698138033927, 0.0012050501861457909, 0.0011980842344116332, 0.001200227020849842, 0.001197105812363673, 0.0012017004868708724, 0.0012053083493049409, 0.0011981538372374204, 0.001199860022901449, 0.001208626627272298, 0.001204796067742241, 0.001197247839056302, 0.0012024863958791938, 0.0012018755592709018, 0.001209105627589621, 0.0012022324642816254, 0.0011936822326767238, 0.001195112860566655, 0.0012068128603142361, 0.0012052563955834092, 0.0011947083254453055, 0.0011915059321624942, 0.0011929974181924103, 0.0011996774890914905, 0.001202346093757728, 0.0011945664666073268, 0.001200616302856699, 0.0012025182557747114, 0.0012088329531252384, 0.001203834046717993, 0.0011994686535407985, 0.001201551513161597, 0.0012095360231564143, 0.0012029854196318706, 0.0011985502557742389, 0.0011947707673751337, 0.0011957584864048416, 0.0012043049548167823, 0.0012076856503479701, 0.0012018999767078216, 0.0012099465117031752, 0.0013368276982070055, 0.0012129041647841764, 0.0011916538608412062, 0.0012090109061276496, 0.0013070103961454575, 0.0013126131379976869, 0.001302362184126883, 0.0013020132549193709, 0.0013029609758103656, 0.0012826800676669146, 0.0013158583260942684, 0.0013037353028478318, 0.0011730814639608874, 0.0011670014869724942, 0.004207962628475628, 0.0011723676728907712, 0.0011644597912510467, 0.001164258674306925, 0.0011696769763867175, 0.0011796576734415668, 0.0012004239982817062, 0.0011800146732089479, 0.0011801944184658486, 0.0011678350477501056, 0.001170037815152386, 0.001171236836113209, 0.0011648168587017544, 0.0011690834883687107]
[823.1176321386683, 824.7110115484227, 820.0783057242396, 732.3148176395987, 803.3861416042668, 809.0093341521865, 777.0819597889796, 804.5173787209127, 803.3476967678668, 807.0479344534916, 896.6519761124268, 878.8961422406898, 880.1665455826858, 874.563833935631, 859.0310008070785, 867.880448479833, 857.5133910869839, 863.5016620397413, 863.8488078091723, 865.0672794125212, 226.65622232726298, 802.7828980716001, 798.1473979519888, 800.6127756030272, 802.1700585457863, 794.309866055358, 798.1006808592246, 772.0355397325603, 858.4514271158412, 859.6438227340894, 846.9369536415637, 859.2104918647428, 845.0876872755719, 870.0609628983392, 868.586393831574, 858.4143299722842, 847.0855426332664, 864.0400046344316, 829.2980907543601, 865.5291147893416, 885.2086207881641, 851.2783620987699, 806.7335409410902, 808.3471103312723, 809.3121966683526, 808.6768071507977, 809.5823346470004, 843.8486787399434, 865.0901525584459, 856.2380578857853, 863.6458803005481, 720.8410495639268, 866.997857311202, 862.1688997583767, 864.2518265885125, 854.6962890700017, 844.0265587497829, 853.5940018416912, 852.5788477795475, 815.4414820725974, 348.1175533955843, 790.7570989641886, 783.6422382625724, 793.2318441356816, 787.6309007376682, 786.5195279223738, 779.5566088656392, 786.9912914719339, 788.0477796531574, 787.2437309799058, 779.0183998432124, 779.9651206418317, 786.2782009927618, 784.7826789859964, 781.7847427063236, 783.3733572294564, 776.4297798429702, 777.4891177241346, 781.5624443226089, 786.4330003649088, 782.0784729394733, 774.2610709436734, 783.360678274638, 775.4484560383821, 776.3538028725363, 777.3692402225689, 782.8154366828823, 777.0166119855256, 777.4792801880907, 774.7720009050281, 778.9689021750169, 776.5164891694776, 775.7191037098037, 774.6139166995789, 776.8058070642903, 776.6585309470112, 778.6183326653863, 763.8579620566695, 779.7709688356288, 780.0866438323162, 786.469591251312, 788.1453915611336, 774.6909730426989, 713.6551487533303, 740.9633784667949, 787.466371054646, 784.8109682507742, 787.3978117428203, 784.7573442258825, 790.1159373687661, 801.2473819250197, 801.6894515220938, 808.9651721125356, 855.735882738676, 862.2997457184259, 776.4345473398446, 837.6285587079636, 834.1864785764445, 831.4377197568155, 834.8616854150199, 788.4659471864982, 841.9138701474604, 794.4690651367857, 839.0904958087093, 767.23125963648, 798.6493966879054, 819.3164336976464, 761.7256184738609, 839.4748719032546, 844.8588778288827, 839.9951788453341, 838.3819538972393, 843.9468312418093, 832.4155139788243, 842.5004086535589, 839.5679060101198, 842.3245594122931, 840.4178921132614, 837.0923644350298, 839.4447509561157, 838.246008842234, 839.6744195694728, 834.7968643220725, 841.0060472864027, 842.4529841671779, 838.6849565334594, 842.4061778991254, 840.2132146857194, 806.2444263588671, 826.758630484504, 830.7216148064709, 836.3761387010901, 837.1669742368916, 832.4212675673111, 829.1889954582695, 837.7728159973353, 834.949866155864, 826.9453091322954, 829.8409572454245, 834.66585343316, 833.1757097852474, 835.3480449865249, 832.1541107168196, 829.6632148749861, 834.6173662521475, 833.4305509919762, 827.3853789377954, 830.0159892403833, 835.2489496144949, 831.610239772279, 832.0328941597196, 827.0576012399532, 831.7858897592936, 837.7438924910452, 836.7410585188219, 828.6288892708807, 829.6989782957725, 837.0243838614488, 839.2740422073055, 838.2247813370515, 833.5573594510761, 831.7072806172392, 837.1237833589014, 832.9055649341421, 831.5882068299737, 827.2441592650703, 830.679280691799, 833.7024873872507, 832.2572848905479, 826.7633049823456, 831.2652702856641, 834.3413179233111, 836.9806387186408, 836.2892769480502, 830.3544679446542, 828.030042181813, 832.0159908307387, 826.4828158332016, 748.0395576342642, 824.4674468390003, 839.1698570036814, 827.1223980955702, 765.1048552858716, 761.8390910862286, 767.8355623250918, 768.041336155158, 767.4826940830353, 779.6176343637385, 759.9602329288751, 767.0268633637799, 852.4557166077102, 856.8969372903375, 237.6446960894847, 852.9747306442229, 858.7673078223182, 858.9156534266691, 854.9368929951314, 847.703552067416, 833.0389940815959, 847.4470891794816, 847.3180218051821, 856.2853135179934, 854.6732311124148, 853.7982832904535, 858.5040579808822, 855.3709037455976]
Elapsed: 0.05477853633970253~0.013692928921167295
Time per graph: 0.0012573993893457418~0.000312934294212308
Speed: 811.9656854429605~71.53454271028905
Total Time: 0.0510
best val loss: 0.411594033241272 test_score: 0.7674

Testing...
Test loss: 0.5767 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.3953267310280353, 0.163774271029979, 0.16709847911261022, 0.1736071859486401, 0.1814392131054774, 0.17101437400560826, 0.1733871620381251, 0.17446275218389928, 0.17270455602556467, 0.17102167394477874, 0.2935880918521434, 0.15724992391187698, 0.15791298111435026, 0.15764300292357802, 0.1570837430190295, 0.16603583109099418, 0.15952609106898308, 0.1637241590069607, 0.16027185996063054, 0.15876670693978667, 0.3022761069005355, 0.17059148696716875, 0.17146894102916121, 0.17133061808999628, 0.1715478270780295, 0.17143540608230978, 0.17244740691967309, 0.17668951803352684, 0.16205942211672664, 0.15910033194813877, 0.15972990600857884, 0.25787733390461653, 0.16039869410451502, 0.15845292690210044, 0.15986342704854906, 0.1595118959667161, 0.162252196110785, 0.1670778290135786, 0.16112114395946264, 0.1626806070562452, 0.1562420369591564, 0.15684873389545828, 0.2660882141208276, 0.16956370207481086, 0.16908078989945352, 0.1685571379493922, 0.1697788309538737, 0.1640570560703054, 0.16036046296358109, 0.1591018739854917, 0.1599582409253344, 0.3199528199620545, 0.16118808602914214, 0.15849063196219504, 0.1584856059635058, 0.1603177699726075, 0.1609952028375119, 0.16985826008021832, 0.16151070012710989, 0.16181473701726645, 0.23664692603051662, 0.18400501902215183, 0.17375044291839004, 0.17305170197505504, 0.17360578197985888, 0.17322358500678092, 0.1751155350357294, 0.17329018318559974, 0.17410216596908867, 0.17390741605777293, 0.174434743123129, 0.17468408297281712, 0.17369513399899006, 0.17433397902641445, 0.17421403003390878, 0.17464080592617393, 0.1757492240285501, 0.17472369596362114, 0.17495227011386305, 0.17503687797579914, 0.1759612428722903, 0.18441417592111975, 0.17763835401274264, 0.17552517796866596, 0.17531463806517422, 0.17493232595734298, 0.1752824359573424, 0.17558589403051883, 0.17490696697495878, 0.17560751910787076, 0.17532307701185346, 0.1759726230520755, 0.17597887199372053, 0.17627642897423357, 0.17544958391226828, 0.17584756296128035, 0.17585248604882509, 0.17708558193407953, 0.17690792202483863, 0.17702344001736492, 0.1755319320363924, 0.17599504010286182, 0.17674084706231952, 0.18992511206306517, 0.18810730299446732, 0.17615708091761917, 0.17605788097716868, 0.17570833396166563, 0.17640605696942657, 0.17477357399184257, 0.17384687601588666, 0.1709499468561262, 0.16963975399266928, 0.1682941319886595, 0.1609153610188514, 0.16731517994776368, 0.17130087595432997, 0.16767897410318255, 0.168310169945471, 0.16708453197497874, 0.1761298921192065, 0.16863204597029835, 0.17145734908990562, 0.16655033791903406, 0.182291125995107, 0.17497949593234807, 0.1711436560144648, 0.18091552704572678, 0.17607382009737194, 0.1694596930174157, 0.16941205691546202, 0.1709651758428663, 0.16993316204752773, 0.17104120401199907, 0.17095902189612389, 0.17025958187878132, 0.1703147079097107, 0.17219398613087833, 0.17153669078834355, 0.1721126299817115, 0.1725040809251368, 0.17132731096353382, 0.17283253895584494, 0.17234390194062144, 0.17247298592701554, 0.17224627290852368, 0.1715736980549991, 0.1701585641130805, 0.1754392929142341, 0.17198553297203034, 0.170701599214226, 0.1707452319096774, 0.1709824081044644, 0.17068215901963413, 0.17015600111335516, 0.17014536098577082, 0.17136864305939525, 0.17105744208674878, 0.17227692203596234, 0.170447192969732, 0.17146422411315143, 0.17201719398144633, 0.1702719310997054, 0.1733520160196349, 0.17080115887802094, 0.171949569019489, 0.1721460740081966, 0.17147634096909314, 0.17153548903297633, 0.1725533598801121, 0.17134936503134668, 0.17039301281329244, 0.17109059693757445, 0.17097713390830904, 0.17086012405343354, 0.1696624521864578, 0.171610267017968, 0.17109286598861217, 0.16996151790954173, 0.1697276011109352, 0.17092018597759306, 0.17059469991363585, 0.17031365109141916, 0.17159227200318128, 0.17009124089963734, 0.17110993701498955, 0.17047845595516264, 0.17108772904612124, 0.17093668098095804, 0.17111102805938572, 0.16934529901482165, 0.17015112400986254, 0.17023099295329303, 0.1716524299699813, 0.17119582497980446, 0.17053764697629958, 0.171045319060795, 0.171036698971875, 0.17626988398842514, 0.17297002102714032, 0.16809357097372413, 0.16975169302895665, 0.284977501956746, 0.18345491914078593, 0.18234930199105293, 0.18191233300603926, 0.18258553312625736, 0.18191643222235143, 0.18217018502764404, 0.18373875704128295, 0.17092424898874015, 0.16505823389161378, 0.2977881688857451, 0.1666292998706922, 0.16595445980783552, 0.164846676052548, 0.16546644107438624, 0.16532050597015768, 0.16568996105343103, 0.17093700100667775, 0.16876868507824838, 0.16514402185566723, 0.16552108502946794, 0.2926768900360912, 0.16439702187199146, 0.16415319207590073]
Total Epoch List: [126, 100]
Total Time List: [0.055701536941342056, 0.05104563198983669]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a8172290>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6971;  Loss pred: 0.6971; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6952;  Loss pred: 0.6952; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6871;  Loss pred: 0.6871; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.08s
Epoch 10/1000, LR 0.000240
Train loss: 0.6854;  Loss pred: 0.6854; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6815;  Loss pred: 0.6815; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6797;  Loss pred: 0.6797; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6737;  Loss pred: 0.6737; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6724;  Loss pred: 0.6724; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6727;  Loss pred: 0.6727; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6634;  Loss pred: 0.6634; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6647;  Loss pred: 0.6647; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6619;  Loss pred: 0.6619; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6524;  Loss pred: 0.6524; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6459;  Loss pred: 0.6459; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6425;  Loss pred: 0.6425; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 22/1000, LR 0.000270
Train loss: 0.6345;  Loss pred: 0.6345; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 23/1000, LR 0.000270
Train loss: 0.6246;  Loss pred: 0.6246; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 24/1000, LR 0.000270
Train loss: 0.6206;  Loss pred: 0.6206; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 25/1000, LR 0.000270
Train loss: 0.6105;  Loss pred: 0.6105; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6954 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 26/1000, LR 0.000270
Train loss: 0.6005;  Loss pred: 0.6005; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 27/1000, LR 0.000270
Train loss: 0.5953;  Loss pred: 0.5953; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6963 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6980 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 28/1000, LR 0.000270
Train loss: 0.5844;  Loss pred: 0.5844; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6969 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6987 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 29/1000, LR 0.000270
Train loss: 0.5785;  Loss pred: 0.5785; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6995 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 19 of 20
Epoch 30/1000, LR 0.000270
Train loss: 0.5610;  Loss pred: 0.5610; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6982 score: 0.5000 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.7004 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 009,   Train_Loss: 0.6854,   Val_Loss: 0.6931,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.5000,   Val_Loss: 0.6931,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.5116,   Test_loss: 0.6931


[0.05345530004706234, 0.05335202196147293, 0.05365341296419501, 0.06008344900328666, 0.054768183967098594, 0.05438750598113984, 0.05662208399735391, 0.05469117406755686, 0.054770804941654205, 0.05451968603301793, 0.04907143593300134, 0.05006279796361923, 0.049990538973361254, 0.0503107929835096, 0.05122050305362791, 0.05069822701625526, 0.051311152055859566, 0.05095531593542546, 0.05093483906239271, 0.05086309590842575, 0.1941265920177102, 0.05480933899525553, 0.05512766202446073, 0.054957903921604156, 0.054851212073117495, 0.05539399909321219, 0.055130888940766454, 0.056992194964550436, 0.051255083992145956, 0.051183989038690925, 0.051951918983832, 0.05120980297215283, 0.05206560296937823, 0.050571169005706906, 0.05065702192950994, 0.05125729902647436, 0.05194280599243939, 0.05092356808017939, 0.05305691703688353, 0.050835956004448235, 0.049705796991474926, 0.051686970982700586, 0.05454093299340457, 0.05443206196650863, 0.054367152974009514, 0.054409870062954724, 0.05434901197440922, 0.052142050000838935, 0.050861751078628004, 0.05138757801614702, 0.05094680702313781, 0.06103980902116746, 0.05074983707163483, 0.051034083939157426, 0.050911087077111006, 0.051480274996720254, 0.05213106097653508, 0.051546753966249526, 0.051608129986561835, 0.053958500968292356, 0.1263940860517323, 0.05564287700690329, 0.056148070958442986, 0.055469280923716724, 0.05586373002734035, 0.05594266694970429, 0.05644234106875956, 0.05590913200285286, 0.055834177997894585, 0.05589120404329151, 0.05648133601062, 0.056412779027596116, 0.055959837045520544, 0.05606647697277367, 0.05628147698007524, 0.056167342932894826, 0.05666964501142502, 0.056592431967146695, 0.05629748501814902, 0.05594882206059992, 0.056260338984429836, 0.05682837695349008, 0.05616825202014297, 0.0567413599928841, 0.05667519092094153, 0.05660115904174745, 0.05620737397111952, 0.05662684596609324, 0.05659314803779125, 0.05679090099874884, 0.0564849249785766, 0.05666331702377647, 0.05672156298533082, 0.05680249095894396, 0.05664221302140504, 0.05665295396465808, 0.05651035706978291, 0.05760233209002763, 0.05642682500183582, 0.05640399095136672, 0.05594621901400387, 0.055827262927778065, 0.056796840974129736, 0.06165442802011967, 0.05938215204514563, 0.05587540194392204, 0.056064456002786756, 0.05588026705663651, 0.056068286998197436, 0.05568802997004241, 0.05491437599994242, 0.054884094977751374, 0.05439047503750771, 0.05141773400828242, 0.0510263399919495, 0.05666929704602808, 0.05252925003878772, 0.052746000001206994, 0.05292037990875542, 0.052703340887092054, 0.05580456601455808, 0.05226187803782523, 0.05538289900869131, 0.05243772896938026, 0.05734907102305442, 0.055093011003918946, 0.05248277494683862, 0.056450773030519485, 0.051222498062998056, 0.05089607404079288, 0.0511907699983567, 0.051289271912537515, 0.0509510770207271, 0.0516568940365687, 0.05103855091147125, 0.05121682200115174, 0.0510492060566321, 0.05116502207238227, 0.05136828601825982, 0.05122433602809906, 0.05129758990369737, 0.05121032509487122, 0.05150953703559935, 0.051129239960573614, 0.051041424041613936, 0.051270741969347, 0.05104426003526896, 0.05117748596239835, 0.05333370203152299, 0.052010343060828745, 0.0517622260376811, 0.05141227494459599, 0.05136370798572898, 0.05165653699077666, 0.0518578999908641, 0.05132656393107027, 0.05150009808130562, 0.05199860199354589, 0.051817158004269004, 0.05151762207970023, 0.051609761896543205, 0.05147554993163794, 0.051673120935447514, 0.051828259020112455, 0.05152061500120908, 0.05159398098476231, 0.05197094497270882, 0.05180623091291636, 0.051481657079420984, 0.05170691502280533, 0.051680649048648775, 0.051991541986353695, 0.0516959959641099, 0.05132833600509912, 0.05138985300436616, 0.051892952993512154, 0.051826025010086596, 0.051372457994148135, 0.05123475508298725, 0.05129888898227364, 0.051586132030934095, 0.051700882031582296, 0.05136635806411505, 0.051626501022838056, 0.05170828499831259, 0.05197981698438525, 0.0517648640088737, 0.05157715210225433, 0.051666715065948665, 0.05201004899572581, 0.05172837304417044, 0.05153766099829227, 0.05137514299713075, 0.051417614915408194, 0.051785113057121634, 0.05193048296496272, 0.05168169899843633, 0.05202770000323653, 0.05748359102290124, 0.052154879085719585, 0.05124111601617187, 0.051987468963488936, 0.05620144703425467, 0.056442364933900535, 0.05600157391745597, 0.05598656996153295, 0.05602732195984572, 0.05515524290967733, 0.05658190802205354, 0.056060618022456765, 0.05044250295031816, 0.05018106393981725, 0.18094239302445203, 0.050411809934303164, 0.05007177102379501, 0.05006312299519777, 0.050296109984628856, 0.05072527995798737, 0.05161823192611337, 0.050740630947984755, 0.05074835999403149, 0.050216907053254545, 0.050311626051552594, 0.050363183952867985, 0.05008712492417544, 0.050270589999854565, 0.05648650892544538, 0.056595165049657226, 0.05648639798164368, 0.056725400034338236, 0.05757015093695372, 0.05706965003628284, 0.056493925978429615, 0.05674724990967661, 0.08123759995214641, 0.05635703797452152, 0.05593188700731844, 0.05640861706342548, 0.05606330989394337, 0.05620219500269741, 0.0557713609887287, 0.05648416595067829, 0.056541859987191856, 0.05569472897332162, 0.056869500083848834, 0.056566285085864365, 0.05626233690418303, 0.05640157999005169, 0.055680236080661416, 0.05591184995137155, 0.05616228899452835, 0.05657732707913965, 0.05739573307801038, 0.05950545996893197, 0.06053553195670247, 0.05325130792334676]
[0.0012148931828877803, 0.0012125459536698393, 0.0012193957491862502, 0.0013655329318928786, 0.0012447314537976954, 0.0012360796813895417, 0.001286865545394407, 0.0012429812288081105, 0.001244791021401232, 0.0012390837734776803, 0.0011152599075682122, 0.001137790862809528, 0.0011361486130309377, 0.0011434271132615818, 0.001164102342127907, 0.0011522324321876195, 0.001166162546724081, 0.0011580753621687604, 0.0011576099786907434, 0.0011559794524642216, 0.004411968000402505, 0.0012456667953467165, 0.0012529014096468347, 0.001249043270945549, 0.0012466184562072158, 0.0012589545248457316, 0.001252974748653783, 0.0012952771582852372, 0.0011648882725487717, 0.0011632724781520665, 0.0011807254314507272, 0.0011638591584580188, 0.00118330915839496, 0.0011493447501297023, 0.0011512959529434077, 0.0011649386142380536, 0.0011805183180099862, 0.001157353820004077, 0.001205839023565535, 0.0011553626364647325, 0.0011296772043517028, 0.0011747038859704678, 0.001239566658941013, 0.0012370923174206507, 0.0012356171130456707, 0.0012365879559762436, 0.0012352048176002097, 0.0011850465909281577, 0.0011559488881506365, 0.0011678995003669777, 0.0011578819777985866, 0.001387268386844715, 0.0011534053879917008, 0.0011598655440717596, 0.001157070160843432, 0.0011700062499254602, 0.0011847968403757973, 0.0011715171355965801, 0.0011729120451491326, 0.00122632956746119, 0.0028725928648120976, 0.0012646108410659838, 0.001276092521782795, 0.0012606654755390164, 0.0012696302278940989, 0.0012714242488569157, 0.0012827804788354445, 0.0012706620909739286, 0.0012689585908612405, 0.0012702546373475343, 0.0012836667275140908, 0.0012821086142635481, 0.001271814478307285, 0.0012742381130175834, 0.001279124476819892, 0.0012765305212021551, 0.0012879464775323868, 0.0012861916356169704, 0.0012794882958670232, 0.0012715641377409074, 0.0012786440678279507, 0.001291554021670229, 0.0012765511822759765, 0.0012895763634746386, 0.0012880725209304894, 0.001286389978221533, 0.0012774403175254438, 0.0012869737719566647, 0.0012862079099498012, 0.00129070229542611, 0.00128374829496765, 0.0012878026596312834, 0.0012891264314847913, 0.0012909657036123629, 0.001287323023213751, 0.0012875671355604109, 0.0012843262970405208, 0.0013091439111369916, 0.0012824278409508142, 0.0012819088852583345, 0.0012715049775909972, 0.0012688014301767742, 0.001290837294866585, 0.0014012370004572651, 0.0013495943646624007, 0.001269895498725501, 0.0012741921818815172, 0.0012700060694690117, 0.0012742792499590325, 0.001265637044773691, 0.0012480539999986913, 0.001247365794948895, 0.0012361471599433571, 0.0011685848638246005, 0.0011596895452715796, 0.0012879385692279109, 0.00119384659179063, 0.001198772727300159, 0.0012027359070171688, 0.0011978032019793648, 0.0012682855912399564, 0.0011877699554051187, 0.0012587022501975298, 0.001191766567485915, 0.0013033879777966913, 0.0012521138864527034, 0.0012205296499264795, 0.00131280867512836, 0.0011912208851860013, 0.0011836296288556484, 0.0011904830232175978, 0.0011927737654078491, 0.001184908767923886, 0.0012013231171295047, 0.0011869430444528197, 0.0011910888837477149, 0.0011871908385263279, 0.001189884234241448, 0.0011946113027502285, 0.0011912636285604432, 0.0011929672070627297, 0.0011909377929039818, 0.0011978962101302174, 0.001189052092106363, 0.0011870098614328822, 0.0011923428364964419, 0.0011870758147736968, 0.0011901740921487988, 0.0012403186518958834, 0.0012095428618797382, 0.0012037726985507232, 0.0011956343010371161, 0.0011945048368774182, 0.001201314813738992, 0.0012059976742061418, 0.001193641021652797, 0.001197676699565247, 0.0012092698138033927, 0.0012050501861457909, 0.0011980842344116332, 0.001200227020849842, 0.001197105812363673, 0.0012017004868708724, 0.0012053083493049409, 0.0011981538372374204, 0.001199860022901449, 0.001208626627272298, 0.001204796067742241, 0.001197247839056302, 0.0012024863958791938, 0.0012018755592709018, 0.001209105627589621, 0.0012022324642816254, 0.0011936822326767238, 0.001195112860566655, 0.0012068128603142361, 0.0012052563955834092, 0.0011947083254453055, 0.0011915059321624942, 0.0011929974181924103, 0.0011996774890914905, 0.001202346093757728, 0.0011945664666073268, 0.001200616302856699, 0.0012025182557747114, 0.0012088329531252384, 0.001203834046717993, 0.0011994686535407985, 0.001201551513161597, 0.0012095360231564143, 0.0012029854196318706, 0.0011985502557742389, 0.0011947707673751337, 0.0011957584864048416, 0.0012043049548167823, 0.0012076856503479701, 0.0012018999767078216, 0.0012099465117031752, 0.0013368276982070055, 0.0012129041647841764, 0.0011916538608412062, 0.0012090109061276496, 0.0013070103961454575, 0.0013126131379976869, 0.001302362184126883, 0.0013020132549193709, 0.0013029609758103656, 0.0012826800676669146, 0.0013158583260942684, 0.0013037353028478318, 0.0011730814639608874, 0.0011670014869724942, 0.004207962628475628, 0.0011723676728907712, 0.0011644597912510467, 0.001164258674306925, 0.0011696769763867175, 0.0011796576734415668, 0.0012004239982817062, 0.0011800146732089479, 0.0011801944184658486, 0.0011678350477501056, 0.001170037815152386, 0.001171236836113209, 0.0011648168587017544, 0.0011690834883687107, 0.001313639742452218, 0.001316166629061796, 0.0013136371623638065, 0.001319195349635773, 0.00133884071946404, 0.0013272011636344845, 0.0013138122320565026, 0.001319703486271549, 0.0018892465105150328, 0.0013106287901051515, 0.0013007415583097311, 0.0013118283038005927, 0.0013037979045103108, 0.0013070277907604047, 0.001297008395086714, 0.001313585254666937, 0.0013149269764463221, 0.001295226255193526, 0.0013225465135778798, 0.0013154950019968457, 0.0013084264396321635, 0.0013116646509314346, 0.0012948892111781724, 0.0013002755802644546, 0.001306099744058799, 0.0013157517925381315, 0.001334784490186288, 0.001383847906254232, 0.0014078030687605227, 0.0012384025098452734]
[823.1176321386683, 824.7110115484227, 820.0783057242396, 732.3148176395987, 803.3861416042668, 809.0093341521865, 777.0819597889796, 804.5173787209127, 803.3476967678668, 807.0479344534916, 896.6519761124268, 878.8961422406898, 880.1665455826858, 874.563833935631, 859.0310008070785, 867.880448479833, 857.5133910869839, 863.5016620397413, 863.8488078091723, 865.0672794125212, 226.65622232726298, 802.7828980716001, 798.1473979519888, 800.6127756030272, 802.1700585457863, 794.309866055358, 798.1006808592246, 772.0355397325603, 858.4514271158412, 859.6438227340894, 846.9369536415637, 859.2104918647428, 845.0876872755719, 870.0609628983392, 868.586393831574, 858.4143299722842, 847.0855426332664, 864.0400046344316, 829.2980907543601, 865.5291147893416, 885.2086207881641, 851.2783620987699, 806.7335409410902, 808.3471103312723, 809.3121966683526, 808.6768071507977, 809.5823346470004, 843.8486787399434, 865.0901525584459, 856.2380578857853, 863.6458803005481, 720.8410495639268, 866.997857311202, 862.1688997583767, 864.2518265885125, 854.6962890700017, 844.0265587497829, 853.5940018416912, 852.5788477795475, 815.4414820725974, 348.1175533955843, 790.7570989641886, 783.6422382625724, 793.2318441356816, 787.6309007376682, 786.5195279223738, 779.5566088656392, 786.9912914719339, 788.0477796531574, 787.2437309799058, 779.0183998432124, 779.9651206418317, 786.2782009927618, 784.7826789859964, 781.7847427063236, 783.3733572294564, 776.4297798429702, 777.4891177241346, 781.5624443226089, 786.4330003649088, 782.0784729394733, 774.2610709436734, 783.360678274638, 775.4484560383821, 776.3538028725363, 777.3692402225689, 782.8154366828823, 777.0166119855256, 777.4792801880907, 774.7720009050281, 778.9689021750169, 776.5164891694776, 775.7191037098037, 774.6139166995789, 776.8058070642903, 776.6585309470112, 778.6183326653863, 763.8579620566695, 779.7709688356288, 780.0866438323162, 786.469591251312, 788.1453915611336, 774.6909730426989, 713.6551487533303, 740.9633784667949, 787.466371054646, 784.8109682507742, 787.3978117428203, 784.7573442258825, 790.1159373687661, 801.2473819250197, 801.6894515220938, 808.9651721125356, 855.735882738676, 862.2997457184259, 776.4345473398446, 837.6285587079636, 834.1864785764445, 831.4377197568155, 834.8616854150199, 788.4659471864982, 841.9138701474604, 794.4690651367857, 839.0904958087093, 767.23125963648, 798.6493966879054, 819.3164336976464, 761.7256184738609, 839.4748719032546, 844.8588778288827, 839.9951788453341, 838.3819538972393, 843.9468312418093, 832.4155139788243, 842.5004086535589, 839.5679060101198, 842.3245594122931, 840.4178921132614, 837.0923644350298, 839.4447509561157, 838.246008842234, 839.6744195694728, 834.7968643220725, 841.0060472864027, 842.4529841671779, 838.6849565334594, 842.4061778991254, 840.2132146857194, 806.2444263588671, 826.758630484504, 830.7216148064709, 836.3761387010901, 837.1669742368916, 832.4212675673111, 829.1889954582695, 837.7728159973353, 834.949866155864, 826.9453091322954, 829.8409572454245, 834.66585343316, 833.1757097852474, 835.3480449865249, 832.1541107168196, 829.6632148749861, 834.6173662521475, 833.4305509919762, 827.3853789377954, 830.0159892403833, 835.2489496144949, 831.610239772279, 832.0328941597196, 827.0576012399532, 831.7858897592936, 837.7438924910452, 836.7410585188219, 828.6288892708807, 829.6989782957725, 837.0243838614488, 839.2740422073055, 838.2247813370515, 833.5573594510761, 831.7072806172392, 837.1237833589014, 832.9055649341421, 831.5882068299737, 827.2441592650703, 830.679280691799, 833.7024873872507, 832.2572848905479, 826.7633049823456, 831.2652702856641, 834.3413179233111, 836.9806387186408, 836.2892769480502, 830.3544679446542, 828.030042181813, 832.0159908307387, 826.4828158332016, 748.0395576342642, 824.4674468390003, 839.1698570036814, 827.1223980955702, 765.1048552858716, 761.8390910862286, 767.8355623250918, 768.041336155158, 767.4826940830353, 779.6176343637385, 759.9602329288751, 767.0268633637799, 852.4557166077102, 856.8969372903375, 237.6446960894847, 852.9747306442229, 858.7673078223182, 858.9156534266691, 854.9368929951314, 847.703552067416, 833.0389940815959, 847.4470891794816, 847.3180218051821, 856.2853135179934, 854.6732311124148, 853.7982832904535, 858.5040579808822, 855.3709037455976, 761.2437167387037, 759.7822174786719, 761.2452118822246, 758.0378450212836, 746.9148386824659, 753.4652827319275, 761.1437735167877, 757.7459712751223, 529.311550628397, 762.9925479660569, 768.7922274886531, 762.2948804373467, 766.9900346830107, 765.0946728670691, 771.0050326491087, 761.2752932839161, 760.4985051736992, 772.0658811464451, 756.1170739429829, 760.1701249203209, 764.2768211571213, 762.3899899184472, 772.2668405663342, 769.06773854556, 765.6383094390847, 760.0217652532815, 749.184611712439, 722.6227647421003, 710.3266232260978, 807.4919035208839]
Elapsed: 0.05508568695904614~0.012988155826315243
Time per graph: 0.001266478371584753~0.00029732465932951315
Speed: 805.0145271902525~71.49267972999509
Total Time: 0.0541
best val loss: 0.6931393146514893 test_score: 0.5116

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
test Score 0.5116
Epoch Time List: [0.3953267310280353, 0.163774271029979, 0.16709847911261022, 0.1736071859486401, 0.1814392131054774, 0.17101437400560826, 0.1733871620381251, 0.17446275218389928, 0.17270455602556467, 0.17102167394477874, 0.2935880918521434, 0.15724992391187698, 0.15791298111435026, 0.15764300292357802, 0.1570837430190295, 0.16603583109099418, 0.15952609106898308, 0.1637241590069607, 0.16027185996063054, 0.15876670693978667, 0.3022761069005355, 0.17059148696716875, 0.17146894102916121, 0.17133061808999628, 0.1715478270780295, 0.17143540608230978, 0.17244740691967309, 0.17668951803352684, 0.16205942211672664, 0.15910033194813877, 0.15972990600857884, 0.25787733390461653, 0.16039869410451502, 0.15845292690210044, 0.15986342704854906, 0.1595118959667161, 0.162252196110785, 0.1670778290135786, 0.16112114395946264, 0.1626806070562452, 0.1562420369591564, 0.15684873389545828, 0.2660882141208276, 0.16956370207481086, 0.16908078989945352, 0.1685571379493922, 0.1697788309538737, 0.1640570560703054, 0.16036046296358109, 0.1591018739854917, 0.1599582409253344, 0.3199528199620545, 0.16118808602914214, 0.15849063196219504, 0.1584856059635058, 0.1603177699726075, 0.1609952028375119, 0.16985826008021832, 0.16151070012710989, 0.16181473701726645, 0.23664692603051662, 0.18400501902215183, 0.17375044291839004, 0.17305170197505504, 0.17360578197985888, 0.17322358500678092, 0.1751155350357294, 0.17329018318559974, 0.17410216596908867, 0.17390741605777293, 0.174434743123129, 0.17468408297281712, 0.17369513399899006, 0.17433397902641445, 0.17421403003390878, 0.17464080592617393, 0.1757492240285501, 0.17472369596362114, 0.17495227011386305, 0.17503687797579914, 0.1759612428722903, 0.18441417592111975, 0.17763835401274264, 0.17552517796866596, 0.17531463806517422, 0.17493232595734298, 0.1752824359573424, 0.17558589403051883, 0.17490696697495878, 0.17560751910787076, 0.17532307701185346, 0.1759726230520755, 0.17597887199372053, 0.17627642897423357, 0.17544958391226828, 0.17584756296128035, 0.17585248604882509, 0.17708558193407953, 0.17690792202483863, 0.17702344001736492, 0.1755319320363924, 0.17599504010286182, 0.17674084706231952, 0.18992511206306517, 0.18810730299446732, 0.17615708091761917, 0.17605788097716868, 0.17570833396166563, 0.17640605696942657, 0.17477357399184257, 0.17384687601588666, 0.1709499468561262, 0.16963975399266928, 0.1682941319886595, 0.1609153610188514, 0.16731517994776368, 0.17130087595432997, 0.16767897410318255, 0.168310169945471, 0.16708453197497874, 0.1761298921192065, 0.16863204597029835, 0.17145734908990562, 0.16655033791903406, 0.182291125995107, 0.17497949593234807, 0.1711436560144648, 0.18091552704572678, 0.17607382009737194, 0.1694596930174157, 0.16941205691546202, 0.1709651758428663, 0.16993316204752773, 0.17104120401199907, 0.17095902189612389, 0.17025958187878132, 0.1703147079097107, 0.17219398613087833, 0.17153669078834355, 0.1721126299817115, 0.1725040809251368, 0.17132731096353382, 0.17283253895584494, 0.17234390194062144, 0.17247298592701554, 0.17224627290852368, 0.1715736980549991, 0.1701585641130805, 0.1754392929142341, 0.17198553297203034, 0.170701599214226, 0.1707452319096774, 0.1709824081044644, 0.17068215901963413, 0.17015600111335516, 0.17014536098577082, 0.17136864305939525, 0.17105744208674878, 0.17227692203596234, 0.170447192969732, 0.17146422411315143, 0.17201719398144633, 0.1702719310997054, 0.1733520160196349, 0.17080115887802094, 0.171949569019489, 0.1721460740081966, 0.17147634096909314, 0.17153548903297633, 0.1725533598801121, 0.17134936503134668, 0.17039301281329244, 0.17109059693757445, 0.17097713390830904, 0.17086012405343354, 0.1696624521864578, 0.171610267017968, 0.17109286598861217, 0.16996151790954173, 0.1697276011109352, 0.17092018597759306, 0.17059469991363585, 0.17031365109141916, 0.17159227200318128, 0.17009124089963734, 0.17110993701498955, 0.17047845595516264, 0.17108772904612124, 0.17093668098095804, 0.17111102805938572, 0.16934529901482165, 0.17015112400986254, 0.17023099295329303, 0.1716524299699813, 0.17119582497980446, 0.17053764697629958, 0.171045319060795, 0.171036698971875, 0.17626988398842514, 0.17297002102714032, 0.16809357097372413, 0.16975169302895665, 0.284977501956746, 0.18345491914078593, 0.18234930199105293, 0.18191233300603926, 0.18258553312625736, 0.18191643222235143, 0.18217018502764404, 0.18373875704128295, 0.17092424898874015, 0.16505823389161378, 0.2977881688857451, 0.1666292998706922, 0.16595445980783552, 0.164846676052548, 0.16546644107438624, 0.16532050597015768, 0.16568996105343103, 0.17093700100667775, 0.16876868507824838, 0.16514402185566723, 0.16552108502946794, 0.2926768900360912, 0.16439702187199146, 0.16415319207590073, 0.17833598202560097, 0.17568925791420043, 0.1763986359583214, 0.17706919799093157, 0.17730746790766716, 0.17906642821617424, 0.17779453401453793, 0.17618330905679613, 0.26441283407621086, 0.17613762896507978, 0.1755229278933257, 0.17535371519625187, 0.1748236168641597, 0.1751670641824603, 0.17585727805271745, 0.17664100287947804, 0.17749554791953415, 0.17404076701495796, 0.1748557520331815, 0.24570418999064714, 0.17608945001848042, 0.17490086623001844, 0.17559615208301693, 0.17429303203243762, 0.1755217908648774, 0.17636277293786407, 0.18066819314844906, 0.18275634199380875, 0.1897471770644188, 0.29452245600987226]
Total Epoch List: [126, 100, 30]
Total Time List: [0.055701536941342056, 0.05104563198983669, 0.054066698998212814]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a815ace0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6929;  Loss pred: 0.6929; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6950;  Loss pred: 0.6950; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6919;  Loss pred: 0.6919; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6921;  Loss pred: 0.6921; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6866;  Loss pred: 0.6866; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6855;  Loss pred: 0.6855; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6801;  Loss pred: 0.6801; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6808;  Loss pred: 0.6808; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6751;  Loss pred: 0.6751; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6683;  Loss pred: 0.6683; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6635;  Loss pred: 0.6635; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5116 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.12s
Epoch 13/1000, LR 0.000270
Train loss: 0.6638;  Loss pred: 0.6638; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6579;  Loss pred: 0.6579; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6564;  Loss pred: 0.6564; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6436;  Loss pred: 0.6436; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6372;  Loss pred: 0.6372; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6353;  Loss pred: 0.6353; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6234;  Loss pred: 0.6234; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6153;  Loss pred: 0.6153; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6120;  Loss pred: 0.6120; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6029;  Loss pred: 0.6029; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.06s
Epoch 23/1000, LR 0.000270
Train loss: 0.5969;  Loss pred: 0.5969; Loss self: 0.0000; time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.06s
Epoch 24/1000, LR 0.000270
Train loss: 0.5885;  Loss pred: 0.5885; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5728;  Loss pred: 0.5728; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5644;  Loss pred: 0.5644; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5601;  Loss pred: 0.5601; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5512;  Loss pred: 0.5512; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5377;  Loss pred: 0.5377; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5298;  Loss pred: 0.5298; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5000 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5141;  Loss pred: 0.5141; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5000 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5049;  Loss pred: 0.5049; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.4897;  Loss pred: 0.4897; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5000 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4804;  Loss pred: 0.4804; Loss self: 0.0000; time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5000 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4660;  Loss pred: 0.4660; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6884 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5000 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4531;  Loss pred: 0.4531; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6878 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5000 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4373;  Loss pred: 0.4373; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.5000 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4241;  Loss pred: 0.4241; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6864 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5000 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4087;  Loss pred: 0.4087; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6856 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5000 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.3922;  Loss pred: 0.3922; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6846 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.5000 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3793;  Loss pred: 0.3793; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6834 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.5000 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3663;  Loss pred: 0.3663; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6820 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5000 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3420;  Loss pred: 0.3420; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6805 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6869 score: 0.5000 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3390;  Loss pred: 0.3390; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6788 score: 0.5116 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6859 score: 0.5000 time: 0.11s
Epoch 45/1000, LR 0.000269
Train loss: 0.3288;  Loss pred: 0.3288; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6770 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6850 score: 0.5000 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3143;  Loss pred: 0.3143; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6751 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6839 score: 0.5000 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2951;  Loss pred: 0.2951; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6732 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6828 score: 0.5000 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2881;  Loss pred: 0.2881; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6710 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6816 score: 0.5000 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2676;  Loss pred: 0.2676; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6689 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6804 score: 0.5000 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2549;  Loss pred: 0.2549; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6665 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6791 score: 0.5000 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2446;  Loss pred: 0.2446; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6640 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6777 score: 0.5000 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2318;  Loss pred: 0.2318; Loss self: 0.0000; time: 0.06s
Val loss: 0.6614 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6764 score: 0.5000 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2141;  Loss pred: 0.2141; Loss self: 0.0000; time: 0.06s
Val loss: 0.6583 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6748 score: 0.5000 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2036;  Loss pred: 0.2036; Loss self: 0.0000; time: 0.07s
Val loss: 0.6553 score: 0.5349 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6733 score: 0.5000 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1910;  Loss pred: 0.1910; Loss self: 0.0000; time: 0.07s
Val loss: 0.6516 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6713 score: 0.5000 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1763;  Loss pred: 0.1763; Loss self: 0.0000; time: 0.07s
Val loss: 0.6478 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6692 score: 0.5000 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1669;  Loss pred: 0.1669; Loss self: 0.0000; time: 0.07s
Val loss: 0.6434 score: 0.5349 time: 0.05s
Test loss: 0.6667 score: 0.5227 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1556;  Loss pred: 0.1556; Loss self: 0.0000; time: 0.07s
Val loss: 0.6388 score: 0.5581 time: 0.05s
Test loss: 0.6641 score: 0.5682 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1439;  Loss pred: 0.1439; Loss self: 0.0000; time: 0.07s
Val loss: 0.6336 score: 0.5581 time: 0.05s
Test loss: 0.6612 score: 0.5682 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1346;  Loss pred: 0.1346; Loss self: 0.0000; time: 0.07s
Val loss: 0.6280 score: 0.5814 time: 0.05s
Test loss: 0.6581 score: 0.5682 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1166;  Loss pred: 0.1166; Loss self: 0.0000; time: 0.07s
Val loss: 0.6225 score: 0.5814 time: 0.05s
Test loss: 0.6553 score: 0.5682 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1136;  Loss pred: 0.1136; Loss self: 0.0000; time: 0.07s
Val loss: 0.6165 score: 0.6047 time: 0.05s
Test loss: 0.6522 score: 0.5682 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1038;  Loss pred: 0.1038; Loss self: 0.0000; time: 0.07s
Val loss: 0.6099 score: 0.6279 time: 0.05s
Test loss: 0.6489 score: 0.5682 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0996;  Loss pred: 0.0996; Loss self: 0.0000; time: 0.07s
Val loss: 0.6031 score: 0.6512 time: 0.05s
Test loss: 0.6454 score: 0.5682 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0909;  Loss pred: 0.0909; Loss self: 0.0000; time: 0.12s
Val loss: 0.5960 score: 0.6512 time: 0.08s
Test loss: 0.6419 score: 0.5682 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0823;  Loss pred: 0.0823; Loss self: 0.0000; time: 0.07s
Val loss: 0.5884 score: 0.6512 time: 0.05s
Test loss: 0.6382 score: 0.5682 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0756;  Loss pred: 0.0756; Loss self: 0.0000; time: 0.07s
Val loss: 0.5801 score: 0.6512 time: 0.05s
Test loss: 0.6344 score: 0.5682 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0683;  Loss pred: 0.0683; Loss self: 0.0000; time: 0.07s
Val loss: 0.5718 score: 0.6512 time: 0.05s
Test loss: 0.6306 score: 0.5909 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0651;  Loss pred: 0.0651; Loss self: 0.0000; time: 0.07s
Val loss: 0.5628 score: 0.6512 time: 0.05s
Test loss: 0.6266 score: 0.5909 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0600;  Loss pred: 0.0600; Loss self: 0.0000; time: 0.07s
Val loss: 0.5536 score: 0.6512 time: 0.05s
Test loss: 0.6227 score: 0.5909 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0549;  Loss pred: 0.0549; Loss self: 0.0000; time: 0.07s
Val loss: 0.5448 score: 0.6279 time: 0.05s
Test loss: 0.6196 score: 0.5909 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0522;  Loss pred: 0.0522; Loss self: 0.0000; time: 0.07s
Val loss: 0.5357 score: 0.6512 time: 0.05s
Test loss: 0.6168 score: 0.5909 time: 0.06s
Epoch 73/1000, LR 0.000267
Train loss: 0.0469;  Loss pred: 0.0469; Loss self: 0.0000; time: 0.07s
Val loss: 0.5259 score: 0.6512 time: 0.05s
Test loss: 0.6136 score: 0.5909 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0428;  Loss pred: 0.0428; Loss self: 0.0000; time: 0.07s
Val loss: 0.5155 score: 0.6744 time: 0.05s
Test loss: 0.6100 score: 0.5909 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0400;  Loss pred: 0.0400; Loss self: 0.0000; time: 0.07s
Val loss: 0.5048 score: 0.6977 time: 0.05s
Test loss: 0.6065 score: 0.5909 time: 0.06s
Epoch 76/1000, LR 0.000267
Train loss: 0.0369;  Loss pred: 0.0369; Loss self: 0.0000; time: 0.14s
Val loss: 0.4939 score: 0.7209 time: 0.05s
Test loss: 0.6029 score: 0.5909 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0328;  Loss pred: 0.0328; Loss self: 0.0000; time: 0.07s
Val loss: 0.4832 score: 0.7209 time: 0.05s
Test loss: 0.5997 score: 0.5682 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0292;  Loss pred: 0.0292; Loss self: 0.0000; time: 0.07s
Val loss: 0.4723 score: 0.7209 time: 0.05s
Test loss: 0.5964 score: 0.5682 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0301;  Loss pred: 0.0301; Loss self: 0.0000; time: 0.07s
Val loss: 0.4616 score: 0.7209 time: 0.05s
Test loss: 0.5939 score: 0.5909 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0267;  Loss pred: 0.0267; Loss self: 0.0000; time: 0.07s
Val loss: 0.4516 score: 0.7442 time: 0.05s
Test loss: 0.5923 score: 0.6364 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0263;  Loss pred: 0.0263; Loss self: 0.0000; time: 0.07s
Val loss: 0.4416 score: 0.6977 time: 0.05s
Test loss: 0.5908 score: 0.6591 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0241;  Loss pred: 0.0241; Loss self: 0.0000; time: 0.07s
Val loss: 0.4333 score: 0.7209 time: 0.05s
Test loss: 0.5908 score: 0.6591 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0205;  Loss pred: 0.0205; Loss self: 0.0000; time: 0.07s
Val loss: 0.4251 score: 0.7209 time: 0.05s
Test loss: 0.5908 score: 0.6591 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0184;  Loss pred: 0.0184; Loss self: 0.0000; time: 0.07s
Val loss: 0.4181 score: 0.7209 time: 0.05s
Test loss: 0.5918 score: 0.6591 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0175;  Loss pred: 0.0175; Loss self: 0.0000; time: 0.07s
Val loss: 0.4112 score: 0.7442 time: 0.15s
Test loss: 0.5926 score: 0.6591 time: 0.06s
Epoch 86/1000, LR 0.000266
Train loss: 0.0179;  Loss pred: 0.0179; Loss self: 0.0000; time: 0.07s
Val loss: 0.4042 score: 0.7442 time: 0.05s
Test loss: 0.5927 score: 0.6591 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.07s
Val loss: 0.3980 score: 0.7674 time: 0.05s
Test loss: 0.5934 score: 0.7045 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.07s
Val loss: 0.3926 score: 0.7907 time: 0.05s
Test loss: 0.5950 score: 0.7273 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.07s
Val loss: 0.3884 score: 0.8140 time: 0.05s
Test loss: 0.5976 score: 0.7500 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0123;  Loss pred: 0.0123; Loss self: 0.0000; time: 0.07s
Val loss: 0.3852 score: 0.8140 time: 0.05s
Test loss: 0.6013 score: 0.7727 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.07s
Val loss: 0.3829 score: 0.8140 time: 0.05s
Test loss: 0.6054 score: 0.7955 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.07s
Val loss: 0.3819 score: 0.8140 time: 0.05s
Test loss: 0.6109 score: 0.7955 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.07s
Val loss: 0.3818 score: 0.8372 time: 0.05s
Test loss: 0.6171 score: 0.7955 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0100;  Loss pred: 0.0100; Loss self: 0.0000; time: 0.07s
Val loss: 0.3833 score: 0.8140 time: 0.05s
Test loss: 0.6254 score: 0.7955 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.07s
Val loss: 0.3857 score: 0.8140 time: 0.05s
Test loss: 0.6343 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.08s
Val loss: 0.3889 score: 0.8140 time: 0.14s
Test loss: 0.6436 score: 0.7500 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.3931 score: 0.8140 time: 0.05s
Test loss: 0.6533 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.3984 score: 0.8140 time: 0.05s
Test loss: 0.6644 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.07s
Val loss: 0.4047 score: 0.8372 time: 0.05s
Test loss: 0.6767 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.07s
Val loss: 0.4110 score: 0.8372 time: 0.05s
Test loss: 0.6890 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.07s
Val loss: 0.4178 score: 0.8372 time: 0.05s
Test loss: 0.7020 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.4249 score: 0.8372 time: 0.05s
Test loss: 0.7146 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.07s
Val loss: 0.4327 score: 0.8372 time: 0.05s
Test loss: 0.7279 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.07s
Val loss: 0.4410 score: 0.8372 time: 0.05s
Test loss: 0.7412 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.07s
Val loss: 0.4495 score: 0.8372 time: 0.05s
Test loss: 0.7544 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.4579 score: 0.8372 time: 0.05s
Test loss: 0.7675 score: 0.7500 time: 0.18s
     INFO: Early stopping counter 13 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.07s
Val loss: 0.4659 score: 0.8372 time: 0.05s
Test loss: 0.7809 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.4744 score: 0.8372 time: 0.05s
Test loss: 0.7943 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.4828 score: 0.8372 time: 0.05s
Test loss: 0.8077 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.08s
Val loss: 0.4916 score: 0.8372 time: 0.06s
Test loss: 0.8211 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.07s
Val loss: 0.4988 score: 0.8372 time: 0.05s
Test loss: 0.8325 score: 0.7727 time: 0.06s
     INFO: Early stopping counter 18 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.08s
Val loss: 0.5069 score: 0.8372 time: 0.05s
Test loss: 0.8446 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.08s
Val loss: 0.5126 score: 0.8372 time: 0.05s
Test loss: 0.8540 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 092,   Train_Loss: 0.0098,   Val_Loss: 0.3818,   Val_Precision: 0.8947,   Val_Recall: 0.7727,   Val_accuracy: 0.8293,   Val_Score: 0.8372,   Val_Loss: 0.3818,   Test_Precision: 0.7826,   Test_Recall: 0.8182,   Test_accuracy: 0.8000,   Test_Score: 0.7955,   Test_loss: 0.6171


[0.05340108601376414, 0.05313825700432062, 0.059323825989849865, 0.05864024499896914, 0.057866904069669545, 0.057862470974214375, 0.05792369495611638, 0.05886726500466466, 0.05850587098393589, 0.05808247299864888, 0.05819949693977833, 0.12606153590604663, 0.057285672053694725, 0.05803714494686574, 0.05799870798364282, 0.05758142995182425, 0.05827220797073096, 0.05859114194754511, 0.058789524948224425, 0.058463298017159104, 0.058763497043401, 0.06715877505484968, 0.061017528059892356, 0.05653185595292598, 0.056740344036370516, 0.056628935970366, 0.05695479200221598, 0.0576294349739328, 0.05666861101053655, 0.05690099496860057, 0.056704310001805425, 0.05630652897525579, 0.05752957600634545, 0.056682090973481536, 0.056421984918415546, 0.05639145604800433, 0.05652437498793006, 0.05713567906059325, 0.05717997101601213, 0.05738633801229298, 0.05722431093454361, 0.05657544801943004, 0.05633283290080726, 0.1144046620465815, 0.05103650002274662, 0.05113324709236622, 0.05149173003155738, 0.052352866041474044, 0.05224999599158764, 0.053407890954986215, 0.052964241011068225, 0.05256134795490652, 0.05365614593029022, 0.05597770900931209, 0.05629201093688607, 0.05656752793584019, 0.0559990790206939, 0.05584862793330103, 0.056437677005305886, 0.05593533697538078, 0.05738786095753312, 0.05681226192973554, 0.05670515599194914, 0.05830199900083244, 0.05712968797888607, 0.05788427300285548, 0.05755328305531293, 0.05780242395121604, 0.05756431899499148, 0.058464447036385536, 0.05847931804601103, 0.06098708708304912, 0.059507991070859134, 0.05559113004710525, 0.07110032392665744, 0.05590505700092763, 0.05569252499844879, 0.05568124901037663, 0.055430362932384014, 0.055508460965938866, 0.05717943294439465, 0.056712166988290846, 0.056869110092520714, 0.05577930004801601, 0.06033382599707693, 0.059514419990591705, 0.055944960098713636, 0.05574650492053479, 0.055696010007523, 0.05586854193825275, 0.05581246304791421, 0.05853543395642191, 0.05667927791364491, 0.05623789899982512, 0.05678574205376208, 0.060316353919915855, 0.0586445729713887, 0.05481291399337351, 0.05466787295881659, 0.05515934992581606, 0.05535212403628975, 0.0566393710905686, 0.056531735928729177, 0.05597045295871794, 0.05620331806130707, 0.18981568503659219, 0.05947136809118092, 0.054775993921794, 0.05516786500811577, 0.05800481408368796, 0.06246999104041606, 0.05976834602188319, 0.056535150040872395]
[0.0012136610457673669, 0.001207687659189105, 0.0013482687724965879, 0.0013327328408856622, 0.001315156910674308, 0.0013150561585048722, 0.0013164476126390086, 0.0013378923864696515, 0.001329678885998543, 0.0013200562045147474, 0.0013227158395404165, 0.002865034906955605, 0.0013019470921294255, 0.0013190260215196759, 0.0013181524541737003, 0.0013086688625414602, 0.0013243683629711582, 0.001331616862444207, 0.0013361255670051005, 0.0013287113185717978, 0.001335534023713659, 0.001526335796701129, 0.00138676200136119, 0.001284814908021045, 0.0012895532735538754, 0.0012870212720537727, 0.001294427090959454, 0.0013097598857712, 0.0012879229775121944, 0.0012932044311045584, 0.0012887343182228506, 0.0012796938403467225, 0.0013074903637805785, 0.0012882293403063986, 0.0012823178390548987, 0.0012816240010910076, 0.0012846448860893195, 0.0012985381604680283, 0.0012995447958184575, 0.0013042349548248405, 0.0013005525212396276, 0.0012858056368052282, 0.0012802916568365288, 0.002600105955604125, 0.0011599204550624233, 0.0011621192520992322, 0.001170266591626304, 0.0011898378645789555, 0.001187499908899719, 0.001213815703522414, 0.0012037327502515507, 0.001194576089884239, 0.0012194578620520506, 0.0012722206593025476, 0.001279363884929229, 0.0012856256349054588, 0.0012727063413794067, 0.0012692869984841143, 0.0012826744773933156, 0.0012712576585313814, 0.001304269567216662, 0.0012911877711303532, 0.0012887535452715713, 0.001325045431837101, 0.001298401999520138, 0.0013155516591558064, 0.0013080291603480212, 0.0013136914534367281, 0.0013082799771588973, 0.0013287374326451259, 0.0013290754101366144, 0.0013860701609783891, 0.0013524543425195259, 0.0012634347737978467, 0.0016159164528785782, 0.0012705694772938098, 0.0012657392045101997, 0.0012654829320540143, 0.0012597809757360003, 0.0012615559310440651, 0.0012995325669180602, 0.0012889128860975193, 0.0012924797748300161, 0.0012677113647276367, 0.0013712233181153847, 0.0013526004543316296, 0.0012714763658798554, 0.0012669660209212452, 0.0012658184092618865, 0.0012697395895057443, 0.0012684650692707774, 0.0013303507717368616, 0.0012881654071282935, 0.0012781340681778436, 0.001290585046676411, 0.001370826225452633, 0.0013328312038951976, 0.0012457480453039434, 0.0012424516581549224, 0.0012536215892230923, 0.0012580028190065852, 0.0012872584338765591, 0.0012848121801983905, 0.0012720557490617714, 0.001277348137756979, 0.004313992841740732, 0.0013516220020722937, 0.0012449089527680453, 0.001253815113820813, 0.0013182912291747264, 0.0014197725236458195, 0.0013583715004973453, 0.0012848897736561908]
[823.9532804381355, 828.0286648548221, 741.6918795414219, 750.337929194762, 760.3655441290877, 760.4237990390698, 759.6200489857368, 747.4442713877302, 752.0612762449292, 757.5435019962654, 756.0202804764585, 349.0358869877097, 768.0803667408866, 758.135157066788, 758.6375891754205, 764.1352435466224, 755.076931735629, 750.9667594359549, 748.4326508634069, 752.6089271783112, 748.7641514510766, 655.1638257854535, 721.1042695274605, 778.3222266157112, 775.4623407252525, 776.9879346316035, 772.5425456437109, 763.4987228297878, 776.4439469289084, 773.272945829512, 775.9551257849548, 781.4369097291726, 764.8239923608484, 776.2592953845899, 779.8378604301612, 780.2600444036086, 778.4252370662311, 770.0967368102397, 769.500215165878, 766.7330156277712, 768.9039724799776, 777.7225199328306, 781.0720273464087, 384.59971134816834, 862.1280844178087, 860.4968880720436, 854.50615026984, 840.4506443857938, 842.105327760869, 823.848296819744, 830.7491839787732, 837.1170396495257, 820.0365351839575, 786.0271665044463, 781.6384468718354, 777.8314097428037, 785.7272078303331, 787.8438849482278, 779.6210321672776, 786.6225963627614, 766.7126682515644, 774.4806931718098, 775.9435492294036, 754.691104148449, 770.1774953901635, 760.137386502711, 764.5089500404828, 761.2137518166196, 764.3623822567644, 752.5941359304478, 752.4027548573869, 721.4642001196587, 739.3964946255202, 791.4931745894806, 618.843875386385, 787.0486564260173, 790.0521659096178, 790.212159066336, 793.7887769862307, 792.6719500834171, 769.5074563399174, 775.8476238279612, 773.706497752754, 788.8230931927052, 729.2758129101861, 739.3166228782152, 786.4872889776484, 789.2871501580389, 790.0027307890962, 787.5630627452182, 788.3543853319396, 751.6814521740257, 776.2978220547776, 782.3905370315634, 774.8423883999413, 729.4870651236703, 750.2825542180444, 802.7305391083438, 804.8602884759554, 797.688878842403, 794.9107783317021, 776.8447839867829, 778.3238790945989, 786.1290676431192, 782.8719285221633, 231.80381532494425, 739.8518213426607, 803.2715949037942, 797.5657566869253, 758.5577282692062, 704.3381832972159, 736.1756335684801, 778.2768767428752]
Elapsed: 0.05927513367743684~0.015130688346050197
Time per graph: 0.0013471621290326555~0.00034387928059205
Speed: 761.7353175279634~80.59953127988229
Total Time: 0.0572
best val loss: 0.38180315494537354 test_score: 0.7955

Testing...
Test loss: 0.6171 score: 0.7955 time: 0.05s
test Score 0.7955
Epoch Time List: [0.16344055300578475, 0.1597105999244377, 0.3101115069584921, 0.1751128031173721, 0.17460485198535025, 0.1741151368478313, 0.17437757807783782, 0.1751812678994611, 0.17659674293827266, 0.17607315012719482, 0.17549042694736272, 0.26294736901763827, 0.17354228103067726, 0.17393519601318985, 0.17409701296128333, 0.17390376096591353, 0.1744296740507707, 0.17596557887736708, 0.1782697088783607, 0.17769848788157105, 0.17738243390340358, 0.18696037598419935, 0.29249683499801904, 0.1771285090362653, 0.1696148010669276, 0.16942509799264371, 0.16985778196249157, 0.17119350004941225, 0.170271237147972, 0.17294384981505573, 0.17065586789976805, 0.16921050404198468, 0.16879093693569303, 0.2884873071452603, 0.16918367613106966, 0.1684464409481734, 0.16987571702338755, 0.169719269964844, 0.1717078509973362, 0.17161447601392865, 0.1714298209408298, 0.16911234997678548, 0.16887440287973732, 0.24475880584213883, 0.15318216301966459, 0.1527209150372073, 0.1538352119969204, 0.154616829007864, 0.15776346705388278, 0.16056172689422965, 0.15929883101489395, 0.15846306004095823, 0.15827802591957152, 0.28101094102021307, 0.16965512291062623, 0.16963883803691715, 0.16813165787607431, 0.16857141396030784, 0.16990693705156446, 0.16845453809946775, 0.1731053909752518, 0.17213826102670282, 0.17008262092713267, 0.17109399486798793, 0.25083827797789127, 0.1714956589275971, 0.1714257668936625, 0.17400702484883368, 0.1720972522161901, 0.17490619595628232, 0.17516175005584955, 0.18024662195239216, 0.18348214705474675, 0.16924554109573364, 0.1839720840798691, 0.24104469479061663, 0.16840907314326614, 0.169175281887874, 0.16928910301066935, 0.17020856880117208, 0.17025516915600747, 0.17547545791603625, 0.17325688898563385, 0.1717902849195525, 0.27168897702358663, 0.1807476709363982, 0.17234080599155277, 0.1722579001216218, 0.17257852794136852, 0.171577462926507, 0.17231117887422442, 0.17487274296581745, 0.17699755099602044, 0.17334415798541158, 0.1729213650105521, 0.2753974790684879, 0.17813251307234168, 0.17162680090405047, 0.1656046168645844, 0.16665433498565108, 0.16820841503795236, 0.16788191709201783, 0.1741801000898704, 0.17260149307549, 0.17214286013040692, 0.3043612309265882, 0.18111248093191534, 0.17310836690012366, 0.1688665368128568, 0.18727946083527058, 0.18041723303031176, 0.184493999928236, 0.18469607492443174]
Total Epoch List: [113]
Total Time List: [0.05715318606235087]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a82e5150>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7029;  Loss pred: 0.7029; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6992 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.7052;  Loss pred: 0.7052; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6990 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.7027;  Loss pred: 0.7027; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6989 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.7002;  Loss pred: 0.7002; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6987 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.7012;  Loss pred: 0.7012; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6985 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6987;  Loss pred: 0.6987; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6983 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6998;  Loss pred: 0.6998; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6981 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6972;  Loss pred: 0.6972; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6978 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6975 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6888;  Loss pred: 0.6888; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6972 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6889;  Loss pred: 0.6889; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6968 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6845;  Loss pred: 0.6845; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6965 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6775;  Loss pred: 0.6775; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6961 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6761;  Loss pred: 0.6761; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6958 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6727;  Loss pred: 0.6727; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6955 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6681;  Loss pred: 0.6681; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6668;  Loss pred: 0.6668; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6681;  Loss pred: 0.6681; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6580;  Loss pred: 0.6580; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6516;  Loss pred: 0.6516; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6473;  Loss pred: 0.6473; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6368;  Loss pred: 0.6368; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6357;  Loss pred: 0.6357; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6251;  Loss pred: 0.6251; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6291;  Loss pred: 0.6291; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6169;  Loss pred: 0.6169; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6133;  Loss pred: 0.6133; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.6079;  Loss pred: 0.6079; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5907;  Loss pred: 0.5907; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5855;  Loss pred: 0.5855; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5785;  Loss pred: 0.5785; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5690;  Loss pred: 0.5690; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5550;  Loss pred: 0.5550; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6900 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5425;  Loss pred: 0.5425; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6883 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5350;  Loss pred: 0.5350; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5239;  Loss pred: 0.5239; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5000 time: 0.06s
Test loss: 0.6868 score: 0.5349 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5148;  Loss pred: 0.5148; Loss self: 0.0000; time: 0.08s
Val loss: 0.6873 score: 0.5227 time: 0.05s
Test loss: 0.6859 score: 0.5349 time: 0.06s
Epoch 38/1000, LR 0.000270
Train loss: 0.5042;  Loss pred: 0.5042; Loss self: 0.0000; time: 0.08s
Val loss: 0.6864 score: 0.5455 time: 0.05s
Test loss: 0.6849 score: 0.6047 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4806;  Loss pred: 0.4806; Loss self: 0.0000; time: 0.08s
Val loss: 0.6854 score: 0.5455 time: 0.05s
Test loss: 0.6838 score: 0.6512 time: 0.04s
Epoch 40/1000, LR 0.000269
Train loss: 0.4770;  Loss pred: 0.4770; Loss self: 0.0000; time: 0.08s
Val loss: 0.6841 score: 0.5909 time: 0.05s
Test loss: 0.6826 score: 0.6744 time: 0.04s
Epoch 41/1000, LR 0.000269
Train loss: 0.4592;  Loss pred: 0.4592; Loss self: 0.0000; time: 0.08s
Val loss: 0.6828 score: 0.6591 time: 0.05s
Test loss: 0.6811 score: 0.6977 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4407;  Loss pred: 0.4407; Loss self: 0.0000; time: 0.08s
Val loss: 0.6812 score: 0.7955 time: 0.05s
Test loss: 0.6795 score: 0.8372 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4349;  Loss pred: 0.4349; Loss self: 0.0000; time: 0.08s
Val loss: 0.6795 score: 0.8636 time: 0.05s
Test loss: 0.6776 score: 0.8605 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4148;  Loss pred: 0.4148; Loss self: 0.0000; time: 0.08s
Val loss: 0.6776 score: 0.8182 time: 0.05s
Test loss: 0.6755 score: 0.9070 time: 0.04s
Epoch 45/1000, LR 0.000269
Train loss: 0.3994;  Loss pred: 0.3994; Loss self: 0.0000; time: 0.08s
Val loss: 0.6755 score: 0.7955 time: 0.05s
Test loss: 0.6732 score: 0.9302 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3941;  Loss pred: 0.3941; Loss self: 0.0000; time: 0.08s
Val loss: 0.6731 score: 0.7955 time: 0.05s
Test loss: 0.6706 score: 0.9302 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3730;  Loss pred: 0.3730; Loss self: 0.0000; time: 0.08s
Val loss: 0.6705 score: 0.7955 time: 0.05s
Test loss: 0.6677 score: 0.9302 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3694;  Loss pred: 0.3694; Loss self: 0.0000; time: 0.08s
Val loss: 0.6677 score: 0.7955 time: 0.05s
Test loss: 0.6645 score: 0.9302 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3486;  Loss pred: 0.3486; Loss self: 0.0000; time: 0.08s
Val loss: 0.6646 score: 0.7955 time: 0.05s
Test loss: 0.6610 score: 0.9302 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3398;  Loss pred: 0.3398; Loss self: 0.0000; time: 0.08s
Val loss: 0.6610 score: 0.8182 time: 0.05s
Test loss: 0.6571 score: 0.9302 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3183;  Loss pred: 0.3183; Loss self: 0.0000; time: 0.08s
Val loss: 0.6570 score: 0.8182 time: 0.05s
Test loss: 0.6527 score: 0.9302 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3021;  Loss pred: 0.3021; Loss self: 0.0000; time: 0.08s
Val loss: 0.6527 score: 0.8409 time: 0.05s
Test loss: 0.6479 score: 0.9302 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2903;  Loss pred: 0.2903; Loss self: 0.0000; time: 0.08s
Val loss: 0.6480 score: 0.8409 time: 0.05s
Test loss: 0.6427 score: 0.9302 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2732;  Loss pred: 0.2732; Loss self: 0.0000; time: 0.08s
Val loss: 0.6430 score: 0.8182 time: 0.05s
Test loss: 0.6369 score: 0.9302 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2597;  Loss pred: 0.2597; Loss self: 0.0000; time: 0.08s
Val loss: 0.6377 score: 0.8182 time: 0.05s
Test loss: 0.6308 score: 0.9302 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2492;  Loss pred: 0.2492; Loss self: 0.0000; time: 0.08s
Val loss: 0.6319 score: 0.8409 time: 0.05s
Test loss: 0.6240 score: 0.9302 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2447;  Loss pred: 0.2447; Loss self: 0.0000; time: 0.08s
Val loss: 0.6257 score: 0.8409 time: 0.05s
Test loss: 0.6168 score: 0.9302 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2161;  Loss pred: 0.2161; Loss self: 0.0000; time: 0.08s
Val loss: 0.6192 score: 0.8409 time: 0.05s
Test loss: 0.6091 score: 0.9070 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2115;  Loss pred: 0.2115; Loss self: 0.0000; time: 0.08s
Val loss: 0.6120 score: 0.8409 time: 0.05s
Test loss: 0.6007 score: 0.9070 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2032;  Loss pred: 0.2032; Loss self: 0.0000; time: 0.08s
Val loss: 0.6041 score: 0.8409 time: 0.05s
Test loss: 0.5916 score: 0.9070 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1839;  Loss pred: 0.1839; Loss self: 0.0000; time: 0.08s
Val loss: 0.5958 score: 0.8409 time: 0.05s
Test loss: 0.5818 score: 0.9070 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1756;  Loss pred: 0.1756; Loss self: 0.0000; time: 0.08s
Val loss: 0.5870 score: 0.8409 time: 0.05s
Test loss: 0.5717 score: 0.9070 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1639;  Loss pred: 0.1639; Loss self: 0.0000; time: 0.08s
Val loss: 0.5776 score: 0.8409 time: 0.05s
Test loss: 0.5608 score: 0.9070 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1584;  Loss pred: 0.1584; Loss self: 0.0000; time: 0.08s
Val loss: 0.5678 score: 0.8409 time: 0.05s
Test loss: 0.5497 score: 0.9070 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1460;  Loss pred: 0.1460; Loss self: 0.0000; time: 0.08s
Val loss: 0.5579 score: 0.8409 time: 0.05s
Test loss: 0.5387 score: 0.9070 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1425;  Loss pred: 0.1425; Loss self: 0.0000; time: 0.08s
Val loss: 0.5476 score: 0.8409 time: 0.05s
Test loss: 0.5273 score: 0.9070 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1228;  Loss pred: 0.1228; Loss self: 0.0000; time: 0.08s
Val loss: 0.5373 score: 0.8409 time: 0.05s
Test loss: 0.5158 score: 0.9070 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1248;  Loss pred: 0.1248; Loss self: 0.0000; time: 0.08s
Val loss: 0.5268 score: 0.8409 time: 0.05s
Test loss: 0.5040 score: 0.9070 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1181;  Loss pred: 0.1181; Loss self: 0.0000; time: 0.08s
Val loss: 0.5162 score: 0.8409 time: 0.05s
Test loss: 0.4920 score: 0.9070 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0989;  Loss pred: 0.0989; Loss self: 0.0000; time: 0.08s
Val loss: 0.5053 score: 0.8409 time: 0.05s
Test loss: 0.4796 score: 0.9070 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0962;  Loss pred: 0.0962; Loss self: 0.0000; time: 0.08s
Val loss: 0.4945 score: 0.8409 time: 0.05s
Test loss: 0.4674 score: 0.9070 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0813;  Loss pred: 0.0813; Loss self: 0.0000; time: 0.08s
Val loss: 0.4837 score: 0.8409 time: 0.05s
Test loss: 0.4553 score: 0.9070 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0810;  Loss pred: 0.0810; Loss self: 0.0000; time: 0.08s
Val loss: 0.4734 score: 0.8409 time: 0.05s
Test loss: 0.4436 score: 0.9070 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0784;  Loss pred: 0.0784; Loss self: 0.0000; time: 0.08s
Val loss: 0.4630 score: 0.8409 time: 0.05s
Test loss: 0.4317 score: 0.9070 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0686;  Loss pred: 0.0686; Loss self: 0.0000; time: 0.08s
Val loss: 0.4532 score: 0.8409 time: 0.05s
Test loss: 0.4204 score: 0.9070 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0709;  Loss pred: 0.0709; Loss self: 0.0000; time: 0.08s
Val loss: 0.4440 score: 0.8636 time: 0.05s
Test loss: 0.4095 score: 0.9302 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0696;  Loss pred: 0.0696; Loss self: 0.0000; time: 0.08s
Val loss: 0.4360 score: 0.8636 time: 0.05s
Test loss: 0.3993 score: 0.9302 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0568;  Loss pred: 0.0568; Loss self: 0.0000; time: 0.08s
Val loss: 0.4287 score: 0.8636 time: 0.05s
Test loss: 0.3899 score: 0.9302 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.08s
Val loss: 0.4214 score: 0.8636 time: 0.05s
Test loss: 0.3806 score: 0.9302 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0472;  Loss pred: 0.0472; Loss self: 0.0000; time: 0.08s
Val loss: 0.4144 score: 0.8636 time: 0.05s
Test loss: 0.3714 score: 0.9302 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0453;  Loss pred: 0.0453; Loss self: 0.0000; time: 0.08s
Val loss: 0.4077 score: 0.8636 time: 0.05s
Test loss: 0.3628 score: 0.9302 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0363;  Loss pred: 0.0363; Loss self: 0.0000; time: 0.08s
Val loss: 0.4014 score: 0.8636 time: 0.05s
Test loss: 0.3546 score: 0.9302 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0380;  Loss pred: 0.0380; Loss self: 0.0000; time: 0.08s
Val loss: 0.3957 score: 0.8409 time: 0.05s
Test loss: 0.3465 score: 0.9302 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0351;  Loss pred: 0.0351; Loss self: 0.0000; time: 0.08s
Val loss: 0.3907 score: 0.8409 time: 0.05s
Test loss: 0.3389 score: 0.9302 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0335;  Loss pred: 0.0335; Loss self: 0.0000; time: 0.08s
Val loss: 0.3870 score: 0.8409 time: 0.05s
Test loss: 0.3320 score: 0.9302 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0303;  Loss pred: 0.0303; Loss self: 0.0000; time: 0.08s
Val loss: 0.3847 score: 0.8636 time: 0.05s
Test loss: 0.3259 score: 0.9302 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0282;  Loss pred: 0.0282; Loss self: 0.0000; time: 0.08s
Val loss: 0.3836 score: 0.8636 time: 0.05s
Test loss: 0.3203 score: 0.9302 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0300;  Loss pred: 0.0300; Loss self: 0.0000; time: 0.08s
Val loss: 0.3831 score: 0.8636 time: 0.05s
Test loss: 0.3155 score: 0.9302 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.08s
Val loss: 0.3833 score: 0.8636 time: 0.05s
Test loss: 0.3114 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0233;  Loss pred: 0.0233; Loss self: 0.0000; time: 0.08s
Val loss: 0.3844 score: 0.8409 time: 0.05s
Test loss: 0.3081 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.08s
Val loss: 0.3862 score: 0.8409 time: 0.05s
Test loss: 0.3056 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.08s
Val loss: 0.3890 score: 0.8409 time: 0.05s
Test loss: 0.3042 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0183;  Loss pred: 0.0183; Loss self: 0.0000; time: 0.08s
Val loss: 0.3928 score: 0.8409 time: 0.05s
Test loss: 0.3037 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.08s
Val loss: 0.3971 score: 0.8409 time: 0.06s
Test loss: 0.3036 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0175;  Loss pred: 0.0175; Loss self: 0.0000; time: 0.08s
Val loss: 0.4021 score: 0.8409 time: 0.05s
Test loss: 0.3039 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.08s
Val loss: 0.4082 score: 0.8409 time: 0.06s
Test loss: 0.3051 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0160;  Loss pred: 0.0160; Loss self: 0.0000; time: 0.08s
Val loss: 0.4147 score: 0.8409 time: 0.05s
Test loss: 0.3065 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.08s
Val loss: 0.4225 score: 0.8409 time: 0.05s
Test loss: 0.3091 score: 0.9070 time: 0.04s
     INFO: Early stopping counter 10 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.08s
Val loss: 0.4308 score: 0.8409 time: 0.05s
Test loss: 0.3122 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.08s
Val loss: 0.4402 score: 0.8409 time: 0.05s
Test loss: 0.3158 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0123;  Loss pred: 0.0123; Loss self: 0.0000; time: 0.08s
Val loss: 0.4501 score: 0.8409 time: 0.05s
Test loss: 0.3197 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.08s
Val loss: 0.4595 score: 0.8409 time: 0.05s
Test loss: 0.3235 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.08s
Val loss: 0.4683 score: 0.8409 time: 0.05s
Test loss: 0.3267 score: 0.9070 time: 0.04s
     INFO: Early stopping counter 15 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0131;  Loss pred: 0.0131; Loss self: 0.0000; time: 0.08s
Val loss: 0.4776 score: 0.8409 time: 0.05s
Test loss: 0.3317 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.08s
Val loss: 0.4872 score: 0.8409 time: 0.05s
Test loss: 0.3367 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.08s
Val loss: 0.4969 score: 0.8409 time: 0.05s
Test loss: 0.3417 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.08s
Val loss: 0.5065 score: 0.8409 time: 0.05s
Test loss: 0.3468 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0088;  Loss pred: 0.0088; Loss self: 0.0000; time: 0.08s
Val loss: 0.5156 score: 0.8409 time: 0.06s
Test loss: 0.3515 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 087,   Train_Loss: 0.0300,   Val_Loss: 0.3831,   Val_Precision: 0.9444,   Val_Recall: 0.7727,   Val_accuracy: 0.8500,   Val_Score: 0.8636,   Val_Loss: 0.3831,   Test_Precision: 0.9524,   Test_Recall: 0.9091,   Test_accuracy: 0.9302,   Test_Score: 0.9302,   Test_loss: 0.3155


[0.05340108601376414, 0.05313825700432062, 0.059323825989849865, 0.05864024499896914, 0.057866904069669545, 0.057862470974214375, 0.05792369495611638, 0.05886726500466466, 0.05850587098393589, 0.05808247299864888, 0.05819949693977833, 0.12606153590604663, 0.057285672053694725, 0.05803714494686574, 0.05799870798364282, 0.05758142995182425, 0.05827220797073096, 0.05859114194754511, 0.058789524948224425, 0.058463298017159104, 0.058763497043401, 0.06715877505484968, 0.061017528059892356, 0.05653185595292598, 0.056740344036370516, 0.056628935970366, 0.05695479200221598, 0.0576294349739328, 0.05666861101053655, 0.05690099496860057, 0.056704310001805425, 0.05630652897525579, 0.05752957600634545, 0.056682090973481536, 0.056421984918415546, 0.05639145604800433, 0.05652437498793006, 0.05713567906059325, 0.05717997101601213, 0.05738633801229298, 0.05722431093454361, 0.05657544801943004, 0.05633283290080726, 0.1144046620465815, 0.05103650002274662, 0.05113324709236622, 0.05149173003155738, 0.052352866041474044, 0.05224999599158764, 0.053407890954986215, 0.052964241011068225, 0.05256134795490652, 0.05365614593029022, 0.05597770900931209, 0.05629201093688607, 0.05656752793584019, 0.0559990790206939, 0.05584862793330103, 0.056437677005305886, 0.05593533697538078, 0.05738786095753312, 0.05681226192973554, 0.05670515599194914, 0.05830199900083244, 0.05712968797888607, 0.05788427300285548, 0.05755328305531293, 0.05780242395121604, 0.05756431899499148, 0.058464447036385536, 0.05847931804601103, 0.06098708708304912, 0.059507991070859134, 0.05559113004710525, 0.07110032392665744, 0.05590505700092763, 0.05569252499844879, 0.05568124901037663, 0.055430362932384014, 0.055508460965938866, 0.05717943294439465, 0.056712166988290846, 0.056869110092520714, 0.05577930004801601, 0.06033382599707693, 0.059514419990591705, 0.055944960098713636, 0.05574650492053479, 0.055696010007523, 0.05586854193825275, 0.05581246304791421, 0.05853543395642191, 0.05667927791364491, 0.05623789899982512, 0.05678574205376208, 0.060316353919915855, 0.0586445729713887, 0.05481291399337351, 0.05466787295881659, 0.05515934992581606, 0.05535212403628975, 0.0566393710905686, 0.056531735928729177, 0.05597045295871794, 0.05620331806130707, 0.18981568503659219, 0.05947136809118092, 0.054775993921794, 0.05516786500811577, 0.05800481408368796, 0.06246999104041606, 0.05976834602188319, 0.056535150040872395, 0.05179225001484156, 0.05208042205777019, 0.051993647939525545, 0.051654989016242325, 0.05222810502164066, 0.051826325012370944, 0.05222718801815063, 0.052047442994080484, 0.05193119100295007, 0.05234485992696136, 0.05217529600486159, 0.05211240903008729, 0.051149436039850116, 0.05230385297909379, 0.05145789100788534, 0.052295858040452003, 0.05202167807146907, 0.051926982938311994, 0.0523214410059154, 0.05230961297638714, 0.052500369027256966, 0.05176761792972684, 0.052845661994069815, 0.05213218089193106, 0.051985829952172935, 0.052422453998588026, 0.051627191016450524, 0.0529714219737798, 0.05217171600088477, 0.051895553013309836, 0.052199106896296144, 0.05504842195659876, 0.054207430919632316, 0.05605186300817877, 0.055948939989320934, 0.05195904697757214, 0.06322204496245831, 0.05087679694406688, 0.04952857200987637, 0.04984431399498135, 0.052106391987763345, 0.05077499593608081, 0.05028201499953866, 0.049555889097973704, 0.049957377021200955, 0.05029059899970889, 0.04999591992236674, 0.050196080934256315, 0.050654859049245715, 0.05042713996954262, 0.050565014011226594, 0.05070211598649621, 0.050461781094782054, 0.05039170407690108, 0.050304771051742136, 0.05054652492981404, 0.05028025805950165, 0.05027959495782852, 0.050619504996575415, 0.05045039893593639, 0.05040508403908461, 0.049968253006227314, 0.04997595201712102, 0.05042099894490093, 0.050732453004457057, 0.050403491011820734, 0.050553119042888284, 0.05109811096917838, 0.0505656530149281, 0.05003775598015636, 0.05095040996093303, 0.050745279993861914, 0.050047483993694186, 0.05088863999117166, 0.0508165480569005, 0.05001342890318483, 0.05055896902922541, 0.05125895200762898, 0.051672578090801835, 0.050524662947282195, 0.050488397013396025, 0.05044686095789075, 0.05052268807776272, 0.05045886791776866, 0.05016029090620577, 0.05036511807702482, 0.05096651101484895, 0.051572998985648155, 0.05067176604643464, 0.05057854193728417, 0.05044475197792053, 0.05055159900803119, 0.05009743105620146, 0.05227392399683595, 0.05088709993287921, 0.05584630405064672, 0.05044500099029392, 0.04984790598973632, 0.05048965604510158, 0.05078109190799296, 0.05007796105928719, 0.050169387948699296, 0.04972164297942072, 0.050340685062110424, 0.05045673798304051, 0.050307278987020254, 0.051106091937981546, 0.050800838973373175]
[0.0012136610457673669, 0.001207687659189105, 0.0013482687724965879, 0.0013327328408856622, 0.001315156910674308, 0.0013150561585048722, 0.0013164476126390086, 0.0013378923864696515, 0.001329678885998543, 0.0013200562045147474, 0.0013227158395404165, 0.002865034906955605, 0.0013019470921294255, 0.0013190260215196759, 0.0013181524541737003, 0.0013086688625414602, 0.0013243683629711582, 0.001331616862444207, 0.0013361255670051005, 0.0013287113185717978, 0.001335534023713659, 0.001526335796701129, 0.00138676200136119, 0.001284814908021045, 0.0012895532735538754, 0.0012870212720537727, 0.001294427090959454, 0.0013097598857712, 0.0012879229775121944, 0.0012932044311045584, 0.0012887343182228506, 0.0012796938403467225, 0.0013074903637805785, 0.0012882293403063986, 0.0012823178390548987, 0.0012816240010910076, 0.0012846448860893195, 0.0012985381604680283, 0.0012995447958184575, 0.0013042349548248405, 0.0013005525212396276, 0.0012858056368052282, 0.0012802916568365288, 0.002600105955604125, 0.0011599204550624233, 0.0011621192520992322, 0.001170266591626304, 0.0011898378645789555, 0.001187499908899719, 0.001213815703522414, 0.0012037327502515507, 0.001194576089884239, 0.0012194578620520506, 0.0012722206593025476, 0.001279363884929229, 0.0012856256349054588, 0.0012727063413794067, 0.0012692869984841143, 0.0012826744773933156, 0.0012712576585313814, 0.001304269567216662, 0.0012911877711303532, 0.0012887535452715713, 0.001325045431837101, 0.001298401999520138, 0.0013155516591558064, 0.0013080291603480212, 0.0013136914534367281, 0.0013082799771588973, 0.0013287374326451259, 0.0013290754101366144, 0.0013860701609783891, 0.0013524543425195259, 0.0012634347737978467, 0.0016159164528785782, 0.0012705694772938098, 0.0012657392045101997, 0.0012654829320540143, 0.0012597809757360003, 0.0012615559310440651, 0.0012995325669180602, 0.0012889128860975193, 0.0012924797748300161, 0.0012677113647276367, 0.0013712233181153847, 0.0013526004543316296, 0.0012714763658798554, 0.0012669660209212452, 0.0012658184092618865, 0.0012697395895057443, 0.0012684650692707774, 0.0013303507717368616, 0.0012881654071282935, 0.0012781340681778436, 0.001290585046676411, 0.001370826225452633, 0.0013328312038951976, 0.0012457480453039434, 0.0012424516581549224, 0.0012536215892230923, 0.0012580028190065852, 0.0012872584338765591, 0.0012848121801983905, 0.0012720557490617714, 0.001277348137756979, 0.004313992841740732, 0.0013516220020722937, 0.0012449089527680453, 0.001253815113820813, 0.0013182912291747264, 0.0014197725236458195, 0.0013583715004973453, 0.0012848897736561908, 0.0012044709305777106, 0.0012111726059946557, 0.0012091546032447801, 0.001201278814331217, 0.001214607093526527, 0.0012052633723807196, 0.0012145857678639682, 0.0012104056510251276, 0.001207702116347676, 0.0012173223238828223, 0.0012133789768572463, 0.0012119164890717975, 0.0011895217683686073, 0.0012163686739324138, 0.0011966951397182637, 0.0012161827451267907, 0.0012098064667783505, 0.0012076042543793487, 0.0012167776978119862, 0.0012165026273578405, 0.0012209388145873713, 0.0012038980913889963, 0.001228968883583019, 0.0012123762998123501, 0.001208972789585417, 0.0012191268371764658, 0.0012006323492197797, 0.0012318935342739488, 0.0012132957209508087, 0.0012068733258909265, 0.001213932718518515, 0.001280195859455785, 0.0012606379283635423, 0.0013035316978646226, 0.0013011381392865333, 0.0012083499297109801, 0.0014702801154060073, 0.001183181324280625, 0.0011518272560436366, 0.001159170092906543, 0.0012117765578549616, 0.0011808138589786236, 0.0011693491860357828, 0.0011524625371621793, 0.0011617994656093246, 0.0011695488139467185, 0.0011626958121480637, 0.0011673507194013097, 0.0011780199778894352, 0.0011727241853382005, 0.0011759305584006184, 0.0011791189764301445, 0.0011735297929019082, 0.001171900094811653, 0.0011698783965521427, 0.0011755005797631172, 0.0011693083269651546, 0.001169292905996012, 0.001177197790618033, 0.0011732650915334045, 0.001172211256722898, 0.0011620523954936584, 0.0011622314422586283, 0.0011725813708116496, 0.0011798244884757454, 0.0011721742095772265, 0.0011756539312299601, 0.0011883281620739157, 0.0011759454189518162, 0.0011636687437245666, 0.0011848932549054193, 0.0011801227905549282, 0.0011638949765975391, 0.0011834567439807362, 0.001181780187369779, 0.0011631029977484844, 0.0011757899774238467, 0.0011920686513402087, 0.0012016878625767868, 0.0011749921615647023, 0.0011741487677533959, 0.0011731828129742034, 0.001174946234366575, 0.001173462044599271, 0.001166518393167576, 0.0011712818157447631, 0.001185267698019743, 0.001199372069433678, 0.001178413163870573, 0.00117624516133219, 0.0011731337669283845, 0.0011756185815821206, 0.0011650565361907316, 0.001215672651089208, 0.0011834209286716096, 0.0012987512569917843, 0.001173139557913812, 0.0011592536276682865, 0.0011741780475605019, 0.001180955625767278, 0.0011646037455648184, 0.0011667299522953325, 0.0011563172785911797, 0.0011707136060955913, 0.0011734125112335002, 0.001169936720628378, 0.0011885137659995708, 0.0011814148598458878]
[823.9532804381355, 828.0286648548221, 741.6918795414219, 750.337929194762, 760.3655441290877, 760.4237990390698, 759.6200489857368, 747.4442713877302, 752.0612762449292, 757.5435019962654, 756.0202804764585, 349.0358869877097, 768.0803667408866, 758.135157066788, 758.6375891754205, 764.1352435466224, 755.076931735629, 750.9667594359549, 748.4326508634069, 752.6089271783112, 748.7641514510766, 655.1638257854535, 721.1042695274605, 778.3222266157112, 775.4623407252525, 776.9879346316035, 772.5425456437109, 763.4987228297878, 776.4439469289084, 773.272945829512, 775.9551257849548, 781.4369097291726, 764.8239923608484, 776.2592953845899, 779.8378604301612, 780.2600444036086, 778.4252370662311, 770.0967368102397, 769.500215165878, 766.7330156277712, 768.9039724799776, 777.7225199328306, 781.0720273464087, 384.59971134816834, 862.1280844178087, 860.4968880720436, 854.50615026984, 840.4506443857938, 842.105327760869, 823.848296819744, 830.7491839787732, 837.1170396495257, 820.0365351839575, 786.0271665044463, 781.6384468718354, 777.8314097428037, 785.7272078303331, 787.8438849482278, 779.6210321672776, 786.6225963627614, 766.7126682515644, 774.4806931718098, 775.9435492294036, 754.691104148449, 770.1774953901635, 760.137386502711, 764.5089500404828, 761.2137518166196, 764.3623822567644, 752.5941359304478, 752.4027548573869, 721.4642001196587, 739.3964946255202, 791.4931745894806, 618.843875386385, 787.0486564260173, 790.0521659096178, 790.212159066336, 793.7887769862307, 792.6719500834171, 769.5074563399174, 775.8476238279612, 773.706497752754, 788.8230931927052, 729.2758129101861, 739.3166228782152, 786.4872889776484, 789.2871501580389, 790.0027307890962, 787.5630627452182, 788.3543853319396, 751.6814521740257, 776.2978220547776, 782.3905370315634, 774.8423883999413, 729.4870651236703, 750.2825542180444, 802.7305391083438, 804.8602884759554, 797.688878842403, 794.9107783317021, 776.8447839867829, 778.3238790945989, 786.1290676431192, 782.8719285221633, 231.80381532494425, 739.8518213426607, 803.2715949037942, 797.5657566869253, 758.5577282692062, 704.3381832972159, 736.1756335684801, 778.2768767428752, 830.2400453287498, 825.6461507224781, 827.0241020598099, 832.4462132104827, 823.3115098122553, 829.6941754935527, 823.325965492458, 826.1693087380013, 828.0187526905995, 821.4751182828538, 824.1448212578102, 825.1393631634605, 840.6739805791611, 822.1191661957944, 835.63471331172, 822.2448509543251, 826.5784879319965, 828.0858537666817, 821.8428080973241, 822.0286397341622, 819.041861928159, 830.6350904221893, 813.6902515257607, 824.8264174702017, 827.1484756434606, 820.2591965869851, 832.8944332124994, 811.7584614074448, 824.2013737725393, 828.5873741237835, 823.7688833532728, 781.1304751642479, 793.2491776589006, 767.1466690362403, 768.5579031203715, 827.5748402113828, 680.142504494021, 845.1789928378057, 868.1857411803732, 862.6861632468153, 825.2346470294491, 846.8735291309814, 855.1765477257529, 867.7071642279996, 860.7337407196463, 855.0305793782434, 860.070183062339, 856.6405822860695, 848.8820383094186, 852.7154232020986, 850.3903507364403, 848.090837302578, 852.1300490609589, 853.3150602404545, 854.789696901142, 850.7014094382807, 855.2064301084893, 855.2177088153911, 849.4749208414642, 852.3222988702794, 853.0885488983088, 860.5463952210038, 860.4138243383305, 852.8192796614273, 847.5836955138415, 853.1155111838493, 850.5904445484291, 841.5183885356732, 850.3796042603354, 859.3510871481258, 843.9578804757582, 847.3694500296624, 859.1840501995636, 844.9822987499723, 846.1810501542111, 859.7690848839557, 850.4920259577291, 838.87786066325, 832.1628528856851, 851.0695072793759, 851.6808325007994, 852.3820745931679, 851.1027745359853, 852.1792456793887, 857.2518066214024, 853.7654956797454, 843.6912620420902, 833.7696245270928, 848.5988027454109, 850.1629021516411, 852.4177107426542, 850.616020932761, 858.3274450093209, 822.5898634011619, 845.007871478579, 769.9703808689565, 852.4135029410266, 862.6239988667468, 851.6595946224867, 846.7718669363978, 858.6611573321125, 857.0963641009463, 864.8145439964094, 854.1798735346276, 852.2152187970046, 854.7470836396141, 841.386973047783, 846.4427137224659]
Elapsed: 0.0553884873708196~0.011588096276638041
Time per graph: 0.0012720852771093802~0.0002590938442882784
Speed: 799.3361187190214~71.46731096372926
Total Time: 0.0517
best val loss: 0.38306063413619995 test_score: 0.9302

Testing...
Test loss: 0.6776 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.16344055300578475, 0.1597105999244377, 0.3101115069584921, 0.1751128031173721, 0.17460485198535025, 0.1741151368478313, 0.17437757807783782, 0.1751812678994611, 0.17659674293827266, 0.17607315012719482, 0.17549042694736272, 0.26294736901763827, 0.17354228103067726, 0.17393519601318985, 0.17409701296128333, 0.17390376096591353, 0.1744296740507707, 0.17596557887736708, 0.1782697088783607, 0.17769848788157105, 0.17738243390340358, 0.18696037598419935, 0.29249683499801904, 0.1771285090362653, 0.1696148010669276, 0.16942509799264371, 0.16985778196249157, 0.17119350004941225, 0.170271237147972, 0.17294384981505573, 0.17065586789976805, 0.16921050404198468, 0.16879093693569303, 0.2884873071452603, 0.16918367613106966, 0.1684464409481734, 0.16987571702338755, 0.169719269964844, 0.1717078509973362, 0.17161447601392865, 0.1714298209408298, 0.16911234997678548, 0.16887440287973732, 0.24475880584213883, 0.15318216301966459, 0.1527209150372073, 0.1538352119969204, 0.154616829007864, 0.15776346705388278, 0.16056172689422965, 0.15929883101489395, 0.15846306004095823, 0.15827802591957152, 0.28101094102021307, 0.16965512291062623, 0.16963883803691715, 0.16813165787607431, 0.16857141396030784, 0.16990693705156446, 0.16845453809946775, 0.1731053909752518, 0.17213826102670282, 0.17008262092713267, 0.17109399486798793, 0.25083827797789127, 0.1714956589275971, 0.1714257668936625, 0.17400702484883368, 0.1720972522161901, 0.17490619595628232, 0.17516175005584955, 0.18024662195239216, 0.18348214705474675, 0.16924554109573364, 0.1839720840798691, 0.24104469479061663, 0.16840907314326614, 0.169175281887874, 0.16928910301066935, 0.17020856880117208, 0.17025516915600747, 0.17547545791603625, 0.17325688898563385, 0.1717902849195525, 0.27168897702358663, 0.1807476709363982, 0.17234080599155277, 0.1722579001216218, 0.17257852794136852, 0.171577462926507, 0.17231117887422442, 0.17487274296581745, 0.17699755099602044, 0.17334415798541158, 0.1729213650105521, 0.2753974790684879, 0.17813251307234168, 0.17162680090405047, 0.1656046168645844, 0.16665433498565108, 0.16820841503795236, 0.16788191709201783, 0.1741801000898704, 0.17260149307549, 0.17214286013040692, 0.3043612309265882, 0.18111248093191534, 0.17310836690012366, 0.1688665368128568, 0.18727946083527058, 0.18041723303031176, 0.184493999928236, 0.18469607492443174, 0.17995762103237212, 0.17943534499499947, 0.1795564639614895, 0.18094660306815058, 0.17866443505045027, 0.17890919698402286, 0.18024700798559934, 0.1787929431302473, 0.18079553090501577, 0.1794516610680148, 0.17913012497592717, 0.17919424804858863, 0.17885527713224292, 0.1803571319906041, 0.17846090404782444, 0.1810118849389255, 0.17963371006771922, 0.18008255888707936, 0.18042235099710524, 0.17951662687119097, 0.1823452189564705, 0.18349127192050219, 0.17981833894737065, 0.1814494589343667, 0.180594322970137, 0.18114648398477584, 0.18185838381759822, 0.18152909795753658, 0.18086379393935204, 0.1818060039076954, 0.18179124302696437, 0.194044979987666, 0.18680185999255627, 0.18445806298404932, 0.19953720388002694, 0.1951424591243267, 0.1850174181163311, 0.18131364602595568, 0.17398715601302683, 0.17319064680486917, 0.17606274387799203, 0.17823031288571656, 0.17484458803664893, 0.17353866307530552, 0.17200761113781482, 0.17351672006770968, 0.17295349307823926, 0.1759395127883181, 0.17544802895281464, 0.1744447599630803, 0.1755317458882928, 0.17489306686911732, 0.1753510950366035, 0.17632373899687082, 0.1765308160101995, 0.17486899008508772, 0.17539128195494413, 0.17562624299898744, 0.17600433307234198, 0.17454945808276534, 0.17590913688763976, 0.1767266149399802, 0.17616755794733763, 0.17630819196347147, 0.17676918290089816, 0.17695991904474795, 0.17693416308611631, 0.17499227996449918, 0.17809924797620624, 0.17669720004778355, 0.17722829699050635, 0.1779854989144951, 0.1759611750021577, 0.17454966297373176, 0.17648905992973596, 0.17613521101884544, 0.17634854593779892, 0.17651354800909758, 0.17725110799074173, 0.17878630105406046, 0.17566715902648866, 0.1754276220453903, 0.1757130017504096, 0.17804934305604547, 0.17574658093508333, 0.1756725999293849, 0.1760974209755659, 0.18016091000754386, 0.178554903017357, 0.17760514211840928, 0.17673861794173717, 0.17552815098315477, 0.17576476105023175, 0.1846948271850124, 0.17989756516180933, 0.18456906510982662, 0.18122092995326966, 0.1754624160239473, 0.18300473398994654, 0.17901150917168707, 0.17687215993646532, 0.17535266594495624, 0.17417090095113963, 0.17582852800842375, 0.17630020796786994, 0.17771977407392114, 0.17896729696076363, 0.18370393698569387]
Total Epoch List: [113, 108]
Total Time List: [0.05715318606235087, 0.0516512799076736]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a82e5270>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6938;  Loss pred: 0.6938; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6948;  Loss pred: 0.6948; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6943;  Loss pred: 0.6943; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4884 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6910;  Loss pred: 0.6910; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6955 score: 0.4884 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6924;  Loss pred: 0.6924; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6880;  Loss pred: 0.6880; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6857;  Loss pred: 0.6857; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6821;  Loss pred: 0.6821; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6822;  Loss pred: 0.6822; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6784;  Loss pred: 0.6784; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6766;  Loss pred: 0.6766; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6719;  Loss pred: 0.6719; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6689;  Loss pred: 0.6689; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6654;  Loss pred: 0.6654; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6640;  Loss pred: 0.6640; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.06s
Epoch 18/1000, LR 0.000270
Train loss: 0.6571;  Loss pred: 0.6571; Loss self: 0.0000; time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6530;  Loss pred: 0.6530; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6482;  Loss pred: 0.6482; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6429;  Loss pred: 0.6429; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6384;  Loss pred: 0.6384; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6319;  Loss pred: 0.6319; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6234;  Loss pred: 0.6234; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6185;  Loss pred: 0.6185; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6109;  Loss pred: 0.6109; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6014;  Loss pred: 0.6014; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5977;  Loss pred: 0.5977; Loss self: 0.0000; time: 0.09s
Val loss: 0.6913 score: 0.5682 time: 0.12s
Test loss: 0.6909 score: 0.5349 time: 0.06s
Epoch 29/1000, LR 0.000270
Train loss: 0.5879;  Loss pred: 0.5879; Loss self: 0.0000; time: 0.07s
Val loss: 0.6910 score: 0.6364 time: 0.05s
Test loss: 0.6903 score: 0.6744 time: 0.06s
Epoch 30/1000, LR 0.000270
Train loss: 0.5754;  Loss pred: 0.5754; Loss self: 0.0000; time: 0.07s
Val loss: 0.6906 score: 0.7955 time: 0.06s
Test loss: 0.6898 score: 0.8605 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5641;  Loss pred: 0.5641; Loss self: 0.0000; time: 0.07s
Val loss: 0.6902 score: 0.7273 time: 0.05s
Test loss: 0.6892 score: 0.8372 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5580;  Loss pred: 0.5580; Loss self: 0.0000; time: 0.07s
Val loss: 0.6897 score: 0.6591 time: 0.05s
Test loss: 0.6885 score: 0.6977 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5456;  Loss pred: 0.5456; Loss self: 0.0000; time: 0.07s
Val loss: 0.6892 score: 0.5909 time: 0.05s
Test loss: 0.6878 score: 0.6512 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5278;  Loss pred: 0.5278; Loss self: 0.0000; time: 0.07s
Val loss: 0.6886 score: 0.5227 time: 0.05s
Test loss: 0.6869 score: 0.6047 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5205;  Loss pred: 0.5205; Loss self: 0.0000; time: 0.07s
Val loss: 0.6879 score: 0.5227 time: 0.05s
Test loss: 0.6860 score: 0.6047 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5108;  Loss pred: 0.5108; Loss self: 0.0000; time: 0.07s
Val loss: 0.6871 score: 0.5227 time: 0.05s
Test loss: 0.6850 score: 0.6047 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4967;  Loss pred: 0.4967; Loss self: 0.0000; time: 0.07s
Val loss: 0.6862 score: 0.5227 time: 0.05s
Test loss: 0.6837 score: 0.6047 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4773;  Loss pred: 0.4773; Loss self: 0.0000; time: 0.09s
Val loss: 0.6851 score: 0.5227 time: 0.11s
Test loss: 0.6823 score: 0.6047 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4650;  Loss pred: 0.4650; Loss self: 0.0000; time: 0.07s
Val loss: 0.6839 score: 0.5227 time: 0.06s
Test loss: 0.6807 score: 0.6047 time: 0.06s
Epoch 40/1000, LR 0.000269
Train loss: 0.4487;  Loss pred: 0.4487; Loss self: 0.0000; time: 0.07s
Val loss: 0.6826 score: 0.5227 time: 0.05s
Test loss: 0.6790 score: 0.6047 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4365;  Loss pred: 0.4365; Loss self: 0.0000; time: 0.07s
Val loss: 0.6812 score: 0.5227 time: 0.05s
Test loss: 0.6771 score: 0.6047 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4254;  Loss pred: 0.4254; Loss self: 0.0000; time: 0.06s
Val loss: 0.6796 score: 0.5227 time: 0.05s
Test loss: 0.6750 score: 0.6047 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4059;  Loss pred: 0.4059; Loss self: 0.0000; time: 0.07s
Val loss: 0.6778 score: 0.5227 time: 0.05s
Test loss: 0.6726 score: 0.6047 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3894;  Loss pred: 0.3894; Loss self: 0.0000; time: 0.07s
Val loss: 0.6757 score: 0.5227 time: 0.05s
Test loss: 0.6699 score: 0.6047 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3729;  Loss pred: 0.3729; Loss self: 0.0000; time: 0.07s
Val loss: 0.6734 score: 0.5227 time: 0.05s
Test loss: 0.6669 score: 0.6047 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3472;  Loss pred: 0.3472; Loss self: 0.0000; time: 0.07s
Val loss: 0.6708 score: 0.5227 time: 0.05s
Test loss: 0.6635 score: 0.6279 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3380;  Loss pred: 0.3380; Loss self: 0.0000; time: 0.07s
Val loss: 0.6679 score: 0.5909 time: 0.05s
Test loss: 0.6598 score: 0.6279 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3288;  Loss pred: 0.3288; Loss self: 0.0000; time: 0.07s
Val loss: 0.6646 score: 0.5909 time: 0.05s
Test loss: 0.6557 score: 0.6279 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3087;  Loss pred: 0.3087; Loss self: 0.0000; time: 0.10s
Val loss: 0.6610 score: 0.5909 time: 0.09s
Test loss: 0.6511 score: 0.6512 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2976;  Loss pred: 0.2976; Loss self: 0.0000; time: 0.07s
Val loss: 0.6570 score: 0.5909 time: 0.05s
Test loss: 0.6461 score: 0.6512 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2649;  Loss pred: 0.2649; Loss self: 0.0000; time: 0.07s
Val loss: 0.6528 score: 0.5909 time: 0.05s
Test loss: 0.6407 score: 0.6512 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2589;  Loss pred: 0.2589; Loss self: 0.0000; time: 0.07s
Val loss: 0.6484 score: 0.5909 time: 0.05s
Test loss: 0.6352 score: 0.6512 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2410;  Loss pred: 0.2410; Loss self: 0.0000; time: 0.07s
Val loss: 0.6437 score: 0.6136 time: 0.05s
Test loss: 0.6291 score: 0.6744 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2303;  Loss pred: 0.2303; Loss self: 0.0000; time: 0.07s
Val loss: 0.6387 score: 0.6136 time: 0.05s
Test loss: 0.6227 score: 0.6744 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2132;  Loss pred: 0.2132; Loss self: 0.0000; time: 0.07s
Val loss: 0.6334 score: 0.6136 time: 0.05s
Test loss: 0.6158 score: 0.6977 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1932;  Loss pred: 0.1932; Loss self: 0.0000; time: 0.07s
Val loss: 0.6277 score: 0.6364 time: 0.06s
Test loss: 0.6086 score: 0.6977 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1833;  Loss pred: 0.1833; Loss self: 0.0000; time: 0.07s
Val loss: 0.6216 score: 0.6591 time: 0.05s
Test loss: 0.6009 score: 0.6977 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1725;  Loss pred: 0.1725; Loss self: 0.0000; time: 0.07s
Val loss: 0.6148 score: 0.6818 time: 0.05s
Test loss: 0.5927 score: 0.6977 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1636;  Loss pred: 0.1636; Loss self: 0.0000; time: 0.07s
Val loss: 0.6081 score: 0.7045 time: 0.05s
Test loss: 0.5844 score: 0.6977 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1466;  Loss pred: 0.1466; Loss self: 0.0000; time: 0.07s
Val loss: 0.6010 score: 0.7273 time: 0.16s
Test loss: 0.5759 score: 0.6977 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1404;  Loss pred: 0.1404; Loss self: 0.0000; time: 0.07s
Val loss: 0.5931 score: 0.7500 time: 0.05s
Test loss: 0.5667 score: 0.7209 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1272;  Loss pred: 0.1272; Loss self: 0.0000; time: 0.07s
Val loss: 0.5852 score: 0.7500 time: 0.05s
Test loss: 0.5575 score: 0.7209 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1165;  Loss pred: 0.1165; Loss self: 0.0000; time: 0.07s
Val loss: 0.5764 score: 0.7500 time: 0.05s
Test loss: 0.5475 score: 0.7209 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1061;  Loss pred: 0.1061; Loss self: 0.0000; time: 0.07s
Val loss: 0.5674 score: 0.7500 time: 0.05s
Test loss: 0.5376 score: 0.7209 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0962;  Loss pred: 0.0962; Loss self: 0.0000; time: 0.07s
Val loss: 0.5585 score: 0.7727 time: 0.05s
Test loss: 0.5277 score: 0.7674 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0840;  Loss pred: 0.0840; Loss self: 0.0000; time: 0.07s
Val loss: 0.5496 score: 0.7727 time: 0.05s
Test loss: 0.5176 score: 0.8140 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0807;  Loss pred: 0.0807; Loss self: 0.0000; time: 0.07s
Val loss: 0.5405 score: 0.7727 time: 0.05s
Test loss: 0.5073 score: 0.8140 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0753;  Loss pred: 0.0753; Loss self: 0.0000; time: 0.07s
Val loss: 0.5318 score: 0.7727 time: 0.05s
Test loss: 0.4973 score: 0.8372 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0672;  Loss pred: 0.0672; Loss self: 0.0000; time: 0.07s
Val loss: 0.5229 score: 0.7727 time: 0.05s
Test loss: 0.4872 score: 0.8372 time: 0.06s
Epoch 70/1000, LR 0.000268
Train loss: 0.0601;  Loss pred: 0.0601; Loss self: 0.0000; time: 0.17s
Val loss: 0.5143 score: 0.7955 time: 0.05s
Test loss: 0.4773 score: 0.8372 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0551;  Loss pred: 0.0551; Loss self: 0.0000; time: 0.07s
Val loss: 0.5062 score: 0.7955 time: 0.05s
Test loss: 0.4678 score: 0.8372 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0532;  Loss pred: 0.0532; Loss self: 0.0000; time: 0.07s
Val loss: 0.4980 score: 0.7955 time: 0.05s
Test loss: 0.4587 score: 0.8372 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0467;  Loss pred: 0.0467; Loss self: 0.0000; time: 0.07s
Val loss: 0.4900 score: 0.7955 time: 0.05s
Test loss: 0.4496 score: 0.8372 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0412;  Loss pred: 0.0412; Loss self: 0.0000; time: 0.07s
Val loss: 0.4834 score: 0.7955 time: 0.05s
Test loss: 0.4417 score: 0.8372 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0366;  Loss pred: 0.0366; Loss self: 0.0000; time: 0.07s
Val loss: 0.4774 score: 0.7955 time: 0.05s
Test loss: 0.4342 score: 0.8605 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0364;  Loss pred: 0.0364; Loss self: 0.0000; time: 0.07s
Val loss: 0.4712 score: 0.7955 time: 0.05s
Test loss: 0.4264 score: 0.8605 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0342;  Loss pred: 0.0342; Loss self: 0.0000; time: 0.07s
Val loss: 0.4667 score: 0.7955 time: 0.05s
Test loss: 0.4198 score: 0.8605 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0286;  Loss pred: 0.0286; Loss self: 0.0000; time: 0.07s
Val loss: 0.4629 score: 0.7955 time: 0.05s
Test loss: 0.4141 score: 0.8605 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0271;  Loss pred: 0.0271; Loss self: 0.0000; time: 0.07s
Val loss: 0.4597 score: 0.7955 time: 0.06s
Test loss: 0.4089 score: 0.8605 time: 0.12s
Epoch 80/1000, LR 0.000267
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.07s
Val loss: 0.4571 score: 0.7955 time: 0.05s
Test loss: 0.4043 score: 0.8605 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0232;  Loss pred: 0.0232; Loss self: 0.0000; time: 0.07s
Val loss: 0.4547 score: 0.7955 time: 0.05s
Test loss: 0.4003 score: 0.8605 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0213;  Loss pred: 0.0213; Loss self: 0.0000; time: 0.07s
Val loss: 0.4524 score: 0.7955 time: 0.05s
Test loss: 0.3967 score: 0.8605 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0182;  Loss pred: 0.0182; Loss self: 0.0000; time: 0.07s
Val loss: 0.4511 score: 0.7955 time: 0.05s
Test loss: 0.3940 score: 0.8605 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0205;  Loss pred: 0.0205; Loss self: 0.0000; time: 0.07s
Val loss: 0.4486 score: 0.7955 time: 0.05s
Test loss: 0.3904 score: 0.8605 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0172;  Loss pred: 0.0172; Loss self: 0.0000; time: 0.07s
Val loss: 0.4464 score: 0.7727 time: 0.05s
Test loss: 0.3875 score: 0.8605 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0149;  Loss pred: 0.0149; Loss self: 0.0000; time: 0.07s
Val loss: 0.4448 score: 0.7727 time: 0.05s
Test loss: 0.3854 score: 0.8605 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0137;  Loss pred: 0.0137; Loss self: 0.0000; time: 0.07s
Val loss: 0.4437 score: 0.7727 time: 0.05s
Test loss: 0.3837 score: 0.8605 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.07s
Val loss: 0.4437 score: 0.7727 time: 0.05s
Test loss: 0.3827 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.07s
Val loss: 0.4440 score: 0.7727 time: 0.05s
Test loss: 0.3818 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.10s
Val loss: 0.4453 score: 0.7727 time: 0.10s
Test loss: 0.3819 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.07s
Val loss: 0.4470 score: 0.7727 time: 0.05s
Test loss: 0.3824 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0101;  Loss pred: 0.0101; Loss self: 0.0000; time: 0.07s
Val loss: 0.4499 score: 0.7727 time: 0.05s
Test loss: 0.3840 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.07s
Val loss: 0.4528 score: 0.7727 time: 0.05s
Test loss: 0.3859 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.07s
Val loss: 0.4561 score: 0.7955 time: 0.05s
Test loss: 0.3880 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.07s
Val loss: 0.4593 score: 0.7955 time: 0.05s
Test loss: 0.3902 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.07s
Val loss: 0.4636 score: 0.7955 time: 0.05s
Test loss: 0.3934 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0090;  Loss pred: 0.0090; Loss self: 0.0000; time: 0.07s
Val loss: 0.4672 score: 0.7955 time: 0.05s
Test loss: 0.3965 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.4704 score: 0.7955 time: 0.05s
Test loss: 0.3994 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.4739 score: 0.7955 time: 0.05s
Test loss: 0.4030 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.07s
Val loss: 0.4781 score: 0.7955 time: 0.05s
Test loss: 0.4072 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.4820 score: 0.7955 time: 0.17s
Test loss: 0.4112 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.07s
Val loss: 0.4851 score: 0.7955 time: 0.05s
Test loss: 0.4147 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.07s
Val loss: 0.4891 score: 0.7955 time: 0.05s
Test loss: 0.4190 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.07s
Val loss: 0.4930 score: 0.7955 time: 0.05s
Test loss: 0.4233 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.07s
Val loss: 0.4965 score: 0.7955 time: 0.05s
Test loss: 0.4272 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.07s
Val loss: 0.4999 score: 0.7955 time: 0.05s
Test loss: 0.4311 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.5023 score: 0.7955 time: 0.05s
Test loss: 0.4344 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 086,   Train_Loss: 0.0137,   Val_Loss: 0.4437,   Val_Precision: 0.9286,   Val_Recall: 0.5909,   Val_accuracy: 0.7222,   Val_Score: 0.7727,   Val_Loss: 0.4437,   Test_Precision: 1.0000,   Test_Recall: 0.7143,   Test_accuracy: 0.8333,   Test_Score: 0.8605,   Test_loss: 0.3837


[0.05340108601376414, 0.05313825700432062, 0.059323825989849865, 0.05864024499896914, 0.057866904069669545, 0.057862470974214375, 0.05792369495611638, 0.05886726500466466, 0.05850587098393589, 0.05808247299864888, 0.05819949693977833, 0.12606153590604663, 0.057285672053694725, 0.05803714494686574, 0.05799870798364282, 0.05758142995182425, 0.05827220797073096, 0.05859114194754511, 0.058789524948224425, 0.058463298017159104, 0.058763497043401, 0.06715877505484968, 0.061017528059892356, 0.05653185595292598, 0.056740344036370516, 0.056628935970366, 0.05695479200221598, 0.0576294349739328, 0.05666861101053655, 0.05690099496860057, 0.056704310001805425, 0.05630652897525579, 0.05752957600634545, 0.056682090973481536, 0.056421984918415546, 0.05639145604800433, 0.05652437498793006, 0.05713567906059325, 0.05717997101601213, 0.05738633801229298, 0.05722431093454361, 0.05657544801943004, 0.05633283290080726, 0.1144046620465815, 0.05103650002274662, 0.05113324709236622, 0.05149173003155738, 0.052352866041474044, 0.05224999599158764, 0.053407890954986215, 0.052964241011068225, 0.05256134795490652, 0.05365614593029022, 0.05597770900931209, 0.05629201093688607, 0.05656752793584019, 0.0559990790206939, 0.05584862793330103, 0.056437677005305886, 0.05593533697538078, 0.05738786095753312, 0.05681226192973554, 0.05670515599194914, 0.05830199900083244, 0.05712968797888607, 0.05788427300285548, 0.05755328305531293, 0.05780242395121604, 0.05756431899499148, 0.058464447036385536, 0.05847931804601103, 0.06098708708304912, 0.059507991070859134, 0.05559113004710525, 0.07110032392665744, 0.05590505700092763, 0.05569252499844879, 0.05568124901037663, 0.055430362932384014, 0.055508460965938866, 0.05717943294439465, 0.056712166988290846, 0.056869110092520714, 0.05577930004801601, 0.06033382599707693, 0.059514419990591705, 0.055944960098713636, 0.05574650492053479, 0.055696010007523, 0.05586854193825275, 0.05581246304791421, 0.05853543395642191, 0.05667927791364491, 0.05623789899982512, 0.05678574205376208, 0.060316353919915855, 0.0586445729713887, 0.05481291399337351, 0.05466787295881659, 0.05515934992581606, 0.05535212403628975, 0.0566393710905686, 0.056531735928729177, 0.05597045295871794, 0.05620331806130707, 0.18981568503659219, 0.05947136809118092, 0.054775993921794, 0.05516786500811577, 0.05800481408368796, 0.06246999104041606, 0.05976834602188319, 0.056535150040872395, 0.05179225001484156, 0.05208042205777019, 0.051993647939525545, 0.051654989016242325, 0.05222810502164066, 0.051826325012370944, 0.05222718801815063, 0.052047442994080484, 0.05193119100295007, 0.05234485992696136, 0.05217529600486159, 0.05211240903008729, 0.051149436039850116, 0.05230385297909379, 0.05145789100788534, 0.052295858040452003, 0.05202167807146907, 0.051926982938311994, 0.0523214410059154, 0.05230961297638714, 0.052500369027256966, 0.05176761792972684, 0.052845661994069815, 0.05213218089193106, 0.051985829952172935, 0.052422453998588026, 0.051627191016450524, 0.0529714219737798, 0.05217171600088477, 0.051895553013309836, 0.052199106896296144, 0.05504842195659876, 0.054207430919632316, 0.05605186300817877, 0.055948939989320934, 0.05195904697757214, 0.06322204496245831, 0.05087679694406688, 0.04952857200987637, 0.04984431399498135, 0.052106391987763345, 0.05077499593608081, 0.05028201499953866, 0.049555889097973704, 0.049957377021200955, 0.05029059899970889, 0.04999591992236674, 0.050196080934256315, 0.050654859049245715, 0.05042713996954262, 0.050565014011226594, 0.05070211598649621, 0.050461781094782054, 0.05039170407690108, 0.050304771051742136, 0.05054652492981404, 0.05028025805950165, 0.05027959495782852, 0.050619504996575415, 0.05045039893593639, 0.05040508403908461, 0.049968253006227314, 0.04997595201712102, 0.05042099894490093, 0.050732453004457057, 0.050403491011820734, 0.050553119042888284, 0.05109811096917838, 0.0505656530149281, 0.05003775598015636, 0.05095040996093303, 0.050745279993861914, 0.050047483993694186, 0.05088863999117166, 0.0508165480569005, 0.05001342890318483, 0.05055896902922541, 0.05125895200762898, 0.051672578090801835, 0.050524662947282195, 0.050488397013396025, 0.05044686095789075, 0.05052268807776272, 0.05045886791776866, 0.05016029090620577, 0.05036511807702482, 0.05096651101484895, 0.051572998985648155, 0.05067176604643464, 0.05057854193728417, 0.05044475197792053, 0.05055159900803119, 0.05009743105620146, 0.05227392399683595, 0.05088709993287921, 0.05584630405064672, 0.05044500099029392, 0.04984790598973632, 0.05048965604510158, 0.05078109190799296, 0.05007796105928719, 0.050169387948699296, 0.04972164297942072, 0.050340685062110424, 0.05045673798304051, 0.050307278987020254, 0.051106091937981546, 0.050800838973373175, 0.0582477489951998, 0.05792764411307871, 0.05669797898735851, 0.059251955011859536, 0.05674746399745345, 0.05704845709260553, 0.056907568010501564, 0.05568021105136722, 0.05545022897422314, 0.05575687298551202, 0.05542249197605997, 0.05593304696958512, 0.05700702604372054, 0.05705237598158419, 0.05587613210082054, 0.0552264490397647, 0.06471833400428295, 0.05557117308489978, 0.05553754896391183, 0.05481571797281504, 0.054669830948114395, 0.055263006943278015, 0.05484040500596166, 0.057914539938792586, 0.057172256987541914, 0.05629910703282803, 0.057197992922738194, 0.0605114649515599, 0.060543081955984235, 0.05876456596888602, 0.05818286200519651, 0.05685954401269555, 0.05896889395080507, 0.057809763005934656, 0.057288628071546555, 0.05592361406888813, 0.05769113695714623, 0.059757031966000795, 0.06223939603660256, 0.05439664900768548, 0.05452760006301105, 0.05450151697732508, 0.055548875010572374, 0.05550451995804906, 0.05634044494945556, 0.057235012063756585, 0.05614198907278478, 0.05720760708209127, 0.056102595990523696, 0.05592961492948234, 0.05578956298995763, 0.05594425997696817, 0.05593879905063659, 0.055888680974021554, 0.05531788396183401, 0.05651274207048118, 0.05706471798475832, 0.05536317394580692, 0.05648026696871966, 0.05653765599709004, 0.0562686879420653, 0.05600111198145896, 0.05586461292114109, 0.05650654702913016, 0.05644373001996428, 0.05840290093328804, 0.057001468958333135, 0.056834221933968365, 0.06459549302235246, 0.05637768399901688, 0.05575843004044145, 0.05664403794799, 0.05588605999946594, 0.05604973097797483, 0.058991478057578206, 0.05640779703389853, 0.05617080698721111, 0.0573305879952386, 0.12226200103759766, 0.05804057093337178, 0.05645053100306541, 0.056588300969451666, 0.05650903796777129, 0.05701611505355686, 0.05701833497732878, 0.05749766097869724, 0.05704169801902026, 0.056529229041188955, 0.05855435004923493, 0.05660677095875144, 0.0567882820032537, 0.056526848929934204, 0.05673998792190105, 0.05636380705982447, 0.05682383803650737, 0.05592785694170743, 0.058292597997933626, 0.056995959021151066, 0.056583517929539084, 0.05645630706567317, 0.055935302982106805, 0.055693093105219305, 0.055367688997648656, 0.0557206500088796, 0.05586754600517452, 0.05611835396848619, 0.05716920108534396]
[0.0012136610457673669, 0.001207687659189105, 0.0013482687724965879, 0.0013327328408856622, 0.001315156910674308, 0.0013150561585048722, 0.0013164476126390086, 0.0013378923864696515, 0.001329678885998543, 0.0013200562045147474, 0.0013227158395404165, 0.002865034906955605, 0.0013019470921294255, 0.0013190260215196759, 0.0013181524541737003, 0.0013086688625414602, 0.0013243683629711582, 0.001331616862444207, 0.0013361255670051005, 0.0013287113185717978, 0.001335534023713659, 0.001526335796701129, 0.00138676200136119, 0.001284814908021045, 0.0012895532735538754, 0.0012870212720537727, 0.001294427090959454, 0.0013097598857712, 0.0012879229775121944, 0.0012932044311045584, 0.0012887343182228506, 0.0012796938403467225, 0.0013074903637805785, 0.0012882293403063986, 0.0012823178390548987, 0.0012816240010910076, 0.0012846448860893195, 0.0012985381604680283, 0.0012995447958184575, 0.0013042349548248405, 0.0013005525212396276, 0.0012858056368052282, 0.0012802916568365288, 0.002600105955604125, 0.0011599204550624233, 0.0011621192520992322, 0.001170266591626304, 0.0011898378645789555, 0.001187499908899719, 0.001213815703522414, 0.0012037327502515507, 0.001194576089884239, 0.0012194578620520506, 0.0012722206593025476, 0.001279363884929229, 0.0012856256349054588, 0.0012727063413794067, 0.0012692869984841143, 0.0012826744773933156, 0.0012712576585313814, 0.001304269567216662, 0.0012911877711303532, 0.0012887535452715713, 0.001325045431837101, 0.001298401999520138, 0.0013155516591558064, 0.0013080291603480212, 0.0013136914534367281, 0.0013082799771588973, 0.0013287374326451259, 0.0013290754101366144, 0.0013860701609783891, 0.0013524543425195259, 0.0012634347737978467, 0.0016159164528785782, 0.0012705694772938098, 0.0012657392045101997, 0.0012654829320540143, 0.0012597809757360003, 0.0012615559310440651, 0.0012995325669180602, 0.0012889128860975193, 0.0012924797748300161, 0.0012677113647276367, 0.0013712233181153847, 0.0013526004543316296, 0.0012714763658798554, 0.0012669660209212452, 0.0012658184092618865, 0.0012697395895057443, 0.0012684650692707774, 0.0013303507717368616, 0.0012881654071282935, 0.0012781340681778436, 0.001290585046676411, 0.001370826225452633, 0.0013328312038951976, 0.0012457480453039434, 0.0012424516581549224, 0.0012536215892230923, 0.0012580028190065852, 0.0012872584338765591, 0.0012848121801983905, 0.0012720557490617714, 0.001277348137756979, 0.004313992841740732, 0.0013516220020722937, 0.0012449089527680453, 0.001253815113820813, 0.0013182912291747264, 0.0014197725236458195, 0.0013583715004973453, 0.0012848897736561908, 0.0012044709305777106, 0.0012111726059946557, 0.0012091546032447801, 0.001201278814331217, 0.001214607093526527, 0.0012052633723807196, 0.0012145857678639682, 0.0012104056510251276, 0.001207702116347676, 0.0012173223238828223, 0.0012133789768572463, 0.0012119164890717975, 0.0011895217683686073, 0.0012163686739324138, 0.0011966951397182637, 0.0012161827451267907, 0.0012098064667783505, 0.0012076042543793487, 0.0012167776978119862, 0.0012165026273578405, 0.0012209388145873713, 0.0012038980913889963, 0.001228968883583019, 0.0012123762998123501, 0.001208972789585417, 0.0012191268371764658, 0.0012006323492197797, 0.0012318935342739488, 0.0012132957209508087, 0.0012068733258909265, 0.001213932718518515, 0.001280195859455785, 0.0012606379283635423, 0.0013035316978646226, 0.0013011381392865333, 0.0012083499297109801, 0.0014702801154060073, 0.001183181324280625, 0.0011518272560436366, 0.001159170092906543, 0.0012117765578549616, 0.0011808138589786236, 0.0011693491860357828, 0.0011524625371621793, 0.0011617994656093246, 0.0011695488139467185, 0.0011626958121480637, 0.0011673507194013097, 0.0011780199778894352, 0.0011727241853382005, 0.0011759305584006184, 0.0011791189764301445, 0.0011735297929019082, 0.001171900094811653, 0.0011698783965521427, 0.0011755005797631172, 0.0011693083269651546, 0.001169292905996012, 0.001177197790618033, 0.0011732650915334045, 0.001172211256722898, 0.0011620523954936584, 0.0011622314422586283, 0.0011725813708116496, 0.0011798244884757454, 0.0011721742095772265, 0.0011756539312299601, 0.0011883281620739157, 0.0011759454189518162, 0.0011636687437245666, 0.0011848932549054193, 0.0011801227905549282, 0.0011638949765975391, 0.0011834567439807362, 0.001181780187369779, 0.0011631029977484844, 0.0011757899774238467, 0.0011920686513402087, 0.0012016878625767868, 0.0011749921615647023, 0.0011741487677533959, 0.0011731828129742034, 0.001174946234366575, 0.001173462044599271, 0.001166518393167576, 0.0011712818157447631, 0.001185267698019743, 0.001199372069433678, 0.001178413163870573, 0.00117624516133219, 0.0011731337669283845, 0.0011756185815821206, 0.0011650565361907316, 0.001215672651089208, 0.0011834209286716096, 0.0012987512569917843, 0.001173139557913812, 0.0011592536276682865, 0.0011741780475605019, 0.001180955625767278, 0.0011646037455648184, 0.0011667299522953325, 0.0011563172785911797, 0.0011707136060955913, 0.0011734125112335002, 0.001169936720628378, 0.0011885137659995708, 0.0011814148598458878, 0.0013545988138418557, 0.0013471545142576444, 0.0013185576508688026, 0.0013779524421362683, 0.001319708465057057, 0.0013267083044791984, 0.0013234318141977107, 0.0012948886291015633, 0.0012895402087028636, 0.0012966714647793492, 0.0012888951622339528, 0.001300768534176398, 0.0013257447917144312, 0.0013267994414321905, 0.001299444932577222, 0.0012843360241805745, 0.0015050775349833244, 0.0012923528624395298, 0.0012915709061374844, 0.0012747841389026753, 0.0012713914173980091, 0.0012851862079832097, 0.0012753582559525967, 0.0013468497660184323, 0.0013295873718033003, 0.0013092815589029775, 0.001330185881924144, 0.0014072433709665093, 0.0014079786501391682, 0.0013666178132299073, 0.0013530898140743375, 0.0013223149770394313, 0.0013713696267629086, 0.001344413093161271, 0.001332293676082478, 0.0013005491643927473, 0.00134165434784061, 0.001389698417813972, 0.0014474278148047107, 0.0012650383490159414, 0.0012680837223956057, 0.00126747713900756, 0.0012918343025714505, 0.0012908027897220711, 0.0013102429058012921, 0.0013310467921803858, 0.00130562765285546, 0.0013304094670253785, 0.0013047115346633417, 0.001300688719290287, 0.0012974316974408752, 0.0013010293017899574, 0.0013009023035031764, 0.0012997367668377106, 0.00128646241771707, 0.0013142498155925856, 0.0013270864647618214, 0.0012875156731583005, 0.001313494580667899, 0.0013148292092346522, 0.0013085741381875652, 0.001302351441429278, 0.0012991770446776998, 0.0013141057448634922, 0.0013126448841852157, 0.0013582069984485591, 0.001325615557170538, 0.0013217260914876363, 0.001502220767961685, 0.001311108930209695, 0.0012967076753591035, 0.0013173032080927907, 0.0012996758139410683, 0.0013034821157668565, 0.0013718948385483304, 0.0013118092333464775, 0.0013062978369118862, 0.0013332694882613628, 0.0028433023497115733, 0.001349780719380739, 0.0013128030465829165, 0.0013160069992895736, 0.0013141636736690998, 0.001325956164036206, 0.0013260077901704366, 0.001337154906481331, 0.0013265511167214015, 0.0013146332335160222, 0.00136172907091244, 0.001316436533924452, 0.0013206577210059, 0.001314577882091493, 0.001319534602834908, 0.0013107862106935923, 0.0013214846055001714, 0.0013006478358536613, 0.0013556418139054332, 0.0013254874190965363, 0.0013158957658032345, 0.0013129373736203063, 0.0013008209995838793, 0.0012951882117492861, 0.0012876206743639223, 0.0012958290699739443, 0.0012992452559342912, 0.0013050779992671206, 0.0013295163043103245]
[823.9532804381355, 828.0286648548221, 741.6918795414219, 750.337929194762, 760.3655441290877, 760.4237990390698, 759.6200489857368, 747.4442713877302, 752.0612762449292, 757.5435019962654, 756.0202804764585, 349.0358869877097, 768.0803667408866, 758.135157066788, 758.6375891754205, 764.1352435466224, 755.076931735629, 750.9667594359549, 748.4326508634069, 752.6089271783112, 748.7641514510766, 655.1638257854535, 721.1042695274605, 778.3222266157112, 775.4623407252525, 776.9879346316035, 772.5425456437109, 763.4987228297878, 776.4439469289084, 773.272945829512, 775.9551257849548, 781.4369097291726, 764.8239923608484, 776.2592953845899, 779.8378604301612, 780.2600444036086, 778.4252370662311, 770.0967368102397, 769.500215165878, 766.7330156277712, 768.9039724799776, 777.7225199328306, 781.0720273464087, 384.59971134816834, 862.1280844178087, 860.4968880720436, 854.50615026984, 840.4506443857938, 842.105327760869, 823.848296819744, 830.7491839787732, 837.1170396495257, 820.0365351839575, 786.0271665044463, 781.6384468718354, 777.8314097428037, 785.7272078303331, 787.8438849482278, 779.6210321672776, 786.6225963627614, 766.7126682515644, 774.4806931718098, 775.9435492294036, 754.691104148449, 770.1774953901635, 760.137386502711, 764.5089500404828, 761.2137518166196, 764.3623822567644, 752.5941359304478, 752.4027548573869, 721.4642001196587, 739.3964946255202, 791.4931745894806, 618.843875386385, 787.0486564260173, 790.0521659096178, 790.212159066336, 793.7887769862307, 792.6719500834171, 769.5074563399174, 775.8476238279612, 773.706497752754, 788.8230931927052, 729.2758129101861, 739.3166228782152, 786.4872889776484, 789.2871501580389, 790.0027307890962, 787.5630627452182, 788.3543853319396, 751.6814521740257, 776.2978220547776, 782.3905370315634, 774.8423883999413, 729.4870651236703, 750.2825542180444, 802.7305391083438, 804.8602884759554, 797.688878842403, 794.9107783317021, 776.8447839867829, 778.3238790945989, 786.1290676431192, 782.8719285221633, 231.80381532494425, 739.8518213426607, 803.2715949037942, 797.5657566869253, 758.5577282692062, 704.3381832972159, 736.1756335684801, 778.2768767428752, 830.2400453287498, 825.6461507224781, 827.0241020598099, 832.4462132104827, 823.3115098122553, 829.6941754935527, 823.325965492458, 826.1693087380013, 828.0187526905995, 821.4751182828538, 824.1448212578102, 825.1393631634605, 840.6739805791611, 822.1191661957944, 835.63471331172, 822.2448509543251, 826.5784879319965, 828.0858537666817, 821.8428080973241, 822.0286397341622, 819.041861928159, 830.6350904221893, 813.6902515257607, 824.8264174702017, 827.1484756434606, 820.2591965869851, 832.8944332124994, 811.7584614074448, 824.2013737725393, 828.5873741237835, 823.7688833532728, 781.1304751642479, 793.2491776589006, 767.1466690362403, 768.5579031203715, 827.5748402113828, 680.142504494021, 845.1789928378057, 868.1857411803732, 862.6861632468153, 825.2346470294491, 846.8735291309814, 855.1765477257529, 867.7071642279996, 860.7337407196463, 855.0305793782434, 860.070183062339, 856.6405822860695, 848.8820383094186, 852.7154232020986, 850.3903507364403, 848.090837302578, 852.1300490609589, 853.3150602404545, 854.789696901142, 850.7014094382807, 855.2064301084893, 855.2177088153911, 849.4749208414642, 852.3222988702794, 853.0885488983088, 860.5463952210038, 860.4138243383305, 852.8192796614273, 847.5836955138415, 853.1155111838493, 850.5904445484291, 841.5183885356732, 850.3796042603354, 859.3510871481258, 843.9578804757582, 847.3694500296624, 859.1840501995636, 844.9822987499723, 846.1810501542111, 859.7690848839557, 850.4920259577291, 838.87786066325, 832.1628528856851, 851.0695072793759, 851.6808325007994, 852.3820745931679, 851.1027745359853, 852.1792456793887, 857.2518066214024, 853.7654956797454, 843.6912620420902, 833.7696245270928, 848.5988027454109, 850.1629021516411, 852.4177107426542, 850.616020932761, 858.3274450093209, 822.5898634011619, 845.007871478579, 769.9703808689565, 852.4135029410266, 862.6239988667468, 851.6595946224867, 846.7718669363978, 858.6611573321125, 857.0963641009463, 864.8145439964094, 854.1798735346276, 852.2152187970046, 854.7470836396141, 841.386973047783, 846.4427137224659, 738.2259527925041, 742.305347617125, 758.4044575837062, 725.7144509644173, 757.7431125720373, 753.7451877129478, 755.6112746210645, 772.2671877146942, 775.4701972464205, 771.205372495929, 775.8582926688694, 768.7762839629002, 754.2929877980637, 753.6934134676508, 769.5593517892866, 778.6124356653586, 664.4175976030892, 773.782477730064, 774.2509491720872, 784.4465345017492, 786.5398384130746, 778.0973634702003, 784.0934069565224, 742.4733071426427, 752.1130398852347, 763.7776559213751, 751.7746305903332, 710.6091388536366, 710.2380422467041, 731.7334739231655, 739.0492409287037, 756.2494695771566, 729.1980079509859, 743.8189981091202, 750.585263558733, 768.9059570976852, 745.348458497897, 719.5805846660049, 690.8807401458715, 790.4898699536566, 788.5914646951273, 788.9688651765382, 774.0930845461046, 774.7116817242971, 763.2172596183149, 751.2883888641522, 765.9151503209663, 751.6482893314561, 766.4529464423205, 768.823458810071, 770.7534831871724, 768.6221967669744, 768.6972321496532, 769.386560044018, 777.325467287711, 760.8903483460695, 753.5304040490496, 776.6895742301768, 761.327846127473, 760.5550538248912, 764.1905573535525, 767.8418959651477, 769.7180335018006, 760.9737678331807, 761.8206660826773, 736.2647970024241, 754.3665239826028, 756.5864110879997, 665.6811178005931, 762.7131331033364, 771.1838365752444, 759.1266717157802, 769.4226431494887, 767.1758499054558, 728.9188441427109, 762.3059623150847, 765.5222046176083, 750.0359145727098, 351.70371525963134, 740.8610788712305, 761.7288843158091, 759.8743779781071, 760.9402238368333, 754.1727450144381, 754.1433824242212, 747.856508735745, 753.8345016598537, 760.6684317005078, 734.3604696123143, 759.626441708422, 757.1984656541697, 760.7004602945245, 757.8429530014483, 762.9009153757102, 756.7246684811042, 768.8476253402325, 737.6579784885257, 754.4394504186306, 759.9386106312083, 761.6509515930605, 768.7452772671189, 772.0885589665738, 776.6262377652446, 771.7067190197449, 769.6776227833112, 766.2377272174995, 752.1532430689082]
Elapsed: 0.0560576958960155~0.010259154771739595
Time per graph: 0.0012928740026455186~0.00023154340601641403
Speed: 784.3825225707513~67.40590945466877
Total Time: 0.0582
best val loss: 0.44368788599967957 test_score: 0.8605

Testing...
Test loss: 0.6898 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.16344055300578475, 0.1597105999244377, 0.3101115069584921, 0.1751128031173721, 0.17460485198535025, 0.1741151368478313, 0.17437757807783782, 0.1751812678994611, 0.17659674293827266, 0.17607315012719482, 0.17549042694736272, 0.26294736901763827, 0.17354228103067726, 0.17393519601318985, 0.17409701296128333, 0.17390376096591353, 0.1744296740507707, 0.17596557887736708, 0.1782697088783607, 0.17769848788157105, 0.17738243390340358, 0.18696037598419935, 0.29249683499801904, 0.1771285090362653, 0.1696148010669276, 0.16942509799264371, 0.16985778196249157, 0.17119350004941225, 0.170271237147972, 0.17294384981505573, 0.17065586789976805, 0.16921050404198468, 0.16879093693569303, 0.2884873071452603, 0.16918367613106966, 0.1684464409481734, 0.16987571702338755, 0.169719269964844, 0.1717078509973362, 0.17161447601392865, 0.1714298209408298, 0.16911234997678548, 0.16887440287973732, 0.24475880584213883, 0.15318216301966459, 0.1527209150372073, 0.1538352119969204, 0.154616829007864, 0.15776346705388278, 0.16056172689422965, 0.15929883101489395, 0.15846306004095823, 0.15827802591957152, 0.28101094102021307, 0.16965512291062623, 0.16963883803691715, 0.16813165787607431, 0.16857141396030784, 0.16990693705156446, 0.16845453809946775, 0.1731053909752518, 0.17213826102670282, 0.17008262092713267, 0.17109399486798793, 0.25083827797789127, 0.1714956589275971, 0.1714257668936625, 0.17400702484883368, 0.1720972522161901, 0.17490619595628232, 0.17516175005584955, 0.18024662195239216, 0.18348214705474675, 0.16924554109573364, 0.1839720840798691, 0.24104469479061663, 0.16840907314326614, 0.169175281887874, 0.16928910301066935, 0.17020856880117208, 0.17025516915600747, 0.17547545791603625, 0.17325688898563385, 0.1717902849195525, 0.27168897702358663, 0.1807476709363982, 0.17234080599155277, 0.1722579001216218, 0.17257852794136852, 0.171577462926507, 0.17231117887422442, 0.17487274296581745, 0.17699755099602044, 0.17334415798541158, 0.1729213650105521, 0.2753974790684879, 0.17813251307234168, 0.17162680090405047, 0.1656046168645844, 0.16665433498565108, 0.16820841503795236, 0.16788191709201783, 0.1741801000898704, 0.17260149307549, 0.17214286013040692, 0.3043612309265882, 0.18111248093191534, 0.17310836690012366, 0.1688665368128568, 0.18727946083527058, 0.18041723303031176, 0.184493999928236, 0.18469607492443174, 0.17995762103237212, 0.17943534499499947, 0.1795564639614895, 0.18094660306815058, 0.17866443505045027, 0.17890919698402286, 0.18024700798559934, 0.1787929431302473, 0.18079553090501577, 0.1794516610680148, 0.17913012497592717, 0.17919424804858863, 0.17885527713224292, 0.1803571319906041, 0.17846090404782444, 0.1810118849389255, 0.17963371006771922, 0.18008255888707936, 0.18042235099710524, 0.17951662687119097, 0.1823452189564705, 0.18349127192050219, 0.17981833894737065, 0.1814494589343667, 0.180594322970137, 0.18114648398477584, 0.18185838381759822, 0.18152909795753658, 0.18086379393935204, 0.1818060039076954, 0.18179124302696437, 0.194044979987666, 0.18680185999255627, 0.18445806298404932, 0.19953720388002694, 0.1951424591243267, 0.1850174181163311, 0.18131364602595568, 0.17398715601302683, 0.17319064680486917, 0.17606274387799203, 0.17823031288571656, 0.17484458803664893, 0.17353866307530552, 0.17200761113781482, 0.17351672006770968, 0.17295349307823926, 0.1759395127883181, 0.17544802895281464, 0.1744447599630803, 0.1755317458882928, 0.17489306686911732, 0.1753510950366035, 0.17632373899687082, 0.1765308160101995, 0.17486899008508772, 0.17539128195494413, 0.17562624299898744, 0.17600433307234198, 0.17454945808276534, 0.17590913688763976, 0.1767266149399802, 0.17616755794733763, 0.17630819196347147, 0.17676918290089816, 0.17695991904474795, 0.17693416308611631, 0.17499227996449918, 0.17809924797620624, 0.17669720004778355, 0.17722829699050635, 0.1779854989144951, 0.1759611750021577, 0.17454966297373176, 0.17648905992973596, 0.17613521101884544, 0.17634854593779892, 0.17651354800909758, 0.17725110799074173, 0.17878630105406046, 0.17566715902648866, 0.1754276220453903, 0.1757130017504096, 0.17804934305604547, 0.17574658093508333, 0.1756725999293849, 0.1760974209755659, 0.18016091000754386, 0.178554903017357, 0.17760514211840928, 0.17673861794173717, 0.17552815098315477, 0.17576476105023175, 0.1846948271850124, 0.17989756516180933, 0.18456906510982662, 0.18122092995326966, 0.1754624160239473, 0.18300473398994654, 0.17901150917168707, 0.17687215993646532, 0.17535266594495624, 0.17417090095113963, 0.17582852800842375, 0.17630020796786994, 0.17771977407392114, 0.17896729696076363, 0.18370393698569387, 0.17873282998334616, 0.17559189803432673, 0.17425221600569785, 0.17858122917823493, 0.1737574340077117, 0.17042384191881865, 0.1704323630547151, 0.30175111698918045, 0.1677472989540547, 0.1684412619797513, 0.1682835470419377, 0.1690018749795854, 0.16884082392789423, 0.17190524586476386, 0.16878941503819078, 0.1672260609921068, 0.17522140103392303, 0.2603595299879089, 0.16765871411189437, 0.16650872596073896, 0.16555835295002908, 0.16558013297617435, 0.16838099085725844, 0.17268500803038478, 0.17245134606491774, 0.1700942108873278, 0.17157437896821648, 0.2651390479877591, 0.18189432693179697, 0.18230259593110532, 0.1740999760804698, 0.17367367597762495, 0.17528503492940217, 0.1748460209928453, 0.17605139699298888, 0.16961572400759906, 0.17153030505869538, 0.25398917903658, 0.18506495200563222, 0.1725693780463189, 0.16445022297557443, 0.16312821209430695, 0.16555749508552253, 0.1688520540483296, 0.17218146589584649, 0.17168207583017647, 0.16922302707098424, 0.16965588100720197, 0.2437405490782112, 0.1702790119452402, 0.1686620720429346, 0.17067236895672977, 0.16993717791046947, 0.1692432501586154, 0.1690798660274595, 0.1802019119495526, 0.17046347609721124, 0.1680668449262157, 0.1681958200642839, 0.2834168210392818, 0.1698489401023835, 0.1690773390000686, 0.1691747111035511, 0.16941485600546002, 0.17179261497221887, 0.1769337090663612, 0.17439668893348426, 0.1728523540077731, 0.17851745209190995, 0.2744002300314605, 0.16924266808200628, 0.16881144104991108, 0.1682713849004358, 0.1687805160181597, 0.17225344094913453, 0.1726314469706267, 0.1703855221858248, 0.17292400007136166, 0.2493499581469223, 0.17435137392021716, 0.17386409593746066, 0.17182415002025664, 0.17259010020643473, 0.17541329900268465, 0.1770990809891373, 0.17825806501787156, 0.17452452110592276, 0.17550996295176446, 0.17554543586447835, 0.25214358302764595, 0.17254007793962955, 0.17004567594267428, 0.17128679913002998, 0.17174962512217462, 0.1716732430504635, 0.17015222506597638, 0.17482194292824715, 0.1748795110033825, 0.17127316899131984, 0.17081887100357562, 0.2930399519391358, 0.16887348017189652, 0.167535082786344, 0.16857821797020733, 0.16787904093507677, 0.1677570700412616, 0.1701917750760913]
Total Epoch List: [113, 108, 107]
Total Time List: [0.05715318606235087, 0.0516512799076736, 0.05822958005592227]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a8172710>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6965;  Loss pred: 0.6965; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6975;  Loss pred: 0.6975; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6944;  Loss pred: 0.6944; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6930;  Loss pred: 0.6930; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.4884 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6867;  Loss pred: 0.6867; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6827;  Loss pred: 0.6827; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6803;  Loss pred: 0.6803; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6784;  Loss pred: 0.6784; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6740;  Loss pred: 0.6740; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6709;  Loss pred: 0.6709; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6653;  Loss pred: 0.6653; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.11s
Epoch 16/1000, LR 0.000270
Train loss: 0.6648;  Loss pred: 0.6648; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6638;  Loss pred: 0.6638; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6570;  Loss pred: 0.6570; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6565;  Loss pred: 0.6565; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6503;  Loss pred: 0.6503; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6413;  Loss pred: 0.6413; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6361;  Loss pred: 0.6361; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6285;  Loss pred: 0.6285; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6255;  Loss pred: 0.6255; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6215;  Loss pred: 0.6215; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6133;  Loss pred: 0.6133; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6072;  Loss pred: 0.6072; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5982;  Loss pred: 0.5982; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5893;  Loss pred: 0.5893; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5000 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5807;  Loss pred: 0.5807; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5000 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5738;  Loss pred: 0.5738; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5000 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5608;  Loss pred: 0.5608; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5000 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5562;  Loss pred: 0.5562; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5000 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5408;  Loss pred: 0.5408; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5000 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5277;  Loss pred: 0.5277; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.5000 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5215;  Loss pred: 0.5215; Loss self: 0.0000; time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6883 score: 0.5000 time: 0.06s
Epoch 37/1000, LR 0.000270
Train loss: 0.5120;  Loss pred: 0.5120; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6890 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.5000 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4958;  Loss pred: 0.4958; Loss self: 0.0000; time: 0.07s
Val loss: 0.6883 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6867 score: 0.5000 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4876;  Loss pred: 0.4876; Loss self: 0.0000; time: 0.07s
Val loss: 0.6873 score: 0.5349 time: 0.05s
Test loss: 0.6857 score: 0.5227 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4613;  Loss pred: 0.4613; Loss self: 0.0000; time: 0.07s
Val loss: 0.6863 score: 0.5349 time: 0.05s
Test loss: 0.6845 score: 0.5227 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4526;  Loss pred: 0.4526; Loss self: 0.0000; time: 0.07s
Val loss: 0.6853 score: 0.5349 time: 0.05s
Test loss: 0.6833 score: 0.5682 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4366;  Loss pred: 0.4366; Loss self: 0.0000; time: 0.08s
Val loss: 0.6841 score: 0.5581 time: 0.05s
Test loss: 0.6819 score: 0.5909 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4252;  Loss pred: 0.4252; Loss self: 0.0000; time: 0.08s
Val loss: 0.6829 score: 0.5581 time: 0.05s
Test loss: 0.6804 score: 0.6591 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4095;  Loss pred: 0.4095; Loss self: 0.0000; time: 0.07s
Val loss: 0.6814 score: 0.5581 time: 0.05s
Test loss: 0.6787 score: 0.6591 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4015;  Loss pred: 0.4015; Loss self: 0.0000; time: 0.07s
Val loss: 0.6797 score: 0.5581 time: 0.05s
Test loss: 0.6767 score: 0.6818 time: 0.07s
Epoch 46/1000, LR 0.000269
Train loss: 0.3808;  Loss pred: 0.3808; Loss self: 0.0000; time: 0.13s
Val loss: 0.6776 score: 0.5581 time: 0.05s
Test loss: 0.6744 score: 0.6818 time: 0.06s
Epoch 47/1000, LR 0.000269
Train loss: 0.3669;  Loss pred: 0.3669; Loss self: 0.0000; time: 0.08s
Val loss: 0.6755 score: 0.5581 time: 0.05s
Test loss: 0.6719 score: 0.6818 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3451;  Loss pred: 0.3451; Loss self: 0.0000; time: 0.07s
Val loss: 0.6731 score: 0.5581 time: 0.05s
Test loss: 0.6692 score: 0.7045 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3317;  Loss pred: 0.3317; Loss self: 0.0000; time: 0.07s
Val loss: 0.6705 score: 0.5581 time: 0.05s
Test loss: 0.6662 score: 0.7045 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3162;  Loss pred: 0.3162; Loss self: 0.0000; time: 0.07s
Val loss: 0.6676 score: 0.5814 time: 0.05s
Test loss: 0.6629 score: 0.7273 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3048;  Loss pred: 0.3048; Loss self: 0.0000; time: 0.07s
Val loss: 0.6645 score: 0.6047 time: 0.05s
Test loss: 0.6594 score: 0.7273 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2921;  Loss pred: 0.2921; Loss self: 0.0000; time: 0.08s
Val loss: 0.6611 score: 0.6047 time: 0.05s
Test loss: 0.6554 score: 0.7955 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2876;  Loss pred: 0.2876; Loss self: 0.0000; time: 0.08s
Val loss: 0.6572 score: 0.6512 time: 0.05s
Test loss: 0.6509 score: 0.7955 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2665;  Loss pred: 0.2665; Loss self: 0.0000; time: 0.07s
Val loss: 0.6531 score: 0.6744 time: 0.05s
Test loss: 0.6462 score: 0.7955 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2511;  Loss pred: 0.2511; Loss self: 0.0000; time: 0.07s
Val loss: 0.6485 score: 0.7209 time: 0.05s
Test loss: 0.6409 score: 0.8182 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2463;  Loss pred: 0.2463; Loss self: 0.0000; time: 0.11s
Val loss: 0.6434 score: 0.7209 time: 0.08s
Test loss: 0.6352 score: 0.8409 time: 0.06s
Epoch 57/1000, LR 0.000269
Train loss: 0.2255;  Loss pred: 0.2255; Loss self: 0.0000; time: 0.08s
Val loss: 0.6380 score: 0.7442 time: 0.05s
Test loss: 0.6292 score: 0.8636 time: 0.06s
Epoch 58/1000, LR 0.000269
Train loss: 0.2149;  Loss pred: 0.2149; Loss self: 0.0000; time: 0.08s
Val loss: 0.6320 score: 0.7442 time: 0.05s
Test loss: 0.6226 score: 0.8636 time: 0.06s
Epoch 59/1000, LR 0.000268
Train loss: 0.2075;  Loss pred: 0.2075; Loss self: 0.0000; time: 0.08s
Val loss: 0.6254 score: 0.7442 time: 0.05s
Test loss: 0.6155 score: 0.8409 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1991;  Loss pred: 0.1991; Loss self: 0.0000; time: 0.08s
Val loss: 0.6181 score: 0.7674 time: 0.05s
Test loss: 0.6080 score: 0.8409 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1834;  Loss pred: 0.1834; Loss self: 0.0000; time: 0.08s
Val loss: 0.6102 score: 0.7674 time: 0.05s
Test loss: 0.5999 score: 0.8409 time: 0.06s
Epoch 62/1000, LR 0.000268
Train loss: 0.1769;  Loss pred: 0.1769; Loss self: 0.0000; time: 0.08s
Val loss: 0.6015 score: 0.8140 time: 0.05s
Test loss: 0.5914 score: 0.8409 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1616;  Loss pred: 0.1616; Loss self: 0.0000; time: 0.07s
Val loss: 0.5924 score: 0.8605 time: 0.05s
Test loss: 0.5824 score: 0.8409 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1511;  Loss pred: 0.1511; Loss self: 0.0000; time: 0.07s
Val loss: 0.5829 score: 0.8605 time: 0.05s
Test loss: 0.5728 score: 0.8409 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1471;  Loss pred: 0.1471; Loss self: 0.0000; time: 0.07s
Val loss: 0.5731 score: 0.8605 time: 0.22s
Test loss: 0.5630 score: 0.8409 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1389;  Loss pred: 0.1389; Loss self: 0.0000; time: 0.07s
Val loss: 0.5627 score: 0.8837 time: 0.05s
Test loss: 0.5524 score: 0.8409 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1234;  Loss pred: 0.1234; Loss self: 0.0000; time: 0.07s
Val loss: 0.5518 score: 0.8837 time: 0.05s
Test loss: 0.5414 score: 0.8409 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1372;  Loss pred: 0.1372; Loss self: 0.0000; time: 0.08s
Val loss: 0.5401 score: 0.8837 time: 0.05s
Test loss: 0.5299 score: 0.8409 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1147;  Loss pred: 0.1147; Loss self: 0.0000; time: 0.07s
Val loss: 0.5284 score: 0.8837 time: 0.05s
Test loss: 0.5181 score: 0.8409 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1084;  Loss pred: 0.1084; Loss self: 0.0000; time: 0.07s
Val loss: 0.5168 score: 0.8837 time: 0.05s
Test loss: 0.5064 score: 0.8409 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.1019;  Loss pred: 0.1019; Loss self: 0.0000; time: 0.07s
Val loss: 0.5051 score: 0.8837 time: 0.05s
Test loss: 0.4940 score: 0.8409 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0929;  Loss pred: 0.0929; Loss self: 0.0000; time: 0.07s
Val loss: 0.4939 score: 0.8837 time: 0.05s
Test loss: 0.4818 score: 0.8409 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0857;  Loss pred: 0.0857; Loss self: 0.0000; time: 0.07s
Val loss: 0.4824 score: 0.9070 time: 0.05s
Test loss: 0.4700 score: 0.8409 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0850;  Loss pred: 0.0850; Loss self: 0.0000; time: 0.07s
Val loss: 0.4712 score: 0.9070 time: 0.05s
Test loss: 0.4579 score: 0.8409 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0750;  Loss pred: 0.0750; Loss self: 0.0000; time: 0.07s
Val loss: 0.4600 score: 0.9070 time: 0.05s
Test loss: 0.4464 score: 0.8409 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0698;  Loss pred: 0.0698; Loss self: 0.0000; time: 0.07s
Val loss: 0.4494 score: 0.8837 time: 0.05s
Test loss: 0.4347 score: 0.8409 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0713;  Loss pred: 0.0713; Loss self: 0.0000; time: 0.07s
Val loss: 0.4389 score: 0.8837 time: 0.05s
Test loss: 0.4233 score: 0.8409 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0606;  Loss pred: 0.0606; Loss self: 0.0000; time: 0.07s
Val loss: 0.4288 score: 0.9070 time: 0.05s
Test loss: 0.4120 score: 0.8409 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0523;  Loss pred: 0.0523; Loss self: 0.0000; time: 0.07s
Val loss: 0.4192 score: 0.9070 time: 0.05s
Test loss: 0.4008 score: 0.8409 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0533;  Loss pred: 0.0533; Loss self: 0.0000; time: 0.07s
Val loss: 0.4094 score: 0.9070 time: 0.05s
Test loss: 0.3902 score: 0.8409 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0475;  Loss pred: 0.0475; Loss self: 0.0000; time: 0.07s
Val loss: 0.4001 score: 0.9070 time: 0.05s
Test loss: 0.3797 score: 0.8636 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0447;  Loss pred: 0.0447; Loss self: 0.0000; time: 0.07s
Val loss: 0.3911 score: 0.8837 time: 0.05s
Test loss: 0.3700 score: 0.8636 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0403;  Loss pred: 0.0403; Loss self: 0.0000; time: 0.07s
Val loss: 0.3828 score: 0.8837 time: 0.05s
Test loss: 0.3610 score: 0.8636 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0402;  Loss pred: 0.0402; Loss self: 0.0000; time: 0.07s
Val loss: 0.3749 score: 0.8837 time: 0.05s
Test loss: 0.3526 score: 0.8636 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0335;  Loss pred: 0.0335; Loss self: 0.0000; time: 0.07s
Val loss: 0.3677 score: 0.8837 time: 0.05s
Test loss: 0.3447 score: 0.8636 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0318;  Loss pred: 0.0318; Loss self: 0.0000; time: 0.07s
Val loss: 0.3598 score: 0.8837 time: 0.05s
Test loss: 0.3381 score: 0.8636 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0330;  Loss pred: 0.0330; Loss self: 0.0000; time: 0.07s
Val loss: 0.3532 score: 0.8837 time: 0.05s
Test loss: 0.3316 score: 0.8636 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0348;  Loss pred: 0.0348; Loss self: 0.0000; time: 0.07s
Val loss: 0.3473 score: 0.8837 time: 0.05s
Test loss: 0.3262 score: 0.8864 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0272;  Loss pred: 0.0272; Loss self: 0.0000; time: 0.07s
Val loss: 0.3425 score: 0.8837 time: 0.05s
Test loss: 0.3215 score: 0.8864 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.07s
Val loss: 0.3392 score: 0.8837 time: 0.05s
Test loss: 0.3175 score: 0.8864 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0257;  Loss pred: 0.0257; Loss self: 0.0000; time: 0.07s
Val loss: 0.3366 score: 0.8837 time: 0.05s
Test loss: 0.3141 score: 0.8864 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.07s
Val loss: 0.3355 score: 0.8837 time: 0.05s
Test loss: 0.3117 score: 0.8864 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0198;  Loss pred: 0.0198; Loss self: 0.0000; time: 0.07s
Val loss: 0.3358 score: 0.8837 time: 0.05s
Test loss: 0.3099 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.07s
Val loss: 0.3357 score: 0.8837 time: 0.05s
Test loss: 0.3084 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0162;  Loss pred: 0.0162; Loss self: 0.0000; time: 0.07s
Val loss: 0.3360 score: 0.8837 time: 0.05s
Test loss: 0.3073 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.07s
Val loss: 0.3348 score: 0.8837 time: 0.05s
Test loss: 0.3067 score: 0.8864 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.07s
Val loss: 0.3335 score: 0.8837 time: 0.05s
Test loss: 0.3063 score: 0.8636 time: 0.05s
Epoch 98/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.07s
Val loss: 0.3322 score: 0.8837 time: 0.05s
Test loss: 0.3066 score: 0.8636 time: 0.05s
Epoch 99/1000, LR 0.000265
Train loss: 0.0153;  Loss pred: 0.0153; Loss self: 0.0000; time: 0.07s
Val loss: 0.3313 score: 0.8837 time: 0.05s
Test loss: 0.3073 score: 0.8636 time: 0.05s
Epoch 100/1000, LR 0.000265
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.08s
Val loss: 0.3312 score: 0.8837 time: 0.06s
Test loss: 0.3087 score: 0.8636 time: 0.06s
Epoch 101/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.08s
Val loss: 0.3311 score: 0.8837 time: 0.05s
Test loss: 0.3098 score: 0.8636 time: 0.06s
Epoch 102/1000, LR 0.000264
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.08s
Val loss: 0.3317 score: 0.8837 time: 0.05s
Test loss: 0.3119 score: 0.8636 time: 0.06s
     INFO: Early stopping counter 1 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0116;  Loss pred: 0.0116; Loss self: 0.0000; time: 0.08s
Val loss: 0.3321 score: 0.8837 time: 0.05s
Test loss: 0.3136 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.07s
Val loss: 0.3329 score: 0.8837 time: 0.05s
Test loss: 0.3157 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.07s
Val loss: 0.3340 score: 0.8837 time: 0.05s
Test loss: 0.3178 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.07s
Val loss: 0.3348 score: 0.9070 time: 0.05s
Test loss: 0.3196 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.3363 score: 0.9070 time: 0.05s
Test loss: 0.3217 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.3381 score: 0.9070 time: 0.05s
Test loss: 0.3237 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.07s
Val loss: 0.3401 score: 0.9070 time: 0.05s
Test loss: 0.3256 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0088;  Loss pred: 0.0088; Loss self: 0.0000; time: 0.07s
Val loss: 0.3426 score: 0.9070 time: 0.05s
Test loss: 0.3277 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.07s
Val loss: 0.3447 score: 0.9070 time: 0.05s
Test loss: 0.3297 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.3478 score: 0.9070 time: 0.05s
Test loss: 0.3325 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.07s
Val loss: 0.3506 score: 0.9070 time: 0.05s
Test loss: 0.3354 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.07s
Val loss: 0.3531 score: 0.9070 time: 0.05s
Test loss: 0.3376 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.3556 score: 0.9070 time: 0.05s
Test loss: 0.3398 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.3578 score: 0.9070 time: 0.05s
Test loss: 0.3421 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.3604 score: 0.8837 time: 0.05s
Test loss: 0.3445 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.3628 score: 0.8837 time: 0.05s
Test loss: 0.3463 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.3659 score: 0.8605 time: 0.05s
Test loss: 0.3488 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.3690 score: 0.8605 time: 0.05s
Test loss: 0.3514 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 121/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.3714 score: 0.8605 time: 0.05s
Test loss: 0.3534 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 100,   Train_Loss: 0.0126,   Val_Loss: 0.3311,   Val_Precision: 0.9048,   Val_Recall: 0.8636,   Val_accuracy: 0.8837,   Val_Score: 0.8837,   Val_Loss: 0.3311,   Test_Precision: 0.9444,   Test_Recall: 0.7727,   Test_accuracy: 0.8500,   Test_Score: 0.8636,   Test_loss: 0.3098


[0.05495344300288707, 0.05605329293757677, 0.05643790389876813, 0.05562433903105557, 0.054668394033797085, 0.05514952493831515, 0.05538214195985347, 0.05489778297487646, 0.05582942895125598, 0.05716046190354973, 0.06032039306592196, 0.05890176410321146, 0.05818613199517131, 0.056038266979157925, 0.12206410302314907, 0.05897732696030289, 0.059574118931777775, 0.05967151199001819, 0.0549457959132269, 0.055263229995034635, 0.05773346102796495, 0.0561538910260424, 0.0559643569868058, 0.055899297003634274, 0.05503514199517667, 0.05550429900176823, 0.05432229698635638, 0.0545734609477222, 0.05436052498407662, 0.05519188195466995, 0.05640814907383174, 0.0557326819980517, 0.05460704304277897, 0.05494357296265662, 0.05612980201840401, 0.060220289044082165, 0.055925668915733695, 0.055131684988737106, 0.05537912901490927, 0.055924420012161136, 0.057718195021152496, 0.0562024200335145, 0.05553656001575291, 0.05570493498817086, 0.07476338208653033, 0.06032199098262936, 0.05710485903546214, 0.05513549398165196, 0.0551172069972381, 0.05579463194590062, 0.05594674602616578, 0.057475302019156516, 0.05763070599641651, 0.055833914084360003, 0.056938193971291184, 0.06105862301774323, 0.06044658203609288, 0.0599975559161976, 0.059258893015794456, 0.059307676972821355, 0.06174111505970359, 0.05973893799819052, 0.0575460169930011, 0.0559361589839682, 0.05892923509236425, 0.05920447898097336, 0.060205004061572254, 0.05434923991560936, 0.054467592970468104, 0.056515612988732755, 0.05556874698959291, 0.05641218496020883, 0.0556343209464103, 0.05544479889795184, 0.05600564298219979, 0.05625417607370764, 0.05579160095658153, 0.05567215697374195, 0.05585398292168975, 0.0560819529928267, 0.0555464819772169, 0.05604685808066279, 0.0559015569742769, 0.0559255100088194, 0.05616548203397542, 0.055752902990207076, 0.05606783099938184, 0.05589190393220633, 0.05604315095115453, 0.05594507802743465, 0.05593965610023588, 0.05590981198474765, 0.05560033000074327, 0.05575783096719533, 0.05578964902088046, 0.05555380892474204, 0.05551423307042569, 0.05611342203337699, 0.05575776204932481, 0.060433037928305566, 0.06032165593933314, 0.05997039098292589, 0.05500688299071044, 0.05500738101545721, 0.05557430803310126, 0.05552723095752299, 0.05521986703388393, 0.05568961100652814, 0.055861620930954814, 0.05523666203953326, 0.05529789999127388, 0.055307219037786126, 0.05587819602806121, 0.05524353706277907, 0.05542303097900003, 0.055198268964886665, 0.05539679597131908, 0.05548180791083723, 0.055490481900051236, 0.05566414911299944, 0.05537799501325935]
[0.0012489418864292516, 0.0012739384758540175, 0.0012826796340629119, 0.0012641895234330811, 0.0012424635007681156, 0.001253398294052617, 0.0012586850445421244, 0.001247676885792647, 0.0012688506579830903, 0.0012991014068988575, 0.001370918024225499, 0.0013386764568911697, 0.0013224120907993479, 0.0012735969767990437, 0.0027741841596170243, 0.0013403937945523385, 0.001353957248449495, 0.001356170727045868, 0.0012487680889369751, 0.0012559824998871509, 0.0013121241142719307, 0.0012762247960464183, 0.0012719172042455864, 0.0012704385682644154, 0.0012507986817085607, 0.0012614613409492779, 0.0012345976587808268, 0.00124030593063005, 0.0012354664769108322, 0.0012543609535152261, 0.0012820033880416304, 0.001266651863592084, 0.0012410691600631583, 0.0012487175673331049, 0.001275677318600091, 0.0013686429328200493, 0.0012710379299030385, 0.001252992840653116, 0.0012586165685206652, 0.0012710095457309349, 0.0013117771595716476, 0.0012773277280344205, 0.0012621945458125663, 0.0012660212497311559, 0.001699167774693871, 0.0013709543405143036, 0.0012978377053514123, 0.0012530794086739081, 0.001252663795391775, 0.0012680598169522868, 0.0012715169551401314, 0.001306256864071739, 0.0013097887726458298, 0.0012689525928263638, 0.0012940498629838905, 0.0013876959776759825, 0.0013737859553657472, 0.0013635808162772182, 0.0013467930230862376, 0.0013479017493823035, 0.0014032071604478088, 0.001357703136322512, 0.0013078640225682068, 0.0012712763405447317, 0.001339300797553733, 0.0013455563404766674, 0.0013682955468539149, 0.001235209998082031, 0.0012378998402379114, 0.0012844457497439262, 0.0012629260679452934, 0.0012820951127320188, 0.0012644163851456885, 0.001260109065862542, 0.0012728555223227224, 0.0012785040016751736, 0.0012679909308313984, 0.0012652762948577715, 0.001269408702765676, 0.0012745898407460613, 0.0012624200449367477, 0.0012737922291059724, 0.0012704899312335658, 0.001271034318382259, 0.001276488228044896, 0.0012671114315956154, 0.0012742688863495873, 0.0012702705439137803, 0.001273707976162603, 0.0012714790460780603, 0.0012713558204599064, 0.001270677545107901, 0.0012636438636532562, 0.0012672234310726212, 0.0012679465686563742, 0.0012625865664714101, 0.0012616871152369474, 0.0012753050462131134, 0.001267221864757382, 0.0013734781347342175, 0.001370946725893935, 0.0013629634314301338, 0.0012501564316070553, 0.0012501677503513004, 0.0012630524552977558, 0.0012619825217618861, 0.0012549969780428166, 0.0012656729774210942, 0.0012695822938853366, 0.001255378682716665, 0.0012567704543471336, 0.0012569822508587756, 0.0012699590006377548, 0.001255534933244979, 0.0012596143404318188, 0.0012545061128383334, 0.0012590180902572517, 0.0012609501797917553, 0.0012611473159102554, 0.0012650942980227146, 0.0012585907957558943]
[800.6777664083465, 784.9672640820619, 779.6178979099255, 791.0206353271794, 804.8526169032573, 797.8309885572737, 794.4799251696624, 801.4895614297621, 788.1148137555891, 769.7628489119601, 729.4382175513015, 747.0064890229836, 756.1939330088384, 785.1777432083104, 360.4663362139772, 746.0494103033188, 738.5757572073752, 737.3702883104469, 800.7892008605528, 796.1894374243665, 762.1230256520957, 783.5610176967824, 786.2146975149465, 787.129755802463, 799.4891700989197, 792.7313882227081, 809.9804765444853, 806.252695649065, 809.4108732924959, 797.2186930704404, 780.0291398040573, 789.4829106113742, 805.7568684964419, 800.8215998239756, 783.8972955146563, 730.6507607061025, 786.7585824730544, 798.0891570607499, 794.5231494730486, 786.7761523576268, 762.3246011742906, 782.8844376053917, 792.2708930390976, 789.8761574597215, 588.5234023933652, 729.4188948881093, 770.5123652030378, 798.034021689229, 798.298796276176, 788.6063312087642, 786.462182794717, 765.5462164484982, 763.4818841666789, 788.0515045662028, 772.7677492226966, 720.6189367751365, 727.9154340559312, 733.3632066855789, 742.5045889445242, 741.8938364448783, 712.6531478651146, 736.5380348966489, 764.6054809553787, 786.6110365677914, 746.6582576718579, 743.1870148564326, 730.8362599726887, 809.5789392514207, 807.8197989005398, 778.5459216158916, 791.8119875591303, 779.973334325484, 790.8787103267235, 793.5821010187735, 785.6351191965508, 782.1641533305639, 788.6491738109817, 790.3412116895852, 787.7683505881816, 784.5661153353188, 792.1293740627384, 785.0573878142301, 787.0979339671451, 786.7608179712843, 783.3993122926227, 789.1965734542745, 784.7637266454111, 787.2338729661003, 785.1093176104433, 786.4856311116957, 786.5618608945017, 786.9817199886725, 791.3622095302636, 789.1268228473062, 788.6767666083016, 792.024900751741, 792.5895318445872, 784.1261218007384, 789.1277982261272, 728.0785727204245, 729.422946284031, 733.6953999937601, 799.8998962989908, 799.8926541810068, 791.732754887252, 792.4040014467668, 796.8146676811226, 790.0935058577112, 787.6606383188231, 796.5723918746013, 795.6902523774554, 795.5561817335096, 787.4269952792292, 796.4732589442661, 793.893787885252, 797.1264466280594, 794.2697628718525, 793.0527438959951, 792.9287779344257, 790.4549104070385, 794.5394193030088]
Elapsed: 0.05714643410260766~0.0063870961838400735
Time per graph: 0.001298782593241083~0.00014516127690545623
Speed: 775.0596675983622~47.42703863341697
Total Time: 0.0560
best val loss: 0.33109351992607117 test_score: 0.8636

Testing...
Test loss: 0.4700 score: 0.8409 time: 0.05s
test Score 0.8409
Epoch Time List: [0.17074914497788996, 0.17188847495708615, 0.17724713205825537, 0.17562680481933057, 0.17239926510956138, 0.30416767892893404, 0.17425355897285044, 0.1725768499309197, 0.17567582800984383, 0.17698338301852345, 0.1795063988538459, 0.18597672402393073, 0.18416661594528705, 0.1785605939803645, 0.23948958318214864, 0.20238051493652165, 0.18506932200398296, 0.18592030892614275, 0.17424879979807884, 0.17320827406365424, 0.17653955100104213, 0.17583022196777165, 0.17450483702123165, 0.17405944899655879, 0.2966968599939719, 0.1724033768987283, 0.17087435408029705, 0.17062224098481238, 0.16976054199039936, 0.17438998213037848, 0.17417190806008875, 0.17777374107390642, 0.17230207100510597, 0.17197985504753888, 0.17314819304738194, 0.305553380982019, 0.17781592905521393, 0.17136436991859227, 0.17161975800991058, 0.17579474591184407, 0.17657386185601354, 0.1783624008530751, 0.17581264290492982, 0.17307613405864686, 0.18934279098175466, 0.23526909004431218, 0.18333219597116113, 0.17226528900209814, 0.17291788407601416, 0.17230440804269165, 0.17242133093532175, 0.17969768401235342, 0.1790964580141008, 0.17476260708644986, 0.17436100996565074, 0.2532826839014888, 0.18846102396491915, 0.187870503985323, 0.18652345694135875, 0.1839986388804391, 0.18725227192044258, 0.18846638104878366, 0.1780634589958936, 0.17453147587366402, 0.34109129197895527, 0.18275899707805365, 0.18300458183512092, 0.17748215200845152, 0.16918718093074858, 0.1707961279898882, 0.173312094877474, 0.17335709906183183, 0.17336680786684155, 0.17270396498497576, 0.17581690894439816, 0.1740230000577867, 0.1746521230088547, 0.17349295690655708, 0.17361892899498343, 0.17468503292184323, 0.1743669779971242, 0.1754961940459907, 0.17430437298025936, 0.17391993897035718, 0.1753379439469427, 0.17502808605786413, 0.17385010689031333, 0.17598688986618072, 0.17595619603525847, 0.17443441785871983, 0.17418186902068555, 0.1739344228990376, 0.1744676030939445, 0.1737085139611736, 0.17446400702465326, 0.17484624695498496, 0.17474283196497709, 0.17500709102023393, 0.1748696519061923, 0.19134803698398173, 0.18789653899148107, 0.1874838877702132, 0.1805434519192204, 0.17325648094993085, 0.17318998591508716, 0.17431304801721126, 0.17366994405165315, 0.1731930220266804, 0.17342997493688017, 0.17392638395540416, 0.1729989240411669, 0.17246173589956015, 0.17499328695703298, 0.17349632107652724, 0.1738227199530229, 0.17351664591114968, 0.17385404102969915, 0.17401228903327137, 0.17455006507225335, 0.17318361706566066, 0.17468336212914437]
Total Epoch List: [121]
Total Time List: [0.05600782891269773]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a8159000>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6955;  Loss pred: 0.6955; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6953;  Loss pred: 0.6953; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6936;  Loss pred: 0.6936; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6919;  Loss pred: 0.6919; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6894;  Loss pred: 0.6894; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6889;  Loss pred: 0.6889; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6828;  Loss pred: 0.6828; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6839;  Loss pred: 0.6839; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6794;  Loss pred: 0.6794; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6769;  Loss pred: 0.6769; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6734;  Loss pred: 0.6734; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6651;  Loss pred: 0.6651; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6661;  Loss pred: 0.6661; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6577;  Loss pred: 0.6577; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6552;  Loss pred: 0.6552; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6491;  Loss pred: 0.6491; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6432;  Loss pred: 0.6432; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6362;  Loss pred: 0.6362; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6338;  Loss pred: 0.6338; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6231;  Loss pred: 0.6231; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6171;  Loss pred: 0.6171; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6066;  Loss pred: 0.6066; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5969;  Loss pred: 0.5969; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5936;  Loss pred: 0.5936; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5815;  Loss pred: 0.5815; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5714;  Loss pred: 0.5714; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5550;  Loss pred: 0.5550; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5485;  Loss pred: 0.5485; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5359;  Loss pred: 0.5359; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5246;  Loss pred: 0.5246; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5082;  Loss pred: 0.5082; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6894 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5026;  Loss pred: 0.5026; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4864;  Loss pred: 0.4864; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6881 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4624;  Loss pred: 0.4624; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4563;  Loss pred: 0.4563; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4367;  Loss pred: 0.4367; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6878 score: 0.5000 time: 0.05s
Test loss: 0.6854 score: 0.5349 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4243;  Loss pred: 0.4243; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.5000 time: 0.05s
Test loss: 0.6842 score: 0.5349 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4115;  Loss pred: 0.4115; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5000 time: 0.05s
Test loss: 0.6828 score: 0.5349 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4022;  Loss pred: 0.4022; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6848 score: 0.5000 time: 0.05s
Test loss: 0.6812 score: 0.5349 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3820;  Loss pred: 0.3820; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6835 score: 0.5000 time: 0.05s
Test loss: 0.6794 score: 0.5349 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3651;  Loss pred: 0.3651; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6820 score: 0.5000 time: 0.05s
Test loss: 0.6774 score: 0.5349 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3469;  Loss pred: 0.3469; Loss self: 0.0000; time: 0.08s
Val loss: 0.6804 score: 0.5227 time: 0.05s
Test loss: 0.6753 score: 0.5349 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3228;  Loss pred: 0.3228; Loss self: 0.0000; time: 0.08s
Val loss: 0.6786 score: 0.5455 time: 0.05s
Test loss: 0.6730 score: 0.5349 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3104;  Loss pred: 0.3104; Loss self: 0.0000; time: 0.08s
Val loss: 0.6766 score: 0.5455 time: 0.05s
Test loss: 0.6704 score: 0.5349 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2948;  Loss pred: 0.2948; Loss self: 0.0000; time: 0.08s
Val loss: 0.6743 score: 0.5455 time: 0.05s
Test loss: 0.6674 score: 0.5349 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2882;  Loss pred: 0.2882; Loss self: 0.0000; time: 0.08s
Val loss: 0.6717 score: 0.5455 time: 0.05s
Test loss: 0.6641 score: 0.5349 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2718;  Loss pred: 0.2718; Loss self: 0.0000; time: 0.08s
Val loss: 0.6688 score: 0.5455 time: 0.05s
Test loss: 0.6604 score: 0.5349 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2568;  Loss pred: 0.2568; Loss self: 0.0000; time: 0.08s
Val loss: 0.6655 score: 0.5455 time: 0.05s
Test loss: 0.6564 score: 0.5349 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2386;  Loss pred: 0.2386; Loss self: 0.0000; time: 0.08s
Val loss: 0.6618 score: 0.5682 time: 0.05s
Test loss: 0.6517 score: 0.5581 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2267;  Loss pred: 0.2267; Loss self: 0.0000; time: 0.08s
Val loss: 0.6577 score: 0.5909 time: 0.05s
Test loss: 0.6467 score: 0.5581 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2151;  Loss pred: 0.2151; Loss self: 0.0000; time: 0.08s
Val loss: 0.6531 score: 0.6136 time: 0.05s
Test loss: 0.6412 score: 0.6047 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.1995;  Loss pred: 0.1995; Loss self: 0.0000; time: 0.08s
Val loss: 0.6481 score: 0.6591 time: 0.05s
Test loss: 0.6351 score: 0.6279 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1853;  Loss pred: 0.1853; Loss self: 0.0000; time: 0.08s
Val loss: 0.6426 score: 0.7045 time: 0.05s
Test loss: 0.6286 score: 0.6512 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1754;  Loss pred: 0.1754; Loss self: 0.0000; time: 0.08s
Val loss: 0.6367 score: 0.7045 time: 0.05s
Test loss: 0.6216 score: 0.6977 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1635;  Loss pred: 0.1635; Loss self: 0.0000; time: 0.08s
Val loss: 0.6304 score: 0.7500 time: 0.05s
Test loss: 0.6141 score: 0.7209 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1525;  Loss pred: 0.1525; Loss self: 0.0000; time: 0.08s
Val loss: 0.6235 score: 0.7727 time: 0.05s
Test loss: 0.6061 score: 0.6977 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1381;  Loss pred: 0.1381; Loss self: 0.0000; time: 0.08s
Val loss: 0.6162 score: 0.8182 time: 0.05s
Test loss: 0.5978 score: 0.7209 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1266;  Loss pred: 0.1266; Loss self: 0.0000; time: 0.08s
Val loss: 0.6085 score: 0.8182 time: 0.05s
Test loss: 0.5891 score: 0.7674 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1190;  Loss pred: 0.1190; Loss self: 0.0000; time: 0.08s
Val loss: 0.6005 score: 0.8409 time: 0.05s
Test loss: 0.5800 score: 0.7442 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1095;  Loss pred: 0.1095; Loss self: 0.0000; time: 0.08s
Val loss: 0.5921 score: 0.8409 time: 0.05s
Test loss: 0.5705 score: 0.7442 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.0963;  Loss pred: 0.0963; Loss self: 0.0000; time: 0.08s
Val loss: 0.5834 score: 0.8409 time: 0.05s
Test loss: 0.5607 score: 0.7674 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0918;  Loss pred: 0.0918; Loss self: 0.0000; time: 0.08s
Val loss: 0.5743 score: 0.8182 time: 0.05s
Test loss: 0.5505 score: 0.7907 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0839;  Loss pred: 0.0839; Loss self: 0.0000; time: 0.08s
Val loss: 0.5646 score: 0.7955 time: 0.05s
Test loss: 0.5398 score: 0.7907 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0765;  Loss pred: 0.0765; Loss self: 0.0000; time: 0.08s
Val loss: 0.5547 score: 0.7955 time: 0.06s
Test loss: 0.5288 score: 0.7674 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0709;  Loss pred: 0.0709; Loss self: 0.0000; time: 0.09s
Val loss: 0.5443 score: 0.7955 time: 0.05s
Test loss: 0.5176 score: 0.7674 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0641;  Loss pred: 0.0641; Loss self: 0.0000; time: 0.08s
Val loss: 0.5338 score: 0.7955 time: 0.05s
Test loss: 0.5064 score: 0.7674 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0595;  Loss pred: 0.0595; Loss self: 0.0000; time: 0.08s
Val loss: 0.5234 score: 0.7955 time: 0.05s
Test loss: 0.4953 score: 0.7907 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0546;  Loss pred: 0.0546; Loss self: 0.0000; time: 0.08s
Val loss: 0.5129 score: 0.7727 time: 0.05s
Test loss: 0.4840 score: 0.7907 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0504;  Loss pred: 0.0504; Loss self: 0.0000; time: 0.09s
Val loss: 0.5025 score: 0.7727 time: 0.06s
Test loss: 0.4729 score: 0.7907 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.0445;  Loss pred: 0.0445; Loss self: 0.0000; time: 0.10s
Val loss: 0.4923 score: 0.7727 time: 0.06s
Test loss: 0.4619 score: 0.7907 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0428;  Loss pred: 0.0428; Loss self: 0.0000; time: 0.08s
Val loss: 0.4824 score: 0.7727 time: 0.05s
Test loss: 0.4514 score: 0.8140 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0390;  Loss pred: 0.0390; Loss self: 0.0000; time: 0.08s
Val loss: 0.4733 score: 0.7727 time: 0.05s
Test loss: 0.4415 score: 0.8372 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0351;  Loss pred: 0.0351; Loss self: 0.0000; time: 0.08s
Val loss: 0.4645 score: 0.7727 time: 0.05s
Test loss: 0.4323 score: 0.8372 time: 0.06s
Epoch 76/1000, LR 0.000267
Train loss: 0.0315;  Loss pred: 0.0315; Loss self: 0.0000; time: 0.18s
Val loss: 0.4565 score: 0.7727 time: 0.05s
Test loss: 0.4239 score: 0.8372 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0294;  Loss pred: 0.0294; Loss self: 0.0000; time: 0.08s
Val loss: 0.4495 score: 0.7500 time: 0.05s
Test loss: 0.4164 score: 0.8372 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0261;  Loss pred: 0.0261; Loss self: 0.0000; time: 0.08s
Val loss: 0.4430 score: 0.7500 time: 0.05s
Test loss: 0.4096 score: 0.8372 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0242;  Loss pred: 0.0242; Loss self: 0.0000; time: 0.08s
Val loss: 0.4376 score: 0.7500 time: 0.05s
Test loss: 0.4038 score: 0.8605 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.08s
Val loss: 0.4336 score: 0.7500 time: 0.05s
Test loss: 0.3993 score: 0.8372 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0203;  Loss pred: 0.0203; Loss self: 0.0000; time: 0.08s
Val loss: 0.4300 score: 0.7500 time: 0.05s
Test loss: 0.3955 score: 0.8372 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0199;  Loss pred: 0.0199; Loss self: 0.0000; time: 0.08s
Val loss: 0.4275 score: 0.7500 time: 0.05s
Test loss: 0.3926 score: 0.8372 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.08s
Val loss: 0.4260 score: 0.7500 time: 0.05s
Test loss: 0.3906 score: 0.8372 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.08s
Val loss: 0.4254 score: 0.7500 time: 0.05s
Test loss: 0.3895 score: 0.8372 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0152;  Loss pred: 0.0152; Loss self: 0.0000; time: 0.09s
Val loss: 0.4259 score: 0.7500 time: 0.13s
Test loss: 0.3894 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 86/1000, LR 0.000266
Train loss: 0.0145;  Loss pred: 0.0145; Loss self: 0.0000; time: 0.08s
Val loss: 0.4272 score: 0.7500 time: 0.05s
Test loss: 0.3902 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 87/1000, LR 0.000266
Train loss: 0.0128;  Loss pred: 0.0128; Loss self: 0.0000; time: 0.08s
Val loss: 0.4292 score: 0.7500 time: 0.05s
Test loss: 0.3920 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0137;  Loss pred: 0.0137; Loss self: 0.0000; time: 0.09s
Val loss: 0.4306 score: 0.7500 time: 0.05s
Test loss: 0.3939 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.08s
Val loss: 0.4324 score: 0.7500 time: 0.05s
Test loss: 0.3961 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.08s
Val loss: 0.4348 score: 0.7500 time: 0.05s
Test loss: 0.3991 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.09s
Val loss: 0.4373 score: 0.7500 time: 0.05s
Test loss: 0.4024 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.08s
Val loss: 0.4409 score: 0.7500 time: 0.05s
Test loss: 0.4066 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.08s
Val loss: 0.4451 score: 0.7500 time: 0.05s
Test loss: 0.4115 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.08s
Val loss: 0.4496 score: 0.7500 time: 0.05s
Test loss: 0.4169 score: 0.8372 time: 0.06s
     INFO: Early stopping counter 10 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.15s
Val loss: 0.4550 score: 0.7500 time: 0.05s
Test loss: 0.4231 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.08s
Val loss: 0.4601 score: 0.7500 time: 0.05s
Test loss: 0.4289 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.08s
Val loss: 0.4658 score: 0.7500 time: 0.05s
Test loss: 0.4355 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.08s
Val loss: 0.4718 score: 0.7500 time: 0.05s
Test loss: 0.4423 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.08s
Val loss: 0.4789 score: 0.7500 time: 0.06s
Test loss: 0.4499 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.08s
Val loss: 0.4868 score: 0.7500 time: 0.05s
Test loss: 0.4584 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.09s
Val loss: 0.4952 score: 0.7500 time: 0.05s
Test loss: 0.4674 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.08s
Val loss: 0.5036 score: 0.7500 time: 0.05s
Test loss: 0.4767 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.09s
Val loss: 0.5123 score: 0.7500 time: 0.05s
Test loss: 0.4858 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.08s
Val loss: 0.5209 score: 0.7500 time: 0.05s
Test loss: 0.4950 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 083,   Train_Loss: 0.0166,   Val_Loss: 0.4254,   Val_Precision: 0.7895,   Val_Recall: 0.6818,   Val_accuracy: 0.7317,   Val_Score: 0.7500,   Val_Loss: 0.4254,   Test_Precision: 0.9412,   Test_Recall: 0.7273,   Test_accuracy: 0.8205,   Test_Score: 0.8372,   Test_loss: 0.3895


[0.05495344300288707, 0.05605329293757677, 0.05643790389876813, 0.05562433903105557, 0.054668394033797085, 0.05514952493831515, 0.05538214195985347, 0.05489778297487646, 0.05582942895125598, 0.05716046190354973, 0.06032039306592196, 0.05890176410321146, 0.05818613199517131, 0.056038266979157925, 0.12206410302314907, 0.05897732696030289, 0.059574118931777775, 0.05967151199001819, 0.0549457959132269, 0.055263229995034635, 0.05773346102796495, 0.0561538910260424, 0.0559643569868058, 0.055899297003634274, 0.05503514199517667, 0.05550429900176823, 0.05432229698635638, 0.0545734609477222, 0.05436052498407662, 0.05519188195466995, 0.05640814907383174, 0.0557326819980517, 0.05460704304277897, 0.05494357296265662, 0.05612980201840401, 0.060220289044082165, 0.055925668915733695, 0.055131684988737106, 0.05537912901490927, 0.055924420012161136, 0.057718195021152496, 0.0562024200335145, 0.05553656001575291, 0.05570493498817086, 0.07476338208653033, 0.06032199098262936, 0.05710485903546214, 0.05513549398165196, 0.0551172069972381, 0.05579463194590062, 0.05594674602616578, 0.057475302019156516, 0.05763070599641651, 0.055833914084360003, 0.056938193971291184, 0.06105862301774323, 0.06044658203609288, 0.0599975559161976, 0.059258893015794456, 0.059307676972821355, 0.06174111505970359, 0.05973893799819052, 0.0575460169930011, 0.0559361589839682, 0.05892923509236425, 0.05920447898097336, 0.060205004061572254, 0.05434923991560936, 0.054467592970468104, 0.056515612988732755, 0.05556874698959291, 0.05641218496020883, 0.0556343209464103, 0.05544479889795184, 0.05600564298219979, 0.05625417607370764, 0.05579160095658153, 0.05567215697374195, 0.05585398292168975, 0.0560819529928267, 0.0555464819772169, 0.05604685808066279, 0.0559015569742769, 0.0559255100088194, 0.05616548203397542, 0.055752902990207076, 0.05606783099938184, 0.05589190393220633, 0.05604315095115453, 0.05594507802743465, 0.05593965610023588, 0.05590981198474765, 0.05560033000074327, 0.05575783096719533, 0.05578964902088046, 0.05555380892474204, 0.05551423307042569, 0.05611342203337699, 0.05575776204932481, 0.060433037928305566, 0.06032165593933314, 0.05997039098292589, 0.05500688299071044, 0.05500738101545721, 0.05557430803310126, 0.05552723095752299, 0.05521986703388393, 0.05568961100652814, 0.055861620930954814, 0.05523666203953326, 0.05529789999127388, 0.055307219037786126, 0.05587819602806121, 0.05524353706277907, 0.05542303097900003, 0.055198268964886665, 0.05539679597131908, 0.05548180791083723, 0.055490481900051236, 0.05566414911299944, 0.05537799501325935, 0.05201731401029974, 0.05149092699866742, 0.051766803953796625, 0.051586927962489426, 0.051755178021267056, 0.05139364500064403, 0.051968323066830635, 0.051619878038764, 0.0515691110631451, 0.051894031930714846, 0.05161625100299716, 0.052146260044537485, 0.051518047926947474, 0.05174837994854897, 0.051584055996499956, 0.05147716694045812, 0.05175143596716225, 0.05190626299008727, 0.05172425101045519, 0.05164942902047187, 0.05156979104503989, 0.05138842505402863, 0.053069973015226424, 0.05201899399980903, 0.05173307505901903, 0.05230551504064351, 0.051734801032580435, 0.05239445308689028, 0.05190926103387028, 0.052148950984701514, 0.05170372605789453, 0.05180776596534997, 0.052400512038730085, 0.05168436502572149, 0.05199707194697112, 0.05147507297806442, 0.05223416304215789, 0.051876278943382204, 0.05202749103773385, 0.05211333406623453, 0.0517597789876163, 0.05194639100227505, 0.05175825790502131, 0.052291175932623446, 0.05173031101003289, 0.05180823290720582, 0.05184502503834665, 0.0516686060000211, 0.051817390020005405, 0.05156663793604821, 0.05192851007450372, 0.0514165700878948, 0.05167428299318999, 0.051268620998598635, 0.05171091004740447, 0.05146566696930677, 0.051534262020140886, 0.05162086593918502, 0.05164359696209431, 0.051820053020492196, 0.05184671201277524, 0.0514857720118016, 0.05185004509985447, 0.051953495014458895, 0.05126346705947071, 0.0570338349789381, 0.05164756008889526, 0.05141591397114098, 0.05178215308114886, 0.052160058985464275, 0.06500981806311756, 0.0537106889532879, 0.05028046993538737, 0.0509542659856379, 0.06510289490688592, 0.05507510097231716, 0.05513528804294765, 0.05487352900672704, 0.05477708100806922, 0.0516872740117833, 0.05139456200413406, 0.05192865198478103, 0.05139093904290348, 0.05281147302594036, 0.05034049798268825, 0.050939157023094594, 0.05675784300547093, 0.05108180001843721, 0.05141163698863238, 0.05211179703474045, 0.05257201299536973, 0.05157287896145135, 0.05117408197838813, 0.07186836004257202, 0.055252849007956684, 0.055201971903443336, 0.0502360169775784, 0.0501092349877581, 0.05226459901314229, 0.05142569600138813, 0.051764204050414264, 0.050826409948058426, 0.05047385103534907, 0.05374964606016874]
[0.0012489418864292516, 0.0012739384758540175, 0.0012826796340629119, 0.0012641895234330811, 0.0012424635007681156, 0.001253398294052617, 0.0012586850445421244, 0.001247676885792647, 0.0012688506579830903, 0.0012991014068988575, 0.001370918024225499, 0.0013386764568911697, 0.0013224120907993479, 0.0012735969767990437, 0.0027741841596170243, 0.0013403937945523385, 0.001353957248449495, 0.001356170727045868, 0.0012487680889369751, 0.0012559824998871509, 0.0013121241142719307, 0.0012762247960464183, 0.0012719172042455864, 0.0012704385682644154, 0.0012507986817085607, 0.0012614613409492779, 0.0012345976587808268, 0.00124030593063005, 0.0012354664769108322, 0.0012543609535152261, 0.0012820033880416304, 0.001266651863592084, 0.0012410691600631583, 0.0012487175673331049, 0.001275677318600091, 0.0013686429328200493, 0.0012710379299030385, 0.001252992840653116, 0.0012586165685206652, 0.0012710095457309349, 0.0013117771595716476, 0.0012773277280344205, 0.0012621945458125663, 0.0012660212497311559, 0.001699167774693871, 0.0013709543405143036, 0.0012978377053514123, 0.0012530794086739081, 0.001252663795391775, 0.0012680598169522868, 0.0012715169551401314, 0.001306256864071739, 0.0013097887726458298, 0.0012689525928263638, 0.0012940498629838905, 0.0013876959776759825, 0.0013737859553657472, 0.0013635808162772182, 0.0013467930230862376, 0.0013479017493823035, 0.0014032071604478088, 0.001357703136322512, 0.0013078640225682068, 0.0012712763405447317, 0.001339300797553733, 0.0013455563404766674, 0.0013682955468539149, 0.001235209998082031, 0.0012378998402379114, 0.0012844457497439262, 0.0012629260679452934, 0.0012820951127320188, 0.0012644163851456885, 0.001260109065862542, 0.0012728555223227224, 0.0012785040016751736, 0.0012679909308313984, 0.0012652762948577715, 0.001269408702765676, 0.0012745898407460613, 0.0012624200449367477, 0.0012737922291059724, 0.0012704899312335658, 0.001271034318382259, 0.001276488228044896, 0.0012671114315956154, 0.0012742688863495873, 0.0012702705439137803, 0.001273707976162603, 0.0012714790460780603, 0.0012713558204599064, 0.001270677545107901, 0.0012636438636532562, 0.0012672234310726212, 0.0012679465686563742, 0.0012625865664714101, 0.0012616871152369474, 0.0012753050462131134, 0.001267221864757382, 0.0013734781347342175, 0.001370946725893935, 0.0013629634314301338, 0.0012501564316070553, 0.0012501677503513004, 0.0012630524552977558, 0.0012619825217618861, 0.0012549969780428166, 0.0012656729774210942, 0.0012695822938853366, 0.001255378682716665, 0.0012567704543471336, 0.0012569822508587756, 0.0012699590006377548, 0.001255534933244979, 0.0012596143404318188, 0.0012545061128383334, 0.0012590180902572517, 0.0012609501797917553, 0.0012611473159102554, 0.0012650942980227146, 0.0012585907957558943, 0.0012097049769837149, 0.001197463418573661, 0.0012038791617162007, 0.001199695999127661, 0.0012036087911922572, 0.0011952010465266054, 0.0012085656527169916, 0.0012004622799712558, 0.0011992816526312814, 0.0012068379518770894, 0.0012003779303022596, 0.001212703721965988, 0.0011980941378359879, 0.0012034506964778832, 0.0011996292092209292, 0.0011971434172199562, 0.001203521766678192, 0.0012071223951183087, 0.0012028895583826788, 0.001201149512103997, 0.0011992974661637185, 0.0011950796524192705, 0.001234185418958754, 0.0012097440465071866, 0.001203094768814396, 0.0012164073265265934, 0.0012031349077344287, 0.0012184756531834948, 0.0012071921170667508, 0.0012127663019698026, 0.001202412233904524, 0.0012048317666360458, 0.0012186165590402345, 0.0012019619773423603, 0.0012092342313249098, 0.0011970947204201028, 0.001214747977724602, 0.0012064250917065628, 0.001209941652040322, 0.0012119380015403378, 0.0012037157904096814, 0.0012080556047040709, 0.0012036804163958444, 0.0012160738588982197, 0.001203030488605416, 0.0012048426257489726, 0.001205698256705736, 0.0012015954883725837, 0.0012050555818605908, 0.0011992241380476328, 0.001207639769174505, 0.0011957341880905767, 0.0012017275114695346, 0.0011922935115953172, 0.0012025793034280109, 0.00119687597603039, 0.0011984712097707184, 0.0012004852543996518, 0.0012010138828394024, 0.0012051175121044696, 0.0012057374886691916, 0.0011973435351581767, 0.001205815002322197, 0.0012082208142897418, 0.0011921736525458305, 0.001326368255324142, 0.0012011060485789596, 0.0011957189295614182, 0.0012042361181662526, 0.0012130246275689365, 0.0015118562340259898, 0.0012490857896113464, 0.0011693132543113343, 0.001184982929898556, 0.0015140208117880446, 0.0012808163016817945, 0.0012822160009987825, 0.0012761285815517916, 0.001273885604838819, 0.001202029628181007, 0.0011952223721891642, 0.0012076430694135123, 0.0011951381172768253, 0.0012281737913009386, 0.0011707092554113546, 0.0011846315586766184, 0.0013199498373365334, 0.0011879488376380747, 0.0011956194648519158, 0.0012119022566218708, 0.0012226049533806914, 0.0011993692781732872, 0.0011900949297299565, 0.0016713572102923725, 0.0012849499769292253, 0.0012837667884521705, 0.0011682794645948465, 0.0011653310462269326, 0.001215455791003309, 0.0011959464186369333, 0.0012038186988468434, 0.0011820095336757773, 0.0011738104891941645, 0.0012499917688411335]
[800.6777664083465, 784.9672640820619, 779.6178979099255, 791.0206353271794, 804.8526169032573, 797.8309885572737, 794.4799251696624, 801.4895614297621, 788.1148137555891, 769.7628489119601, 729.4382175513015, 747.0064890229836, 756.1939330088384, 785.1777432083104, 360.4663362139772, 746.0494103033188, 738.5757572073752, 737.3702883104469, 800.7892008605528, 796.1894374243665, 762.1230256520957, 783.5610176967824, 786.2146975149465, 787.129755802463, 799.4891700989197, 792.7313882227081, 809.9804765444853, 806.252695649065, 809.4108732924959, 797.2186930704404, 780.0291398040573, 789.4829106113742, 805.7568684964419, 800.8215998239756, 783.8972955146563, 730.6507607061025, 786.7585824730544, 798.0891570607499, 794.5231494730486, 786.7761523576268, 762.3246011742906, 782.8844376053917, 792.2708930390976, 789.8761574597215, 588.5234023933652, 729.4188948881093, 770.5123652030378, 798.034021689229, 798.298796276176, 788.6063312087642, 786.462182794717, 765.5462164484982, 763.4818841666789, 788.0515045662028, 772.7677492226966, 720.6189367751365, 727.9154340559312, 733.3632066855789, 742.5045889445242, 741.8938364448783, 712.6531478651146, 736.5380348966489, 764.6054809553787, 786.6110365677914, 746.6582576718579, 743.1870148564326, 730.8362599726887, 809.5789392514207, 807.8197989005398, 778.5459216158916, 791.8119875591303, 779.973334325484, 790.8787103267235, 793.5821010187735, 785.6351191965508, 782.1641533305639, 788.6491738109817, 790.3412116895852, 787.7683505881816, 784.5661153353188, 792.1293740627384, 785.0573878142301, 787.0979339671451, 786.7608179712843, 783.3993122926227, 789.1965734542745, 784.7637266454111, 787.2338729661003, 785.1093176104433, 786.4856311116957, 786.5618608945017, 786.9817199886725, 791.3622095302636, 789.1268228473062, 788.6767666083016, 792.024900751741, 792.5895318445872, 784.1261218007384, 789.1277982261272, 728.0785727204245, 729.422946284031, 733.6953999937601, 799.8998962989908, 799.8926541810068, 791.732754887252, 792.4040014467668, 796.8146676811226, 790.0935058577112, 787.6606383188231, 796.5723918746013, 795.6902523774554, 795.5561817335096, 787.4269952792292, 796.4732589442661, 793.893787885252, 797.1264466280594, 794.2697628718525, 793.0527438959951, 792.9287779344257, 790.4549104070385, 794.5394193030088, 826.6478348244921, 835.0985796218591, 830.6481512433866, 833.544498545576, 830.8347424161229, 836.67932094447, 827.4271221856153, 833.0124291984787, 833.8324844759795, 828.6116611137575, 833.0709643655281, 824.6037196775804, 834.6589541003949, 830.9438873787531, 833.5909065180451, 835.3218049030677, 830.8948185956563, 828.416409176131, 831.3315158745995, 832.5358249934658, 833.8214898416937, 836.7643093710456, 810.2510243911896, 826.6211376590225, 831.1897166550411, 822.0930425135332, 831.1619865498349, 820.6975637037257, 828.3685635968295, 824.5611692671351, 831.6615315470948, 829.9913960536192, 820.6026683139659, 831.9730730676562, 826.9696425185879, 835.3557850869685, 823.2160236834837, 828.8952267939306, 826.4861353551239, 825.124716552356, 830.7608888803002, 827.7764666676607, 830.7853034564436, 822.3184740653946, 831.2341287037752, 829.9839154332416, 829.3949123989329, 832.2268264791669, 829.8372415785274, 833.8724749386927, 828.0615010580187, 836.3062710424485, 832.1353971310419, 838.7196527321332, 831.5459921432634, 835.5084570388344, 834.3963474861544, 832.9964873246927, 832.629842409339, 829.7945967557325, 829.3679257694224, 835.1821934445018, 829.3146113410168, 827.6632782459179, 838.8039761359826, 753.9384299842255, 832.565951343855, 836.3169431187256, 830.4019327395257, 824.3855708058735, 661.4385531467202, 800.5855228816192, 855.2028263708931, 843.8940129589952, 660.4929022204187, 780.752086530235, 779.8997978663889, 783.6200947587781, 784.9998431582301, 831.9262492000867, 836.6643925585197, 828.0592381370157, 836.7233757706131, 814.2170164213924, 854.1830479068245, 844.144318691902, 757.6045480772622, 841.7870941211899, 836.3865171129977, 825.1490535115101, 817.9256899253071, 833.7715649370818, 840.2691037654528, 598.316143216966, 778.2404124320863, 778.9576806280318, 855.9595801393248, 858.1252539677583, 822.7366288448393, 836.1578616036485, 830.6898712886879, 846.0168649319015, 851.9262770317486, 800.0052679763637]
Elapsed: 0.05497989319057928~0.005585969032542092
Time per graph: 0.0012623589947388287~0.0001221981912234764
Speed: 796.5990501992011~48.565539355649115
Total Time: 0.0547
best val loss: 0.42543908953666687 test_score: 0.8372

Testing...
Test loss: 0.5800 score: 0.7442 time: 0.05s
test Score 0.7442
Epoch Time List: [0.17074914497788996, 0.17188847495708615, 0.17724713205825537, 0.17562680481933057, 0.17239926510956138, 0.30416767892893404, 0.17425355897285044, 0.1725768499309197, 0.17567582800984383, 0.17698338301852345, 0.1795063988538459, 0.18597672402393073, 0.18416661594528705, 0.1785605939803645, 0.23948958318214864, 0.20238051493652165, 0.18506932200398296, 0.18592030892614275, 0.17424879979807884, 0.17320827406365424, 0.17653955100104213, 0.17583022196777165, 0.17450483702123165, 0.17405944899655879, 0.2966968599939719, 0.1724033768987283, 0.17087435408029705, 0.17062224098481238, 0.16976054199039936, 0.17438998213037848, 0.17417190806008875, 0.17777374107390642, 0.17230207100510597, 0.17197985504753888, 0.17314819304738194, 0.305553380982019, 0.17781592905521393, 0.17136436991859227, 0.17161975800991058, 0.17579474591184407, 0.17657386185601354, 0.1783624008530751, 0.17581264290492982, 0.17307613405864686, 0.18934279098175466, 0.23526909004431218, 0.18333219597116113, 0.17226528900209814, 0.17291788407601416, 0.17230440804269165, 0.17242133093532175, 0.17969768401235342, 0.1790964580141008, 0.17476260708644986, 0.17436100996565074, 0.2532826839014888, 0.18846102396491915, 0.187870503985323, 0.18652345694135875, 0.1839986388804391, 0.18725227192044258, 0.18846638104878366, 0.1780634589958936, 0.17453147587366402, 0.34109129197895527, 0.18275899707805365, 0.18300458183512092, 0.17748215200845152, 0.16918718093074858, 0.1707961279898882, 0.173312094877474, 0.17335709906183183, 0.17336680786684155, 0.17270396498497576, 0.17581690894439816, 0.1740230000577867, 0.1746521230088547, 0.17349295690655708, 0.17361892899498343, 0.17468503292184323, 0.1743669779971242, 0.1754961940459907, 0.17430437298025936, 0.17391993897035718, 0.1753379439469427, 0.17502808605786413, 0.17385010689031333, 0.17598688986618072, 0.17595619603525847, 0.17443441785871983, 0.17418186902068555, 0.1739344228990376, 0.1744676030939445, 0.1737085139611736, 0.17446400702465326, 0.17484624695498496, 0.17474283196497709, 0.17500709102023393, 0.1748696519061923, 0.19134803698398173, 0.18789653899148107, 0.1874838877702132, 0.1805434519192204, 0.17325648094993085, 0.17318998591508716, 0.17431304801721126, 0.17366994405165315, 0.1731930220266804, 0.17342997493688017, 0.17392638395540416, 0.1729989240411669, 0.17246173589956015, 0.17499328695703298, 0.17349632107652724, 0.1738227199530229, 0.17351664591114968, 0.17385404102969915, 0.17401228903327137, 0.17455006507225335, 0.17318361706566066, 0.17468336212914437, 0.18173997709527612, 0.17974156606942415, 0.17780271300580353, 0.17885872186161578, 0.17967770888935775, 0.1792446339968592, 0.18099055695347488, 0.1797225649934262, 0.17921398696489632, 0.17921255389228463, 0.17921228904742748, 0.17981254495680332, 0.18091813602950424, 0.1801506009651348, 0.17975974804721773, 0.1789372261846438, 0.1791248848894611, 0.18033279804512858, 0.1791879319353029, 0.18039256904739887, 0.18083419394679368, 0.18071628990583122, 0.1809812051942572, 0.1795883410377428, 0.1792729569133371, 0.17937527899630368, 0.17933366703800857, 0.1800296170404181, 0.18108655198011547, 0.1793005260406062, 0.18037330289371312, 0.17897353484295309, 0.17973684496246278, 0.17958450713194907, 0.17978764593135566, 0.17892958701122552, 0.18062038195785135, 0.18091574497520924, 0.18051523994654417, 0.18018250481691211, 0.17994801804888994, 0.18008573213592172, 0.18025049706920981, 0.17933275399263948, 0.18004028999712318, 0.17954816098790616, 0.18000054999720305, 0.17927149101160467, 0.17976548103615642, 0.1799681899137795, 0.1804124800255522, 0.1784194599604234, 0.1786441958975047, 0.1786508649820462, 0.1795260349754244, 0.1785371460719034, 0.17845937702804804, 0.17915462981909513, 0.18107550090644509, 0.18009794398676604, 0.1817480589961633, 0.17945237003732473, 0.18236620200332254, 0.18015788693446666, 0.18072813004255295, 0.19205495400819927, 0.18606265413109213, 0.18203904223628342, 0.1802150149596855, 0.1811761511489749, 0.2093903321074322, 0.2056016840506345, 0.17900539201218635, 0.17654333298560232, 0.1916441050125286, 0.2814819139894098, 0.18761688692029566, 0.1880177779821679, 0.18701515102293342, 0.17751447192858905, 0.18124234001152217, 0.1807954900432378, 0.17934988299384713, 0.17819276580121368, 0.26452892692759633, 0.17692847712896764, 0.1839015771402046, 0.1883985080057755, 0.1786430679494515, 0.17894263903144747, 0.1858966089785099, 0.18187360803131014, 0.17909230501390994, 0.1985074538970366, 0.24935813096817583, 0.18804462207481265, 0.1743887859629467, 0.17581961199175566, 0.18746520089916885, 0.1784023289801553, 0.18717266793828458, 0.17858492594677955, 0.18275556399021298, 0.18257043103221804]
Total Epoch List: [121, 104]
Total Time List: [0.05600782891269773, 0.054652777034789324]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7f80a8334f10>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6956;  Loss pred: 0.6956; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6971;  Loss pred: 0.6971; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6925;  Loss pred: 0.6925; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6914;  Loss pred: 0.6914; Loss self: 0.0000; time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6918;  Loss pred: 0.6918; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6893;  Loss pred: 0.6893; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6881;  Loss pred: 0.6881; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6878;  Loss pred: 0.6878; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6875;  Loss pred: 0.6875; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6827;  Loss pred: 0.6827; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6808;  Loss pred: 0.6808; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6768;  Loss pred: 0.6768; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6772;  Loss pred: 0.6772; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6687;  Loss pred: 0.6687; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.18s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6645;  Loss pred: 0.6645; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6643;  Loss pred: 0.6643; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 7 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6613;  Loss pred: 0.6613; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6550;  Loss pred: 0.6550; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6526;  Loss pred: 0.6526; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6465;  Loss pred: 0.6465; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6438;  Loss pred: 0.6438; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6433;  Loss pred: 0.6433; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6322;  Loss pred: 0.6322; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.09s
Epoch 24/1000, LR 0.000270
Train loss: 0.6222;  Loss pred: 0.6222; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6152;  Loss pred: 0.6152; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6184;  Loss pred: 0.6184; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6025;  Loss pred: 0.6025; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.06s
Epoch 28/1000, LR 0.000270
Train loss: 0.5996;  Loss pred: 0.5996; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.06s
Epoch 29/1000, LR 0.000270
Train loss: 0.5978;  Loss pred: 0.5978; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5823;  Loss pred: 0.5823; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5755;  Loss pred: 0.5755; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5641;  Loss pred: 0.5641; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5589;  Loss pred: 0.5589; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.08s
Epoch 34/1000, LR 0.000270
Train loss: 0.5514;  Loss pred: 0.5514; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5437;  Loss pred: 0.5437; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4884 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5241;  Loss pred: 0.5241; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4884 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5143;  Loss pred: 0.5143; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4884 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.5080;  Loss pred: 0.5080; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4884 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4961;  Loss pred: 0.4961; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.4884 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4809;  Loss pred: 0.4809; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.4884 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4777;  Loss pred: 0.4777; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.4884 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4609;  Loss pred: 0.4609; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.4884 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4563;  Loss pred: 0.4563; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.4884 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4299;  Loss pred: 0.4299; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6876 score: 0.5000 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6903 score: 0.4884 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4204;  Loss pred: 0.4204; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6869 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.4884 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.4062;  Loss pred: 0.4062; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6861 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.4884 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3905;  Loss pred: 0.3905; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6853 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.4884 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3868;  Loss pred: 0.3868; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6844 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.4884 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3783;  Loss pred: 0.3783; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6834 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.4884 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3640;  Loss pred: 0.3640; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.4884 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3569;  Loss pred: 0.3569; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6811 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.4884 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3365;  Loss pred: 0.3365; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6797 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6857 score: 0.4884 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.3210;  Loss pred: 0.3210; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6781 score: 0.5000 time: 0.05s
Test loss: 0.6848 score: 0.5116 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.3138;  Loss pred: 0.3138; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6763 score: 0.5000 time: 0.16s
Test loss: 0.6839 score: 0.5116 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.3067;  Loss pred: 0.3067; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6743 score: 0.5000 time: 0.05s
Test loss: 0.6829 score: 0.5116 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2940;  Loss pred: 0.2940; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6720 score: 0.5000 time: 0.05s
Test loss: 0.6817 score: 0.5116 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2721;  Loss pred: 0.2721; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6695 score: 0.5000 time: 0.05s
Test loss: 0.6803 score: 0.5116 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2561;  Loss pred: 0.2561; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6667 score: 0.5000 time: 0.05s
Test loss: 0.6787 score: 0.5116 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2507;  Loss pred: 0.2507; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6637 score: 0.5000 time: 0.05s
Test loss: 0.6769 score: 0.5116 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2392;  Loss pred: 0.2392; Loss self: 0.0000; time: 0.06s
Val loss: 0.6602 score: 0.5227 time: 0.05s
Test loss: 0.6748 score: 0.5116 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.2259;  Loss pred: 0.2259; Loss self: 0.0000; time: 0.07s
Val loss: 0.6567 score: 0.5227 time: 0.05s
Test loss: 0.6727 score: 0.5116 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.2091;  Loss pred: 0.2091; Loss self: 0.0000; time: 0.07s
Val loss: 0.6531 score: 0.5227 time: 0.05s
Test loss: 0.6706 score: 0.5116 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.2012;  Loss pred: 0.2012; Loss self: 0.0000; time: 0.06s
Val loss: 0.6492 score: 0.5227 time: 0.05s
Test loss: 0.6684 score: 0.5116 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1891;  Loss pred: 0.1891; Loss self: 0.0000; time: 0.06s
Val loss: 0.6451 score: 0.5227 time: 0.05s
Test loss: 0.6662 score: 0.5116 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1785;  Loss pred: 0.1785; Loss self: 0.0000; time: 0.08s
Val loss: 0.6407 score: 0.5227 time: 0.12s
Test loss: 0.6640 score: 0.5116 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1728;  Loss pred: 0.1728; Loss self: 0.0000; time: 0.07s
Val loss: 0.6358 score: 0.5227 time: 0.05s
Test loss: 0.6615 score: 0.5116 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1574;  Loss pred: 0.1574; Loss self: 0.0000; time: 0.07s
Val loss: 0.6305 score: 0.5227 time: 0.05s
Test loss: 0.6586 score: 0.5349 time: 0.06s
Epoch 68/1000, LR 0.000268
Train loss: 0.1436;  Loss pred: 0.1436; Loss self: 0.0000; time: 0.07s
Val loss: 0.6246 score: 0.5455 time: 0.05s
Test loss: 0.6552 score: 0.5349 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1362;  Loss pred: 0.1362; Loss self: 0.0000; time: 0.07s
Val loss: 0.6181 score: 0.5455 time: 0.05s
Test loss: 0.6516 score: 0.5349 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1239;  Loss pred: 0.1239; Loss self: 0.0000; time: 0.07s
Val loss: 0.6112 score: 0.5682 time: 0.05s
Test loss: 0.6476 score: 0.5349 time: 0.06s
Epoch 71/1000, LR 0.000268
Train loss: 0.1250;  Loss pred: 0.1250; Loss self: 0.0000; time: 0.07s
Val loss: 0.6033 score: 0.5682 time: 0.06s
Test loss: 0.6429 score: 0.5581 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.1093;  Loss pred: 0.1093; Loss self: 0.0000; time: 0.07s
Val loss: 0.5942 score: 0.5909 time: 0.06s
Test loss: 0.6371 score: 0.5581 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.1073;  Loss pred: 0.1073; Loss self: 0.0000; time: 0.06s
Val loss: 0.5851 score: 0.5909 time: 0.05s
Test loss: 0.6314 score: 0.5814 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0945;  Loss pred: 0.0945; Loss self: 0.0000; time: 0.06s
Val loss: 0.5750 score: 0.6364 time: 0.05s
Test loss: 0.6247 score: 0.5814 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0933;  Loss pred: 0.0933; Loss self: 0.0000; time: 0.06s
Val loss: 0.5648 score: 0.6591 time: 0.06s
Test loss: 0.6182 score: 0.6047 time: 0.11s
Epoch 76/1000, LR 0.000267
Train loss: 0.0819;  Loss pred: 0.0819; Loss self: 0.0000; time: 0.06s
Val loss: 0.5533 score: 0.6591 time: 0.05s
Test loss: 0.6107 score: 0.6512 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0767;  Loss pred: 0.0767; Loss self: 0.0000; time: 0.07s
Val loss: 0.5419 score: 0.6818 time: 0.05s
Test loss: 0.6035 score: 0.6512 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0709;  Loss pred: 0.0709; Loss self: 0.0000; time: 0.07s
Val loss: 0.5307 score: 0.7273 time: 0.05s
Test loss: 0.5963 score: 0.6744 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0642;  Loss pred: 0.0642; Loss self: 0.0000; time: 0.07s
Val loss: 0.5190 score: 0.7273 time: 0.05s
Test loss: 0.5888 score: 0.6512 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0629;  Loss pred: 0.0629; Loss self: 0.0000; time: 0.07s
Val loss: 0.5072 score: 0.7273 time: 0.05s
Test loss: 0.5814 score: 0.6744 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0559;  Loss pred: 0.0559; Loss self: 0.0000; time: 0.07s
Val loss: 0.4959 score: 0.7273 time: 0.06s
Test loss: 0.5743 score: 0.6977 time: 0.06s
Epoch 82/1000, LR 0.000267
Train loss: 0.0498;  Loss pred: 0.0498; Loss self: 0.0000; time: 0.07s
Val loss: 0.4849 score: 0.7500 time: 0.06s
Test loss: 0.5679 score: 0.7209 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0481;  Loss pred: 0.0481; Loss self: 0.0000; time: 0.07s
Val loss: 0.4729 score: 0.7500 time: 0.05s
Test loss: 0.5599 score: 0.7209 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0450;  Loss pred: 0.0450; Loss self: 0.0000; time: 0.06s
Val loss: 0.4614 score: 0.7500 time: 0.05s
Test loss: 0.5519 score: 0.7442 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0412;  Loss pred: 0.0412; Loss self: 0.0000; time: 0.07s
Val loss: 0.4513 score: 0.7727 time: 0.05s
Test loss: 0.5447 score: 0.7442 time: 0.08s
Epoch 86/1000, LR 0.000266
Train loss: 0.0361;  Loss pred: 0.0361; Loss self: 0.0000; time: 0.12s
Val loss: 0.4418 score: 0.7727 time: 0.05s
Test loss: 0.5378 score: 0.7674 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0396;  Loss pred: 0.0396; Loss self: 0.0000; time: 0.07s
Val loss: 0.4339 score: 0.7727 time: 0.05s
Test loss: 0.5320 score: 0.7907 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0323;  Loss pred: 0.0323; Loss self: 0.0000; time: 0.06s
Val loss: 0.4269 score: 0.8182 time: 0.05s
Test loss: 0.5263 score: 0.7907 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0288;  Loss pred: 0.0288; Loss self: 0.0000; time: 0.07s
Val loss: 0.4203 score: 0.8182 time: 0.05s
Test loss: 0.5205 score: 0.8372 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0295;  Loss pred: 0.0295; Loss self: 0.0000; time: 0.06s
Val loss: 0.4157 score: 0.8409 time: 0.05s
Test loss: 0.5172 score: 0.8372 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.07s
Val loss: 0.4123 score: 0.8182 time: 0.05s
Test loss: 0.5153 score: 0.8372 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0263;  Loss pred: 0.0263; Loss self: 0.0000; time: 0.07s
Val loss: 0.4102 score: 0.8182 time: 0.05s
Test loss: 0.5147 score: 0.8372 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0232;  Loss pred: 0.0232; Loss self: 0.0000; time: 0.07s
Val loss: 0.4092 score: 0.8182 time: 0.05s
Test loss: 0.5153 score: 0.8605 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.07s
Val loss: 0.4084 score: 0.8182 time: 0.05s
Test loss: 0.5168 score: 0.8605 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0192;  Loss pred: 0.0192; Loss self: 0.0000; time: 0.06s
Val loss: 0.4087 score: 0.8182 time: 0.05s
Test loss: 0.5199 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0188;  Loss pred: 0.0188; Loss self: 0.0000; time: 0.19s
Val loss: 0.4095 score: 0.8182 time: 0.05s
Test loss: 0.5245 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.07s
Val loss: 0.4116 score: 0.8182 time: 0.05s
Test loss: 0.5304 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 3 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.07s
Val loss: 0.4154 score: 0.8182 time: 0.05s
Test loss: 0.5380 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0140;  Loss pred: 0.0140; Loss self: 0.0000; time: 0.07s
Val loss: 0.4202 score: 0.8409 time: 0.05s
Test loss: 0.5470 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 5 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0132;  Loss pred: 0.0132; Loss self: 0.0000; time: 0.07s
Val loss: 0.4259 score: 0.8409 time: 0.05s
Test loss: 0.5564 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.07s
Val loss: 0.4319 score: 0.8409 time: 0.06s
Test loss: 0.5673 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 7 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0145;  Loss pred: 0.0145; Loss self: 0.0000; time: 0.07s
Val loss: 0.4391 score: 0.8409 time: 0.05s
Test loss: 0.5801 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.06s
Val loss: 0.4468 score: 0.8182 time: 0.05s
Test loss: 0.5933 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.07s
Val loss: 0.4546 score: 0.7955 time: 0.05s
Test loss: 0.6065 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.08s
Val loss: 0.4631 score: 0.7955 time: 0.12s
Test loss: 0.6204 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.06s
Val loss: 0.4709 score: 0.7955 time: 0.05s
Test loss: 0.6329 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.06s
Val loss: 0.4792 score: 0.7955 time: 0.05s
Test loss: 0.6457 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.06s
Val loss: 0.4869 score: 0.7955 time: 0.05s
Test loss: 0.6578 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0096;  Loss pred: 0.0096; Loss self: 0.0000; time: 0.06s
Val loss: 0.4942 score: 0.7955 time: 0.05s
Test loss: 0.6690 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.06s
Val loss: 0.5016 score: 0.7955 time: 0.05s
Test loss: 0.6798 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.06s
Val loss: 0.5087 score: 0.7955 time: 0.05s
Test loss: 0.6902 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.07s
Val loss: 0.5151 score: 0.7955 time: 0.05s
Test loss: 0.6993 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.5213 score: 0.7955 time: 0.05s
Test loss: 0.7089 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.07s
Val loss: 0.5277 score: 0.7955 time: 0.05s
Test loss: 0.7181 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 093,   Train_Loss: 0.0230,   Val_Loss: 0.4084,   Val_Precision: 0.7917,   Val_Recall: 0.8636,   Val_accuracy: 0.8261,   Val_Score: 0.8182,   Val_Loss: 0.4084,   Test_Precision: 0.8261,   Test_Recall: 0.9048,   Test_accuracy: 0.8636,   Test_Score: 0.8605,   Test_loss: 0.5168


[0.05495344300288707, 0.05605329293757677, 0.05643790389876813, 0.05562433903105557, 0.054668394033797085, 0.05514952493831515, 0.05538214195985347, 0.05489778297487646, 0.05582942895125598, 0.05716046190354973, 0.06032039306592196, 0.05890176410321146, 0.05818613199517131, 0.056038266979157925, 0.12206410302314907, 0.05897732696030289, 0.059574118931777775, 0.05967151199001819, 0.0549457959132269, 0.055263229995034635, 0.05773346102796495, 0.0561538910260424, 0.0559643569868058, 0.055899297003634274, 0.05503514199517667, 0.05550429900176823, 0.05432229698635638, 0.0545734609477222, 0.05436052498407662, 0.05519188195466995, 0.05640814907383174, 0.0557326819980517, 0.05460704304277897, 0.05494357296265662, 0.05612980201840401, 0.060220289044082165, 0.055925668915733695, 0.055131684988737106, 0.05537912901490927, 0.055924420012161136, 0.057718195021152496, 0.0562024200335145, 0.05553656001575291, 0.05570493498817086, 0.07476338208653033, 0.06032199098262936, 0.05710485903546214, 0.05513549398165196, 0.0551172069972381, 0.05579463194590062, 0.05594674602616578, 0.057475302019156516, 0.05763070599641651, 0.055833914084360003, 0.056938193971291184, 0.06105862301774323, 0.06044658203609288, 0.0599975559161976, 0.059258893015794456, 0.059307676972821355, 0.06174111505970359, 0.05973893799819052, 0.0575460169930011, 0.0559361589839682, 0.05892923509236425, 0.05920447898097336, 0.060205004061572254, 0.05434923991560936, 0.054467592970468104, 0.056515612988732755, 0.05556874698959291, 0.05641218496020883, 0.0556343209464103, 0.05544479889795184, 0.05600564298219979, 0.05625417607370764, 0.05579160095658153, 0.05567215697374195, 0.05585398292168975, 0.0560819529928267, 0.0555464819772169, 0.05604685808066279, 0.0559015569742769, 0.0559255100088194, 0.05616548203397542, 0.055752902990207076, 0.05606783099938184, 0.05589190393220633, 0.05604315095115453, 0.05594507802743465, 0.05593965610023588, 0.05590981198474765, 0.05560033000074327, 0.05575783096719533, 0.05578964902088046, 0.05555380892474204, 0.05551423307042569, 0.05611342203337699, 0.05575776204932481, 0.060433037928305566, 0.06032165593933314, 0.05997039098292589, 0.05500688299071044, 0.05500738101545721, 0.05557430803310126, 0.05552723095752299, 0.05521986703388393, 0.05568961100652814, 0.055861620930954814, 0.05523666203953326, 0.05529789999127388, 0.055307219037786126, 0.05587819602806121, 0.05524353706277907, 0.05542303097900003, 0.055198268964886665, 0.05539679597131908, 0.05548180791083723, 0.055490481900051236, 0.05566414911299944, 0.05537799501325935, 0.05201731401029974, 0.05149092699866742, 0.051766803953796625, 0.051586927962489426, 0.051755178021267056, 0.05139364500064403, 0.051968323066830635, 0.051619878038764, 0.0515691110631451, 0.051894031930714846, 0.05161625100299716, 0.052146260044537485, 0.051518047926947474, 0.05174837994854897, 0.051584055996499956, 0.05147716694045812, 0.05175143596716225, 0.05190626299008727, 0.05172425101045519, 0.05164942902047187, 0.05156979104503989, 0.05138842505402863, 0.053069973015226424, 0.05201899399980903, 0.05173307505901903, 0.05230551504064351, 0.051734801032580435, 0.05239445308689028, 0.05190926103387028, 0.052148950984701514, 0.05170372605789453, 0.05180776596534997, 0.052400512038730085, 0.05168436502572149, 0.05199707194697112, 0.05147507297806442, 0.05223416304215789, 0.051876278943382204, 0.05202749103773385, 0.05211333406623453, 0.0517597789876163, 0.05194639100227505, 0.05175825790502131, 0.052291175932623446, 0.05173031101003289, 0.05180823290720582, 0.05184502503834665, 0.0516686060000211, 0.051817390020005405, 0.05156663793604821, 0.05192851007450372, 0.0514165700878948, 0.05167428299318999, 0.051268620998598635, 0.05171091004740447, 0.05146566696930677, 0.051534262020140886, 0.05162086593918502, 0.05164359696209431, 0.051820053020492196, 0.05184671201277524, 0.0514857720118016, 0.05185004509985447, 0.051953495014458895, 0.05126346705947071, 0.0570338349789381, 0.05164756008889526, 0.05141591397114098, 0.05178215308114886, 0.052160058985464275, 0.06500981806311756, 0.0537106889532879, 0.05028046993538737, 0.0509542659856379, 0.06510289490688592, 0.05507510097231716, 0.05513528804294765, 0.05487352900672704, 0.05477708100806922, 0.0516872740117833, 0.05139456200413406, 0.05192865198478103, 0.05139093904290348, 0.05281147302594036, 0.05034049798268825, 0.050939157023094594, 0.05675784300547093, 0.05108180001843721, 0.05141163698863238, 0.05211179703474045, 0.05257201299536973, 0.05157287896145135, 0.05117408197838813, 0.07186836004257202, 0.055252849007956684, 0.055201971903443336, 0.0502360169775784, 0.0501092349877581, 0.05226459901314229, 0.05142569600138813, 0.051764204050414264, 0.050826409948058426, 0.05047385103534907, 0.05374964606016874, 0.0574213300133124, 0.05629995989147574, 0.059457515948452055, 0.056255670031532645, 0.05614345194771886, 0.05614277103450149, 0.05625264602713287, 0.056973741040565073, 0.05638718500267714, 0.05796541494783014, 0.05758970498573035, 0.05673552502412349, 0.05614647502079606, 0.061712577007710934, 0.06103881599847227, 0.0614395720185712, 0.0563384098932147, 0.05624982505105436, 0.058076572022400796, 0.056302708107978106, 0.0558416600106284, 0.05604786495678127, 0.1009865190135315, 0.056153424084186554, 0.05617655499372631, 0.05654044903349131, 0.06302059895824641, 0.06084060703869909, 0.05794364004395902, 0.05730300792492926, 0.05643575789872557, 0.056681705988012254, 0.08371847798116505, 0.05755785503424704, 0.056599076022394, 0.056149452924728394, 0.056445610942319036, 0.056344961980357766, 0.05602608097251505, 0.05934943107422441, 0.05606452305801213, 0.05583445494994521, 0.05604186898563057, 0.0558691379847005, 0.0560033229412511, 0.05565723602194339, 0.0561193919274956, 0.05655195692088455, 0.05627243593335152, 0.059212949010543525, 0.05753911903593689, 0.05646456696558744, 0.05694017303176224, 0.05665380007121712, 0.056477756006643176, 0.05675931402947754, 0.0565856050234288, 0.055919672944583, 0.056892815977334976, 0.05743273696862161, 0.056476016994565725, 0.05516810098197311, 0.05458175600506365, 0.05516507802531123, 0.059424553997814655, 0.059948323061689734, 0.06000344699714333, 0.059728319058194757, 0.05980514897964895, 0.06020202301442623, 0.06214230589102954, 0.05698623799253255, 0.05663489201106131, 0.056518509052693844, 0.11795594508294016, 0.05863277695607394, 0.05851670901756734, 0.05947532202117145, 0.05957341904286295, 0.059738655923865736, 0.06165478308685124, 0.05636523896828294, 0.05527744092978537, 0.055515174055472016, 0.09183638298418373, 0.055720475036650896, 0.055760083021596074, 0.05615119799040258, 0.05518505093641579, 0.0556939149973914, 0.05684349499642849, 0.05649764696136117, 0.056141522945836186, 0.055658094002865255, 0.057288348907604814, 0.0591814509825781, 0.060014958027750254, 0.05949062597937882, 0.060441868961788714, 0.060386315919458866, 0.06167986197397113, 0.05556907202117145, 0.057176728034392, 0.05648938589729369, 0.056937775923870504, 0.05601771408692002, 0.05580468405969441, 0.056095930049195886, 0.05605559004470706, 0.056321894051507115, 0.05780375306494534, 0.05736820597667247, 0.056552806054241955, 0.056295668007805943]
[0.0012489418864292516, 0.0012739384758540175, 0.0012826796340629119, 0.0012641895234330811, 0.0012424635007681156, 0.001253398294052617, 0.0012586850445421244, 0.001247676885792647, 0.0012688506579830903, 0.0012991014068988575, 0.001370918024225499, 0.0013386764568911697, 0.0013224120907993479, 0.0012735969767990437, 0.0027741841596170243, 0.0013403937945523385, 0.001353957248449495, 0.001356170727045868, 0.0012487680889369751, 0.0012559824998871509, 0.0013121241142719307, 0.0012762247960464183, 0.0012719172042455864, 0.0012704385682644154, 0.0012507986817085607, 0.0012614613409492779, 0.0012345976587808268, 0.00124030593063005, 0.0012354664769108322, 0.0012543609535152261, 0.0012820033880416304, 0.001266651863592084, 0.0012410691600631583, 0.0012487175673331049, 0.001275677318600091, 0.0013686429328200493, 0.0012710379299030385, 0.001252992840653116, 0.0012586165685206652, 0.0012710095457309349, 0.0013117771595716476, 0.0012773277280344205, 0.0012621945458125663, 0.0012660212497311559, 0.001699167774693871, 0.0013709543405143036, 0.0012978377053514123, 0.0012530794086739081, 0.001252663795391775, 0.0012680598169522868, 0.0012715169551401314, 0.001306256864071739, 0.0013097887726458298, 0.0012689525928263638, 0.0012940498629838905, 0.0013876959776759825, 0.0013737859553657472, 0.0013635808162772182, 0.0013467930230862376, 0.0013479017493823035, 0.0014032071604478088, 0.001357703136322512, 0.0013078640225682068, 0.0012712763405447317, 0.001339300797553733, 0.0013455563404766674, 0.0013682955468539149, 0.001235209998082031, 0.0012378998402379114, 0.0012844457497439262, 0.0012629260679452934, 0.0012820951127320188, 0.0012644163851456885, 0.001260109065862542, 0.0012728555223227224, 0.0012785040016751736, 0.0012679909308313984, 0.0012652762948577715, 0.001269408702765676, 0.0012745898407460613, 0.0012624200449367477, 0.0012737922291059724, 0.0012704899312335658, 0.001271034318382259, 0.001276488228044896, 0.0012671114315956154, 0.0012742688863495873, 0.0012702705439137803, 0.001273707976162603, 0.0012714790460780603, 0.0012713558204599064, 0.001270677545107901, 0.0012636438636532562, 0.0012672234310726212, 0.0012679465686563742, 0.0012625865664714101, 0.0012616871152369474, 0.0012753050462131134, 0.001267221864757382, 0.0013734781347342175, 0.001370946725893935, 0.0013629634314301338, 0.0012501564316070553, 0.0012501677503513004, 0.0012630524552977558, 0.0012619825217618861, 0.0012549969780428166, 0.0012656729774210942, 0.0012695822938853366, 0.001255378682716665, 0.0012567704543471336, 0.0012569822508587756, 0.0012699590006377548, 0.001255534933244979, 0.0012596143404318188, 0.0012545061128383334, 0.0012590180902572517, 0.0012609501797917553, 0.0012611473159102554, 0.0012650942980227146, 0.0012585907957558943, 0.0012097049769837149, 0.001197463418573661, 0.0012038791617162007, 0.001199695999127661, 0.0012036087911922572, 0.0011952010465266054, 0.0012085656527169916, 0.0012004622799712558, 0.0011992816526312814, 0.0012068379518770894, 0.0012003779303022596, 0.001212703721965988, 0.0011980941378359879, 0.0012034506964778832, 0.0011996292092209292, 0.0011971434172199562, 0.001203521766678192, 0.0012071223951183087, 0.0012028895583826788, 0.001201149512103997, 0.0011992974661637185, 0.0011950796524192705, 0.001234185418958754, 0.0012097440465071866, 0.001203094768814396, 0.0012164073265265934, 0.0012031349077344287, 0.0012184756531834948, 0.0012071921170667508, 0.0012127663019698026, 0.001202412233904524, 0.0012048317666360458, 0.0012186165590402345, 0.0012019619773423603, 0.0012092342313249098, 0.0011970947204201028, 0.001214747977724602, 0.0012064250917065628, 0.001209941652040322, 0.0012119380015403378, 0.0012037157904096814, 0.0012080556047040709, 0.0012036804163958444, 0.0012160738588982197, 0.001203030488605416, 0.0012048426257489726, 0.001205698256705736, 0.0012015954883725837, 0.0012050555818605908, 0.0011992241380476328, 0.001207639769174505, 0.0011957341880905767, 0.0012017275114695346, 0.0011922935115953172, 0.0012025793034280109, 0.00119687597603039, 0.0011984712097707184, 0.0012004852543996518, 0.0012010138828394024, 0.0012051175121044696, 0.0012057374886691916, 0.0011973435351581767, 0.001205815002322197, 0.0012082208142897418, 0.0011921736525458305, 0.001326368255324142, 0.0012011060485789596, 0.0011957189295614182, 0.0012042361181662526, 0.0012130246275689365, 0.0015118562340259898, 0.0012490857896113464, 0.0011693132543113343, 0.001184982929898556, 0.0015140208117880446, 0.0012808163016817945, 0.0012822160009987825, 0.0012761285815517916, 0.001273885604838819, 0.001202029628181007, 0.0011952223721891642, 0.0012076430694135123, 0.0011951381172768253, 0.0012281737913009386, 0.0011707092554113546, 0.0011846315586766184, 0.0013199498373365334, 0.0011879488376380747, 0.0011956194648519158, 0.0012119022566218708, 0.0012226049533806914, 0.0011993692781732872, 0.0011900949297299565, 0.0016713572102923725, 0.0012849499769292253, 0.0012837667884521705, 0.0011682794645948465, 0.0011653310462269326, 0.001215455791003309, 0.0011959464186369333, 0.0012038186988468434, 0.0011820095336757773, 0.0011738104891941645, 0.0012499917688411335, 0.0013353797677514512, 0.0013093013928250172, 0.0013827329290337688, 0.0013082713960821544, 0.0013056616732027642, 0.0013056458380116627, 0.0013082010703984388, 0.0013249707218736064, 0.0013113298837831894, 0.0013480329057634916, 0.0013392954647844268, 0.0013194308145144998, 0.0013057319772278155, 0.0014351762094816497, 0.0014195073488016809, 0.0014288272562458417, 0.00131019557891197, 0.0013081354663035897, 0.001350617954009321, 0.0013093653048367002, 0.0012986432560611256, 0.0013034387199251458, 0.002348523697989105, 0.0013058935833531757, 0.0013064315114820072, 0.0013148941635695655, 0.0014655953246103816, 0.0014148978381092812, 0.0013475265126502098, 0.0013326280912774246, 0.0013124594860168736, 0.0013181792090235407, 0.0019469413483991873, 0.0013385547682383033, 0.0013162575819161396, 0.001305801230807637, 0.001312688626565559, 0.0013103479530315759, 0.0013029321156398847, 0.0013802193273075444, 0.001303826117628189, 0.0012984756965103538, 0.0013032992787355947, 0.0012992822787139652, 0.0013024028590988628, 0.0012943543260917068, 0.0013051021378487349, 0.0013151617888577801, 0.0013086613007756167, 0.0013770453258265937, 0.0013381190473473695, 0.0013131294643159868, 0.0013241900705060986, 0.0013175302342143516, 0.0013134361862010041, 0.001319984047197152, 0.0013159443028704372, 0.0013004575103391395, 0.001323088743658953, 0.001335645045781898, 0.001313395744059668, 0.0012829790926040259, 0.001269343162908457, 0.0012829087912863077, 0.0013819663720422012, 0.001394147047946273, 0.0013954289999335658, 0.001389030675771971, 0.0013908174181313708, 0.0014000470468471216, 0.0014451699044425474, 0.0013252613486635478, 0.0013170905118851468, 0.0013143839314579964, 0.002743161513556748, 0.0013635529524668357, 0.0013608536980829614, 0.0013831470237481733, 0.0013854283498340222, 0.0013892710679968775, 0.001433832164810494, 0.001310819510890301, 0.001285521882088032, 0.0012910505594295818, 0.0021357298368414822, 0.0012958250008523464, 0.0012967461167813041, 0.0013058418137302926, 0.001283373277591065, 0.0012952073255207302, 0.001321941744102988, 0.001313898766543283, 0.0013056168126938648, 0.0012943742791364013, 0.0013322871838977865, 0.0013763128135483279, 0.0013956966983197734, 0.0013835029297529957, 0.0014056248595764817, 0.0014043329283595085, 0.0014344153947435147, 0.0012923040004923594, 0.0013296913496370231, 0.0013137066487742717, 0.0013241343238109419, 0.0013027375369051167, 0.0012977833502254513, 0.0013045565127719973, 0.0013036183731327223, 0.001309811489569933, 0.0013442733270917521, 0.0013341443250388947, 0.0013151815361451618, 0.0013092015815768824]
[800.6777664083465, 784.9672640820619, 779.6178979099255, 791.0206353271794, 804.8526169032573, 797.8309885572737, 794.4799251696624, 801.4895614297621, 788.1148137555891, 769.7628489119601, 729.4382175513015, 747.0064890229836, 756.1939330088384, 785.1777432083104, 360.4663362139772, 746.0494103033188, 738.5757572073752, 737.3702883104469, 800.7892008605528, 796.1894374243665, 762.1230256520957, 783.5610176967824, 786.2146975149465, 787.129755802463, 799.4891700989197, 792.7313882227081, 809.9804765444853, 806.252695649065, 809.4108732924959, 797.2186930704404, 780.0291398040573, 789.4829106113742, 805.7568684964419, 800.8215998239756, 783.8972955146563, 730.6507607061025, 786.7585824730544, 798.0891570607499, 794.5231494730486, 786.7761523576268, 762.3246011742906, 782.8844376053917, 792.2708930390976, 789.8761574597215, 588.5234023933652, 729.4188948881093, 770.5123652030378, 798.034021689229, 798.298796276176, 788.6063312087642, 786.462182794717, 765.5462164484982, 763.4818841666789, 788.0515045662028, 772.7677492226966, 720.6189367751365, 727.9154340559312, 733.3632066855789, 742.5045889445242, 741.8938364448783, 712.6531478651146, 736.5380348966489, 764.6054809553787, 786.6110365677914, 746.6582576718579, 743.1870148564326, 730.8362599726887, 809.5789392514207, 807.8197989005398, 778.5459216158916, 791.8119875591303, 779.973334325484, 790.8787103267235, 793.5821010187735, 785.6351191965508, 782.1641533305639, 788.6491738109817, 790.3412116895852, 787.7683505881816, 784.5661153353188, 792.1293740627384, 785.0573878142301, 787.0979339671451, 786.7608179712843, 783.3993122926227, 789.1965734542745, 784.7637266454111, 787.2338729661003, 785.1093176104433, 786.4856311116957, 786.5618608945017, 786.9817199886725, 791.3622095302636, 789.1268228473062, 788.6767666083016, 792.024900751741, 792.5895318445872, 784.1261218007384, 789.1277982261272, 728.0785727204245, 729.422946284031, 733.6953999937601, 799.8998962989908, 799.8926541810068, 791.732754887252, 792.4040014467668, 796.8146676811226, 790.0935058577112, 787.6606383188231, 796.5723918746013, 795.6902523774554, 795.5561817335096, 787.4269952792292, 796.4732589442661, 793.893787885252, 797.1264466280594, 794.2697628718525, 793.0527438959951, 792.9287779344257, 790.4549104070385, 794.5394193030088, 826.6478348244921, 835.0985796218591, 830.6481512433866, 833.544498545576, 830.8347424161229, 836.67932094447, 827.4271221856153, 833.0124291984787, 833.8324844759795, 828.6116611137575, 833.0709643655281, 824.6037196775804, 834.6589541003949, 830.9438873787531, 833.5909065180451, 835.3218049030677, 830.8948185956563, 828.416409176131, 831.3315158745995, 832.5358249934658, 833.8214898416937, 836.7643093710456, 810.2510243911896, 826.6211376590225, 831.1897166550411, 822.0930425135332, 831.1619865498349, 820.6975637037257, 828.3685635968295, 824.5611692671351, 831.6615315470948, 829.9913960536192, 820.6026683139659, 831.9730730676562, 826.9696425185879, 835.3557850869685, 823.2160236834837, 828.8952267939306, 826.4861353551239, 825.124716552356, 830.7608888803002, 827.7764666676607, 830.7853034564436, 822.3184740653946, 831.2341287037752, 829.9839154332416, 829.3949123989329, 832.2268264791669, 829.8372415785274, 833.8724749386927, 828.0615010580187, 836.3062710424485, 832.1353971310419, 838.7196527321332, 831.5459921432634, 835.5084570388344, 834.3963474861544, 832.9964873246927, 832.629842409339, 829.7945967557325, 829.3679257694224, 835.1821934445018, 829.3146113410168, 827.6632782459179, 838.8039761359826, 753.9384299842255, 832.565951343855, 836.3169431187256, 830.4019327395257, 824.3855708058735, 661.4385531467202, 800.5855228816192, 855.2028263708931, 843.8940129589952, 660.4929022204187, 780.752086530235, 779.8997978663889, 783.6200947587781, 784.9998431582301, 831.9262492000867, 836.6643925585197, 828.0592381370157, 836.7233757706131, 814.2170164213924, 854.1830479068245, 844.144318691902, 757.6045480772622, 841.7870941211899, 836.3865171129977, 825.1490535115101, 817.9256899253071, 833.7715649370818, 840.2691037654528, 598.316143216966, 778.2404124320863, 778.9576806280318, 855.9595801393248, 858.1252539677583, 822.7366288448393, 836.1578616036485, 830.6898712886879, 846.0168649319015, 851.9262770317486, 800.0052679763637, 748.8506446999921, 763.7660858531187, 723.2054571078912, 764.3673957824602, 765.8951936201194, 765.904482583789, 764.4084863005272, 754.7336582546716, 762.5846191463264, 741.8216541484389, 746.6612306948715, 757.9025660151509, 765.8539558195462, 696.7785512283369, 704.4697590640723, 699.8746668841133, 763.2448285548585, 764.4468220296092, 740.4018264613553, 763.7288053273389, 770.0344150194634, 767.2013917596588, 425.79940788174207, 765.7591803401583, 765.4438760938999, 760.5174832362804, 682.3165871287445, 706.7648087838579, 742.1004266797528, 750.3969085939232, 761.9282809520137, 758.6221912426943, 513.6261556221092, 747.0743997394433, 759.729716841784, 765.8133385136272, 761.7952801315427, 763.156074450633, 767.4996939567252, 724.5225307420848, 766.9734380065312, 770.133782778911, 767.283475342791, 769.6556909787179, 767.8115822717892, 772.5859757578843, 766.2235552294397, 760.3627237896726, 764.1396589074045, 726.1925088774648, 747.3176635385003, 761.539533743463, 755.1785972974448, 758.9958651660877, 761.3616942383854, 757.5849133354266, 759.9105811839638, 768.9601482936688, 755.8072009852771, 748.7019123517143, 761.3851381222153, 779.4359282740365, 787.80902534559, 779.4786400967372, 723.6066088368342, 717.2844510721495, 716.6254965660083, 719.9265051826429, 719.0016367091141, 714.2617115988926, 691.9601611726996, 754.568146885476, 759.2492626559914, 760.8127093358011, 364.54288056244013, 733.3781927506933, 734.8328489746568, 722.9889395923451, 721.7984243788591, 719.8019328523493, 697.4316970579102, 762.8815345606246, 777.8941875152931, 774.5630042884028, 468.2240153927399, 771.7091423164675, 771.1609751970052, 765.7895385838358, 779.1965264206169, 772.0771650190876, 756.4629867094153, 761.0936439425127, 765.9215094945897, 772.5740661867864, 750.5889211321277, 726.5790088968652, 716.4880458654536, 722.8029507523597, 711.4273720950713, 712.0818573756326, 697.1481229667145, 773.8117344053773, 752.0542269249012, 761.2049470351926, 755.2103906814658, 767.6143288046161, 770.5446366115574, 766.5440248925223, 767.0956628180242, 763.4686425970677, 743.8963340613437, 749.5440944673259, 760.351307037834, 763.8243140491313]
Elapsed: 0.05626198257406168~0.00680800883044557
Time per graph: 0.0012976373327038993~0.00015645788263064873
Speed: 777.5000566115131~59.75669253559034
Total Time: 0.0574
best val loss: 0.4083787202835083 test_score: 0.8605

Testing...
Test loss: 0.5172 score: 0.8372 time: 0.05s
test Score 0.8372
Epoch Time List: [0.17074914497788996, 0.17188847495708615, 0.17724713205825537, 0.17562680481933057, 0.17239926510956138, 0.30416767892893404, 0.17425355897285044, 0.1725768499309197, 0.17567582800984383, 0.17698338301852345, 0.1795063988538459, 0.18597672402393073, 0.18416661594528705, 0.1785605939803645, 0.23948958318214864, 0.20238051493652165, 0.18506932200398296, 0.18592030892614275, 0.17424879979807884, 0.17320827406365424, 0.17653955100104213, 0.17583022196777165, 0.17450483702123165, 0.17405944899655879, 0.2966968599939719, 0.1724033768987283, 0.17087435408029705, 0.17062224098481238, 0.16976054199039936, 0.17438998213037848, 0.17417190806008875, 0.17777374107390642, 0.17230207100510597, 0.17197985504753888, 0.17314819304738194, 0.305553380982019, 0.17781592905521393, 0.17136436991859227, 0.17161975800991058, 0.17579474591184407, 0.17657386185601354, 0.1783624008530751, 0.17581264290492982, 0.17307613405864686, 0.18934279098175466, 0.23526909004431218, 0.18333219597116113, 0.17226528900209814, 0.17291788407601416, 0.17230440804269165, 0.17242133093532175, 0.17969768401235342, 0.1790964580141008, 0.17476260708644986, 0.17436100996565074, 0.2532826839014888, 0.18846102396491915, 0.187870503985323, 0.18652345694135875, 0.1839986388804391, 0.18725227192044258, 0.18846638104878366, 0.1780634589958936, 0.17453147587366402, 0.34109129197895527, 0.18275899707805365, 0.18300458183512092, 0.17748215200845152, 0.16918718093074858, 0.1707961279898882, 0.173312094877474, 0.17335709906183183, 0.17336680786684155, 0.17270396498497576, 0.17581690894439816, 0.1740230000577867, 0.1746521230088547, 0.17349295690655708, 0.17361892899498343, 0.17468503292184323, 0.1743669779971242, 0.1754961940459907, 0.17430437298025936, 0.17391993897035718, 0.1753379439469427, 0.17502808605786413, 0.17385010689031333, 0.17598688986618072, 0.17595619603525847, 0.17443441785871983, 0.17418186902068555, 0.1739344228990376, 0.1744676030939445, 0.1737085139611736, 0.17446400702465326, 0.17484624695498496, 0.17474283196497709, 0.17500709102023393, 0.1748696519061923, 0.19134803698398173, 0.18789653899148107, 0.1874838877702132, 0.1805434519192204, 0.17325648094993085, 0.17318998591508716, 0.17431304801721126, 0.17366994405165315, 0.1731930220266804, 0.17342997493688017, 0.17392638395540416, 0.1729989240411669, 0.17246173589956015, 0.17499328695703298, 0.17349632107652724, 0.1738227199530229, 0.17351664591114968, 0.17385404102969915, 0.17401228903327137, 0.17455006507225335, 0.17318361706566066, 0.17468336212914437, 0.18173997709527612, 0.17974156606942415, 0.17780271300580353, 0.17885872186161578, 0.17967770888935775, 0.1792446339968592, 0.18099055695347488, 0.1797225649934262, 0.17921398696489632, 0.17921255389228463, 0.17921228904742748, 0.17981254495680332, 0.18091813602950424, 0.1801506009651348, 0.17975974804721773, 0.1789372261846438, 0.1791248848894611, 0.18033279804512858, 0.1791879319353029, 0.18039256904739887, 0.18083419394679368, 0.18071628990583122, 0.1809812051942572, 0.1795883410377428, 0.1792729569133371, 0.17937527899630368, 0.17933366703800857, 0.1800296170404181, 0.18108655198011547, 0.1793005260406062, 0.18037330289371312, 0.17897353484295309, 0.17973684496246278, 0.17958450713194907, 0.17978764593135566, 0.17892958701122552, 0.18062038195785135, 0.18091574497520924, 0.18051523994654417, 0.18018250481691211, 0.17994801804888994, 0.18008573213592172, 0.18025049706920981, 0.17933275399263948, 0.18004028999712318, 0.17954816098790616, 0.18000054999720305, 0.17927149101160467, 0.17976548103615642, 0.1799681899137795, 0.1804124800255522, 0.1784194599604234, 0.1786441958975047, 0.1786508649820462, 0.1795260349754244, 0.1785371460719034, 0.17845937702804804, 0.17915462981909513, 0.18107550090644509, 0.18009794398676604, 0.1817480589961633, 0.17945237003732473, 0.18236620200332254, 0.18015788693446666, 0.18072813004255295, 0.19205495400819927, 0.18606265413109213, 0.18203904223628342, 0.1802150149596855, 0.1811761511489749, 0.2093903321074322, 0.2056016840506345, 0.17900539201218635, 0.17654333298560232, 0.1916441050125286, 0.2814819139894098, 0.18761688692029566, 0.1880177779821679, 0.18701515102293342, 0.17751447192858905, 0.18124234001152217, 0.1807954900432378, 0.17934988299384713, 0.17819276580121368, 0.26452892692759633, 0.17692847712896764, 0.1839015771402046, 0.1883985080057755, 0.1786430679494515, 0.17894263903144747, 0.1858966089785099, 0.18187360803131014, 0.17909230501390994, 0.1985074538970366, 0.24935813096817583, 0.18804462207481265, 0.1743887859629467, 0.17581961199175566, 0.18746520089916885, 0.1784023289801553, 0.18717266793828458, 0.17858492594677955, 0.18275556399021298, 0.18257043103221804, 0.17462500603869557, 0.16975217103026807, 0.16897732089273632, 0.2864367531146854, 0.1667428290238604, 0.1669548659119755, 0.16837644518818706, 0.16879256907850504, 0.16877010103780776, 0.17253578687086701, 0.17249305895529687, 0.1690856150817126, 0.1704608139116317, 0.3041155969258398, 0.180862543056719, 0.18095805903431028, 0.16915661201346666, 0.1670484059723094, 0.17094992310740054, 0.17524774104822427, 0.16782977804541588, 0.16809166397433728, 0.20989973284304142, 0.20959712099283934, 0.1659412479493767, 0.16673867194913328, 0.17356531496625394, 0.17835640802513808, 0.16998890100512654, 0.17480680893640965, 0.17025166703388095, 0.16785147599875927, 0.19416554283816367, 0.22338354610837996, 0.16733224596828222, 0.1670712580671534, 0.16828219091985375, 0.16761728085111827, 0.16589072300121188, 0.17314098216593266, 0.16710224014241248, 0.16569461405742913, 0.16523972002323717, 0.28812887507956475, 0.16581138200126588, 0.16600739595014602, 0.16539636987727135, 0.16643403097987175, 0.16653519705869257, 0.16939164698123932, 0.17502104712184519, 0.16840713494457304, 0.1676430570660159, 0.28786017990205437, 0.16953817708417773, 0.16895654401741922, 0.16885046905372292, 0.16485428204759955, 0.1677380258915946, 0.16774872713722289, 0.17307587002869695, 0.16534847591537982, 0.16144978010561317, 0.16067264589946717, 0.25769063585903496, 0.17595092894043773, 0.17480649903882295, 0.1754336190642789, 0.17544742999598384, 0.17639619600959122, 0.17804231902118772, 0.17616818577516824, 0.16613388690166175, 0.16646099998615682, 0.23931967397220433, 0.1718780348310247, 0.173380607040599, 0.17612375493627042, 0.17419045907445252, 0.17808580491691828, 0.1803121971897781, 0.17619251389987767, 0.16572398995049298, 0.1639914979459718, 0.19953405507840216, 0.21730319305788726, 0.16594679688569158, 0.16577442293055356, 0.16597031790297478, 0.16471487400121987, 0.16680599399842322, 0.16883756406605244, 0.16840501897968352, 0.16635977290570736, 0.16462015290744603, 0.2980591900413856, 0.1743721819948405, 0.1772166439332068, 0.1778859889600426, 0.17786631698254496, 0.18204433692153543, 0.16777338611427695, 0.16752280294895172, 0.16661183908581734, 0.24955805484205484, 0.16421725996769965, 0.16574695007875562, 0.16585054202005267, 0.16540261392947286, 0.1696496339282021, 0.16749326488934457, 0.1732957570347935, 0.17114219313953072, 0.16731292905751616]
Total Epoch List: [121, 104, 114]
Total Time List: [0.05600782891269773, 0.054652777034789324, 0.05738992104306817]
T-times Epoch Time: 0.17984713616636525 ~ 0.001861528027861342
T-times Total Epoch: 102.55555555555554 ~ 12.269605123089466
T-times Total Time: 0.05509982677176595 ~ 0.0010662793479196636
T-times Inference Elapsed: 0.05580178847637444 ~ 0.0005131824230860507
T-times Time Per Graph: 0.0012856632356447236 ~ 1.3704417415829465e-05
T-times Speed: 788.9657021241724 ~ 11.690898851136325
T-times cross validation test micro f1 score:0.7476872283242354 ~ 0.06781341364327527
T-times cross validation test precision:0.7866700947689865 ~ 0.1713086998258355
T-times cross validation test recall:0.7202982202982202 ~ 0.12373451060614786
T-times cross validation test f1_score:0.7476872283242354 ~ 0.14420911937743028
