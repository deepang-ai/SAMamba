Namespace(seed=15, model='I2BGNNT', dataset='mining/Volume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/mining/Volume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 132], edge_attr=[132, 2], x=[32, 14887], y=[1, 1], num_nodes=32)
Data(edge_index=[2, 132], edge_attr=[132, 2], x=[32, 14887], y=[1, 1], num_nodes=32)
Data(edge_index=[2, 124], edge_attr=[124, 2], x=[30, 14887], y=[1, 1], num_nodes=32)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7adfa34f0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6885;  Loss pred: 0.6885; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6907;  Loss pred: 0.6907; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6892;  Loss pred: 0.6892; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6904;  Loss pred: 0.6904; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6861;  Loss pred: 0.6861; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6853;  Loss pred: 0.6853; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6818;  Loss pred: 0.6818; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6790;  Loss pred: 0.6790; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6749;  Loss pred: 0.6749; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6731;  Loss pred: 0.6731; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6688;  Loss pred: 0.6688; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6649;  Loss pred: 0.6649; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6585;  Loss pred: 0.6585; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6586;  Loss pred: 0.6586; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6506;  Loss pred: 0.6506; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6480;  Loss pred: 0.6480; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6402;  Loss pred: 0.6402; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6342;  Loss pred: 0.6342; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6250;  Loss pred: 0.6250; Loss self: 0.0000; time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6194;  Loss pred: 0.6194; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6091;  Loss pred: 0.6091; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6038;  Loss pred: 0.6038; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5949;  Loss pred: 0.5949; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5870;  Loss pred: 0.5870; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5798;  Loss pred: 0.5798; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5688;  Loss pred: 0.5688; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5600;  Loss pred: 0.5600; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5524;  Loss pred: 0.5524; Loss self: 0.0000; time: 0.06s
Val loss: 0.6913 score: 0.5116 time: 0.05s
Test loss: 0.6914 score: 0.5227 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5443;  Loss pred: 0.5443; Loss self: 0.0000; time: 0.19s
Val loss: 0.6910 score: 0.6279 time: 0.05s
Test loss: 0.6911 score: 0.6364 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5312;  Loss pred: 0.5312; Loss self: 0.0000; time: 0.06s
Val loss: 0.6906 score: 0.7674 time: 0.05s
Test loss: 0.6908 score: 0.7273 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5207;  Loss pred: 0.5207; Loss self: 0.0000; time: 0.06s
Val loss: 0.6902 score: 0.8140 time: 0.05s
Test loss: 0.6905 score: 0.7955 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5109;  Loss pred: 0.5109; Loss self: 0.0000; time: 0.06s
Val loss: 0.6898 score: 0.7442 time: 0.05s
Test loss: 0.6901 score: 0.7955 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5037;  Loss pred: 0.5037; Loss self: 0.0000; time: 0.06s
Val loss: 0.6892 score: 0.7674 time: 0.05s
Test loss: 0.6897 score: 0.7500 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4906;  Loss pred: 0.4906; Loss self: 0.0000; time: 0.07s
Val loss: 0.6886 score: 0.7209 time: 0.05s
Test loss: 0.6892 score: 0.6364 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4772;  Loss pred: 0.4772; Loss self: 0.0000; time: 0.06s
Val loss: 0.6879 score: 0.7209 time: 0.05s
Test loss: 0.6886 score: 0.6364 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4646;  Loss pred: 0.4646; Loss self: 0.0000; time: 0.07s
Val loss: 0.6871 score: 0.6744 time: 0.05s
Test loss: 0.6880 score: 0.6364 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4580;  Loss pred: 0.4580; Loss self: 0.0000; time: 0.07s
Val loss: 0.6862 score: 0.6512 time: 0.05s
Test loss: 0.6872 score: 0.6364 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4482;  Loss pred: 0.4482; Loss self: 0.0000; time: 0.06s
Val loss: 0.6851 score: 0.6047 time: 0.05s
Test loss: 0.6862 score: 0.6364 time: 0.04s
Epoch 40/1000, LR 0.000269
Train loss: 0.4285;  Loss pred: 0.4285; Loss self: 0.0000; time: 0.20s
Val loss: 0.6839 score: 0.5814 time: 0.05s
Test loss: 0.6852 score: 0.6591 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4145;  Loss pred: 0.4145; Loss self: 0.0000; time: 0.06s
Val loss: 0.6825 score: 0.6047 time: 0.05s
Test loss: 0.6841 score: 0.6591 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4005;  Loss pred: 0.4005; Loss self: 0.0000; time: 0.06s
Val loss: 0.6810 score: 0.6279 time: 0.05s
Test loss: 0.6828 score: 0.6591 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3861;  Loss pred: 0.3861; Loss self: 0.0000; time: 0.06s
Val loss: 0.6793 score: 0.6279 time: 0.05s
Test loss: 0.6814 score: 0.6591 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3793;  Loss pred: 0.3793; Loss self: 0.0000; time: 0.07s
Val loss: 0.6774 score: 0.6279 time: 0.05s
Test loss: 0.6798 score: 0.6364 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3652;  Loss pred: 0.3652; Loss self: 0.0000; time: 0.07s
Val loss: 0.6753 score: 0.6279 time: 0.05s
Test loss: 0.6781 score: 0.6591 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3508;  Loss pred: 0.3508; Loss self: 0.0000; time: 0.07s
Val loss: 0.6730 score: 0.6512 time: 0.05s
Test loss: 0.6762 score: 0.6591 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3372;  Loss pred: 0.3372; Loss self: 0.0000; time: 0.07s
Val loss: 0.6706 score: 0.6512 time: 0.05s
Test loss: 0.6741 score: 0.6591 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3170;  Loss pred: 0.3170; Loss self: 0.0000; time: 0.07s
Val loss: 0.6679 score: 0.6512 time: 0.05s
Test loss: 0.6718 score: 0.6591 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3066;  Loss pred: 0.3066; Loss self: 0.0000; time: 0.06s
Val loss: 0.6650 score: 0.6512 time: 0.05s
Test loss: 0.6693 score: 0.6591 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3004;  Loss pred: 0.3004; Loss self: 0.0000; time: 0.07s
Val loss: 0.6618 score: 0.6744 time: 0.17s
Test loss: 0.6665 score: 0.6591 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2781;  Loss pred: 0.2781; Loss self: 0.0000; time: 0.07s
Val loss: 0.6584 score: 0.6744 time: 0.05s
Test loss: 0.6636 score: 0.6591 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2671;  Loss pred: 0.2671; Loss self: 0.0000; time: 0.07s
Val loss: 0.6545 score: 0.6977 time: 0.05s
Test loss: 0.6603 score: 0.6591 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2487;  Loss pred: 0.2487; Loss self: 0.0000; time: 0.06s
Val loss: 0.6504 score: 0.7209 time: 0.05s
Test loss: 0.6568 score: 0.6591 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2376;  Loss pred: 0.2376; Loss self: 0.0000; time: 0.07s
Val loss: 0.6460 score: 0.7209 time: 0.05s
Test loss: 0.6530 score: 0.6818 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2194;  Loss pred: 0.2194; Loss self: 0.0000; time: 0.07s
Val loss: 0.6413 score: 0.7209 time: 0.05s
Test loss: 0.6490 score: 0.7273 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2183;  Loss pred: 0.2183; Loss self: 0.0000; time: 0.07s
Val loss: 0.6362 score: 0.7209 time: 0.05s
Test loss: 0.6446 score: 0.7273 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1994;  Loss pred: 0.1994; Loss self: 0.0000; time: 0.07s
Val loss: 0.6306 score: 0.7209 time: 0.05s
Test loss: 0.6398 score: 0.7045 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1891;  Loss pred: 0.1891; Loss self: 0.0000; time: 0.07s
Val loss: 0.6246 score: 0.7209 time: 0.05s
Test loss: 0.6346 score: 0.7045 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1758;  Loss pred: 0.1758; Loss self: 0.0000; time: 0.07s
Val loss: 0.6180 score: 0.8140 time: 0.05s
Test loss: 0.6290 score: 0.7273 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1665;  Loss pred: 0.1665; Loss self: 0.0000; time: 0.07s
Val loss: 0.6110 score: 0.8140 time: 0.05s
Test loss: 0.6231 score: 0.7273 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1593;  Loss pred: 0.1593; Loss self: 0.0000; time: 0.07s
Val loss: 0.6037 score: 0.8140 time: 0.05s
Test loss: 0.6170 score: 0.7273 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1449;  Loss pred: 0.1449; Loss self: 0.0000; time: 0.07s
Val loss: 0.5959 score: 0.8140 time: 0.07s
Test loss: 0.6104 score: 0.7273 time: 0.10s
Epoch 63/1000, LR 0.000268
Train loss: 0.1411;  Loss pred: 0.1411; Loss self: 0.0000; time: 0.06s
Val loss: 0.5874 score: 0.8140 time: 0.05s
Test loss: 0.6033 score: 0.7273 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1294;  Loss pred: 0.1294; Loss self: 0.0000; time: 0.06s
Val loss: 0.5787 score: 0.8140 time: 0.05s
Test loss: 0.5960 score: 0.7273 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1173;  Loss pred: 0.1173; Loss self: 0.0000; time: 0.06s
Val loss: 0.5699 score: 0.8140 time: 0.05s
Test loss: 0.5886 score: 0.7500 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1071;  Loss pred: 0.1071; Loss self: 0.0000; time: 0.06s
Val loss: 0.5608 score: 0.7907 time: 0.05s
Test loss: 0.5811 score: 0.7500 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1063;  Loss pred: 0.1063; Loss self: 0.0000; time: 0.06s
Val loss: 0.5518 score: 0.8140 time: 0.05s
Test loss: 0.5737 score: 0.7500 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0927;  Loss pred: 0.0927; Loss self: 0.0000; time: 0.06s
Val loss: 0.5425 score: 0.8140 time: 0.05s
Test loss: 0.5663 score: 0.7500 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0864;  Loss pred: 0.0864; Loss self: 0.0000; time: 0.06s
Val loss: 0.5328 score: 0.8372 time: 0.05s
Test loss: 0.5586 score: 0.7500 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0759;  Loss pred: 0.0759; Loss self: 0.0000; time: 0.06s
Val loss: 0.5230 score: 0.8605 time: 0.05s
Test loss: 0.5512 score: 0.7500 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0697;  Loss pred: 0.0697; Loss self: 0.0000; time: 0.06s
Val loss: 0.5134 score: 0.8605 time: 0.05s
Test loss: 0.5440 score: 0.7500 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0679;  Loss pred: 0.0679; Loss self: 0.0000; time: 0.06s
Val loss: 0.5037 score: 0.8605 time: 0.05s
Test loss: 0.5370 score: 0.7500 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0620;  Loss pred: 0.0620; Loss self: 0.0000; time: 0.06s
Val loss: 0.4937 score: 0.8605 time: 0.05s
Test loss: 0.5299 score: 0.7273 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0538;  Loss pred: 0.0538; Loss self: 0.0000; time: 0.07s
Val loss: 0.4838 score: 0.8605 time: 0.18s
Test loss: 0.5233 score: 0.7273 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0523;  Loss pred: 0.0523; Loss self: 0.0000; time: 0.06s
Val loss: 0.4738 score: 0.8837 time: 0.05s
Test loss: 0.5169 score: 0.7273 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0450;  Loss pred: 0.0450; Loss self: 0.0000; time: 0.06s
Val loss: 0.4639 score: 0.8837 time: 0.05s
Test loss: 0.5110 score: 0.7273 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0440;  Loss pred: 0.0440; Loss self: 0.0000; time: 0.06s
Val loss: 0.4546 score: 0.8837 time: 0.05s
Test loss: 0.5057 score: 0.7273 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0403;  Loss pred: 0.0403; Loss self: 0.0000; time: 0.07s
Val loss: 0.4454 score: 0.8837 time: 0.05s
Test loss: 0.5009 score: 0.7273 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0369;  Loss pred: 0.0369; Loss self: 0.0000; time: 0.07s
Val loss: 0.4366 score: 0.8837 time: 0.05s
Test loss: 0.4966 score: 0.7500 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0325;  Loss pred: 0.0325; Loss self: 0.0000; time: 0.06s
Val loss: 0.4283 score: 0.8837 time: 0.05s
Test loss: 0.4931 score: 0.7273 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0308;  Loss pred: 0.0308; Loss self: 0.0000; time: 0.06s
Val loss: 0.4205 score: 0.8837 time: 0.05s
Test loss: 0.4905 score: 0.7273 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0259;  Loss pred: 0.0259; Loss self: 0.0000; time: 0.06s
Val loss: 0.4134 score: 0.8605 time: 0.05s
Test loss: 0.4882 score: 0.7273 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0279;  Loss pred: 0.0279; Loss self: 0.0000; time: 0.06s
Val loss: 0.4072 score: 0.8605 time: 0.05s
Test loss: 0.4866 score: 0.7273 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0243;  Loss pred: 0.0243; Loss self: 0.0000; time: 0.06s
Val loss: 0.4012 score: 0.8605 time: 0.05s
Test loss: 0.4861 score: 0.7273 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0225;  Loss pred: 0.0225; Loss self: 0.0000; time: 0.06s
Val loss: 0.3955 score: 0.8605 time: 0.05s
Test loss: 0.4857 score: 0.7273 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0195;  Loss pred: 0.0195; Loss self: 0.0000; time: 0.07s
Val loss: 0.3906 score: 0.8605 time: 0.16s
Test loss: 0.4863 score: 0.7273 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0212;  Loss pred: 0.0212; Loss self: 0.0000; time: 0.06s
Val loss: 0.3863 score: 0.8605 time: 0.05s
Test loss: 0.4876 score: 0.7273 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.06s
Val loss: 0.3825 score: 0.8605 time: 0.05s
Test loss: 0.4894 score: 0.7273 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0152;  Loss pred: 0.0152; Loss self: 0.0000; time: 0.06s
Val loss: 0.3793 score: 0.8605 time: 0.05s
Test loss: 0.4922 score: 0.7273 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.06s
Val loss: 0.3764 score: 0.8837 time: 0.05s
Test loss: 0.4954 score: 0.7273 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.06s
Val loss: 0.3740 score: 0.8837 time: 0.05s
Test loss: 0.5000 score: 0.7500 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.07s
Val loss: 0.3721 score: 0.8837 time: 0.05s
Test loss: 0.5055 score: 0.7727 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.07s
Val loss: 0.3706 score: 0.9070 time: 0.05s
Test loss: 0.5116 score: 0.7727 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.06s
Val loss: 0.3694 score: 0.8837 time: 0.05s
Test loss: 0.5177 score: 0.7727 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.07s
Val loss: 0.3691 score: 0.8837 time: 0.18s
Test loss: 0.5248 score: 0.7727 time: 0.06s
Epoch 96/1000, LR 0.000265
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.07s
Val loss: 0.3692 score: 0.8837 time: 0.06s
Test loss: 0.5324 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.07s
Val loss: 0.3699 score: 0.8837 time: 0.05s
Test loss: 0.5406 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.3710 score: 0.8837 time: 0.05s
Test loss: 0.5487 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.07s
Val loss: 0.3724 score: 0.8837 time: 0.05s
Test loss: 0.5569 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.07s
Val loss: 0.3745 score: 0.8837 time: 0.05s
Test loss: 0.5660 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.3766 score: 0.8837 time: 0.05s
Test loss: 0.5746 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.3782 score: 0.8837 time: 0.05s
Test loss: 0.5818 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.07s
Val loss: 0.3798 score: 0.9070 time: 0.05s
Test loss: 0.5886 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.07s
Val loss: 0.3819 score: 0.9070 time: 0.05s
Test loss: 0.5954 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.3843 score: 0.9070 time: 0.05s
Test loss: 0.6024 score: 0.7727 time: 0.16s
     INFO: Early stopping counter 10 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.3869 score: 0.8837 time: 0.05s
Test loss: 0.6090 score: 0.7727 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.06s
Val loss: 0.3900 score: 0.8837 time: 0.05s
Test loss: 0.6157 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.06s
Val loss: 0.3936 score: 0.8837 time: 0.05s
Test loss: 0.6234 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.06s
Val loss: 0.3970 score: 0.8837 time: 0.05s
Test loss: 0.6305 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.06s
Val loss: 0.4010 score: 0.8837 time: 0.05s
Test loss: 0.6388 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.06s
Val loss: 0.4050 score: 0.8837 time: 0.05s
Test loss: 0.6473 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.06s
Val loss: 0.4091 score: 0.8837 time: 0.05s
Test loss: 0.6556 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.06s
Val loss: 0.4135 score: 0.8837 time: 0.05s
Test loss: 0.6645 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.06s
Val loss: 0.4179 score: 0.8837 time: 0.05s
Test loss: 0.6732 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.06s
Val loss: 0.4219 score: 0.8605 time: 0.05s
Test loss: 0.6808 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 094,   Train_Loss: 0.0105,   Val_Loss: 0.3691,   Val_Precision: 0.9474,   Val_Recall: 0.8182,   Val_accuracy: 0.8780,   Val_Score: 0.8837,   Val_Loss: 0.3691,   Test_Precision: 0.8333,   Test_Recall: 0.6818,   Test_accuracy: 0.7500,   Test_Score: 0.7727,   Test_loss: 0.5248


[0.054035031935200095, 0.05690660292748362, 0.055626944988034666, 0.059371399926021695, 0.059272755053825676, 0.05451734201051295, 0.05443407397251576, 0.054617397021502256, 0.054742610082030296, 0.054515342926606536, 0.054460498970001936, 0.05474030098412186, 0.05499934498220682, 0.055648586014285684, 0.054714682046324015, 0.0542374060023576, 0.054608682985417545, 0.054897906025871634, 0.05522894999012351, 0.0537695080274716, 0.0538681399775669, 0.0533947559306398, 0.05360470700543374, 0.05373368505388498, 0.05389509501401335, 0.053910596994683146, 0.05419908999465406, 0.053977156057953835, 0.0549793770769611, 0.054137713043019176, 0.05425394501071423, 0.05516823998186737, 0.05510196904651821, 0.05540576810017228, 0.05505208903923631, 0.05552198505029082, 0.05536802508868277, 0.05464385007508099, 0.04919966193847358, 0.05340135109145194, 0.05330951197538525, 0.05366797302849591, 0.05377714894711971, 0.053551650955341756, 0.05402222601696849, 0.05338680907152593, 0.054038579924963415, 0.05362511600833386, 0.05350604606792331, 0.0532734269509092, 0.053887141053564847, 0.053584067965857685, 0.05346075294073671, 0.05380351596977562, 0.05473195598460734, 0.05425238097086549, 0.05532533209770918, 0.05413987301290035, 0.05474308202974498, 0.05453767906874418, 0.05471894494257867, 0.10651256400160491, 0.051669530919753015, 0.05177777505014092, 0.051354287075810134, 0.05160738294944167, 0.05185517598874867, 0.05242751294281334, 0.0515090940752998, 0.05268107890151441, 0.052265534992329776, 0.051369563094340265, 0.0518201949307695, 0.053490042919293046, 0.05365105904638767, 0.05443136696703732, 0.054306214093230665, 0.05422999197617173, 0.05118524900171906, 0.05061193695291877, 0.05342856398783624, 0.050980384927242994, 0.050714035984128714, 0.0505549400113523, 0.05167000996880233, 0.05188982200343162, 0.0518716179067269, 0.05216999398544431, 0.05229440110269934, 0.05670847895089537, 0.05326528393197805, 0.05264701007399708, 0.05675963091198355, 0.05218213703483343, 0.06205144093837589, 0.05514680698979646, 0.05521291901823133, 0.055143292993307114, 0.054900795919820666, 0.05540479102637619, 0.0554546540370211, 0.055738945957273245, 0.05521905701607466, 0.05570366105530411, 0.16655763902235776, 0.052436962025240064, 0.05093453999143094, 0.050913163111545146, 0.0509051630506292, 0.05128363403491676, 0.05100734205916524, 0.05168098502326757, 0.05152839201036841, 0.05065455997828394, 0.05191515898332]
[0.001228068907618184, 0.0012933318847155367, 0.0012642487497280606, 0.0013493499983186748, 0.001347108069405129, 0.0012390305002389307, 0.0012371380448299037, 0.001241304477761415, 0.0012441502291370523, 0.0012389850665137849, 0.0012377386129545894, 0.001244097749639133, 0.0012499851132319732, 0.0012647405912337656, 0.0012435155010528185, 0.0012326683182354, 0.0012411064314867624, 0.0012476796824061735, 0.0012552034088664434, 0.0012220342733516272, 0.0012242759085810658, 0.0012135171802418138, 0.0012182887955780395, 0.0012212201148610222, 0.001224888523045758, 0.0012252408407882533, 0.0012317974998785014, 0.001226753546771678, 0.0012495312972036613, 0.0012304025691595268, 0.0012330442047889599, 0.0012538236359515313, 0.0012523174783299592, 0.0012592220022766428, 0.0012511838418008251, 0.0012618632965975187, 0.001258364206560972, 0.001241905683524568, 0.0011181741349653087, 0.0012136670702602714, 0.001211579817622392, 0.0012197266597385433, 0.001222207930616357, 0.001217082976257767, 0.001227777864022011, 0.0012133365698074076, 0.0012281495437491685, 0.0012187526365530423, 0.0012160465015437114, 0.0012107597034297544, 0.0012247077512173828, 0.0012178197264967655, 0.0012150171122894708, 0.001222807181131264, 0.0012439080905592577, 0.001233008658428761, 0.0012573939113115723, 0.001230451659384099, 0.0012441609552214768, 0.0012394927061078224, 0.0012436123850586062, 0.0024207400909455664, 0.0011743075209034776, 0.00117676761477593, 0.001167142888086594, 0.0011728950670327652, 0.0011785267270170152, 0.0011915343850639395, 0.0011706612289840864, 0.001197297247761691, 0.0011878530680074948, 0.0011674900703259152, 0.001177731702972034, 0.0012156827936202965, 0.0012193422510542653, 0.0012370765219781208, 0.0012342321384825152, 0.0012324998176402667, 0.001163301113675433, 0.0011502712943845174, 0.0012142855451780963, 0.0011586451119827952, 0.0011525917269120162, 0.0011489759093489158, 0.0011743184083818712, 0.0011793141364416276, 0.0011789004069710659, 0.0011856816814873707, 0.0011885091159704396, 0.0012888290670658039, 0.0012105746348176829, 0.0011965229562272064, 0.0012899916116359898, 0.001185957659882578, 0.0014102600213267249, 0.001253336522495374, 0.0012548390685961667, 0.001253256658938798, 0.001247745361814106, 0.0012591997960540043, 0.001260333046295934, 0.0012667942263016646, 0.0012549785685471513, 0.0012659922967114571, 0.0037854008868717674, 0.0011917491369372742, 0.0011576031816234304, 0.0011571173434442078, 0.0011569355238779363, 0.0011655371371571991, 0.0011592577740719373, 0.0011745678414378992, 0.0011710998184174639, 0.0011512399995064532, 0.0011798899768936362]
[814.2865549291373, 773.196742319506, 790.9835783623275, 741.0975664179241, 742.330940413408, 807.0826342105083, 808.3172320009703, 805.604118824588, 803.7614562781572, 807.1122300236974, 807.9250251496261, 803.7953611684155, 800.0095276450058, 790.6759749242264, 804.1717205401566, 811.2482370209113, 805.7326709701013, 801.4877649297625, 796.6836234958014, 818.3076545450216, 816.8093425598798, 824.0509621798129, 820.8234399180628, 818.8532008529866, 816.4008243896683, 816.1660685067063, 811.8217483788003, 815.1596566658379, 800.3000823091907, 812.7421260856827, 811.0009325830729, 797.5603357015171, 798.5195585815509, 794.1411428580698, 799.243058127016, 792.4788704896913, 794.6824892079021, 805.2141263754975, 894.3150880797515, 823.9491904361792, 825.3686512890279, 819.8558193475551, 818.1913854017474, 821.6366669384824, 814.479580796606, 824.1736257555722, 814.2330916374426, 820.5110454802928, 822.3369737345972, 825.9277189084429, 816.5213284605907, 821.1395974645973, 823.033675727981, 817.790421442294, 803.9179161142064, 811.0243128984292, 795.2957231651553, 812.7097008431431, 803.7545269389899, 806.7816737220968, 804.1090712946495, 413.09680611328645, 851.5656948451028, 849.7854524917492, 856.7931229392085, 852.5911891929413, 848.5170315408234, 839.2540010050474, 854.2180908031027, 835.2144815078026, 841.8549624806714, 856.5383341725906, 849.0898202676178, 822.5830004733435, 820.114286317383, 808.3574316008934, 810.2203538707857, 811.3591464172313, 859.6226619611103, 869.3601282426821, 823.5295264536253, 863.0770454714083, 867.6099061366381, 870.3402672443017, 851.557799709476, 847.9504901190479, 848.2480742960192, 843.3966853106447, 841.3902649652641, 775.8980810982462, 826.0539839830725, 835.7549638271304, 775.1988392636, 843.2004226010988, 709.0890934135919, 797.8703102092766, 796.9149391552941, 797.9211543521783, 801.4455758393625, 794.1551476848495, 793.4410693577844, 789.3941882885308, 796.8263562920187, 789.8942217876057, 264.17281283684434, 839.102768364441, 863.8538800468683, 864.2165858679972, 864.3524028444527, 857.9735197790848, 862.6209134552204, 851.376961568951, 853.8981769729286, 868.6286095242598, 847.5366513687633]
Elapsed: 0.05519297002895695~0.011678267760222731
Time per graph: 0.001254385682476294~0.0002654151763686985
Speed: 811.207504796098~69.67399822747673
Total Time: 0.0525
best val loss: 0.3691099286079407 test_score: 0.7727

Testing...
Test loss: 0.5116 score: 0.7727 time: 0.17s
test Score 0.7727
Epoch Time List: [0.35388022603001446, 0.1640924260718748, 0.16747411794494838, 0.17407483293209225, 0.17448691104073077, 0.1721685560187325, 0.2884179169777781, 0.16737152298446745, 0.16701822692994028, 0.16697604989167303, 0.16508857801090926, 0.16457538993563503, 0.16619894094765186, 0.16671766992658377, 0.16753240500111133, 0.164621019968763, 0.16708064498379827, 0.16525445494335145, 0.16663702810183167, 0.29217719298321754, 0.1625385438092053, 0.162223165971227, 0.16242288402281702, 0.1636550968978554, 0.16412331291940063, 0.16421422292478383, 0.1641853938344866, 0.16391908307559788, 0.16435342596378177, 0.2930149359162897, 0.162615081993863, 0.16581235802732408, 0.16628121805842966, 0.1669620069442317, 0.16788284399081022, 0.16770464892033488, 0.16799871088005602, 0.16723406093660742, 0.16021263704169542, 0.29567900707479566, 0.16250477393623441, 0.16413217701483518, 0.16330884513445199, 0.16495695209596306, 0.16590503603219986, 0.1659004760440439, 0.1657963899197057, 0.1649516219040379, 0.16399451403412968, 0.2866682519670576, 0.1665690578520298, 0.16516766394488513, 0.1646501610521227, 0.16639862197916955, 0.1674750359961763, 0.16639281599782407, 0.1685670220758766, 0.16934920300263911, 0.16921799501869828, 0.1674647710751742, 0.16804768494330347, 0.24389016802888364, 0.15808181487955153, 0.15769422403536737, 0.15770868014078587, 0.15773426496889442, 0.15772662602830678, 0.1589079120894894, 0.15782158100046217, 0.1615420349407941, 0.1616310611134395, 0.15663455694448203, 0.15805481013376266, 0.295314752147533, 0.16255746909882873, 0.16455299907829612, 0.16385183203965425, 0.16627535491716117, 0.16328006784897298, 0.15455255389679223, 0.16065649595111609, 0.15648630494251847, 0.15656128898262978, 0.15555244695860893, 0.15657884906977415, 0.2772407609736547, 0.16014930605888367, 0.15956903609912843, 0.15964680793695152, 0.16540854098275304, 0.16141846508253366, 0.16687758709304035, 0.16972047602757812, 0.15956318809185177, 0.3030579958576709, 0.1751237070420757, 0.16704569896683097, 0.1676835670368746, 0.16752498503774405, 0.1682206679834053, 0.16863838105928153, 0.17193744098767638, 0.17091186391189694, 0.16890940407756716, 0.2771728200605139, 0.16972917306702584, 0.1560840648598969, 0.15678411512635648, 0.15744406706653535, 0.15678492898587137, 0.15789153787773103, 0.15757182706147432, 0.15842352306935936, 0.1562279909849167, 0.15533298102673143]
Total Epoch List: [115]
Total Time List: [0.05252736108377576]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7ae0cf8e0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6930;  Loss pred: 0.6930; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6918;  Loss pred: 0.6918; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5000 time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.4884 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6923;  Loss pred: 0.6923; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.4884 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6912;  Loss pred: 0.6912; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.4884 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6876;  Loss pred: 0.6876; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6838;  Loss pred: 0.6838; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6848;  Loss pred: 0.6848; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6823;  Loss pred: 0.6823; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6778;  Loss pred: 0.6778; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6736;  Loss pred: 0.6736; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6724;  Loss pred: 0.6724; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.09s
Epoch 14/1000, LR 0.000270
Train loss: 0.6654;  Loss pred: 0.6654; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6637;  Loss pred: 0.6637; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6577;  Loss pred: 0.6577; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6554;  Loss pred: 0.6554; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6492;  Loss pred: 0.6492; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6453;  Loss pred: 0.6453; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6389;  Loss pred: 0.6389; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6349;  Loss pred: 0.6349; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6300;  Loss pred: 0.6300; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6231;  Loss pred: 0.6231; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6133;  Loss pred: 0.6133; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.13s
Epoch 25/1000, LR 0.000270
Train loss: 0.6101;  Loss pred: 0.6101; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5961;  Loss pred: 0.5961; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5911;  Loss pred: 0.5911; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5852;  Loss pred: 0.5852; Loss self: 0.0000; time: 0.07s
Val loss: 0.6911 score: 0.6591 time: 0.05s
Test loss: 0.6915 score: 0.5814 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5761;  Loss pred: 0.5761; Loss self: 0.0000; time: 0.07s
Val loss: 0.6907 score: 0.7955 time: 0.05s
Test loss: 0.6911 score: 0.7907 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5645;  Loss pred: 0.5645; Loss self: 0.0000; time: 0.07s
Val loss: 0.6904 score: 0.5682 time: 0.05s
Test loss: 0.6907 score: 0.6512 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5580;  Loss pred: 0.5580; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5462;  Loss pred: 0.5462; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6895 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5329;  Loss pred: 0.5329; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6890 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5232;  Loss pred: 0.5232; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6884 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5154;  Loss pred: 0.5154; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6878 score: 0.5000 time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5015;  Loss pred: 0.5015; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6873 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4875;  Loss pred: 0.4875; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6864 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6867 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4700;  Loss pred: 0.4700; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6856 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6859 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4586;  Loss pred: 0.4586; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6851 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4493;  Loss pred: 0.4493; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6836 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6841 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4309;  Loss pred: 0.4309; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6823 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6829 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4143;  Loss pred: 0.4143; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6816 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3977;  Loss pred: 0.3977; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6793 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6802 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3809;  Loss pred: 0.3809; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6774 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6785 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3716;  Loss pred: 0.3716; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6754 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6766 score: 0.5116 time: 0.06s
Epoch 46/1000, LR 0.000269
Train loss: 0.3528;  Loss pred: 0.3528; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6732 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6745 score: 0.5116 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3423;  Loss pred: 0.3423; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6708 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6723 score: 0.5116 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3206;  Loss pred: 0.3206; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6681 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6699 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3148;  Loss pred: 0.3148; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6651 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6673 score: 0.5116 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2982;  Loss pred: 0.2982; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6619 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6644 score: 0.5116 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2815;  Loss pred: 0.2815; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6583 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6611 score: 0.5116 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2655;  Loss pred: 0.2655; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6543 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6576 score: 0.5116 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2518;  Loss pred: 0.2518; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6500 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6537 score: 0.5116 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2387;  Loss pred: 0.2387; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6453 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6495 score: 0.5116 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2201;  Loss pred: 0.2201; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6403 score: 0.5000 time: 0.13s
Test loss: 0.6450 score: 0.5349 time: 0.07s
Epoch 56/1000, LR 0.000269
Train loss: 0.2147;  Loss pred: 0.2147; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6346 score: 0.5000 time: 0.05s
Test loss: 0.6398 score: 0.5349 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2050;  Loss pred: 0.2050; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6287 score: 0.5000 time: 0.05s
Test loss: 0.6345 score: 0.5581 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1860;  Loss pred: 0.1860; Loss self: 0.0000; time: 0.07s
Val loss: 0.6224 score: 0.5227 time: 0.05s
Test loss: 0.6286 score: 0.5581 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1774;  Loss pred: 0.1774; Loss self: 0.0000; time: 0.07s
Val loss: 0.6149 score: 0.5682 time: 0.05s
Test loss: 0.6218 score: 0.5814 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1647;  Loss pred: 0.1647; Loss self: 0.0000; time: 0.07s
Val loss: 0.6067 score: 0.5682 time: 0.05s
Test loss: 0.6144 score: 0.6047 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1587;  Loss pred: 0.1587; Loss self: 0.0000; time: 0.07s
Val loss: 0.5979 score: 0.5909 time: 0.05s
Test loss: 0.6064 score: 0.6047 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1511;  Loss pred: 0.1511; Loss self: 0.0000; time: 0.07s
Val loss: 0.5879 score: 0.6136 time: 0.05s
Test loss: 0.5973 score: 0.6047 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1412;  Loss pred: 0.1412; Loss self: 0.0000; time: 0.07s
Val loss: 0.5771 score: 0.6591 time: 0.05s
Test loss: 0.5876 score: 0.6047 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1334;  Loss pred: 0.1334; Loss self: 0.0000; time: 0.07s
Val loss: 0.5661 score: 0.6591 time: 0.05s
Test loss: 0.5776 score: 0.6744 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1219;  Loss pred: 0.1219; Loss self: 0.0000; time: 0.07s
Val loss: 0.5539 score: 0.6818 time: 0.05s
Test loss: 0.5667 score: 0.7442 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1205;  Loss pred: 0.1205; Loss self: 0.0000; time: 0.07s
Val loss: 0.5418 score: 0.7273 time: 0.15s
Test loss: 0.5556 score: 0.7674 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1095;  Loss pred: 0.1095; Loss self: 0.0000; time: 0.07s
Val loss: 0.5293 score: 0.7727 time: 0.05s
Test loss: 0.5442 score: 0.7674 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1057;  Loss pred: 0.1057; Loss self: 0.0000; time: 0.07s
Val loss: 0.5165 score: 0.7500 time: 0.05s
Test loss: 0.5325 score: 0.7907 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0992;  Loss pred: 0.0992; Loss self: 0.0000; time: 0.07s
Val loss: 0.5035 score: 0.7955 time: 0.05s
Test loss: 0.5206 score: 0.7907 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0949;  Loss pred: 0.0949; Loss self: 0.0000; time: 0.07s
Val loss: 0.4907 score: 0.7727 time: 0.05s
Test loss: 0.5088 score: 0.7674 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0929;  Loss pred: 0.0929; Loss self: 0.0000; time: 0.07s
Val loss: 0.4780 score: 0.7727 time: 0.05s
Test loss: 0.4972 score: 0.7674 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0858;  Loss pred: 0.0858; Loss self: 0.0000; time: 0.07s
Val loss: 0.4654 score: 0.7955 time: 0.05s
Test loss: 0.4857 score: 0.8140 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0843;  Loss pred: 0.0843; Loss self: 0.0000; time: 0.07s
Val loss: 0.4535 score: 0.8182 time: 0.05s
Test loss: 0.4747 score: 0.8140 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0786;  Loss pred: 0.0786; Loss self: 0.0000; time: 0.07s
Val loss: 0.4419 score: 0.8182 time: 0.06s
Test loss: 0.4640 score: 0.8605 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0775;  Loss pred: 0.0775; Loss self: 0.0000; time: 0.07s
Val loss: 0.4308 score: 0.8182 time: 0.05s
Test loss: 0.4537 score: 0.8605 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0700;  Loss pred: 0.0700; Loss self: 0.0000; time: 0.07s
Val loss: 0.4204 score: 0.8409 time: 0.05s
Test loss: 0.4440 score: 0.8605 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0744;  Loss pred: 0.0744; Loss self: 0.0000; time: 0.07s
Val loss: 0.4102 score: 0.8409 time: 0.05s
Test loss: 0.4345 score: 0.8605 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0655;  Loss pred: 0.0655; Loss self: 0.0000; time: 0.07s
Val loss: 0.4005 score: 0.8182 time: 0.05s
Test loss: 0.4254 score: 0.8372 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0635;  Loss pred: 0.0635; Loss self: 0.0000; time: 0.07s
Val loss: 0.3917 score: 0.8182 time: 0.05s
Test loss: 0.4172 score: 0.8372 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0599;  Loss pred: 0.0599; Loss self: 0.0000; time: 0.07s
Val loss: 0.3836 score: 0.8182 time: 0.05s
Test loss: 0.4094 score: 0.8372 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0546;  Loss pred: 0.0546; Loss self: 0.0000; time: 0.07s
Val loss: 0.3761 score: 0.8182 time: 0.05s
Test loss: 0.4023 score: 0.8372 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0562;  Loss pred: 0.0562; Loss self: 0.0000; time: 0.07s
Val loss: 0.3693 score: 0.8182 time: 0.05s
Test loss: 0.3958 score: 0.8372 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0561;  Loss pred: 0.0561; Loss self: 0.0000; time: 0.07s
Val loss: 0.3629 score: 0.8182 time: 0.05s
Test loss: 0.3895 score: 0.8372 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0477;  Loss pred: 0.0477; Loss self: 0.0000; time: 0.07s
Val loss: 0.3570 score: 0.8409 time: 0.05s
Test loss: 0.3838 score: 0.8372 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0479;  Loss pred: 0.0479; Loss self: 0.0000; time: 0.07s
Val loss: 0.3514 score: 0.8864 time: 0.05s
Test loss: 0.3785 score: 0.8605 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0461;  Loss pred: 0.0461; Loss self: 0.0000; time: 0.07s
Val loss: 0.3468 score: 0.8864 time: 0.05s
Test loss: 0.3740 score: 0.8837 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0465;  Loss pred: 0.0465; Loss self: 0.0000; time: 0.07s
Val loss: 0.3429 score: 0.8864 time: 0.05s
Test loss: 0.3704 score: 0.8837 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0421;  Loss pred: 0.0421; Loss self: 0.0000; time: 0.07s
Val loss: 0.3401 score: 0.8636 time: 0.05s
Test loss: 0.3678 score: 0.8837 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0429;  Loss pred: 0.0429; Loss self: 0.0000; time: 0.07s
Val loss: 0.3382 score: 0.8636 time: 0.05s
Test loss: 0.3663 score: 0.8605 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0369;  Loss pred: 0.0369; Loss self: 0.0000; time: 0.07s
Val loss: 0.3378 score: 0.8636 time: 0.05s
Test loss: 0.3660 score: 0.8605 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0371;  Loss pred: 0.0371; Loss self: 0.0000; time: 0.07s
Val loss: 0.3385 score: 0.8636 time: 0.05s
Test loss: 0.3666 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0395;  Loss pred: 0.0395; Loss self: 0.0000; time: 0.07s
Val loss: 0.3416 score: 0.8636 time: 0.05s
Test loss: 0.3692 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0350;  Loss pred: 0.0350; Loss self: 0.0000; time: 0.07s
Val loss: 0.3438 score: 0.8636 time: 0.05s
Test loss: 0.3706 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0336;  Loss pred: 0.0336; Loss self: 0.0000; time: 0.07s
Val loss: 0.3462 score: 0.8409 time: 0.05s
Test loss: 0.3721 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0296;  Loss pred: 0.0296; Loss self: 0.0000; time: 0.07s
Val loss: 0.3488 score: 0.8409 time: 0.05s
Test loss: 0.3739 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0266;  Loss pred: 0.0266; Loss self: 0.0000; time: 0.07s
Val loss: 0.3517 score: 0.8409 time: 0.05s
Test loss: 0.3761 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0237;  Loss pred: 0.0237; Loss self: 0.0000; time: 0.07s
Val loss: 0.3557 score: 0.8409 time: 0.05s
Test loss: 0.3790 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.07s
Val loss: 0.3596 score: 0.8409 time: 0.05s
Test loss: 0.3818 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0210;  Loss pred: 0.0210; Loss self: 0.0000; time: 0.07s
Val loss: 0.3641 score: 0.8409 time: 0.05s
Test loss: 0.3850 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0194;  Loss pred: 0.0194; Loss self: 0.0000; time: 0.07s
Val loss: 0.3689 score: 0.8409 time: 0.05s
Test loss: 0.3883 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0207;  Loss pred: 0.0207; Loss self: 0.0000; time: 0.07s
Val loss: 0.3747 score: 0.8409 time: 0.05s
Test loss: 0.3926 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0167;  Loss pred: 0.0167; Loss self: 0.0000; time: 0.07s
Val loss: 0.3819 score: 0.8409 time: 0.05s
Test loss: 0.3978 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0178;  Loss pred: 0.0178; Loss self: 0.0000; time: 0.07s
Val loss: 0.3893 score: 0.8409 time: 0.05s
Test loss: 0.4032 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0159;  Loss pred: 0.0159; Loss self: 0.0000; time: 0.07s
Val loss: 0.3975 score: 0.8409 time: 0.05s
Test loss: 0.4091 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.07s
Val loss: 0.4066 score: 0.8182 time: 0.05s
Test loss: 0.4152 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.07s
Val loss: 0.4152 score: 0.8182 time: 0.05s
Test loss: 0.4209 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.07s
Val loss: 0.4233 score: 0.8182 time: 0.05s
Test loss: 0.4264 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0110;  Loss pred: 0.0110; Loss self: 0.0000; time: 0.07s
Val loss: 0.4323 score: 0.8182 time: 0.05s
Test loss: 0.4327 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.07s
Val loss: 0.4414 score: 0.8182 time: 0.05s
Test loss: 0.4392 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.07s
Val loss: 0.4498 score: 0.8182 time: 0.05s
Test loss: 0.4447 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 089,   Train_Loss: 0.0369,   Val_Loss: 0.3378,   Val_Precision: 1.0000,   Val_Recall: 0.7273,   Val_accuracy: 0.8421,   Val_Score: 0.8636,   Val_Loss: 0.3378,   Test_Precision: 0.9444,   Test_Recall: 0.7727,   Test_accuracy: 0.8500,   Test_Score: 0.8605,   Test_loss: 0.3660


[0.054035031935200095, 0.05690660292748362, 0.055626944988034666, 0.059371399926021695, 0.059272755053825676, 0.05451734201051295, 0.05443407397251576, 0.054617397021502256, 0.054742610082030296, 0.054515342926606536, 0.054460498970001936, 0.05474030098412186, 0.05499934498220682, 0.055648586014285684, 0.054714682046324015, 0.0542374060023576, 0.054608682985417545, 0.054897906025871634, 0.05522894999012351, 0.0537695080274716, 0.0538681399775669, 0.0533947559306398, 0.05360470700543374, 0.05373368505388498, 0.05389509501401335, 0.053910596994683146, 0.05419908999465406, 0.053977156057953835, 0.0549793770769611, 0.054137713043019176, 0.05425394501071423, 0.05516823998186737, 0.05510196904651821, 0.05540576810017228, 0.05505208903923631, 0.05552198505029082, 0.05536802508868277, 0.05464385007508099, 0.04919966193847358, 0.05340135109145194, 0.05330951197538525, 0.05366797302849591, 0.05377714894711971, 0.053551650955341756, 0.05402222601696849, 0.05338680907152593, 0.054038579924963415, 0.05362511600833386, 0.05350604606792331, 0.0532734269509092, 0.053887141053564847, 0.053584067965857685, 0.05346075294073671, 0.05380351596977562, 0.05473195598460734, 0.05425238097086549, 0.05532533209770918, 0.05413987301290035, 0.05474308202974498, 0.05453767906874418, 0.05471894494257867, 0.10651256400160491, 0.051669530919753015, 0.05177777505014092, 0.051354287075810134, 0.05160738294944167, 0.05185517598874867, 0.05242751294281334, 0.0515090940752998, 0.05268107890151441, 0.052265534992329776, 0.051369563094340265, 0.0518201949307695, 0.053490042919293046, 0.05365105904638767, 0.05443136696703732, 0.054306214093230665, 0.05422999197617173, 0.05118524900171906, 0.05061193695291877, 0.05342856398783624, 0.050980384927242994, 0.050714035984128714, 0.0505549400113523, 0.05167000996880233, 0.05188982200343162, 0.0518716179067269, 0.05216999398544431, 0.05229440110269934, 0.05670847895089537, 0.05326528393197805, 0.05264701007399708, 0.05675963091198355, 0.05218213703483343, 0.06205144093837589, 0.05514680698979646, 0.05521291901823133, 0.055143292993307114, 0.054900795919820666, 0.05540479102637619, 0.0554546540370211, 0.055738945957273245, 0.05521905701607466, 0.05570366105530411, 0.16655763902235776, 0.052436962025240064, 0.05093453999143094, 0.050913163111545146, 0.0509051630506292, 0.05128363403491676, 0.05100734205916524, 0.05168098502326757, 0.05152839201036841, 0.05065455997828394, 0.05191515898332, 0.05735192890278995, 0.055054625030606985, 0.05505807290319353, 0.059353357064537704, 0.057179242954589427, 0.054779430967755616, 0.055218418943695724, 0.0550902730319649, 0.05646848899777979, 0.05465767893474549, 0.05407344503328204, 0.05410203407518566, 0.10085104906465858, 0.0555223049595952, 0.055436923052184284, 0.05595084500964731, 0.055980134988203645, 0.05591650295536965, 0.05617454298771918, 0.055945920990779996, 0.05646905803587288, 0.056442029075697064, 0.0560599589953199, 0.13732124597299844, 0.056115605984814465, 0.05587958393152803, 0.056152004981413484, 0.05649901204742491, 0.05695955909322947, 0.05604346003383398, 0.057389187975786626, 0.05754992691799998, 0.056441627093590796, 0.057732764980755746, 0.0567826310871169, 0.056356362998485565, 0.05620750703383237, 0.05642447201535106, 0.05650117702316493, 0.0564726380398497, 0.058178116916678846, 0.0579554489813745, 0.05685407994315028, 0.061681463033892214, 0.06483864306937903, 0.05625624896492809, 0.05140335392206907, 0.05247954302467406, 0.051755190012045205, 0.052530408021993935, 0.0531276649562642, 0.05313097208272666, 0.052808827022090554, 0.05271110904868692, 0.0729359369724989, 0.054358330089598894, 0.05411872698459774, 0.05459462304133922, 0.054475017939694226, 0.054728719987906516, 0.055041332030668855, 0.055222762981429696, 0.05494873598217964, 0.05459699302446097, 0.054801312973722816, 0.05640839401166886, 0.05218096298631281, 0.05241739796474576, 0.052470244001597166, 0.05257928802166134, 0.053008908056654036, 0.052940089954063296, 0.0523014540085569, 0.054487284971401095, 0.05308699293527752, 0.05258349794894457, 0.05229134589899331, 0.05567532707937062, 0.05672617699019611, 0.052520144963636994, 0.05267783091403544, 0.05861803097650409, 0.0569059019908309, 0.05278392299078405, 0.05274997605010867, 0.05287216801661998, 0.05279217101633549, 0.053106190986, 0.05291169905103743, 0.05297235993202776, 0.052751403069123626, 0.05333927401807159, 0.05320798105094582, 0.053089449065737426, 0.05297767498996109, 0.05304955504834652, 0.05314005701802671, 0.05311556009110063, 0.056684300070628524, 0.053032311028800905, 0.053123258985579014, 0.05299738608300686, 0.05311915499623865, 0.053100030054338276, 0.053438905044458807, 0.0536126249935478, 0.053251396981067955, 0.053268415038473904, 0.05298346106428653, 0.05347390298265964]
[0.001228068907618184, 0.0012933318847155367, 0.0012642487497280606, 0.0013493499983186748, 0.001347108069405129, 0.0012390305002389307, 0.0012371380448299037, 0.001241304477761415, 0.0012441502291370523, 0.0012389850665137849, 0.0012377386129545894, 0.001244097749639133, 0.0012499851132319732, 0.0012647405912337656, 0.0012435155010528185, 0.0012326683182354, 0.0012411064314867624, 0.0012476796824061735, 0.0012552034088664434, 0.0012220342733516272, 0.0012242759085810658, 0.0012135171802418138, 0.0012182887955780395, 0.0012212201148610222, 0.001224888523045758, 0.0012252408407882533, 0.0012317974998785014, 0.001226753546771678, 0.0012495312972036613, 0.0012304025691595268, 0.0012330442047889599, 0.0012538236359515313, 0.0012523174783299592, 0.0012592220022766428, 0.0012511838418008251, 0.0012618632965975187, 0.001258364206560972, 0.001241905683524568, 0.0011181741349653087, 0.0012136670702602714, 0.001211579817622392, 0.0012197266597385433, 0.001222207930616357, 0.001217082976257767, 0.001227777864022011, 0.0012133365698074076, 0.0012281495437491685, 0.0012187526365530423, 0.0012160465015437114, 0.0012107597034297544, 0.0012247077512173828, 0.0012178197264967655, 0.0012150171122894708, 0.001222807181131264, 0.0012439080905592577, 0.001233008658428761, 0.0012573939113115723, 0.001230451659384099, 0.0012441609552214768, 0.0012394927061078224, 0.0012436123850586062, 0.0024207400909455664, 0.0011743075209034776, 0.00117676761477593, 0.001167142888086594, 0.0011728950670327652, 0.0011785267270170152, 0.0011915343850639395, 0.0011706612289840864, 0.001197297247761691, 0.0011878530680074948, 0.0011674900703259152, 0.001177731702972034, 0.0012156827936202965, 0.0012193422510542653, 0.0012370765219781208, 0.0012342321384825152, 0.0012324998176402667, 0.001163301113675433, 0.0011502712943845174, 0.0012142855451780963, 0.0011586451119827952, 0.0011525917269120162, 0.0011489759093489158, 0.0011743184083818712, 0.0011793141364416276, 0.0011789004069710659, 0.0011856816814873707, 0.0011885091159704396, 0.0012888290670658039, 0.0012105746348176829, 0.0011965229562272064, 0.0012899916116359898, 0.001185957659882578, 0.0014102600213267249, 0.001253336522495374, 0.0012548390685961667, 0.001253256658938798, 0.001247745361814106, 0.0012591997960540043, 0.001260333046295934, 0.0012667942263016646, 0.0012549785685471513, 0.0012659922967114571, 0.0037854008868717674, 0.0011917491369372742, 0.0011576031816234304, 0.0011571173434442078, 0.0011569355238779363, 0.0011655371371571991, 0.0011592577740719373, 0.0011745678414378992, 0.0011710998184174639, 0.0011512399995064532, 0.0011798899768936362, 0.0013337657884369756, 0.0012803401169908602, 0.0012804203000742682, 0.0013803106294078536, 0.0013297498361532424, 0.001273940255064084, 0.0012841492777603658, 0.0012811691402782534, 0.0013132206743669717, 0.0012711088124359416, 0.001257521977518187, 0.001258186838957806, 0.0023453732340618276, 0.0012912163944091908, 0.0012892307686554485, 0.0013011824420848211, 0.0013018636043768289, 0.0013003837896597592, 0.0013063847206446321, 0.0013010679300181395, 0.0013132339078109972, 0.0013126053273417922, 0.0013037199766353467, 0.003193517348209266, 0.0013050140926701038, 0.0012995252077099542, 0.0013058605809631043, 0.0013139305127308118, 0.0013246409091448716, 0.0013033362798566042, 0.0013346322785066657, 0.00133837039344186, 0.0013125959789207161, 0.0013426224414129244, 0.0013205263043515557, 0.0013106130929880363, 0.0013071513263681947, 0.0013121970236128152, 0.0013139808610038355, 0.0013133171637174348, 0.0013529794631785778, 0.0013478011391017326, 0.0013221879056546577, 0.0014344526286951679, 0.001507875420218117, 0.0013082848596494905, 0.0011954268353969553, 0.0012204544889459082, 0.0012036090700475628, 0.0012216373958603241, 0.0012355270920061442, 0.0012356040019238757, 0.0012281122563276873, 0.0012258397453183004, 0.0016961845807557882, 0.0012641472113860209, 0.001258575046153436, 0.0012696423963102143, 0.0012668608823184703, 0.0012727609299513143, 0.0012800309774574153, 0.0012842503018937138, 0.001277877580980922, 0.0012696975121967667, 0.0012744491389237863, 0.0013118231165504387, 0.0012135107671235536, 0.0012190092549940875, 0.0012202382325952829, 0.001222774140038636, 0.0012327653036431172, 0.0012311648826526349, 0.001216312883919928, 0.0012671461621256068, 0.0012345812310529656, 0.0012228720453242923, 0.0012160778116044957, 0.0012947750483574562, 0.0013192134183766537, 0.0012213987200845812, 0.0012250658352101265, 0.0013632100227093974, 0.001323393069554207, 0.0012275330928089314, 0.0012267436290722947, 0.0012295853027120926, 0.0012277249073566392, 0.0012350276973488372, 0.0012305046290938938, 0.0012319153472564596, 0.0012267768155610145, 0.001240448232978409, 0.0012373949081615307, 0.0012346383503659866, 0.001232038953254909, 0.0012337105825196864, 0.0012358152794889933, 0.0012352455835139683, 0.0013182395365262448, 0.0012333095588093234, 0.0012354246275716049, 0.0012324973507676013, 0.0012353291859590384, 0.001234884419868332, 0.0012427652335920652, 0.0012468052324080884, 0.0012384045809550688, 0.0012388003497319513, 0.0012321735131229426, 0.0012435791391316195]
[814.2865549291373, 773.196742319506, 790.9835783623275, 741.0975664179241, 742.330940413408, 807.0826342105083, 808.3172320009703, 805.604118824588, 803.7614562781572, 807.1122300236974, 807.9250251496261, 803.7953611684155, 800.0095276450058, 790.6759749242264, 804.1717205401566, 811.2482370209113, 805.7326709701013, 801.4877649297625, 796.6836234958014, 818.3076545450216, 816.8093425598798, 824.0509621798129, 820.8234399180628, 818.8532008529866, 816.4008243896683, 816.1660685067063, 811.8217483788003, 815.1596566658379, 800.3000823091907, 812.7421260856827, 811.0009325830729, 797.5603357015171, 798.5195585815509, 794.1411428580698, 799.243058127016, 792.4788704896913, 794.6824892079021, 805.2141263754975, 894.3150880797515, 823.9491904361792, 825.3686512890279, 819.8558193475551, 818.1913854017474, 821.6366669384824, 814.479580796606, 824.1736257555722, 814.2330916374426, 820.5110454802928, 822.3369737345972, 825.9277189084429, 816.5213284605907, 821.1395974645973, 823.033675727981, 817.790421442294, 803.9179161142064, 811.0243128984292, 795.2957231651553, 812.7097008431431, 803.7545269389899, 806.7816737220968, 804.1090712946495, 413.09680611328645, 851.5656948451028, 849.7854524917492, 856.7931229392085, 852.5911891929413, 848.5170315408234, 839.2540010050474, 854.2180908031027, 835.2144815078026, 841.8549624806714, 856.5383341725906, 849.0898202676178, 822.5830004733435, 820.114286317383, 808.3574316008934, 810.2203538707857, 811.3591464172313, 859.6226619611103, 869.3601282426821, 823.5295264536253, 863.0770454714083, 867.6099061366381, 870.3402672443017, 851.557799709476, 847.9504901190479, 848.2480742960192, 843.3966853106447, 841.3902649652641, 775.8980810982462, 826.0539839830725, 835.7549638271304, 775.1988392636, 843.2004226010988, 709.0890934135919, 797.8703102092766, 796.9149391552941, 797.9211543521783, 801.4455758393625, 794.1551476848495, 793.4410693577844, 789.3941882885308, 796.8263562920187, 789.8942217876057, 264.17281283684434, 839.102768364441, 863.8538800468683, 864.2165858679972, 864.3524028444527, 857.9735197790848, 862.6209134552204, 851.376961568951, 853.8981769729286, 868.6286095242598, 847.5366513687633, 749.7568228765923, 781.0424642088589, 780.9935533996119, 724.4746064362303, 752.0211492507816, 784.966167781311, 778.7256647794568, 780.5370645930583, 761.48664083593, 786.714709406828, 795.2147301421915, 794.7945162328435, 426.37137043989924, 774.4635247274414, 775.6563249284765, 768.5317351790798, 768.1296232862092, 769.0037417812216, 765.4712920299256, 768.5993766567269, 761.4789673432052, 761.8436244085178, 767.0358803435764, 313.13435656165774, 766.2752499124094, 769.5118140587801, 765.7785330057787, 761.0752549780175, 754.9215739120989, 767.2616925157812, 749.270054459428, 747.1773172061287, 761.8490503241152, 744.8110274007028, 757.2738208278629, 763.0016862719746, 765.0223656800413, 762.0806799627874, 761.046092586185, 761.4306944481187, 739.1095188175901, 741.9492171274383, 756.3221503715599, 697.1300271586088, 663.1847608838588, 764.3595296730066, 836.5212912992191, 819.3668908241616, 830.8345499261509, 818.573500932952, 809.3711635058401, 809.3207843637341, 814.2578130359266, 815.7673169100426, 589.5584780958324, 791.0471114385423, 794.5493620394628, 787.623351981756, 789.3526542313859, 785.6935080795197, 781.2310933180275, 778.6644071840453, 782.5475733226198, 787.5891622957112, 784.6527330580285, 762.297894726534, 824.055317094838, 820.338316467376, 819.5121028728416, 817.8125193000918, 811.1844136469125, 812.238891874033, 822.1568752747272, 789.174942788387, 809.9912544005768, 817.74704379215, 822.3158012237702, 772.3349328275934, 758.027462478771, 818.7334598899453, 816.2826611097822, 733.5626817153876, 755.6333964608535, 814.6419887644141, 815.166246884228, 813.28233006226, 814.5147125450573, 809.6984400808519, 812.6747160117307, 811.7440879578721, 815.1441951914393, 806.160203557165, 808.1494383112971, 809.9537809623099, 811.6626486184645, 810.5628776869496, 809.1824211895953, 809.5556165886036, 758.5874738935134, 810.8264408210961, 809.4382916468453, 811.360770371797, 809.500828901454, 809.7923853526501, 804.657205536414, 802.0498903975507, 807.4905530701373, 807.2325780472839, 811.574010762089, 804.1305683997653]
Elapsed: 0.0556511733862054~0.010603031887213208
Time per graph: 0.0012793033238668156~0.000244210999977682
Speed: 794.2569354940601~69.96925538482432
Total Time: 0.0543
best val loss: 0.337799996137619 test_score: 0.8605

Testing...
Test loss: 0.3785 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.35388022603001446, 0.1640924260718748, 0.16747411794494838, 0.17407483293209225, 0.17448691104073077, 0.1721685560187325, 0.2884179169777781, 0.16737152298446745, 0.16701822692994028, 0.16697604989167303, 0.16508857801090926, 0.16457538993563503, 0.16619894094765186, 0.16671766992658377, 0.16753240500111133, 0.164621019968763, 0.16708064498379827, 0.16525445494335145, 0.16663702810183167, 0.29217719298321754, 0.1625385438092053, 0.162223165971227, 0.16242288402281702, 0.1636550968978554, 0.16412331291940063, 0.16421422292478383, 0.1641853938344866, 0.16391908307559788, 0.16435342596378177, 0.2930149359162897, 0.162615081993863, 0.16581235802732408, 0.16628121805842966, 0.1669620069442317, 0.16788284399081022, 0.16770464892033488, 0.16799871088005602, 0.16723406093660742, 0.16021263704169542, 0.29567900707479566, 0.16250477393623441, 0.16413217701483518, 0.16330884513445199, 0.16495695209596306, 0.16590503603219986, 0.1659004760440439, 0.1657963899197057, 0.1649516219040379, 0.16399451403412968, 0.2866682519670576, 0.1665690578520298, 0.16516766394488513, 0.1646501610521227, 0.16639862197916955, 0.1674750359961763, 0.16639281599782407, 0.1685670220758766, 0.16934920300263911, 0.16921799501869828, 0.1674647710751742, 0.16804768494330347, 0.24389016802888364, 0.15808181487955153, 0.15769422403536737, 0.15770868014078587, 0.15773426496889442, 0.15772662602830678, 0.1589079120894894, 0.15782158100046217, 0.1615420349407941, 0.1616310611134395, 0.15663455694448203, 0.15805481013376266, 0.295314752147533, 0.16255746909882873, 0.16455299907829612, 0.16385183203965425, 0.16627535491716117, 0.16328006784897298, 0.15455255389679223, 0.16065649595111609, 0.15648630494251847, 0.15656128898262978, 0.15555244695860893, 0.15657884906977415, 0.2772407609736547, 0.16014930605888367, 0.15956903609912843, 0.15964680793695152, 0.16540854098275304, 0.16141846508253366, 0.16687758709304035, 0.16972047602757812, 0.15956318809185177, 0.3030579958576709, 0.1751237070420757, 0.16704569896683097, 0.1676835670368746, 0.16752498503774405, 0.1682206679834053, 0.16863838105928153, 0.17193744098767638, 0.17091186391189694, 0.16890940407756716, 0.2771728200605139, 0.16972917306702584, 0.1560840648598969, 0.15678411512635648, 0.15744406706653535, 0.15678492898587137, 0.15789153787773103, 0.15757182706147432, 0.15842352306935936, 0.1562279909849167, 0.15533298102673143, 0.18763383815530688, 0.3115221788175404, 0.16968554304912686, 0.18357378605287522, 0.18003788881469518, 0.16931301192380488, 0.1697102909674868, 0.16966367093846202, 0.17105429514776915, 0.17000459996052086, 0.1669003029819578, 0.16659897903446108, 0.2120474100811407, 0.2077844380401075, 0.17202676401939243, 0.17155980109237134, 0.17238204402383417, 0.17267546604853123, 0.1724409011658281, 0.1734675350598991, 0.17425789404660463, 0.17524749180302024, 0.17319052398670465, 0.25430186791345477, 0.18801467097364366, 0.1711340630427003, 0.17156895506195724, 0.17392364097759128, 0.17487473285291344, 0.17533943592570722, 0.1778089200379327, 0.17820194317027926, 0.17529475397896022, 0.17678706592414528, 0.25323069805745035, 0.17365510505624115, 0.17384423990733922, 0.17443228792399168, 0.1747505731182173, 0.1747984930407256, 0.17714941094163805, 0.17702029494103044, 0.17540568602271378, 0.1784339729929343, 0.25857039191760123, 0.17376960394904017, 0.15743724605999887, 0.1586037860251963, 0.16145435196813196, 0.16235321608837694, 0.16197784303221852, 0.16623076505493373, 0.16471890616230667, 0.16299780120607466, 0.2611376449931413, 0.16989398619625717, 0.1685600298224017, 0.1674117639195174, 0.16844416211824864, 0.16960522206500173, 0.170214076875709, 0.1720846270909533, 0.17387628613505512, 0.1710794969694689, 0.16992137616034597, 0.27698873600456864, 0.1625594119541347, 0.16156083799432963, 0.16247712296899408, 0.16256885102484375, 0.16291455691680312, 0.16552865807898343, 0.1650929938768968, 0.17762614507228136, 0.1645109939854592, 0.16565978212747723, 0.16488672408740968, 0.16663771192543209, 0.16881952609401196, 0.16915835486724973, 0.1645391118945554, 0.16966564522590488, 0.17453081195708364, 0.165261126938276, 0.16568616894073784, 0.1656139639671892, 0.16577387799043208, 0.1655626689316705, 0.1657376082148403, 0.16560597205534577, 0.1658113410230726, 0.16587726213037968, 0.16572498821187764, 0.16649417497683316, 0.16620398487430066, 0.16587380215059966, 0.16582606185693294, 0.1674165140138939, 0.17496793600730598, 0.16529001912567765, 0.1667274640640244, 0.16736161394510418, 0.1651117659639567, 0.1665033120661974, 0.16460927797015756, 0.16763299389276654, 0.16787132597528398, 0.16696794796735048, 0.16626920690760016, 0.16657784394919872]
Total Epoch List: [115, 110]
Total Time List: [0.05252736108377576, 0.05427345901262015]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7adf8d420>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6934;  Loss pred: 0.6934; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6935;  Loss pred: 0.6935; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6927;  Loss pred: 0.6927; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6880;  Loss pred: 0.6880; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6856;  Loss pred: 0.6856; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6853;  Loss pred: 0.6853; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6785;  Loss pred: 0.6785; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6760;  Loss pred: 0.6760; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6720;  Loss pred: 0.6720; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6696;  Loss pred: 0.6696; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6653;  Loss pred: 0.6653; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6571;  Loss pred: 0.6571; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6515;  Loss pred: 0.6515; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6489;  Loss pred: 0.6489; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6450;  Loss pred: 0.6450; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6396;  Loss pred: 0.6396; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6293;  Loss pred: 0.6293; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6222;  Loss pred: 0.6222; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6198;  Loss pred: 0.6198; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6075;  Loss pred: 0.6075; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5955;  Loss pred: 0.5955; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5912;  Loss pred: 0.5912; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5783;  Loss pred: 0.5783; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5671;  Loss pred: 0.5671; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5624;  Loss pred: 0.5624; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.4884 time: 0.04s
Epoch 29/1000, LR 0.000270
Train loss: 0.5571;  Loss pred: 0.5571; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5386;  Loss pred: 0.5386; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5299;  Loss pred: 0.5299; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5160;  Loss pred: 0.5160; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5086;  Loss pred: 0.5086; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.4884 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4914;  Loss pred: 0.4914; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4775;  Loss pred: 0.4775; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6878 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.4884 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4619;  Loss pred: 0.4619; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.5000 time: 0.05s
Test loss: 0.6876 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4550;  Loss pred: 0.4550; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5000 time: 0.05s
Test loss: 0.6866 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4427;  Loss pred: 0.4427; Loss self: 0.0000; time: 0.08s
Val loss: 0.6848 score: 0.5227 time: 0.05s
Test loss: 0.6855 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4208;  Loss pred: 0.4208; Loss self: 0.0000; time: 0.08s
Val loss: 0.6836 score: 0.5227 time: 0.05s
Test loss: 0.6842 score: 0.5349 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4045;  Loss pred: 0.4045; Loss self: 0.0000; time: 0.08s
Val loss: 0.6821 score: 0.5227 time: 0.05s
Test loss: 0.6827 score: 0.5349 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3896;  Loss pred: 0.3896; Loss self: 0.0000; time: 0.08s
Val loss: 0.6805 score: 0.5227 time: 0.05s
Test loss: 0.6812 score: 0.5349 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3845;  Loss pred: 0.3845; Loss self: 0.0000; time: 0.08s
Val loss: 0.6787 score: 0.5455 time: 0.05s
Test loss: 0.6794 score: 0.5349 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3635;  Loss pred: 0.3635; Loss self: 0.0000; time: 0.08s
Val loss: 0.6767 score: 0.5682 time: 0.05s
Test loss: 0.6774 score: 0.5349 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3502;  Loss pred: 0.3502; Loss self: 0.0000; time: 0.08s
Val loss: 0.6744 score: 0.5682 time: 0.05s
Test loss: 0.6751 score: 0.5349 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3327;  Loss pred: 0.3327; Loss self: 0.0000; time: 0.08s
Val loss: 0.6720 score: 0.5682 time: 0.05s
Test loss: 0.6726 score: 0.5349 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3146;  Loss pred: 0.3146; Loss self: 0.0000; time: 0.08s
Val loss: 0.6694 score: 0.5682 time: 0.05s
Test loss: 0.6699 score: 0.5349 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2950;  Loss pred: 0.2950; Loss self: 0.0000; time: 0.08s
Val loss: 0.6664 score: 0.5682 time: 0.05s
Test loss: 0.6670 score: 0.5581 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2870;  Loss pred: 0.2870; Loss self: 0.0000; time: 0.08s
Val loss: 0.6632 score: 0.5682 time: 0.05s
Test loss: 0.6638 score: 0.5581 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2773;  Loss pred: 0.2773; Loss self: 0.0000; time: 0.08s
Val loss: 0.6596 score: 0.5455 time: 0.05s
Test loss: 0.6602 score: 0.5581 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2651;  Loss pred: 0.2651; Loss self: 0.0000; time: 0.08s
Val loss: 0.6557 score: 0.5909 time: 0.05s
Test loss: 0.6562 score: 0.5581 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2456;  Loss pred: 0.2456; Loss self: 0.0000; time: 0.08s
Val loss: 0.6512 score: 0.5909 time: 0.05s
Test loss: 0.6518 score: 0.5349 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2293;  Loss pred: 0.2293; Loss self: 0.0000; time: 0.08s
Val loss: 0.6461 score: 0.6136 time: 0.05s
Test loss: 0.6468 score: 0.5349 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2207;  Loss pred: 0.2207; Loss self: 0.0000; time: 0.08s
Val loss: 0.6406 score: 0.6136 time: 0.05s
Test loss: 0.6414 score: 0.5814 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2090;  Loss pred: 0.2090; Loss self: 0.0000; time: 0.08s
Val loss: 0.6346 score: 0.6136 time: 0.05s
Test loss: 0.6356 score: 0.5814 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1916;  Loss pred: 0.1916; Loss self: 0.0000; time: 0.08s
Val loss: 0.6281 score: 0.6364 time: 0.05s
Test loss: 0.6294 score: 0.6279 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1739;  Loss pred: 0.1739; Loss self: 0.0000; time: 0.08s
Val loss: 0.6210 score: 0.6818 time: 0.05s
Test loss: 0.6228 score: 0.6047 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1649;  Loss pred: 0.1649; Loss self: 0.0000; time: 0.08s
Val loss: 0.6134 score: 0.7273 time: 0.05s
Test loss: 0.6158 score: 0.6512 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1538;  Loss pred: 0.1538; Loss self: 0.0000; time: 0.08s
Val loss: 0.6051 score: 0.7727 time: 0.05s
Test loss: 0.6081 score: 0.6744 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1437;  Loss pred: 0.1437; Loss self: 0.0000; time: 0.08s
Val loss: 0.5961 score: 0.7727 time: 0.05s
Test loss: 0.5998 score: 0.6744 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1348;  Loss pred: 0.1348; Loss self: 0.0000; time: 0.08s
Val loss: 0.5864 score: 0.7727 time: 0.05s
Test loss: 0.5911 score: 0.6977 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1255;  Loss pred: 0.1255; Loss self: 0.0000; time: 0.08s
Val loss: 0.5760 score: 0.8182 time: 0.05s
Test loss: 0.5817 score: 0.7209 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1122;  Loss pred: 0.1122; Loss self: 0.0000; time: 0.08s
Val loss: 0.5650 score: 0.8409 time: 0.05s
Test loss: 0.5718 score: 0.7674 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1076;  Loss pred: 0.1076; Loss self: 0.0000; time: 0.08s
Val loss: 0.5534 score: 0.8636 time: 0.05s
Test loss: 0.5613 score: 0.7907 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0926;  Loss pred: 0.0926; Loss self: 0.0000; time: 0.08s
Val loss: 0.5412 score: 0.8864 time: 0.05s
Test loss: 0.5502 score: 0.7907 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0905;  Loss pred: 0.0905; Loss self: 0.0000; time: 0.08s
Val loss: 0.5283 score: 0.9318 time: 0.05s
Test loss: 0.5386 score: 0.7907 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0845;  Loss pred: 0.0845; Loss self: 0.0000; time: 0.08s
Val loss: 0.5152 score: 0.9091 time: 0.05s
Test loss: 0.5268 score: 0.8140 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0793;  Loss pred: 0.0793; Loss self: 0.0000; time: 0.08s
Val loss: 0.5023 score: 0.9091 time: 0.05s
Test loss: 0.5151 score: 0.8605 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0669;  Loss pred: 0.0669; Loss self: 0.0000; time: 0.08s
Val loss: 0.4891 score: 0.9091 time: 0.05s
Test loss: 0.5033 score: 0.8837 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0655;  Loss pred: 0.0655; Loss self: 0.0000; time: 0.08s
Val loss: 0.4760 score: 0.8864 time: 0.05s
Test loss: 0.4919 score: 0.8837 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0578;  Loss pred: 0.0578; Loss self: 0.0000; time: 0.08s
Val loss: 0.4629 score: 0.8864 time: 0.05s
Test loss: 0.4806 score: 0.8837 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0482;  Loss pred: 0.0482; Loss self: 0.0000; time: 0.08s
Val loss: 0.4497 score: 0.8864 time: 0.05s
Test loss: 0.4695 score: 0.8837 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0464;  Loss pred: 0.0464; Loss self: 0.0000; time: 0.08s
Val loss: 0.4372 score: 0.8864 time: 0.05s
Test loss: 0.4592 score: 0.8605 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0444;  Loss pred: 0.0444; Loss self: 0.0000; time: 0.08s
Val loss: 0.4248 score: 0.8864 time: 0.05s
Test loss: 0.4492 score: 0.8605 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0385;  Loss pred: 0.0385; Loss self: 0.0000; time: 0.08s
Val loss: 0.4135 score: 0.8864 time: 0.05s
Test loss: 0.4398 score: 0.8605 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0371;  Loss pred: 0.0371; Loss self: 0.0000; time: 0.08s
Val loss: 0.4026 score: 0.8864 time: 0.05s
Test loss: 0.4310 score: 0.8605 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0349;  Loss pred: 0.0349; Loss self: 0.0000; time: 0.08s
Val loss: 0.3927 score: 0.8636 time: 0.05s
Test loss: 0.4229 score: 0.8605 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0320;  Loss pred: 0.0320; Loss self: 0.0000; time: 0.08s
Val loss: 0.3834 score: 0.8636 time: 0.05s
Test loss: 0.4156 score: 0.8605 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0285;  Loss pred: 0.0285; Loss self: 0.0000; time: 0.08s
Val loss: 0.3748 score: 0.8636 time: 0.05s
Test loss: 0.4089 score: 0.8605 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0275;  Loss pred: 0.0275; Loss self: 0.0000; time: 0.08s
Val loss: 0.3670 score: 0.8636 time: 0.05s
Test loss: 0.4033 score: 0.8605 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0257;  Loss pred: 0.0257; Loss self: 0.0000; time: 0.08s
Val loss: 0.3600 score: 0.8636 time: 0.05s
Test loss: 0.3987 score: 0.8605 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0233;  Loss pred: 0.0233; Loss self: 0.0000; time: 0.08s
Val loss: 0.3531 score: 0.8636 time: 0.05s
Test loss: 0.3950 score: 0.8605 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0227;  Loss pred: 0.0227; Loss self: 0.0000; time: 0.08s
Val loss: 0.3472 score: 0.8636 time: 0.05s
Test loss: 0.3923 score: 0.8605 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0197;  Loss pred: 0.0197; Loss self: 0.0000; time: 0.08s
Val loss: 0.3420 score: 0.8636 time: 0.05s
Test loss: 0.3903 score: 0.8605 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.08s
Val loss: 0.3378 score: 0.8409 time: 0.05s
Test loss: 0.3894 score: 0.8605 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.08s
Val loss: 0.3344 score: 0.8409 time: 0.05s
Test loss: 0.3892 score: 0.8605 time: 0.04s
Epoch 86/1000, LR 0.000266
Train loss: 0.0160;  Loss pred: 0.0160; Loss self: 0.0000; time: 0.08s
Val loss: 0.3314 score: 0.8409 time: 0.05s
Test loss: 0.3898 score: 0.8605 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0152;  Loss pred: 0.0152; Loss self: 0.0000; time: 0.08s
Val loss: 0.3292 score: 0.8409 time: 0.05s
Test loss: 0.3912 score: 0.8605 time: 0.04s
Epoch 88/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.08s
Val loss: 0.3271 score: 0.8409 time: 0.05s
Test loss: 0.3936 score: 0.8605 time: 0.04s
Epoch 89/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.08s
Val loss: 0.3257 score: 0.8409 time: 0.05s
Test loss: 0.3966 score: 0.8605 time: 0.04s
Epoch 90/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.08s
Val loss: 0.3244 score: 0.8409 time: 0.05s
Test loss: 0.4005 score: 0.8605 time: 0.04s
Epoch 91/1000, LR 0.000266
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.11s
Val loss: 0.3240 score: 0.8409 time: 0.10s
Test loss: 0.4049 score: 0.8605 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.08s
Val loss: 0.3239 score: 0.8409 time: 0.05s
Test loss: 0.4102 score: 0.8605 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.08s
Val loss: 0.3245 score: 0.8409 time: 0.05s
Test loss: 0.4158 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.08s
Val loss: 0.3248 score: 0.8409 time: 0.05s
Test loss: 0.4219 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.08s
Val loss: 0.3264 score: 0.8409 time: 0.05s
Test loss: 0.4289 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.08s
Val loss: 0.3282 score: 0.8409 time: 0.05s
Test loss: 0.4362 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.08s
Val loss: 0.3303 score: 0.8409 time: 0.05s
Test loss: 0.4439 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.08s
Val loss: 0.3325 score: 0.8409 time: 0.05s
Test loss: 0.4519 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.08s
Val loss: 0.3352 score: 0.8409 time: 0.05s
Test loss: 0.4602 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.08s
Val loss: 0.3376 score: 0.8409 time: 0.05s
Test loss: 0.4684 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.08s
Val loss: 0.3404 score: 0.8409 time: 0.05s
Test loss: 0.4764 score: 0.8837 time: 0.18s
     INFO: Early stopping counter 9 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.08s
Val loss: 0.3427 score: 0.8409 time: 0.05s
Test loss: 0.4842 score: 0.8837 time: 0.04s
     INFO: Early stopping counter 10 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.07s
Val loss: 0.3455 score: 0.8409 time: 0.04s
Test loss: 0.4926 score: 0.8837 time: 0.04s
     INFO: Early stopping counter 11 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.07s
Val loss: 0.3483 score: 0.8409 time: 0.04s
Test loss: 0.5009 score: 0.8837 time: 0.04s
     INFO: Early stopping counter 12 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.07s
Val loss: 0.3514 score: 0.8409 time: 0.04s
Test loss: 0.5091 score: 0.8837 time: 0.04s
     INFO: Early stopping counter 13 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0057;  Loss pred: 0.0057; Loss self: 0.0000; time: 0.07s
Val loss: 0.3546 score: 0.8636 time: 0.04s
Test loss: 0.5174 score: 0.8837 time: 0.04s
     INFO: Early stopping counter 14 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.3570 score: 0.8636 time: 0.04s
Test loss: 0.5252 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.08s
Val loss: 0.3603 score: 0.8636 time: 0.05s
Test loss: 0.5332 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.08s
Val loss: 0.3635 score: 0.8636 time: 0.05s
Test loss: 0.5411 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.08s
Val loss: 0.3673 score: 0.8636 time: 0.05s
Test loss: 0.5491 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.08s
Val loss: 0.3696 score: 0.8636 time: 0.05s
Test loss: 0.5570 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.08s
Val loss: 0.3725 score: 0.8636 time: 0.05s
Test loss: 0.5642 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 091,   Train_Loss: 0.0115,   Val_Loss: 0.3239,   Val_Precision: 0.9412,   Val_Recall: 0.7273,   Val_accuracy: 0.8205,   Val_Score: 0.8409,   Val_Loss: 0.3239,   Test_Precision: 0.8947,   Test_Recall: 0.8095,   Test_accuracy: 0.8500,   Test_Score: 0.8605,   Test_loss: 0.4102


[0.054035031935200095, 0.05690660292748362, 0.055626944988034666, 0.059371399926021695, 0.059272755053825676, 0.05451734201051295, 0.05443407397251576, 0.054617397021502256, 0.054742610082030296, 0.054515342926606536, 0.054460498970001936, 0.05474030098412186, 0.05499934498220682, 0.055648586014285684, 0.054714682046324015, 0.0542374060023576, 0.054608682985417545, 0.054897906025871634, 0.05522894999012351, 0.0537695080274716, 0.0538681399775669, 0.0533947559306398, 0.05360470700543374, 0.05373368505388498, 0.05389509501401335, 0.053910596994683146, 0.05419908999465406, 0.053977156057953835, 0.0549793770769611, 0.054137713043019176, 0.05425394501071423, 0.05516823998186737, 0.05510196904651821, 0.05540576810017228, 0.05505208903923631, 0.05552198505029082, 0.05536802508868277, 0.05464385007508099, 0.04919966193847358, 0.05340135109145194, 0.05330951197538525, 0.05366797302849591, 0.05377714894711971, 0.053551650955341756, 0.05402222601696849, 0.05338680907152593, 0.054038579924963415, 0.05362511600833386, 0.05350604606792331, 0.0532734269509092, 0.053887141053564847, 0.053584067965857685, 0.05346075294073671, 0.05380351596977562, 0.05473195598460734, 0.05425238097086549, 0.05532533209770918, 0.05413987301290035, 0.05474308202974498, 0.05453767906874418, 0.05471894494257867, 0.10651256400160491, 0.051669530919753015, 0.05177777505014092, 0.051354287075810134, 0.05160738294944167, 0.05185517598874867, 0.05242751294281334, 0.0515090940752998, 0.05268107890151441, 0.052265534992329776, 0.051369563094340265, 0.0518201949307695, 0.053490042919293046, 0.05365105904638767, 0.05443136696703732, 0.054306214093230665, 0.05422999197617173, 0.05118524900171906, 0.05061193695291877, 0.05342856398783624, 0.050980384927242994, 0.050714035984128714, 0.0505549400113523, 0.05167000996880233, 0.05188982200343162, 0.0518716179067269, 0.05216999398544431, 0.05229440110269934, 0.05670847895089537, 0.05326528393197805, 0.05264701007399708, 0.05675963091198355, 0.05218213703483343, 0.06205144093837589, 0.05514680698979646, 0.05521291901823133, 0.055143292993307114, 0.054900795919820666, 0.05540479102637619, 0.0554546540370211, 0.055738945957273245, 0.05521905701607466, 0.05570366105530411, 0.16655763902235776, 0.052436962025240064, 0.05093453999143094, 0.050913163111545146, 0.0509051630506292, 0.05128363403491676, 0.05100734205916524, 0.05168098502326757, 0.05152839201036841, 0.05065455997828394, 0.05191515898332, 0.05735192890278995, 0.055054625030606985, 0.05505807290319353, 0.059353357064537704, 0.057179242954589427, 0.054779430967755616, 0.055218418943695724, 0.0550902730319649, 0.05646848899777979, 0.05465767893474549, 0.05407344503328204, 0.05410203407518566, 0.10085104906465858, 0.0555223049595952, 0.055436923052184284, 0.05595084500964731, 0.055980134988203645, 0.05591650295536965, 0.05617454298771918, 0.055945920990779996, 0.05646905803587288, 0.056442029075697064, 0.0560599589953199, 0.13732124597299844, 0.056115605984814465, 0.05587958393152803, 0.056152004981413484, 0.05649901204742491, 0.05695955909322947, 0.05604346003383398, 0.057389187975786626, 0.05754992691799998, 0.056441627093590796, 0.057732764980755746, 0.0567826310871169, 0.056356362998485565, 0.05620750703383237, 0.05642447201535106, 0.05650117702316493, 0.0564726380398497, 0.058178116916678846, 0.0579554489813745, 0.05685407994315028, 0.061681463033892214, 0.06483864306937903, 0.05625624896492809, 0.05140335392206907, 0.05247954302467406, 0.051755190012045205, 0.052530408021993935, 0.0531276649562642, 0.05313097208272666, 0.052808827022090554, 0.05271110904868692, 0.0729359369724989, 0.054358330089598894, 0.05411872698459774, 0.05459462304133922, 0.054475017939694226, 0.054728719987906516, 0.055041332030668855, 0.055222762981429696, 0.05494873598217964, 0.05459699302446097, 0.054801312973722816, 0.05640839401166886, 0.05218096298631281, 0.05241739796474576, 0.052470244001597166, 0.05257928802166134, 0.053008908056654036, 0.052940089954063296, 0.0523014540085569, 0.054487284971401095, 0.05308699293527752, 0.05258349794894457, 0.05229134589899331, 0.05567532707937062, 0.05672617699019611, 0.052520144963636994, 0.05267783091403544, 0.05861803097650409, 0.0569059019908309, 0.05278392299078405, 0.05274997605010867, 0.05287216801661998, 0.05279217101633549, 0.053106190986, 0.05291169905103743, 0.05297235993202776, 0.052751403069123626, 0.05333927401807159, 0.05320798105094582, 0.053089449065737426, 0.05297767498996109, 0.05304955504834652, 0.05314005701802671, 0.05311556009110063, 0.056684300070628524, 0.053032311028800905, 0.053123258985579014, 0.05299738608300686, 0.05311915499623865, 0.053100030054338276, 0.053438905044458807, 0.0536126249935478, 0.053251396981067955, 0.053268415038473904, 0.05298346106428653, 0.05347390298265964, 0.0508217120077461, 0.05030783999245614, 0.05055248294956982, 0.05049628799315542, 0.050131506053730845, 0.04986598901450634, 0.0502831710036844, 0.050428097951225936, 0.05043968092650175, 0.05019364901818335, 0.050195250078104436, 0.0506631430471316, 0.050758718978613615, 0.05078195396345109, 0.050417175982147455, 0.05073548899963498, 0.05040005000773817, 0.05310375802218914, 0.050734448013827205, 0.051016555982641876, 0.0515270420582965, 0.050829896004870534, 0.050644841976463795, 0.05048262397758663, 0.0508484150050208, 0.05077408906072378, 0.051186997909098864, 0.049951652996242046, 0.05040456599090248, 0.05093582102563232, 0.05249190400354564, 0.05125448200851679, 0.053048382978886366, 0.05099265999160707, 0.05030498304404318, 0.05057355994358659, 0.04993111395742744, 0.051041287020780146, 0.050452660070732236, 0.050314976018853486, 0.0505531340604648, 0.05029065709095448, 0.050236143986694515, 0.05060686403885484, 0.0502449240302667, 0.0504897499922663, 0.05098726402502507, 0.05102154507767409, 0.050336383981630206, 0.050058705965057015, 0.05004407907836139, 0.050210164044983685, 0.050172950024716556, 0.050384739064611495, 0.04996306693647057, 0.05020872701425105, 0.05014085897710174, 0.05041899101343006, 0.04997791606001556, 0.055486866971477866, 0.05572823598049581, 0.05577292793896049, 0.0554622010095045, 0.055876304977573454, 0.05556138092651963, 0.050027988967485726, 0.0500651040347293, 0.050256330985575914, 0.0500900459010154, 0.05021821602713317, 0.04991472989786416, 0.05027390201576054, 0.04999885999131948, 0.049975933972746134, 0.05031885206699371, 0.04991618893109262, 0.050139463040977716, 0.04984869307372719, 0.050227617961354554, 0.05031668010633439, 0.05027850309852511, 0.05030135600827634, 0.05250512610655278, 0.05012323195114732, 0.04967038705945015, 0.050453779054805636, 0.049768017954193056, 0.04928146908059716, 0.049282104009762406, 0.050037889974191785, 0.052736269077286124, 0.05253427801653743, 0.053321239072829485, 0.05371245404239744, 0.05395092302933335, 0.05392731702886522, 0.054701930028386414, 0.0536562540801242, 0.05385932407807559, 0.05335450591519475, 0.18527296197135001, 0.04823811806272715, 0.0480308448895812, 0.04764108103699982, 0.04781452100723982, 0.04759445402305573, 0.05158915591891855, 0.05137357709463686, 0.05236763902939856, 0.052273588022217155, 0.0519308450166136, 0.052076100022532046]
[0.001228068907618184, 0.0012933318847155367, 0.0012642487497280606, 0.0013493499983186748, 0.001347108069405129, 0.0012390305002389307, 0.0012371380448299037, 0.001241304477761415, 0.0012441502291370523, 0.0012389850665137849, 0.0012377386129545894, 0.001244097749639133, 0.0012499851132319732, 0.0012647405912337656, 0.0012435155010528185, 0.0012326683182354, 0.0012411064314867624, 0.0012476796824061735, 0.0012552034088664434, 0.0012220342733516272, 0.0012242759085810658, 0.0012135171802418138, 0.0012182887955780395, 0.0012212201148610222, 0.001224888523045758, 0.0012252408407882533, 0.0012317974998785014, 0.001226753546771678, 0.0012495312972036613, 0.0012304025691595268, 0.0012330442047889599, 0.0012538236359515313, 0.0012523174783299592, 0.0012592220022766428, 0.0012511838418008251, 0.0012618632965975187, 0.001258364206560972, 0.001241905683524568, 0.0011181741349653087, 0.0012136670702602714, 0.001211579817622392, 0.0012197266597385433, 0.001222207930616357, 0.001217082976257767, 0.001227777864022011, 0.0012133365698074076, 0.0012281495437491685, 0.0012187526365530423, 0.0012160465015437114, 0.0012107597034297544, 0.0012247077512173828, 0.0012178197264967655, 0.0012150171122894708, 0.001222807181131264, 0.0012439080905592577, 0.001233008658428761, 0.0012573939113115723, 0.001230451659384099, 0.0012441609552214768, 0.0012394927061078224, 0.0012436123850586062, 0.0024207400909455664, 0.0011743075209034776, 0.00117676761477593, 0.001167142888086594, 0.0011728950670327652, 0.0011785267270170152, 0.0011915343850639395, 0.0011706612289840864, 0.001197297247761691, 0.0011878530680074948, 0.0011674900703259152, 0.001177731702972034, 0.0012156827936202965, 0.0012193422510542653, 0.0012370765219781208, 0.0012342321384825152, 0.0012324998176402667, 0.001163301113675433, 0.0011502712943845174, 0.0012142855451780963, 0.0011586451119827952, 0.0011525917269120162, 0.0011489759093489158, 0.0011743184083818712, 0.0011793141364416276, 0.0011789004069710659, 0.0011856816814873707, 0.0011885091159704396, 0.0012888290670658039, 0.0012105746348176829, 0.0011965229562272064, 0.0012899916116359898, 0.001185957659882578, 0.0014102600213267249, 0.001253336522495374, 0.0012548390685961667, 0.001253256658938798, 0.001247745361814106, 0.0012591997960540043, 0.001260333046295934, 0.0012667942263016646, 0.0012549785685471513, 0.0012659922967114571, 0.0037854008868717674, 0.0011917491369372742, 0.0011576031816234304, 0.0011571173434442078, 0.0011569355238779363, 0.0011655371371571991, 0.0011592577740719373, 0.0011745678414378992, 0.0011710998184174639, 0.0011512399995064532, 0.0011798899768936362, 0.0013337657884369756, 0.0012803401169908602, 0.0012804203000742682, 0.0013803106294078536, 0.0013297498361532424, 0.001273940255064084, 0.0012841492777603658, 0.0012811691402782534, 0.0013132206743669717, 0.0012711088124359416, 0.001257521977518187, 0.001258186838957806, 0.0023453732340618276, 0.0012912163944091908, 0.0012892307686554485, 0.0013011824420848211, 0.0013018636043768289, 0.0013003837896597592, 0.0013063847206446321, 0.0013010679300181395, 0.0013132339078109972, 0.0013126053273417922, 0.0013037199766353467, 0.003193517348209266, 0.0013050140926701038, 0.0012995252077099542, 0.0013058605809631043, 0.0013139305127308118, 0.0013246409091448716, 0.0013033362798566042, 0.0013346322785066657, 0.00133837039344186, 0.0013125959789207161, 0.0013426224414129244, 0.0013205263043515557, 0.0013106130929880363, 0.0013071513263681947, 0.0013121970236128152, 0.0013139808610038355, 0.0013133171637174348, 0.0013529794631785778, 0.0013478011391017326, 0.0013221879056546577, 0.0014344526286951679, 0.001507875420218117, 0.0013082848596494905, 0.0011954268353969553, 0.0012204544889459082, 0.0012036090700475628, 0.0012216373958603241, 0.0012355270920061442, 0.0012356040019238757, 0.0012281122563276873, 0.0012258397453183004, 0.0016961845807557882, 0.0012641472113860209, 0.001258575046153436, 0.0012696423963102143, 0.0012668608823184703, 0.0012727609299513143, 0.0012800309774574153, 0.0012842503018937138, 0.001277877580980922, 0.0012696975121967667, 0.0012744491389237863, 0.0013118231165504387, 0.0012135107671235536, 0.0012190092549940875, 0.0012202382325952829, 0.001222774140038636, 0.0012327653036431172, 0.0012311648826526349, 0.001216312883919928, 0.0012671461621256068, 0.0012345812310529656, 0.0012228720453242923, 0.0012160778116044957, 0.0012947750483574562, 0.0013192134183766537, 0.0012213987200845812, 0.0012250658352101265, 0.0013632100227093974, 0.001323393069554207, 0.0012275330928089314, 0.0012267436290722947, 0.0012295853027120926, 0.0012277249073566392, 0.0012350276973488372, 0.0012305046290938938, 0.0012319153472564596, 0.0012267768155610145, 0.001240448232978409, 0.0012373949081615307, 0.0012346383503659866, 0.001232038953254909, 0.0012337105825196864, 0.0012358152794889933, 0.0012352455835139683, 0.0013182395365262448, 0.0012333095588093234, 0.0012354246275716049, 0.0012324973507676013, 0.0012353291859590384, 0.001234884419868332, 0.0012427652335920652, 0.0012468052324080884, 0.0012384045809550688, 0.0012388003497319513, 0.0012321735131229426, 0.0012435791391316195, 0.0011819002792499093, 0.0011699497672664218, 0.001175639138362089, 0.0011743322789105912, 0.0011658489779937406, 0.0011596741631280543, 0.0011693760698531256, 0.0011727464639819986, 0.0011730158355000408, 0.0011672941632135663, 0.0011673313971652195, 0.0011782126290030605, 0.0011804353250840375, 0.00118097567356863, 0.0011724924647011036, 0.001179895093014767, 0.0011720941862264692, 0.0012349711167950962, 0.001179870884042493, 0.0011864315344800437, 0.001198303303681314, 0.001182090604764431, 0.0011777870227084603, 0.0011740145111066658, 0.0011825212791865302, 0.0011807927688540414, 0.0011903953002116016, 0.001161666348749815, 0.0011721992090907554, 0.0011845539773402865, 0.0012207419535708289, 0.0011919646978724835, 0.0012336833250903806, 0.0011858758137583039, 0.0011698833266056555, 0.0011761293010136417, 0.0011611886966843591, 0.0011870066749018638, 0.0011733176760635403, 0.0011701157213686857, 0.0011756542804759256, 0.0011695501649059182, 0.0011682824182952212, 0.0011769038148570893, 0.0011684866053550396, 0.001174180232378286, 0.0011857503261633736, 0.0011865475599459091, 0.0011706135809681443, 0.0011641559526757445, 0.0011638157925200324, 0.0011676782336042717, 0.001166812791272478, 0.0011717381177816628, 0.0011619317892202457, 0.0011676448142849082, 0.0011660664878395755, 0.0011725346747309315, 0.0011622771176747805, 0.001290392255150648, 0.0012960054879185073, 0.001297044835789779, 0.0012898186281280115, 0.0012994489529668245, 0.001292125137826038, 0.001163441603895017, 0.0011643047449937047, 0.0011687518833854863, 0.001164884788395707, 0.0011678654890030968, 0.0011608076720433526, 0.0011691605119944313, 0.001162764185844639, 0.0011622310226220031, 0.0011702058620231097, 0.0011608416030486656, 0.001166034024208784, 0.001159271931947144, 0.0011680841386361525, 0.001170155351310102, 0.0011692675139191885, 0.001169798976936659, 0.0012210494443384368, 0.001165656557003426, 0.001155125280452329, 0.0011733436989489682, 0.0011573957663765827, 0.0011460806762929572, 0.0011460954420874979, 0.0011636718598649252, 0.001226424862262468, 0.0012217273957334286, 0.0012400288156471974, 0.0012491268381952894, 0.0012546726285891478, 0.0012541236518340748, 0.0012721379076368934, 0.0012478198623284698, 0.0012525424204203625, 0.001240802463144064, 0.004308673534217442, 0.0011218166991331896, 0.0011169963927809582, 0.0011079321171395308, 0.0011119656048195307, 0.0011068477679780403, 0.0011997478120678732, 0.0011947343510380665, 0.0012178520704511293, 0.0012156648377259804, 0.0012076940701538047, 0.0012110720935472568]
[814.2865549291373, 773.196742319506, 790.9835783623275, 741.0975664179241, 742.330940413408, 807.0826342105083, 808.3172320009703, 805.604118824588, 803.7614562781572, 807.1122300236974, 807.9250251496261, 803.7953611684155, 800.0095276450058, 790.6759749242264, 804.1717205401566, 811.2482370209113, 805.7326709701013, 801.4877649297625, 796.6836234958014, 818.3076545450216, 816.8093425598798, 824.0509621798129, 820.8234399180628, 818.8532008529866, 816.4008243896683, 816.1660685067063, 811.8217483788003, 815.1596566658379, 800.3000823091907, 812.7421260856827, 811.0009325830729, 797.5603357015171, 798.5195585815509, 794.1411428580698, 799.243058127016, 792.4788704896913, 794.6824892079021, 805.2141263754975, 894.3150880797515, 823.9491904361792, 825.3686512890279, 819.8558193475551, 818.1913854017474, 821.6366669384824, 814.479580796606, 824.1736257555722, 814.2330916374426, 820.5110454802928, 822.3369737345972, 825.9277189084429, 816.5213284605907, 821.1395974645973, 823.033675727981, 817.790421442294, 803.9179161142064, 811.0243128984292, 795.2957231651553, 812.7097008431431, 803.7545269389899, 806.7816737220968, 804.1090712946495, 413.09680611328645, 851.5656948451028, 849.7854524917492, 856.7931229392085, 852.5911891929413, 848.5170315408234, 839.2540010050474, 854.2180908031027, 835.2144815078026, 841.8549624806714, 856.5383341725906, 849.0898202676178, 822.5830004733435, 820.114286317383, 808.3574316008934, 810.2203538707857, 811.3591464172313, 859.6226619611103, 869.3601282426821, 823.5295264536253, 863.0770454714083, 867.6099061366381, 870.3402672443017, 851.557799709476, 847.9504901190479, 848.2480742960192, 843.3966853106447, 841.3902649652641, 775.8980810982462, 826.0539839830725, 835.7549638271304, 775.1988392636, 843.2004226010988, 709.0890934135919, 797.8703102092766, 796.9149391552941, 797.9211543521783, 801.4455758393625, 794.1551476848495, 793.4410693577844, 789.3941882885308, 796.8263562920187, 789.8942217876057, 264.17281283684434, 839.102768364441, 863.8538800468683, 864.2165858679972, 864.3524028444527, 857.9735197790848, 862.6209134552204, 851.376961568951, 853.8981769729286, 868.6286095242598, 847.5366513687633, 749.7568228765923, 781.0424642088589, 780.9935533996119, 724.4746064362303, 752.0211492507816, 784.966167781311, 778.7256647794568, 780.5370645930583, 761.48664083593, 786.714709406828, 795.2147301421915, 794.7945162328435, 426.37137043989924, 774.4635247274414, 775.6563249284765, 768.5317351790798, 768.1296232862092, 769.0037417812216, 765.4712920299256, 768.5993766567269, 761.4789673432052, 761.8436244085178, 767.0358803435764, 313.13435656165774, 766.2752499124094, 769.5118140587801, 765.7785330057787, 761.0752549780175, 754.9215739120989, 767.2616925157812, 749.270054459428, 747.1773172061287, 761.8490503241152, 744.8110274007028, 757.2738208278629, 763.0016862719746, 765.0223656800413, 762.0806799627874, 761.046092586185, 761.4306944481187, 739.1095188175901, 741.9492171274383, 756.3221503715599, 697.1300271586088, 663.1847608838588, 764.3595296730066, 836.5212912992191, 819.3668908241616, 830.8345499261509, 818.573500932952, 809.3711635058401, 809.3207843637341, 814.2578130359266, 815.7673169100426, 589.5584780958324, 791.0471114385423, 794.5493620394628, 787.623351981756, 789.3526542313859, 785.6935080795197, 781.2310933180275, 778.6644071840453, 782.5475733226198, 787.5891622957112, 784.6527330580285, 762.297894726534, 824.055317094838, 820.338316467376, 819.5121028728416, 817.8125193000918, 811.1844136469125, 812.238891874033, 822.1568752747272, 789.174942788387, 809.9912544005768, 817.74704379215, 822.3158012237702, 772.3349328275934, 758.027462478771, 818.7334598899453, 816.2826611097822, 733.5626817153876, 755.6333964608535, 814.6419887644141, 815.166246884228, 813.28233006226, 814.5147125450573, 809.6984400808519, 812.6747160117307, 811.7440879578721, 815.1441951914393, 806.160203557165, 808.1494383112971, 809.9537809623099, 811.6626486184645, 810.5628776869496, 809.1824211895953, 809.5556165886036, 758.5874738935134, 810.8264408210961, 809.4382916468453, 811.360770371797, 809.500828901454, 809.7923853526501, 804.657205536414, 802.0498903975507, 807.4905530701373, 807.2325780472839, 811.574010762089, 804.1305683997653, 846.0950704188411, 854.7375519689978, 850.6011473837194, 851.547741604858, 857.7440293517751, 862.3111834298728, 855.1568873182094, 852.6992241823122, 852.5034102150152, 856.6820870987613, 856.6547618169341, 848.7432364785851, 847.1450987192441, 846.7574924538758, 852.883946043034, 847.5329763808794, 853.1737566410746, 809.7355366456865, 847.5503663365125, 842.863638514339, 834.5132629843334, 845.9588427227891, 849.049939182028, 851.7782280709343, 845.6507443890662, 846.8886551282824, 840.057080049159, 860.8323733197572, 853.097316774061, 844.1996051926051, 819.1739434160266, 838.9510207683853, 810.5807865456391, 843.2586181438154, 854.7860946966725, 850.2466515698186, 861.1864745629931, 842.4552457404465, 852.2841003767896, 854.6163270332773, 850.5901918676146, 855.0295917237913, 855.957416066586, 849.6871089855626, 855.8078418846353, 851.6580099245188, 843.3478599458712, 842.7812198657986, 854.2528604297927, 858.9914415689395, 859.2425076434829, 856.4003089389622, 857.0355137343336, 853.4330195668656, 860.6357182731737, 856.424820087453, 857.584031810009, 852.8532431072674, 860.3800116108046, 774.958154009731, 771.6016709204553, 770.9833711269462, 775.3028047450035, 769.5569708351063, 773.9188494409065, 859.5188590919901, 858.8816667627743, 855.6135944810902, 858.453994731283, 856.2629938261223, 861.4691512502797, 855.3145523997675, 860.0196085963844, 860.4141350004506, 854.5504961589841, 861.4439707999312, 857.6079078640548, 862.6103784988337, 856.1027129155214, 854.5873835302324, 855.2362809158768, 854.8477300080139, 818.967654943571, 857.8856216197314, 865.7069643635672, 852.2651980794355, 864.00869007035, 872.5389239041523, 872.5276824926556, 859.3487859335847, 815.3781212126058, 818.5131998285747, 806.4328726732683, 800.5592141825867, 797.0206548017856, 797.3695405054873, 786.0782970123003, 801.3977258976865, 798.3761537308993, 805.930057122956, 232.08999058723623, 891.4112267830249, 895.2580388467726, 902.5823735318813, 899.3083919734169, 903.466609348432, 833.5085006543251, 837.0061504728076, 821.1177894779697, 822.5951503792752, 828.0242693190056, 825.7146748968329]
Elapsed: 0.05450242006210251~0.011474710609252302
Time per graph: 0.0012575433860633342~0.0002644832351055308
Speed: 809.0036599982918~71.02740603076444
Total Time: 0.0531
best val loss: 0.3239404857158661 test_score: 0.8605

Testing...
Test loss: 0.5386 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.35388022603001446, 0.1640924260718748, 0.16747411794494838, 0.17407483293209225, 0.17448691104073077, 0.1721685560187325, 0.2884179169777781, 0.16737152298446745, 0.16701822692994028, 0.16697604989167303, 0.16508857801090926, 0.16457538993563503, 0.16619894094765186, 0.16671766992658377, 0.16753240500111133, 0.164621019968763, 0.16708064498379827, 0.16525445494335145, 0.16663702810183167, 0.29217719298321754, 0.1625385438092053, 0.162223165971227, 0.16242288402281702, 0.1636550968978554, 0.16412331291940063, 0.16421422292478383, 0.1641853938344866, 0.16391908307559788, 0.16435342596378177, 0.2930149359162897, 0.162615081993863, 0.16581235802732408, 0.16628121805842966, 0.1669620069442317, 0.16788284399081022, 0.16770464892033488, 0.16799871088005602, 0.16723406093660742, 0.16021263704169542, 0.29567900707479566, 0.16250477393623441, 0.16413217701483518, 0.16330884513445199, 0.16495695209596306, 0.16590503603219986, 0.1659004760440439, 0.1657963899197057, 0.1649516219040379, 0.16399451403412968, 0.2866682519670576, 0.1665690578520298, 0.16516766394488513, 0.1646501610521227, 0.16639862197916955, 0.1674750359961763, 0.16639281599782407, 0.1685670220758766, 0.16934920300263911, 0.16921799501869828, 0.1674647710751742, 0.16804768494330347, 0.24389016802888364, 0.15808181487955153, 0.15769422403536737, 0.15770868014078587, 0.15773426496889442, 0.15772662602830678, 0.1589079120894894, 0.15782158100046217, 0.1615420349407941, 0.1616310611134395, 0.15663455694448203, 0.15805481013376266, 0.295314752147533, 0.16255746909882873, 0.16455299907829612, 0.16385183203965425, 0.16627535491716117, 0.16328006784897298, 0.15455255389679223, 0.16065649595111609, 0.15648630494251847, 0.15656128898262978, 0.15555244695860893, 0.15657884906977415, 0.2772407609736547, 0.16014930605888367, 0.15956903609912843, 0.15964680793695152, 0.16540854098275304, 0.16141846508253366, 0.16687758709304035, 0.16972047602757812, 0.15956318809185177, 0.3030579958576709, 0.1751237070420757, 0.16704569896683097, 0.1676835670368746, 0.16752498503774405, 0.1682206679834053, 0.16863838105928153, 0.17193744098767638, 0.17091186391189694, 0.16890940407756716, 0.2771728200605139, 0.16972917306702584, 0.1560840648598969, 0.15678411512635648, 0.15744406706653535, 0.15678492898587137, 0.15789153787773103, 0.15757182706147432, 0.15842352306935936, 0.1562279909849167, 0.15533298102673143, 0.18763383815530688, 0.3115221788175404, 0.16968554304912686, 0.18357378605287522, 0.18003788881469518, 0.16931301192380488, 0.1697102909674868, 0.16966367093846202, 0.17105429514776915, 0.17000459996052086, 0.1669003029819578, 0.16659897903446108, 0.2120474100811407, 0.2077844380401075, 0.17202676401939243, 0.17155980109237134, 0.17238204402383417, 0.17267546604853123, 0.1724409011658281, 0.1734675350598991, 0.17425789404660463, 0.17524749180302024, 0.17319052398670465, 0.25430186791345477, 0.18801467097364366, 0.1711340630427003, 0.17156895506195724, 0.17392364097759128, 0.17487473285291344, 0.17533943592570722, 0.1778089200379327, 0.17820194317027926, 0.17529475397896022, 0.17678706592414528, 0.25323069805745035, 0.17365510505624115, 0.17384423990733922, 0.17443228792399168, 0.1747505731182173, 0.1747984930407256, 0.17714941094163805, 0.17702029494103044, 0.17540568602271378, 0.1784339729929343, 0.25857039191760123, 0.17376960394904017, 0.15743724605999887, 0.1586037860251963, 0.16145435196813196, 0.16235321608837694, 0.16197784303221852, 0.16623076505493373, 0.16471890616230667, 0.16299780120607466, 0.2611376449931413, 0.16989398619625717, 0.1685600298224017, 0.1674117639195174, 0.16844416211824864, 0.16960522206500173, 0.170214076875709, 0.1720846270909533, 0.17387628613505512, 0.1710794969694689, 0.16992137616034597, 0.27698873600456864, 0.1625594119541347, 0.16156083799432963, 0.16247712296899408, 0.16256885102484375, 0.16291455691680312, 0.16552865807898343, 0.1650929938768968, 0.17762614507228136, 0.1645109939854592, 0.16565978212747723, 0.16488672408740968, 0.16663771192543209, 0.16881952609401196, 0.16915835486724973, 0.1645391118945554, 0.16966564522590488, 0.17453081195708364, 0.165261126938276, 0.16568616894073784, 0.1656139639671892, 0.16577387799043208, 0.1655626689316705, 0.1657376082148403, 0.16560597205534577, 0.1658113410230726, 0.16587726213037968, 0.16572498821187764, 0.16649417497683316, 0.16620398487430066, 0.16587380215059966, 0.16582606185693294, 0.1674165140138939, 0.17496793600730598, 0.16529001912567765, 0.1667274640640244, 0.16736161394510418, 0.1651117659639567, 0.1665033120661974, 0.16460927797015756, 0.16763299389276654, 0.16787132597528398, 0.16696794796735048, 0.16626920690760016, 0.16657784394919872, 0.17339678795542568, 0.17081097094342113, 0.1705654530087486, 0.17087285802699625, 0.17126424796879292, 0.17045485600829124, 0.17028688197024167, 0.1705936819780618, 0.171653175028041, 0.17097574600484222, 0.17045695893466473, 0.17131019092630595, 0.17177784605883062, 0.1717282630270347, 0.17163042805623263, 0.17186923208646476, 0.17166365694720298, 0.17408486898057163, 0.17179083602968603, 0.17109368101228029, 0.1784968749852851, 0.1783756040968001, 0.17060305504128337, 0.17033637105487287, 0.17124937707558274, 0.17187824193388224, 0.171767094056122, 0.17016464017797261, 0.1705965509172529, 0.17200725991278887, 0.17382891406305134, 0.18348320783115923, 0.18251250707544386, 0.17467624903656542, 0.17038431903347373, 0.170950737898238, 0.17057305912021548, 0.1707923950161785, 0.17108840483706445, 0.17211973504163325, 0.17053758702240884, 0.1709581681061536, 0.16984909505117685, 0.17115883296355605, 0.17061376199126244, 0.1703820580150932, 0.17197546502575278, 0.176619395846501, 0.17256063502281904, 0.1696045360295102, 0.16898814600426704, 0.16908011096529663, 0.1689745009643957, 0.16947944706771523, 0.16901810106355697, 0.16972734208684415, 0.1693893379997462, 0.169393080053851, 0.16826102184131742, 0.17442725494038314, 0.1839000069303438, 0.1830759790027514, 0.18355910701211542, 0.18374925502575934, 0.18420772813260555, 0.1721568799111992, 0.1693024579435587, 0.16943497210741043, 0.16954128409270197, 0.17033104493748397, 0.16912544600199908, 0.16921144805382937, 0.16971532383468002, 0.16893837600946426, 0.1695906730601564, 0.16913842095527798, 0.1700365711003542, 0.1696202220628038, 0.16944309091195464, 0.16968809603713453, 0.17170157108921558, 0.18102376395836473, 0.17549523594789207, 0.1735660129925236, 0.16833886795211583, 0.168289881083183, 0.16883918596431613, 0.16683488711714745, 0.16614309791475534, 0.1668536989018321, 0.2548907690215856, 0.17180962895508856, 0.17585338500794023, 0.17618343990761787, 0.1774059240706265, 0.1773696520831436, 0.17930172593332827, 0.17877053993288428, 0.1771744090365246, 0.17694749496877193, 0.30985317996237427, 0.17118343303445727, 0.15950823901221156, 0.15951726911589503, 0.15966223401483148, 0.15954148094169796, 0.16340075398329645, 0.17062285996507853, 0.17399789998307824, 0.17503651208244264, 0.17321555700618774, 0.17235321295447648]
Total Epoch List: [115, 110, 112]
Total Time List: [0.05252736108377576, 0.05427345901262015, 0.05311532109044492]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7adf6a7a0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6994;  Loss pred: 0.6994; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6989;  Loss pred: 0.6989; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.7000;  Loss pred: 0.7000; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6995;  Loss pred: 0.6995; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6990;  Loss pred: 0.6990; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6963;  Loss pred: 0.6963; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6942;  Loss pred: 0.6942; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6905;  Loss pred: 0.6905; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6875;  Loss pred: 0.6875; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6973 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6851;  Loss pred: 0.6851; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6823;  Loss pred: 0.6823; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6803;  Loss pred: 0.6803; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6774;  Loss pred: 0.6774; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6741;  Loss pred: 0.6741; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6711;  Loss pred: 0.6711; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6675;  Loss pred: 0.6675; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5116 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6620;  Loss pred: 0.6620; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6550;  Loss pred: 0.6550; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6508;  Loss pred: 0.6508; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6466;  Loss pred: 0.6466; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6405;  Loss pred: 0.6405; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6349;  Loss pred: 0.6349; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6297;  Loss pred: 0.6297; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6217;  Loss pred: 0.6217; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6071;  Loss pred: 0.6071; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6012;  Loss pred: 0.6012; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5971;  Loss pred: 0.5971; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5910;  Loss pred: 0.5910; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.12s
Epoch 30/1000, LR 0.000270
Train loss: 0.5782;  Loss pred: 0.5782; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5721;  Loss pred: 0.5721; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5000 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5623;  Loss pred: 0.5623; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5445;  Loss pred: 0.5445; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5365;  Loss pred: 0.5365; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5233;  Loss pred: 0.5233; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5235;  Loss pred: 0.5235; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5030;  Loss pred: 0.5030; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4899;  Loss pred: 0.4899; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4852;  Loss pred: 0.4852; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4708;  Loss pred: 0.4708; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.19s
Epoch 41/1000, LR 0.000269
Train loss: 0.4542;  Loss pred: 0.4542; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6957 score: 0.5000 time: 0.06s
Epoch 42/1000, LR 0.000269
Train loss: 0.4345;  Loss pred: 0.4345; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.5000 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4247;  Loss pred: 0.4247; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4099;  Loss pred: 0.4099; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4112;  Loss pred: 0.4112; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3931;  Loss pred: 0.3931; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3701;  Loss pred: 0.3701; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3657;  Loss pred: 0.3657; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6900 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3515;  Loss pred: 0.3515; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.5000 time: 0.09s
Epoch 50/1000, LR 0.000269
Train loss: 0.3368;  Loss pred: 0.3368; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3273;  Loss pred: 0.3273; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6874 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3076;  Loss pred: 0.3076; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2993;  Loss pred: 0.2993; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6845 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2841;  Loss pred: 0.2841; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6825 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5000 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2767;  Loss pred: 0.2767; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6800 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5000 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2600;  Loss pred: 0.2600; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6772 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.5000 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2499;  Loss pred: 0.2499; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6736 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6858 score: 0.5000 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2467;  Loss pred: 0.2467; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6694 score: 0.5116 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6827 score: 0.5000 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2227;  Loss pred: 0.2227; Loss self: 0.0000; time: 0.06s
Val loss: 0.6644 score: 0.5349 time: 0.04s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6790 score: 0.5000 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2144;  Loss pred: 0.2144; Loss self: 0.0000; time: 0.06s
Val loss: 0.6590 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6749 score: 0.5000 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.2042;  Loss pred: 0.2042; Loss self: 0.0000; time: 0.06s
Val loss: 0.6525 score: 0.5581 time: 0.05s
Test loss: 0.6700 score: 0.5227 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1927;  Loss pred: 0.1927; Loss self: 0.0000; time: 0.06s
Val loss: 0.6448 score: 0.5581 time: 0.05s
Test loss: 0.6638 score: 0.5227 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1853;  Loss pred: 0.1853; Loss self: 0.0000; time: 0.19s
Val loss: 0.6366 score: 0.5814 time: 0.05s
Test loss: 0.6573 score: 0.5455 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1672;  Loss pred: 0.1672; Loss self: 0.0000; time: 0.07s
Val loss: 0.6274 score: 0.5814 time: 0.05s
Test loss: 0.6497 score: 0.5909 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1618;  Loss pred: 0.1618; Loss self: 0.0000; time: 0.07s
Val loss: 0.6177 score: 0.6047 time: 0.05s
Test loss: 0.6420 score: 0.5909 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1522;  Loss pred: 0.1522; Loss self: 0.0000; time: 0.07s
Val loss: 0.6075 score: 0.6279 time: 0.05s
Test loss: 0.6336 score: 0.5909 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1434;  Loss pred: 0.1434; Loss self: 0.0000; time: 0.07s
Val loss: 0.5964 score: 0.6279 time: 0.05s
Test loss: 0.6245 score: 0.5909 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1321;  Loss pred: 0.1321; Loss self: 0.0000; time: 0.07s
Val loss: 0.5851 score: 0.6744 time: 0.05s
Test loss: 0.6153 score: 0.5909 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1263;  Loss pred: 0.1263; Loss self: 0.0000; time: 0.07s
Val loss: 0.5731 score: 0.6977 time: 0.05s
Test loss: 0.6051 score: 0.5909 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1160;  Loss pred: 0.1160; Loss self: 0.0000; time: 0.06s
Val loss: 0.5604 score: 0.6977 time: 0.05s
Test loss: 0.5945 score: 0.6136 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.1093;  Loss pred: 0.1093; Loss self: 0.0000; time: 0.06s
Val loss: 0.5474 score: 0.6977 time: 0.05s
Test loss: 0.5834 score: 0.6364 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.1011;  Loss pred: 0.1011; Loss self: 0.0000; time: 0.06s
Val loss: 0.5341 score: 0.7209 time: 0.05s
Test loss: 0.5718 score: 0.6364 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0967;  Loss pred: 0.0967; Loss self: 0.0000; time: 0.06s
Val loss: 0.5202 score: 0.7442 time: 0.05s
Test loss: 0.5596 score: 0.6818 time: 0.16s
Epoch 74/1000, LR 0.000267
Train loss: 0.0882;  Loss pred: 0.0882; Loss self: 0.0000; time: 0.06s
Val loss: 0.5058 score: 0.7442 time: 0.05s
Test loss: 0.5464 score: 0.6591 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0847;  Loss pred: 0.0847; Loss self: 0.0000; time: 0.06s
Val loss: 0.4912 score: 0.7442 time: 0.05s
Test loss: 0.5325 score: 0.6818 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0763;  Loss pred: 0.0763; Loss self: 0.0000; time: 0.06s
Val loss: 0.4763 score: 0.7674 time: 0.05s
Test loss: 0.5183 score: 0.7500 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0713;  Loss pred: 0.0713; Loss self: 0.0000; time: 0.06s
Val loss: 0.4611 score: 0.7442 time: 0.05s
Test loss: 0.5035 score: 0.7727 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0659;  Loss pred: 0.0659; Loss self: 0.0000; time: 0.06s
Val loss: 0.4468 score: 0.7907 time: 0.05s
Test loss: 0.4895 score: 0.7727 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0622;  Loss pred: 0.0622; Loss self: 0.0000; time: 0.06s
Val loss: 0.4327 score: 0.8140 time: 0.05s
Test loss: 0.4756 score: 0.7727 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0570;  Loss pred: 0.0570; Loss self: 0.0000; time: 0.07s
Val loss: 0.4196 score: 0.8140 time: 0.05s
Test loss: 0.4626 score: 0.7955 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0511;  Loss pred: 0.0511; Loss self: 0.0000; time: 0.07s
Val loss: 0.4070 score: 0.8372 time: 0.05s
Test loss: 0.4495 score: 0.8182 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0491;  Loss pred: 0.0491; Loss self: 0.0000; time: 0.06s
Val loss: 0.3953 score: 0.8372 time: 0.05s
Test loss: 0.4369 score: 0.8182 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0456;  Loss pred: 0.0456; Loss self: 0.0000; time: 0.07s
Val loss: 0.3848 score: 0.8372 time: 0.05s
Test loss: 0.4250 score: 0.8182 time: 0.17s
Epoch 84/1000, LR 0.000266
Train loss: 0.0429;  Loss pred: 0.0429; Loss self: 0.0000; time: 0.06s
Val loss: 0.3754 score: 0.8372 time: 0.05s
Test loss: 0.4139 score: 0.8409 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0380;  Loss pred: 0.0380; Loss self: 0.0000; time: 0.06s
Val loss: 0.3673 score: 0.8372 time: 0.05s
Test loss: 0.4034 score: 0.8409 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0353;  Loss pred: 0.0353; Loss self: 0.0000; time: 0.06s
Val loss: 0.3604 score: 0.8372 time: 0.05s
Test loss: 0.3940 score: 0.8409 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0318;  Loss pred: 0.0318; Loss self: 0.0000; time: 0.06s
Val loss: 0.3547 score: 0.8372 time: 0.05s
Test loss: 0.3853 score: 0.8409 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0306;  Loss pred: 0.0306; Loss self: 0.0000; time: 0.06s
Val loss: 0.3502 score: 0.8605 time: 0.05s
Test loss: 0.3773 score: 0.8182 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0276;  Loss pred: 0.0276; Loss self: 0.0000; time: 0.06s
Val loss: 0.3468 score: 0.8605 time: 0.05s
Test loss: 0.3702 score: 0.8182 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0286;  Loss pred: 0.0286; Loss self: 0.0000; time: 0.07s
Val loss: 0.3448 score: 0.8605 time: 0.05s
Test loss: 0.3637 score: 0.8182 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.07s
Val loss: 0.3441 score: 0.8605 time: 0.05s
Test loss: 0.3583 score: 0.8182 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0228;  Loss pred: 0.0228; Loss self: 0.0000; time: 0.07s
Val loss: 0.3447 score: 0.8605 time: 0.05s
Test loss: 0.3539 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0231;  Loss pred: 0.0231; Loss self: 0.0000; time: 0.07s
Val loss: 0.3463 score: 0.8605 time: 0.05s
Test loss: 0.3508 score: 0.8182 time: 0.06s
     INFO: Early stopping counter 2 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0202;  Loss pred: 0.0202; Loss self: 0.0000; time: 0.16s
Val loss: 0.3490 score: 0.8837 time: 0.05s
Test loss: 0.3486 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.07s
Val loss: 0.3529 score: 0.8837 time: 0.05s
Test loss: 0.3473 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0175;  Loss pred: 0.0175; Loss self: 0.0000; time: 0.07s
Val loss: 0.3577 score: 0.8605 time: 0.05s
Test loss: 0.3468 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0155;  Loss pred: 0.0155; Loss self: 0.0000; time: 0.07s
Val loss: 0.3639 score: 0.8605 time: 0.05s
Test loss: 0.3471 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0148;  Loss pred: 0.0148; Loss self: 0.0000; time: 0.07s
Val loss: 0.3705 score: 0.8605 time: 0.05s
Test loss: 0.3481 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0145;  Loss pred: 0.0145; Loss self: 0.0000; time: 0.07s
Val loss: 0.3786 score: 0.8605 time: 0.05s
Test loss: 0.3499 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0135;  Loss pred: 0.0135; Loss self: 0.0000; time: 0.07s
Val loss: 0.3869 score: 0.8605 time: 0.05s
Test loss: 0.3522 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.07s
Val loss: 0.3965 score: 0.8605 time: 0.05s
Test loss: 0.3554 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.07s
Val loss: 0.4066 score: 0.8605 time: 0.05s
Test loss: 0.3591 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.08s
Val loss: 0.4174 score: 0.8605 time: 0.14s
Test loss: 0.3634 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.07s
Val loss: 0.4276 score: 0.8605 time: 0.05s
Test loss: 0.3677 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.07s
Val loss: 0.4378 score: 0.8605 time: 0.05s
Test loss: 0.3721 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.4478 score: 0.8605 time: 0.05s
Test loss: 0.3766 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.07s
Val loss: 0.4584 score: 0.8605 time: 0.05s
Test loss: 0.3815 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.4691 score: 0.8605 time: 0.05s
Test loss: 0.3864 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.4796 score: 0.8605 time: 0.05s
Test loss: 0.3915 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.4907 score: 0.8605 time: 0.05s
Test loss: 0.3968 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.5015 score: 0.8605 time: 0.05s
Test loss: 0.4020 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 090,   Train_Loss: 0.0240,   Val_Loss: 0.3441,   Val_Precision: 0.9444,   Val_Recall: 0.7727,   Val_accuracy: 0.8500,   Val_Score: 0.8605,   Val_Loss: 0.3441,   Test_Precision: 0.8182,   Test_Recall: 0.8182,   Test_accuracy: 0.8182,   Test_Score: 0.8182,   Test_loss: 0.3583


[0.05372962600085884, 0.05196734401397407, 0.05202462698798627, 0.05224087706301361, 0.05191899696364999, 0.05178801401052624, 0.051602127961814404, 0.05176456400658935, 0.05171399703249335, 0.051978176925331354, 0.052348086959682405, 0.0523204579949379, 0.05205155408475548, 0.051668316940777004, 0.051963353995233774, 0.05174337502103299, 0.0517998089781031, 0.05207792902365327, 0.05201321595814079, 0.05250471597537398, 0.05246466805692762, 0.05283363698981702, 0.05256791098508984, 0.05395401397254318, 0.053133531007915735, 0.05271779594477266, 0.053082883008755744, 0.05264090304262936, 0.1210161610506475, 0.05133281706366688, 0.05133078095968813, 0.05177214101422578, 0.05181926395744085, 0.05205516400747001, 0.05218752194195986, 0.053231497993692756, 0.05276855803094804, 0.05734268401283771, 0.05297597998287529, 0.1934212710475549, 0.0636078150710091, 0.05688554304651916, 0.05698858806863427, 0.05684251000639051, 0.057978273020125926, 0.05730261409189552, 0.05722681002225727, 0.05701608199160546, 0.09284979396034032, 0.055576039012521505, 0.05573799193371087, 0.05535357806365937, 0.05609325005207211, 0.05556863499805331, 0.05221406405325979, 0.05115515703801066, 0.05171807191800326, 0.05137156799901277, 0.05142518202774227, 0.051177261979319155, 0.051164850941859186, 0.054344394942745566, 0.05518952303100377, 0.05445650708861649, 0.054750930052250624, 0.05478127603419125, 0.05490613402798772, 0.05480163695756346, 0.05609484703745693, 0.04993747209664434, 0.05126859399024397, 0.05075211403891444, 0.1685315240174532, 0.05162537202704698, 0.051225773990154266, 0.05288649594876915, 0.05139271204825491, 0.05160208500456065, 0.05294711096212268, 0.05313216208014637, 0.05165677308104932, 0.05243924097158015, 0.17706317000556737, 0.05191659997217357, 0.05182034394238144, 0.051659283926710486, 0.05246815492864698, 0.05235217197332531, 0.05365886108484119, 0.05323299195151776, 0.05265829002019018, 0.05263414699584246, 0.0676293500000611, 0.05719413293991238, 0.056645869044587016, 0.05642796203028411, 0.056778144906274974, 0.05731599195860326, 0.059537201072089374, 0.05739801691379398, 0.05682333291042596, 0.05845911893993616, 0.058130612946115434, 0.05805691797286272, 0.058051269967108965, 0.057395798969082534, 0.05754371196962893, 0.05744986899662763, 0.05773182399570942, 0.05790532601531595, 0.05728240392636508]
[0.0012211278636558827, 0.0011810760003175926, 0.001182377886090597, 0.0011872926605230366, 0.001179977203719318, 0.001177000318421051, 0.001172775635495782, 0.0011764673637861217, 0.0011753181143748489, 0.00118132220284844, 0.001189729249083691, 0.0011891013180667703, 0.0011829898655626246, 0.0011742799304722046, 0.001180985318073495, 0.001175985795932568, 0.0011772683858659796, 0.0011835892959921198, 0.0011821185445031997, 0.0011932889994403179, 0.0011923788194756278, 0.001200764477041296, 0.0011947252496611327, 0.0012262275902850722, 0.001207580250179903, 0.0011981317260175604, 0.0012064291592899033, 0.0011963841600597582, 0.002750367296605625, 0.0011666549332651564, 0.0011666086581747302, 0.0011766395685051314, 0.001177710544487292, 0.001183071909260682, 0.0011860800441354513, 0.0012098067725839262, 0.0011992854097942736, 0.0013032428184735843, 0.0012039995450653475, 0.0043959379783535205, 0.0014456321607047523, 0.0012928532510572536, 0.0012951951833780515, 0.0012918752274179662, 0.00131768802318468, 0.001302332138452171, 0.0013006093186876651, 0.0012958200452637604, 0.0021102225900077346, 0.001263091795739125, 0.0012667725439479743, 0.0012580358650831674, 0.001274846592092548, 0.0012629235226830299, 0.0011866832739377226, 0.0011626172054093331, 0.001175410725409165, 0.0011675356363411993, 0.0011687541369941425, 0.0011631195904390718, 0.0011628375214058906, 0.0012350998850623992, 0.0012543073416137222, 0.0012376478883776474, 0.0012443393193693323, 0.0012450290007770739, 0.0012478666824542663, 0.001245491749035533, 0.0012748828872149302, 0.0011349425476510078, 0.0011651953179600903, 0.0011534571372480555, 0.0038302619094875727, 0.0011733039097056132, 0.0011642221361398697, 0.0012019658170174807, 0.0011680161829148842, 0.0011727746591945602, 0.0012033434309573336, 0.0012075491381851448, 0.0011740175700238483, 0.001191800931172276, 0.004024162954671986, 0.0011799227266403084, 0.0011777350895995783, 0.0011740746346979656, 0.0011924580665601586, 0.001189822090302848, 0.0012195195701100272, 0.0012098407261708583, 0.001196779318640686, 0.001196230613541874, 0.0015370306818195704, 0.0012998666577252814, 0.001287406114649705, 0.001282453682506457, 0.001290412384233522, 0.001302636180877347, 0.0013531182061838495, 0.0013045003844044086, 0.0012914393843278628, 0.0013286163395440037, 0.0013211502942298962, 0.0013194754084741528, 0.001319347044707022, 0.0013044499765700575, 0.0013078116356733847, 0.0013056788408324462, 0.0013120869089933958, 0.001316030136711726, 0.0013018728165082973]
[818.9150618561291, 846.685564460796, 845.7533008388634, 842.2523218154748, 847.47399936878, 849.6174421953451, 852.6780142198791, 850.0023296709122, 850.8334788423639, 846.5091044498865, 840.5273727364296, 840.9712316405388, 845.3157792052637, 851.5857029063567, 846.7505774172276, 850.3504068320744, 849.4239818258741, 844.8876678643585, 845.9388482229273, 838.0199603524585, 838.6596471411408, 832.8027844927733, 837.0125267576258, 815.5092969059039, 828.1023144018974, 834.6327689058652, 828.8924320998622, 835.8519223039956, 363.5878019761773, 857.1514776878082, 857.185477745892, 849.8779292884531, 849.1050748257866, 845.2571582271054, 843.1134179724882, 826.5782789958951, 833.8298722166066, 767.3167162902492, 830.5650978844221, 227.48273631798273, 691.7388995500041, 773.4829913466453, 772.0844030564251, 774.068562332193, 758.904977813436, 767.8532768057968, 768.870394538627, 771.712093554204, 473.883657930292, 791.7080954633457, 789.4076997307177, 794.8898976213933, 784.4081054165023, 791.813583355816, 842.6848359307711, 860.1283340271237, 850.7664413661838, 856.5049056093746, 855.611944674564, 859.7568196942716, 859.9653705626756, 809.6511157471919, 797.2527679806574, 807.9842493092565, 803.6393164099559, 803.1941419644513, 801.3676573472018, 802.8957243388937, 784.3857738059133, 881.1018690502893, 858.2252130490036, 866.9589599019023, 261.0787522187442, 852.294100213903, 858.9426097975, 831.9704153329151, 856.1525213669681, 852.678724049837, 831.0179573627112, 828.1236501091165, 851.7760087523108, 839.0663019673786, 248.4988831873761, 847.5131272768876, 849.0873786735802, 851.7346090670404, 838.603912408144, 840.4617868083689, 819.9950410880068, 826.5550814816729, 835.5759365359105, 835.9592111082476, 650.6050997083404, 769.3096780787986, 776.7556706627059, 779.7552563813275, 774.9460654734642, 767.6740556419088, 739.0337336604641, 766.5770067645988, 774.329799861614, 752.6627290638405, 756.9161543296661, 757.8769513835839, 757.9506878132, 766.6066295845369, 764.6361086893876, 765.8851232991123, 762.1446362628357, 759.8610184555736, 768.1241879541362]
Elapsed: 0.05840599620693808~0.021734101694318303
Time per graph: 0.001327409004703138~0.0004939568566890524
Speed: 793.5373473902762~113.06742198296578
Total Time: 0.0578
best val loss: 0.34405502676963806 test_score: 0.8182

Testing...
Test loss: 0.3486 score: 0.8182 time: 0.05s
test Score 0.8182
Epoch Time List: [0.16021681309212, 0.15685589390341192, 0.15652737708296627, 0.2788927850779146, 0.1561157020041719, 0.15497915796004236, 0.1559180358890444, 0.15587775316089392, 0.15454333100933582, 0.1562916268594563, 0.15670433710329235, 0.16056136786937714, 0.1564342019846663, 0.15479549602605402, 0.15583424095530063, 0.15574299602303654, 0.27261229208670557, 0.15674111992120743, 0.15654971299227327, 0.15678246296010911, 0.158056540065445, 0.15846228308510035, 0.15926994488108903, 0.1612274720100686, 0.16060875891707838, 0.15883929701521993, 0.15842107799835503, 0.15672101988457143, 0.238232230884023, 0.15486107289325446, 0.1543803330278024, 0.15670443209819496, 0.15804807608947158, 0.15683557803276926, 0.1576765220379457, 0.16023721499368548, 0.16074118204414845, 0.1639973388519138, 0.1620076799299568, 0.2963076781015843, 0.17450952995568514, 0.17716361198108643, 0.16706866712775081, 0.16689290013164282, 0.1678136111004278, 0.16992040001787245, 0.16803808510303497, 0.1688688270514831, 0.20216740283649415, 0.20954329194501042, 0.1655278541147709, 0.16685671999584883, 0.16700412798672915, 0.1674432649742812, 0.16063704900443554, 0.15564836794510484, 0.15641297900583595, 0.1536013449076563, 0.15443786489777267, 0.1533470608992502, 0.15391807502601296, 0.15452825999818742, 0.2896203740965575, 0.1648231450235471, 0.1652707220055163, 0.16485186095815152, 0.16340827208478004, 0.16500008397269994, 0.1672619441524148, 0.1530680648284033, 0.15519097505602986, 0.15395190403796732, 0.2713588820770383, 0.15503247501328588, 0.15560446912422776, 0.15796708990819752, 0.15595784795004874, 0.15888554707635194, 0.157831309014, 0.16326620511244982, 0.15832796995528042, 0.15763569506816566, 0.28249417908955365, 0.1568998059956357, 0.15750484296586365, 0.1558745780494064, 0.1573934480547905, 0.1577274069422856, 0.15858727891463786, 0.16230981203261763, 0.16188045486342162, 0.1610671429662034, 0.1701701529091224, 0.2675013979896903, 0.170392706990242, 0.1697855609236285, 0.17104206699877977, 0.17308881203643978, 0.17418881703633815, 0.17512535897549242, 0.17273606196977198, 0.1735314279794693, 0.2707431298913434, 0.17786680406425148, 0.17646702227648348, 0.17441067495383322, 0.17503174708690494, 0.17651119304355234, 0.17731734993867576, 0.17513375903945416, 0.17349251895211637]
Total Epoch List: [111]
Total Time List: [0.057831665966659784]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7ae0cf250>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6941;  Loss pred: 0.6941; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6949;  Loss pred: 0.6949; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6957;  Loss pred: 0.6957; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6938;  Loss pred: 0.6938; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6940;  Loss pred: 0.6940; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.06s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6926;  Loss pred: 0.6926; Loss self: 0.0000; time: 0.14s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6870;  Loss pred: 0.6870; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6863;  Loss pred: 0.6863; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.04s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6816;  Loss pred: 0.6816; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6806;  Loss pred: 0.6806; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4884 time: 0.04s
Epoch 13/1000, LR 0.000270
Train loss: 0.6782;  Loss pred: 0.6782; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6733;  Loss pred: 0.6733; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6683;  Loss pred: 0.6683; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6669;  Loss pred: 0.6669; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6611;  Loss pred: 0.6611; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.4884 time: 0.06s
Epoch 18/1000, LR 0.000270
Train loss: 0.6615;  Loss pred: 0.6615; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6555;  Loss pred: 0.6555; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6491;  Loss pred: 0.6491; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6411;  Loss pred: 0.6411; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6363;  Loss pred: 0.6363; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6289;  Loss pred: 0.6289; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6255;  Loss pred: 0.6255; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6206;  Loss pred: 0.6206; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6069;  Loss pred: 0.6069; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5992;  Loss pred: 0.5992; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.17s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.4884 time: 0.06s
Epoch 28/1000, LR 0.000270
Train loss: 0.5913;  Loss pred: 0.5913; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5774;  Loss pred: 0.5774; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5707;  Loss pred: 0.5707; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5625;  Loss pred: 0.5625; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6890 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5506;  Loss pred: 0.5506; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6883 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5422;  Loss pred: 0.5422; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6875 score: 0.4884 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5346;  Loss pred: 0.5346; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6866 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5175;  Loss pred: 0.5175; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6856 score: 0.4884 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5079;  Loss pred: 0.5079; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6843 score: 0.4884 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4940;  Loss pred: 0.4940; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.5000 time: 0.20s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6829 score: 0.4884 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4786;  Loss pred: 0.4786; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6853 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6814 score: 0.4884 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4678;  Loss pred: 0.4678; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6842 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6798 score: 0.4884 time: 0.04s
Epoch 40/1000, LR 0.000269
Train loss: 0.4616;  Loss pred: 0.4616; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6829 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6779 score: 0.4884 time: 0.04s
Epoch 41/1000, LR 0.000269
Train loss: 0.4428;  Loss pred: 0.4428; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6815 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6759 score: 0.4884 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4344;  Loss pred: 0.4344; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6799 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6736 score: 0.4884 time: 0.04s
Epoch 43/1000, LR 0.000269
Train loss: 0.4143;  Loss pred: 0.4143; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6781 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6711 score: 0.4884 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4044;  Loss pred: 0.4044; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6762 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6684 score: 0.4884 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3927;  Loss pred: 0.3927; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6741 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6655 score: 0.4884 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3837;  Loss pred: 0.3837; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6717 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6622 score: 0.4884 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3632;  Loss pred: 0.3632; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6691 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6587 score: 0.4884 time: 0.04s
Epoch 48/1000, LR 0.000269
Train loss: 0.3483;  Loss pred: 0.3483; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6662 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6548 score: 0.4884 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3438;  Loss pred: 0.3438; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6631 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6506 score: 0.4884 time: 0.04s
Epoch 50/1000, LR 0.000269
Train loss: 0.3182;  Loss pred: 0.3182; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6597 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6462 score: 0.4884 time: 0.04s
Epoch 51/1000, LR 0.000269
Train loss: 0.3117;  Loss pred: 0.3117; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6559 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6412 score: 0.4884 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2906;  Loss pred: 0.2906; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6518 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6357 score: 0.4884 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2840;  Loss pred: 0.2840; Loss self: 0.0000; time: 0.07s
Val loss: 0.6474 score: 0.5227 time: 0.05s
Test loss: 0.6300 score: 0.5349 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2684;  Loss pred: 0.2684; Loss self: 0.0000; time: 0.07s
Val loss: 0.6426 score: 0.5682 time: 0.05s
Test loss: 0.6238 score: 0.5581 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2503;  Loss pred: 0.2503; Loss self: 0.0000; time: 0.07s
Val loss: 0.6376 score: 0.5682 time: 0.05s
Test loss: 0.6173 score: 0.5581 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2460;  Loss pred: 0.2460; Loss self: 0.0000; time: 0.07s
Val loss: 0.6322 score: 0.5909 time: 0.05s
Test loss: 0.6104 score: 0.6047 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2346;  Loss pred: 0.2346; Loss self: 0.0000; time: 0.07s
Val loss: 0.6262 score: 0.6364 time: 0.05s
Test loss: 0.6027 score: 0.6047 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2161;  Loss pred: 0.2161; Loss self: 0.0000; time: 0.07s
Val loss: 0.6201 score: 0.6364 time: 0.05s
Test loss: 0.5949 score: 0.6977 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2070;  Loss pred: 0.2070; Loss self: 0.0000; time: 0.07s
Val loss: 0.6137 score: 0.7045 time: 0.05s
Test loss: 0.5867 score: 0.7209 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1954;  Loss pred: 0.1954; Loss self: 0.0000; time: 0.07s
Val loss: 0.6064 score: 0.7273 time: 0.05s
Test loss: 0.5774 score: 0.7209 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1857;  Loss pred: 0.1857; Loss self: 0.0000; time: 0.07s
Val loss: 0.5990 score: 0.7500 time: 0.05s
Test loss: 0.5681 score: 0.7209 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1713;  Loss pred: 0.1713; Loss self: 0.0000; time: 0.07s
Val loss: 0.5913 score: 0.7727 time: 0.05s
Test loss: 0.5584 score: 0.7674 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1616;  Loss pred: 0.1616; Loss self: 0.0000; time: 0.07s
Val loss: 0.5834 score: 0.7727 time: 0.05s
Test loss: 0.5485 score: 0.7674 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1499;  Loss pred: 0.1499; Loss self: 0.0000; time: 0.07s
Val loss: 0.5756 score: 0.7727 time: 0.05s
Test loss: 0.5385 score: 0.7907 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1400;  Loss pred: 0.1400; Loss self: 0.0000; time: 0.07s
Val loss: 0.5677 score: 0.7727 time: 0.05s
Test loss: 0.5285 score: 0.8140 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1272;  Loss pred: 0.1272; Loss self: 0.0000; time: 0.07s
Val loss: 0.5592 score: 0.7955 time: 0.05s
Test loss: 0.5177 score: 0.8372 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1185;  Loss pred: 0.1185; Loss self: 0.0000; time: 0.07s
Val loss: 0.5502 score: 0.7955 time: 0.05s
Test loss: 0.5064 score: 0.8372 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1100;  Loss pred: 0.1100; Loss self: 0.0000; time: 0.07s
Val loss: 0.5416 score: 0.7955 time: 0.05s
Test loss: 0.4956 score: 0.8372 time: 0.04s
Epoch 69/1000, LR 0.000268
Train loss: 0.1038;  Loss pred: 0.1038; Loss self: 0.0000; time: 0.07s
Val loss: 0.5327 score: 0.7955 time: 0.05s
Test loss: 0.4847 score: 0.8372 time: 0.04s
Epoch 70/1000, LR 0.000268
Train loss: 0.0914;  Loss pred: 0.0914; Loss self: 0.0000; time: 0.07s
Val loss: 0.5233 score: 0.7955 time: 0.05s
Test loss: 0.4730 score: 0.8605 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0916;  Loss pred: 0.0916; Loss self: 0.0000; time: 0.07s
Val loss: 0.5149 score: 0.7955 time: 0.05s
Test loss: 0.4627 score: 0.8605 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0816;  Loss pred: 0.0816; Loss self: 0.0000; time: 0.07s
Val loss: 0.5070 score: 0.7955 time: 0.05s
Test loss: 0.4529 score: 0.8605 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0775;  Loss pred: 0.0775; Loss self: 0.0000; time: 0.07s
Val loss: 0.4975 score: 0.7955 time: 0.05s
Test loss: 0.4414 score: 0.8837 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0726;  Loss pred: 0.0726; Loss self: 0.0000; time: 0.07s
Val loss: 0.4887 score: 0.8182 time: 0.05s
Test loss: 0.4309 score: 0.8837 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0640;  Loss pred: 0.0640; Loss self: 0.0000; time: 0.07s
Val loss: 0.4809 score: 0.8409 time: 0.05s
Test loss: 0.4212 score: 0.8837 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0585;  Loss pred: 0.0585; Loss self: 0.0000; time: 0.07s
Val loss: 0.4731 score: 0.8409 time: 0.05s
Test loss: 0.4115 score: 0.8837 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0554;  Loss pred: 0.0554; Loss self: 0.0000; time: 0.07s
Val loss: 0.4655 score: 0.8409 time: 0.05s
Test loss: 0.4020 score: 0.8837 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0497;  Loss pred: 0.0497; Loss self: 0.0000; time: 0.07s
Val loss: 0.4572 score: 0.8409 time: 0.05s
Test loss: 0.3921 score: 0.8837 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0491;  Loss pred: 0.0491; Loss self: 0.0000; time: 0.07s
Val loss: 0.4486 score: 0.8636 time: 0.05s
Test loss: 0.3816 score: 0.8837 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0426;  Loss pred: 0.0426; Loss self: 0.0000; time: 0.07s
Val loss: 0.4409 score: 0.8636 time: 0.05s
Test loss: 0.3721 score: 0.8837 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0413;  Loss pred: 0.0413; Loss self: 0.0000; time: 0.07s
Val loss: 0.4340 score: 0.8636 time: 0.05s
Test loss: 0.3637 score: 0.8837 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0357;  Loss pred: 0.0357; Loss self: 0.0000; time: 0.07s
Val loss: 0.4273 score: 0.8636 time: 0.05s
Test loss: 0.3554 score: 0.8837 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0305;  Loss pred: 0.0305; Loss self: 0.0000; time: 0.07s
Val loss: 0.4211 score: 0.8864 time: 0.05s
Test loss: 0.3473 score: 0.8837 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0286;  Loss pred: 0.0286; Loss self: 0.0000; time: 0.07s
Val loss: 0.4151 score: 0.8864 time: 0.05s
Test loss: 0.3394 score: 0.8837 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0274;  Loss pred: 0.0274; Loss self: 0.0000; time: 0.07s
Val loss: 0.4103 score: 0.8636 time: 0.05s
Test loss: 0.3328 score: 0.8837 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0268;  Loss pred: 0.0268; Loss self: 0.0000; time: 0.07s
Val loss: 0.4060 score: 0.8636 time: 0.05s
Test loss: 0.3269 score: 0.8837 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0241;  Loss pred: 0.0241; Loss self: 0.0000; time: 0.07s
Val loss: 0.4028 score: 0.8636 time: 0.05s
Test loss: 0.3220 score: 0.8837 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0214;  Loss pred: 0.0214; Loss self: 0.0000; time: 0.07s
Val loss: 0.4006 score: 0.8636 time: 0.05s
Test loss: 0.3179 score: 0.8837 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0198;  Loss pred: 0.0198; Loss self: 0.0000; time: 0.07s
Val loss: 0.3987 score: 0.8636 time: 0.05s
Test loss: 0.3138 score: 0.8837 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0190;  Loss pred: 0.0190; Loss self: 0.0000; time: 0.07s
Val loss: 0.3971 score: 0.8636 time: 0.05s
Test loss: 0.3099 score: 0.8837 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0160;  Loss pred: 0.0160; Loss self: 0.0000; time: 0.07s
Val loss: 0.3960 score: 0.8636 time: 0.05s
Test loss: 0.3062 score: 0.8837 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0165;  Loss pred: 0.0165; Loss self: 0.0000; time: 0.07s
Val loss: 0.3957 score: 0.8636 time: 0.05s
Test loss: 0.3030 score: 0.8837 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.07s
Val loss: 0.3963 score: 0.8636 time: 0.05s
Test loss: 0.3006 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0152;  Loss pred: 0.0152; Loss self: 0.0000; time: 0.07s
Val loss: 0.3975 score: 0.8636 time: 0.05s
Test loss: 0.2982 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.07s
Val loss: 0.3989 score: 0.8636 time: 0.05s
Test loss: 0.2955 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.07s
Val loss: 0.4010 score: 0.8636 time: 0.05s
Test loss: 0.2933 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0124;  Loss pred: 0.0124; Loss self: 0.0000; time: 0.07s
Val loss: 0.4034 score: 0.8409 time: 0.05s
Test loss: 0.2920 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.07s
Val loss: 0.4061 score: 0.8409 time: 0.05s
Test loss: 0.2910 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.07s
Val loss: 0.4090 score: 0.8409 time: 0.05s
Test loss: 0.2899 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.07s
Val loss: 0.4116 score: 0.8409 time: 0.05s
Test loss: 0.2889 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.07s
Val loss: 0.4146 score: 0.8409 time: 0.05s
Test loss: 0.2885 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.07s
Val loss: 0.4177 score: 0.8409 time: 0.05s
Test loss: 0.2883 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.07s
Val loss: 0.4215 score: 0.8409 time: 0.05s
Test loss: 0.2881 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.4260 score: 0.8409 time: 0.05s
Test loss: 0.2885 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.4306 score: 0.8409 time: 0.05s
Test loss: 0.2885 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.07s
Val loss: 0.4352 score: 0.8409 time: 0.05s
Test loss: 0.2889 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.4397 score: 0.8409 time: 0.05s
Test loss: 0.2889 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.07s
Val loss: 0.4443 score: 0.8409 time: 0.05s
Test loss: 0.2887 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.07s
Val loss: 0.4498 score: 0.8409 time: 0.05s
Test loss: 0.2890 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.4543 score: 0.8409 time: 0.05s
Test loss: 0.2888 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.4594 score: 0.8409 time: 0.05s
Test loss: 0.2893 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.07s
Val loss: 0.4644 score: 0.8409 time: 0.05s
Test loss: 0.2895 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 091,   Train_Loss: 0.0165,   Val_Loss: 0.3957,   Val_Precision: 0.9444,   Val_Recall: 0.7727,   Val_accuracy: 0.8500,   Val_Score: 0.8636,   Val_Loss: 0.3957,   Test_Precision: 1.0000,   Test_Recall: 0.7727,   Test_accuracy: 0.8718,   Test_Score: 0.8837,   Test_loss: 0.3030


[0.05372962600085884, 0.05196734401397407, 0.05202462698798627, 0.05224087706301361, 0.05191899696364999, 0.05178801401052624, 0.051602127961814404, 0.05176456400658935, 0.05171399703249335, 0.051978176925331354, 0.052348086959682405, 0.0523204579949379, 0.05205155408475548, 0.051668316940777004, 0.051963353995233774, 0.05174337502103299, 0.0517998089781031, 0.05207792902365327, 0.05201321595814079, 0.05250471597537398, 0.05246466805692762, 0.05283363698981702, 0.05256791098508984, 0.05395401397254318, 0.053133531007915735, 0.05271779594477266, 0.053082883008755744, 0.05264090304262936, 0.1210161610506475, 0.05133281706366688, 0.05133078095968813, 0.05177214101422578, 0.05181926395744085, 0.05205516400747001, 0.05218752194195986, 0.053231497993692756, 0.05276855803094804, 0.05734268401283771, 0.05297597998287529, 0.1934212710475549, 0.0636078150710091, 0.05688554304651916, 0.05698858806863427, 0.05684251000639051, 0.057978273020125926, 0.05730261409189552, 0.05722681002225727, 0.05701608199160546, 0.09284979396034032, 0.055576039012521505, 0.05573799193371087, 0.05535357806365937, 0.05609325005207211, 0.05556863499805331, 0.05221406405325979, 0.05115515703801066, 0.05171807191800326, 0.05137156799901277, 0.05142518202774227, 0.051177261979319155, 0.051164850941859186, 0.054344394942745566, 0.05518952303100377, 0.05445650708861649, 0.054750930052250624, 0.05478127603419125, 0.05490613402798772, 0.05480163695756346, 0.05609484703745693, 0.04993747209664434, 0.05126859399024397, 0.05075211403891444, 0.1685315240174532, 0.05162537202704698, 0.051225773990154266, 0.05288649594876915, 0.05139271204825491, 0.05160208500456065, 0.05294711096212268, 0.05313216208014637, 0.05165677308104932, 0.05243924097158015, 0.17706317000556737, 0.05191659997217357, 0.05182034394238144, 0.051659283926710486, 0.05246815492864698, 0.05235217197332531, 0.05365886108484119, 0.05323299195151776, 0.05265829002019018, 0.05263414699584246, 0.0676293500000611, 0.05719413293991238, 0.056645869044587016, 0.05642796203028411, 0.056778144906274974, 0.05731599195860326, 0.059537201072089374, 0.05739801691379398, 0.05682333291042596, 0.05845911893993616, 0.058130612946115434, 0.05805691797286272, 0.058051269967108965, 0.057395798969082534, 0.05754371196962893, 0.05744986899662763, 0.05773182399570942, 0.05790532601531595, 0.05728240392636508, 0.050195378018543124, 0.04923180292826146, 0.049773050006479025, 0.0497087009716779, 0.0630458869272843, 0.049189976998604834, 0.04912629700265825, 0.0493264039978385, 0.049641327932477, 0.04938982299063355, 0.050464511034078896, 0.049961025011725724, 0.051323052030056715, 0.0511378200026229, 0.051035723998211324, 0.05268462700769305, 0.0648930900497362, 0.05470212199725211, 0.05423739203251898, 0.054917332949116826, 0.05504412099253386, 0.05465802096296102, 0.055167095037177205, 0.05460162798408419, 0.051414716988801956, 0.0523206670768559, 0.06421372701879591, 0.05011018295772374, 0.05077355110552162, 0.050684235990047455, 0.05184749106410891, 0.05096714198589325, 0.051827625022269785, 0.0509588000131771, 0.050858928938396275, 0.050585905904881656, 0.05478502600453794, 0.05453679501079023, 0.0498408010462299, 0.049696411937475204, 0.05001374601852149, 0.04977379599586129, 0.050390489981509745, 0.04999510396737605, 0.05018810695037246, 0.0501637909328565, 0.04990277299657464, 0.05021389992907643, 0.04984696605242789, 0.04990042408462614, 0.05030909099150449, 0.0500160229858011, 0.05022972892038524, 0.05001682601869106, 0.050066119991242886, 0.05009726795833558, 0.04982470301911235, 0.05009329097811133, 0.04997404105961323, 0.050209535052999854, 0.05007195600774139, 0.050089846015907824, 0.04999060707632452, 0.04999139194842428, 0.05048870004247874, 0.050324185052886605, 0.0500008879462257, 0.04978850902989507, 0.049748847959563136, 0.05007823510095477, 0.05014294001739472, 0.05002366297412664, 0.04996792192105204, 0.050258798990398645, 0.05053384997881949, 0.05050458910409361, 0.050366812967695296, 0.050430893083103, 0.05054949899204075, 0.050564792938530445, 0.05043607298284769, 0.050678214989602566, 0.05062947701662779, 0.05044183996506035, 0.05029597599059343, 0.05073008802719414, 0.050634116982109845, 0.05065284192096442, 0.05045288393739611, 0.05071554391179234, 0.050706933019682765, 0.050342231057584286, 0.050400912994518876, 0.049979129107668996, 0.0499368729069829, 0.05030904698651284, 0.05016600503586233, 0.050237723044119775, 0.0506107360124588, 0.05103614600375295, 0.05044599296525121, 0.05105361295863986, 0.05063227389473468, 0.05065905803348869, 0.050554558052681386, 0.05095363897271454, 0.050541017088107765, 0.05065784195903689, 0.05064577504526824, 0.050689422991126776, 0.0508149970555678, 0.050429972005076706]
[0.0012211278636558827, 0.0011810760003175926, 0.001182377886090597, 0.0011872926605230366, 0.001179977203719318, 0.001177000318421051, 0.001172775635495782, 0.0011764673637861217, 0.0011753181143748489, 0.00118132220284844, 0.001189729249083691, 0.0011891013180667703, 0.0011829898655626246, 0.0011742799304722046, 0.001180985318073495, 0.001175985795932568, 0.0011772683858659796, 0.0011835892959921198, 0.0011821185445031997, 0.0011932889994403179, 0.0011923788194756278, 0.001200764477041296, 0.0011947252496611327, 0.0012262275902850722, 0.001207580250179903, 0.0011981317260175604, 0.0012064291592899033, 0.0011963841600597582, 0.002750367296605625, 0.0011666549332651564, 0.0011666086581747302, 0.0011766395685051314, 0.001177710544487292, 0.001183071909260682, 0.0011860800441354513, 0.0012098067725839262, 0.0011992854097942736, 0.0013032428184735843, 0.0012039995450653475, 0.0043959379783535205, 0.0014456321607047523, 0.0012928532510572536, 0.0012951951833780515, 0.0012918752274179662, 0.00131768802318468, 0.001302332138452171, 0.0013006093186876651, 0.0012958200452637604, 0.0021102225900077346, 0.001263091795739125, 0.0012667725439479743, 0.0012580358650831674, 0.001274846592092548, 0.0012629235226830299, 0.0011866832739377226, 0.0011626172054093331, 0.001175410725409165, 0.0011675356363411993, 0.0011687541369941425, 0.0011631195904390718, 0.0011628375214058906, 0.0012350998850623992, 0.0012543073416137222, 0.0012376478883776474, 0.0012443393193693323, 0.0012450290007770739, 0.0012478666824542663, 0.001245491749035533, 0.0012748828872149302, 0.0011349425476510078, 0.0011651953179600903, 0.0011534571372480555, 0.0038302619094875727, 0.0011733039097056132, 0.0011642221361398697, 0.0012019658170174807, 0.0011680161829148842, 0.0011727746591945602, 0.0012033434309573336, 0.0012075491381851448, 0.0011740175700238483, 0.001191800931172276, 0.004024162954671986, 0.0011799227266403084, 0.0011777350895995783, 0.0011740746346979656, 0.0011924580665601586, 0.001189822090302848, 0.0012195195701100272, 0.0012098407261708583, 0.001196779318640686, 0.001196230613541874, 0.0015370306818195704, 0.0012998666577252814, 0.001287406114649705, 0.001282453682506457, 0.001290412384233522, 0.001302636180877347, 0.0013531182061838495, 0.0013045003844044086, 0.0012914393843278628, 0.0013286163395440037, 0.0013211502942298962, 0.0013194754084741528, 0.001319347044707022, 0.0013044499765700575, 0.0013078116356733847, 0.0013056788408324462, 0.0013120869089933958, 0.001316030136711726, 0.0013018728165082973, 0.0011673343725242587, 0.0011449256494944526, 0.0011575127908483493, 0.001156016301666928, 0.0014661834169135883, 0.0011439529534559264, 0.0011424720233176337, 0.0011471256743683371, 0.0011544494868017906, 0.0011486005346658965, 0.0011735932798623, 0.0011618843025982726, 0.0011935593495362026, 0.0011892516279679744, 0.0011868773022839843, 0.0012252238838998384, 0.0015091416290636326, 0.0012721423720291189, 0.001261334698430674, 0.0012771472778864378, 0.0012800958370356712, 0.0012711167665804888, 0.0012829556985390048, 0.0012698053019554463, 0.0011956910927628363, 0.001216759699461765, 0.0014933424888092072, 0.001165353092040087, 0.0011807802582679446, 0.001178703162559243, 0.0012057556061420677, 0.0011852823717649593, 0.0012052936051690647, 0.0011850883723994673, 0.0011827657892650298, 0.0011764164163925966, 0.0012740703721985567, 0.0012682975583904704, 0.0011590883964239511, 0.001155730510173842, 0.0011631103725237555, 0.0011575301394386346, 0.0011718718600351103, 0.001162676836450606, 0.0011671652779156386, 0.0011665997891361977, 0.0011605296045715033, 0.0011677651146296845, 0.0011592317686611136, 0.0011604749787122357, 0.0011699788602675463, 0.0011631633252511884, 0.0011681332307066335, 0.001163182000434676, 0.0011643283718893694, 0.0011650527432171065, 0.001158714023700287, 0.0011649602553049146, 0.0011621870013863542, 0.0011676636058837175, 0.0011644640932032882, 0.001164880139904833, 0.0011625722575889423, 0.0011625905104284716, 0.001174155814941366, 0.0011703298849508512, 0.0011628113475866443, 0.0011578723030208156, 0.00115694995254798, 0.001164610118626855, 0.0011661148841254586, 0.0011633409993982938, 0.0011620446958384195, 0.0011688092788464802, 0.0011752058134609183, 0.001174525328002177, 0.0011713212318068674, 0.001172811467048907, 0.0011755697440009477, 0.0011759254171751267, 0.0011729319298336672, 0.001178563139293083, 0.0011774296980611113, 0.001173066045699078, 0.001169673860246359, 0.0011797694890045148, 0.0011775376042351127, 0.001177973067929405, 0.0011733228822650259, 0.0011794312537626126, 0.0011792310004577387, 0.0011707495594787043, 0.0011721142556864856, 0.0011623053280853254, 0.0011613226257437884, 0.0011699778368956474, 0.001166651279903775, 0.001168319140560925, 0.001176993860754856, 0.0011868871163663475, 0.0011731626270988652, 0.0011872933246195316, 0.001177494741738016, 0.0011781176286857836, 0.0011756873965739858, 0.0011849683482026638, 0.0011753724904211109, 0.0011780893478845788, 0.0011778087219829823, 0.0011788237904913205, 0.0011817441175713441, 0.001172790046629691]
[818.9150618561291, 846.685564460796, 845.7533008388634, 842.2523218154748, 847.47399936878, 849.6174421953451, 852.6780142198791, 850.0023296709122, 850.8334788423639, 846.5091044498865, 840.5273727364296, 840.9712316405388, 845.3157792052637, 851.5857029063567, 846.7505774172276, 850.3504068320744, 849.4239818258741, 844.8876678643585, 845.9388482229273, 838.0199603524585, 838.6596471411408, 832.8027844927733, 837.0125267576258, 815.5092969059039, 828.1023144018974, 834.6327689058652, 828.8924320998622, 835.8519223039956, 363.5878019761773, 857.1514776878082, 857.185477745892, 849.8779292884531, 849.1050748257866, 845.2571582271054, 843.1134179724882, 826.5782789958951, 833.8298722166066, 767.3167162902492, 830.5650978844221, 227.48273631798273, 691.7388995500041, 773.4829913466453, 772.0844030564251, 774.068562332193, 758.904977813436, 767.8532768057968, 768.870394538627, 771.712093554204, 473.883657930292, 791.7080954633457, 789.4076997307177, 794.8898976213933, 784.4081054165023, 791.813583355816, 842.6848359307711, 860.1283340271237, 850.7664413661838, 856.5049056093746, 855.611944674564, 859.7568196942716, 859.9653705626756, 809.6511157471919, 797.2527679806574, 807.9842493092565, 803.6393164099559, 803.1941419644513, 801.3676573472018, 802.8957243388937, 784.3857738059133, 881.1018690502893, 858.2252130490036, 866.9589599019023, 261.0787522187442, 852.294100213903, 858.9426097975, 831.9704153329151, 856.1525213669681, 852.678724049837, 831.0179573627112, 828.1236501091165, 851.7760087523108, 839.0663019673786, 248.4988831873761, 847.5131272768876, 849.0873786735802, 851.7346090670404, 838.603912408144, 840.4617868083689, 819.9950410880068, 826.5550814816729, 835.5759365359105, 835.9592111082476, 650.6050997083404, 769.3096780787986, 776.7556706627059, 779.7552563813275, 774.9460654734642, 767.6740556419088, 739.0337336604641, 766.5770067645988, 774.329799861614, 752.6627290638405, 756.9161543296661, 757.8769513835839, 757.9506878132, 766.6066295845369, 764.6361086893876, 765.8851232991123, 762.1446362628357, 759.8610184555736, 768.1241879541362, 856.6525783333076, 873.4191608350768, 863.9213388450704, 865.0397045076623, 682.0429070907549, 874.1618236824872, 875.2949565417733, 871.7440663601644, 866.2137334136055, 870.6247035579509, 852.0839520462592, 860.670892759066, 837.8301425803278, 840.864941012239, 842.5470754859291, 816.1773641051137, 662.6283317228904, 786.0755383888043, 792.8109812916261, 782.9950525791425, 781.1915100948289, 786.7097864582205, 779.4501409041426, 787.5223063410134, 836.336413353502, 821.8549648236633, 669.6387516552891, 858.1090202020943, 846.8976280708432, 848.3900202904043, 829.3554638320093, 843.6808171802452, 829.673363993109, 843.8189280140215, 845.475925222186, 850.039140958636, 784.886001449342, 788.4585075359187, 862.746968294416, 865.2536133614597, 859.7636334634062, 863.908390743906, 853.3356197921154, 860.08422000801, 856.7766870051449, 857.1919944717669, 861.6755626576413, 856.3365932686854, 862.6402649014505, 861.7161234356704, 854.7162978409061, 859.7244929331375, 856.0667342671816, 859.7106898372779, 858.8642380819838, 858.3302394007161, 863.025716049036, 858.3983835038748, 860.4467257051715, 856.4110373579508, 858.7641352247548, 858.457420418977, 860.161588643014, 860.1480839813934, 851.6757207815192, 854.4599372013777, 859.9847275961394, 863.6530966247861, 864.3416232462562, 858.6564585056668, 857.5484402207605, 859.5931893720092, 860.552097162232, 855.5715787839388, 850.914783220016, 851.407778239199, 853.7367656671014, 852.6519633341028, 850.6513587161476, 850.3940687005946, 852.5643940324903, 848.4908161982842, 849.3076076191325, 852.4669209090091, 854.9391706414453, 847.6232088726047, 849.2297795020866, 848.9158430062928, 852.2803186703076, 847.8662887809762, 848.0102707712339, 854.1536419157541, 853.1591482217052, 860.3591292550535, 861.0871585831142, 854.7170454556157, 857.1541618524428, 855.9305118632972, 849.6221036859596, 842.5401086680407, 852.3967409982347, 842.2518507130075, 849.2606926838343, 848.8116769082917, 850.5662329238639, 843.9043975451158, 850.7941168860617, 848.8320531847922, 849.0342967713638, 848.3032053358979, 846.2068777250571, 852.6675365925497]
Elapsed: 0.05472895694998899~0.015865691398945468
Time per graph: 0.0012574006674653765~0.0003578188644492092
Speed: 818.6180710521667~87.25047028408943
Total Time: 0.0512
best val loss: 0.39565637707710266 test_score: 0.8837

Testing...
Test loss: 0.3473 score: 0.8837 time: 0.05s
test Score 0.8837
Epoch Time List: [0.16021681309212, 0.15685589390341192, 0.15652737708296627, 0.2788927850779146, 0.1561157020041719, 0.15497915796004236, 0.1559180358890444, 0.15587775316089392, 0.15454333100933582, 0.1562916268594563, 0.15670433710329235, 0.16056136786937714, 0.1564342019846663, 0.15479549602605402, 0.15583424095530063, 0.15574299602303654, 0.27261229208670557, 0.15674111992120743, 0.15654971299227327, 0.15678246296010911, 0.158056540065445, 0.15846228308510035, 0.15926994488108903, 0.1612274720100686, 0.16060875891707838, 0.15883929701521993, 0.15842107799835503, 0.15672101988457143, 0.238232230884023, 0.15486107289325446, 0.1543803330278024, 0.15670443209819496, 0.15804807608947158, 0.15683557803276926, 0.1576765220379457, 0.16023721499368548, 0.16074118204414845, 0.1639973388519138, 0.1620076799299568, 0.2963076781015843, 0.17450952995568514, 0.17716361198108643, 0.16706866712775081, 0.16689290013164282, 0.1678136111004278, 0.16992040001787245, 0.16803808510303497, 0.1688688270514831, 0.20216740283649415, 0.20954329194501042, 0.1655278541147709, 0.16685671999584883, 0.16700412798672915, 0.1674432649742812, 0.16063704900443554, 0.15564836794510484, 0.15641297900583595, 0.1536013449076563, 0.15443786489777267, 0.1533470608992502, 0.15391807502601296, 0.15452825999818742, 0.2896203740965575, 0.1648231450235471, 0.1652707220055163, 0.16485186095815152, 0.16340827208478004, 0.16500008397269994, 0.1672619441524148, 0.1530680648284033, 0.15519097505602986, 0.15395190403796732, 0.2713588820770383, 0.15503247501328588, 0.15560446912422776, 0.15796708990819752, 0.15595784795004874, 0.15888554707635194, 0.157831309014, 0.16326620511244982, 0.15832796995528042, 0.15763569506816566, 0.28249417908955365, 0.1568998059956357, 0.15750484296586365, 0.1558745780494064, 0.1573934480547905, 0.1577274069422856, 0.15858727891463786, 0.16230981203261763, 0.16188045486342162, 0.1610671429662034, 0.1701701529091224, 0.2675013979896903, 0.170392706990242, 0.1697855609236285, 0.17104206699877977, 0.17308881203643978, 0.17418881703633815, 0.17512535897549242, 0.17273606196977198, 0.1735314279794693, 0.2707431298913434, 0.17786680406425148, 0.17646702227648348, 0.17441067495383322, 0.17503174708690494, 0.17651119304355234, 0.17731734993867576, 0.17513375903945416, 0.17349251895211637, 0.16215820307843387, 0.1583408780861646, 0.15699056792072952, 0.16054726508446038, 0.17127713095396757, 0.23440205492079258, 0.16089982993435115, 0.1598442478571087, 0.1597170631866902, 0.16055251588113606, 0.1646557878702879, 0.16229770507197827, 0.164038922986947, 0.16514957905746996, 0.16492094204295427, 0.16793307394254953, 0.3158312179148197, 0.17646109801717103, 0.1764936710242182, 0.17580543912481517, 0.17650182696525007, 0.17755637899972498, 0.17820630909409374, 0.17851502704434097, 0.174034386058338, 0.1682174460729584, 0.31556502310559154, 0.17124186898581684, 0.16381038294639438, 0.16355802898760885, 0.16486578504554927, 0.16507109999656677, 0.16686916293110698, 0.16857338312547654, 0.16584319702815264, 0.16412229603156447, 0.31990997202228755, 0.1772251770598814, 0.16446705698035657, 0.15945338609162718, 0.1616436009062454, 0.16138972993940115, 0.1632301559438929, 0.16384022508282214, 0.16349957801867276, 0.16362597909756005, 0.16282683005556464, 0.16333063994534314, 0.1636822809232399, 0.16274163615889847, 0.1650585001334548, 0.16365717386361212, 0.1641768729314208, 0.16322189895436168, 0.1635964959859848, 0.16391069593373686, 0.16258306696545333, 0.16250347916502506, 0.16268397914245725, 0.16515595593955368, 0.162553969072178, 0.16328626405447721, 0.1638244919013232, 0.16418176412116736, 0.1632087449543178, 0.16483688598964363, 0.16386238299310207, 0.16328785999212414, 0.1640547178685665, 0.16402216698043048, 0.16557773191016167, 0.16471126105170697, 0.16380064096301794, 0.1658118338091299, 0.1642929099034518, 0.16534039191901684, 0.16406437091063708, 0.1660593090346083, 0.1661218989174813, 0.16507345996797085, 0.16605539584998041, 0.16547445312608033, 0.1654845270095393, 0.16562540491577238, 0.16495470807421952, 0.1650526140583679, 0.1652098021004349, 0.16626774589531124, 0.16572622687090188, 0.166394277010113, 0.16574326099362224, 0.1646992889000103, 0.16404591605532914, 0.16441310103982687, 0.16538823989685625, 0.16570137708913535, 0.1649768529459834, 0.16547526407521218, 0.16546165791805834, 0.1657206870149821, 0.16572249005548656, 0.1667115440359339, 0.16676822293084115, 0.16584616003092378, 0.1653691640822217, 0.16556449397467077, 0.16661518590990454, 0.16635727416723967, 0.1657386670121923, 0.16612827696371824, 0.16505992983002216, 0.16529381391592324]
Total Epoch List: [111, 112]
Total Time List: [0.057831665966659784, 0.051170891034416854]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7ae0cf160>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6956;  Loss pred: 0.6956; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6905;  Loss pred: 0.6905; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6903;  Loss pred: 0.6903; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6921;  Loss pred: 0.6921; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6884;  Loss pred: 0.6884; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6870;  Loss pred: 0.6870; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6834;  Loss pred: 0.6834; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6800;  Loss pred: 0.6800; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6796;  Loss pred: 0.6796; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6736;  Loss pred: 0.6736; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6698;  Loss pred: 0.6698; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6681;  Loss pred: 0.6681; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6590;  Loss pred: 0.6590; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6567;  Loss pred: 0.6567; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6537;  Loss pred: 0.6537; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6498;  Loss pred: 0.6498; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6441;  Loss pred: 0.6441; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6417;  Loss pred: 0.6417; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6340;  Loss pred: 0.6340; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6283;  Loss pred: 0.6283; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6219;  Loss pred: 0.6219; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6200;  Loss pred: 0.6200; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6035;  Loss pred: 0.6035; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6055;  Loss pred: 0.6055; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5947;  Loss pred: 0.5947; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5828;  Loss pred: 0.5828; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6913 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5729;  Loss pred: 0.5729; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6912 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5732;  Loss pred: 0.5732; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5578;  Loss pred: 0.5578; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6904 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5466;  Loss pred: 0.5466; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6899 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5373;  Loss pred: 0.5373; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6894 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5265;  Loss pred: 0.5265; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6888 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5076;  Loss pred: 0.5076; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5044;  Loss pred: 0.5044; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6872 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6876 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4849;  Loss pred: 0.4849; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6863 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6869 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4735;  Loss pred: 0.4735; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6855 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6861 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4596;  Loss pred: 0.4596; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6845 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6853 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4475;  Loss pred: 0.4475; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6834 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6844 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4409;  Loss pred: 0.4409; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6822 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6834 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4289;  Loss pred: 0.4289; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6824 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4121;  Loss pred: 0.4121; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6794 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6812 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3971;  Loss pred: 0.3971; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6778 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6798 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3844;  Loss pred: 0.3844; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6759 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6783 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3676;  Loss pred: 0.3676; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6740 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6767 score: 0.5116 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3474;  Loss pred: 0.3474; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6717 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6748 score: 0.5116 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3349;  Loss pred: 0.3349; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6694 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6728 score: 0.5116 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3226;  Loss pred: 0.3226; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6668 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6706 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3166;  Loss pred: 0.3166; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6639 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6681 score: 0.5116 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2910;  Loss pred: 0.2910; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6607 score: 0.5000 time: 0.05s
Test loss: 0.6652 score: 0.5581 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2802;  Loss pred: 0.2802; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6569 score: 0.5000 time: 0.05s
Test loss: 0.6620 score: 0.5814 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2701;  Loss pred: 0.2701; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6528 score: 0.5000 time: 0.05s
Test loss: 0.6585 score: 0.5814 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2403;  Loss pred: 0.2403; Loss self: 0.0000; time: 0.07s
Val loss: 0.6483 score: 0.5227 time: 0.05s
Test loss: 0.6545 score: 0.5814 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2378;  Loss pred: 0.2378; Loss self: 0.0000; time: 0.07s
Val loss: 0.6436 score: 0.5682 time: 0.05s
Test loss: 0.6502 score: 0.6047 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2249;  Loss pred: 0.2249; Loss self: 0.0000; time: 0.07s
Val loss: 0.6384 score: 0.5682 time: 0.05s
Test loss: 0.6455 score: 0.6047 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2078;  Loss pred: 0.2078; Loss self: 0.0000; time: 0.07s
Val loss: 0.6325 score: 0.6364 time: 0.05s
Test loss: 0.6403 score: 0.6047 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1941;  Loss pred: 0.1941; Loss self: 0.0000; time: 0.07s
Val loss: 0.6266 score: 0.6591 time: 0.05s
Test loss: 0.6348 score: 0.6279 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1729;  Loss pred: 0.1729; Loss self: 0.0000; time: 0.07s
Val loss: 0.6202 score: 0.6818 time: 0.05s
Test loss: 0.6289 score: 0.6512 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1721;  Loss pred: 0.1721; Loss self: 0.0000; time: 0.07s
Val loss: 0.6134 score: 0.7045 time: 0.05s
Test loss: 0.6225 score: 0.6512 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1478;  Loss pred: 0.1478; Loss self: 0.0000; time: 0.07s
Val loss: 0.6062 score: 0.7045 time: 0.07s
Test loss: 0.6157 score: 0.6744 time: 0.11s
Epoch 61/1000, LR 0.000268
Train loss: 0.1500;  Loss pred: 0.1500; Loss self: 0.0000; time: 0.07s
Val loss: 0.5988 score: 0.7045 time: 0.05s
Test loss: 0.6087 score: 0.6977 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1271;  Loss pred: 0.1271; Loss self: 0.0000; time: 0.07s
Val loss: 0.5912 score: 0.7045 time: 0.05s
Test loss: 0.6015 score: 0.7209 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1267;  Loss pred: 0.1267; Loss self: 0.0000; time: 0.07s
Val loss: 0.5830 score: 0.7273 time: 0.05s
Test loss: 0.5937 score: 0.7209 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1091;  Loss pred: 0.1091; Loss self: 0.0000; time: 0.07s
Val loss: 0.5748 score: 0.7273 time: 0.05s
Test loss: 0.5860 score: 0.7209 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1069;  Loss pred: 0.1069; Loss self: 0.0000; time: 0.07s
Val loss: 0.5666 score: 0.7273 time: 0.05s
Test loss: 0.5784 score: 0.7209 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1016;  Loss pred: 0.1016; Loss self: 0.0000; time: 0.07s
Val loss: 0.5585 score: 0.7273 time: 0.05s
Test loss: 0.5709 score: 0.7209 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0923;  Loss pred: 0.0923; Loss self: 0.0000; time: 0.07s
Val loss: 0.5495 score: 0.7045 time: 0.05s
Test loss: 0.5627 score: 0.7209 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0720;  Loss pred: 0.0720; Loss self: 0.0000; time: 0.07s
Val loss: 0.5407 score: 0.7045 time: 0.05s
Test loss: 0.5550 score: 0.7209 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0751;  Loss pred: 0.0751; Loss self: 0.0000; time: 0.07s
Val loss: 0.5322 score: 0.7045 time: 0.05s
Test loss: 0.5478 score: 0.7209 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0688;  Loss pred: 0.0688; Loss self: 0.0000; time: 0.07s
Val loss: 0.5248 score: 0.7045 time: 0.05s
Test loss: 0.5418 score: 0.7442 time: 0.16s
Epoch 71/1000, LR 0.000268
Train loss: 0.0625;  Loss pred: 0.0625; Loss self: 0.0000; time: 0.07s
Val loss: 0.5176 score: 0.7045 time: 0.05s
Test loss: 0.5362 score: 0.7674 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0562;  Loss pred: 0.0562; Loss self: 0.0000; time: 0.07s
Val loss: 0.5112 score: 0.7045 time: 0.05s
Test loss: 0.5316 score: 0.7674 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0473;  Loss pred: 0.0473; Loss self: 0.0000; time: 0.07s
Val loss: 0.5056 score: 0.7045 time: 0.05s
Test loss: 0.5276 score: 0.7674 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0534;  Loss pred: 0.0534; Loss self: 0.0000; time: 0.07s
Val loss: 0.4997 score: 0.7045 time: 0.05s
Test loss: 0.5234 score: 0.7674 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0385;  Loss pred: 0.0385; Loss self: 0.0000; time: 0.07s
Val loss: 0.4943 score: 0.7273 time: 0.05s
Test loss: 0.5197 score: 0.7674 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0368;  Loss pred: 0.0368; Loss self: 0.0000; time: 0.07s
Val loss: 0.4895 score: 0.7273 time: 0.05s
Test loss: 0.5171 score: 0.7674 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0354;  Loss pred: 0.0354; Loss self: 0.0000; time: 0.07s
Val loss: 0.4855 score: 0.7273 time: 0.05s
Test loss: 0.5155 score: 0.7674 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0350;  Loss pred: 0.0350; Loss self: 0.0000; time: 0.07s
Val loss: 0.4825 score: 0.7273 time: 0.06s
Test loss: 0.5150 score: 0.7674 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0258;  Loss pred: 0.0258; Loss self: 0.0000; time: 0.07s
Val loss: 0.4799 score: 0.7273 time: 0.05s
Test loss: 0.5152 score: 0.7674 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0296;  Loss pred: 0.0296; Loss self: 0.0000; time: 0.07s
Val loss: 0.4766 score: 0.7273 time: 0.05s
Test loss: 0.5144 score: 0.7674 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0215;  Loss pred: 0.0215; Loss self: 0.0000; time: 0.18s
Val loss: 0.4742 score: 0.7273 time: 0.05s
Test loss: 0.5147 score: 0.7674 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0228;  Loss pred: 0.0228; Loss self: 0.0000; time: 0.07s
Val loss: 0.4722 score: 0.7273 time: 0.05s
Test loss: 0.5151 score: 0.7674 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.07s
Val loss: 0.4714 score: 0.7273 time: 0.05s
Test loss: 0.5169 score: 0.7674 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0188;  Loss pred: 0.0188; Loss self: 0.0000; time: 0.07s
Val loss: 0.4706 score: 0.7273 time: 0.05s
Test loss: 0.5185 score: 0.7674 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.07s
Val loss: 0.4698 score: 0.7273 time: 0.05s
Test loss: 0.5201 score: 0.7674 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0138;  Loss pred: 0.0138; Loss self: 0.0000; time: 0.07s
Val loss: 0.4702 score: 0.7273 time: 0.05s
Test loss: 0.5228 score: 0.7674 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 87/1000, LR 0.000266
Train loss: 0.0134;  Loss pred: 0.0134; Loss self: 0.0000; time: 0.07s
Val loss: 0.4703 score: 0.7273 time: 0.05s
Test loss: 0.5254 score: 0.7674 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 88/1000, LR 0.000266
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.07s
Val loss: 0.4708 score: 0.7500 time: 0.05s
Test loss: 0.5282 score: 0.7674 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.07s
Val loss: 0.4721 score: 0.7727 time: 0.05s
Test loss: 0.5318 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.07s
Val loss: 0.4739 score: 0.7727 time: 0.05s
Test loss: 0.5359 score: 0.7674 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0093;  Loss pred: 0.0093; Loss self: 0.0000; time: 0.07s
Val loss: 0.4767 score: 0.7727 time: 0.05s
Test loss: 0.5410 score: 0.7674 time: 0.10s
     INFO: Early stopping counter 6 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.10s
Val loss: 0.4792 score: 0.7727 time: 0.05s
Test loss: 0.5456 score: 0.7674 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.07s
Val loss: 0.4820 score: 0.7727 time: 0.05s
Test loss: 0.5507 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.06s
Val loss: 0.4854 score: 0.7955 time: 0.05s
Test loss: 0.5563 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0126;  Loss pred: 0.0126; Loss self: 0.0000; time: 0.07s
Val loss: 0.4856 score: 0.8182 time: 0.05s
Test loss: 0.5583 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0067;  Loss pred: 0.0067; Loss self: 0.0000; time: 0.06s
Val loss: 0.4871 score: 0.8182 time: 0.05s
Test loss: 0.5614 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.07s
Val loss: 0.4894 score: 0.8182 time: 0.05s
Test loss: 0.5654 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.4929 score: 0.8409 time: 0.05s
Test loss: 0.5705 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.4949 score: 0.8409 time: 0.05s
Test loss: 0.5739 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0059;  Loss pred: 0.0059; Loss self: 0.0000; time: 0.07s
Val loss: 0.4973 score: 0.8409 time: 0.05s
Test loss: 0.5776 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.5009 score: 0.8409 time: 0.05s
Test loss: 0.5826 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.18s
Val loss: 0.5043 score: 0.8409 time: 0.05s
Test loss: 0.5876 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.5063 score: 0.8409 time: 0.05s
Test loss: 0.5911 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.5092 score: 0.8409 time: 0.05s
Test loss: 0.5955 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.07s
Val loss: 0.5133 score: 0.8409 time: 0.05s
Test loss: 0.6014 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 084,   Train_Loss: 0.0150,   Val_Loss: 0.4698,   Val_Precision: 0.8571,   Val_Recall: 0.5455,   Val_accuracy: 0.6667,   Val_Score: 0.7273,   Val_Loss: 0.4698,   Test_Precision: 1.0000,   Test_Recall: 0.5238,   Test_accuracy: 0.6875,   Test_Score: 0.7674,   Test_loss: 0.5201


[0.05372962600085884, 0.05196734401397407, 0.05202462698798627, 0.05224087706301361, 0.05191899696364999, 0.05178801401052624, 0.051602127961814404, 0.05176456400658935, 0.05171399703249335, 0.051978176925331354, 0.052348086959682405, 0.0523204579949379, 0.05205155408475548, 0.051668316940777004, 0.051963353995233774, 0.05174337502103299, 0.0517998089781031, 0.05207792902365327, 0.05201321595814079, 0.05250471597537398, 0.05246466805692762, 0.05283363698981702, 0.05256791098508984, 0.05395401397254318, 0.053133531007915735, 0.05271779594477266, 0.053082883008755744, 0.05264090304262936, 0.1210161610506475, 0.05133281706366688, 0.05133078095968813, 0.05177214101422578, 0.05181926395744085, 0.05205516400747001, 0.05218752194195986, 0.053231497993692756, 0.05276855803094804, 0.05734268401283771, 0.05297597998287529, 0.1934212710475549, 0.0636078150710091, 0.05688554304651916, 0.05698858806863427, 0.05684251000639051, 0.057978273020125926, 0.05730261409189552, 0.05722681002225727, 0.05701608199160546, 0.09284979396034032, 0.055576039012521505, 0.05573799193371087, 0.05535357806365937, 0.05609325005207211, 0.05556863499805331, 0.05221406405325979, 0.05115515703801066, 0.05171807191800326, 0.05137156799901277, 0.05142518202774227, 0.051177261979319155, 0.051164850941859186, 0.054344394942745566, 0.05518952303100377, 0.05445650708861649, 0.054750930052250624, 0.05478127603419125, 0.05490613402798772, 0.05480163695756346, 0.05609484703745693, 0.04993747209664434, 0.05126859399024397, 0.05075211403891444, 0.1685315240174532, 0.05162537202704698, 0.051225773990154266, 0.05288649594876915, 0.05139271204825491, 0.05160208500456065, 0.05294711096212268, 0.05313216208014637, 0.05165677308104932, 0.05243924097158015, 0.17706317000556737, 0.05191659997217357, 0.05182034394238144, 0.051659283926710486, 0.05246815492864698, 0.05235217197332531, 0.05365886108484119, 0.05323299195151776, 0.05265829002019018, 0.05263414699584246, 0.0676293500000611, 0.05719413293991238, 0.056645869044587016, 0.05642796203028411, 0.056778144906274974, 0.05731599195860326, 0.059537201072089374, 0.05739801691379398, 0.05682333291042596, 0.05845911893993616, 0.058130612946115434, 0.05805691797286272, 0.058051269967108965, 0.057395798969082534, 0.05754371196962893, 0.05744986899662763, 0.05773182399570942, 0.05790532601531595, 0.05728240392636508, 0.050195378018543124, 0.04923180292826146, 0.049773050006479025, 0.0497087009716779, 0.0630458869272843, 0.049189976998604834, 0.04912629700265825, 0.0493264039978385, 0.049641327932477, 0.04938982299063355, 0.050464511034078896, 0.049961025011725724, 0.051323052030056715, 0.0511378200026229, 0.051035723998211324, 0.05268462700769305, 0.0648930900497362, 0.05470212199725211, 0.05423739203251898, 0.054917332949116826, 0.05504412099253386, 0.05465802096296102, 0.055167095037177205, 0.05460162798408419, 0.051414716988801956, 0.0523206670768559, 0.06421372701879591, 0.05011018295772374, 0.05077355110552162, 0.050684235990047455, 0.05184749106410891, 0.05096714198589325, 0.051827625022269785, 0.0509588000131771, 0.050858928938396275, 0.050585905904881656, 0.05478502600453794, 0.05453679501079023, 0.0498408010462299, 0.049696411937475204, 0.05001374601852149, 0.04977379599586129, 0.050390489981509745, 0.04999510396737605, 0.05018810695037246, 0.0501637909328565, 0.04990277299657464, 0.05021389992907643, 0.04984696605242789, 0.04990042408462614, 0.05030909099150449, 0.0500160229858011, 0.05022972892038524, 0.05001682601869106, 0.050066119991242886, 0.05009726795833558, 0.04982470301911235, 0.05009329097811133, 0.04997404105961323, 0.050209535052999854, 0.05007195600774139, 0.050089846015907824, 0.04999060707632452, 0.04999139194842428, 0.05048870004247874, 0.050324185052886605, 0.0500008879462257, 0.04978850902989507, 0.049748847959563136, 0.05007823510095477, 0.05014294001739472, 0.05002366297412664, 0.04996792192105204, 0.050258798990398645, 0.05053384997881949, 0.05050458910409361, 0.050366812967695296, 0.050430893083103, 0.05054949899204075, 0.050564792938530445, 0.05043607298284769, 0.050678214989602566, 0.05062947701662779, 0.05044183996506035, 0.05029597599059343, 0.05073008802719414, 0.050634116982109845, 0.05065284192096442, 0.05045288393739611, 0.05071554391179234, 0.050706933019682765, 0.050342231057584286, 0.050400912994518876, 0.049979129107668996, 0.0499368729069829, 0.05030904698651284, 0.05016600503586233, 0.050237723044119775, 0.0506107360124588, 0.05103614600375295, 0.05044599296525121, 0.05105361295863986, 0.05063227389473468, 0.05065905803348869, 0.050554558052681386, 0.05095363897271454, 0.050541017088107765, 0.05065784195903689, 0.05064577504526824, 0.050689422991126776, 0.0508149970555678, 0.050429972005076706, 0.05594031000509858, 0.05416756996419281, 0.05397240596357733, 0.05392156902235001, 0.053449010010808706, 0.05400534195359796, 0.054347767028957605, 0.053880266030319035, 0.05404022301081568, 0.054153586039319634, 0.053929773974232376, 0.05410177307203412, 0.054431958007626235, 0.05423310201149434, 0.053960603079758584, 0.0545477110426873, 0.05404287902638316, 0.054176372941583395, 0.054205732070840895, 0.054386973031796515, 0.05409840296488255, 0.05461708293296397, 0.053901845938526094, 0.05383747594896704, 0.05357657396234572, 0.05381437495816499, 0.05383308103773743, 0.05424957105424255, 0.05396980908699334, 0.053559136926196516, 0.053804181050509214, 0.05379667098168284, 0.053289155941456556, 0.054221219033934176, 0.05378308903891593, 0.053927398985251784, 0.05370029411278665, 0.053804126917384565, 0.0540366149507463, 0.05349545308854431, 0.05351077695377171, 0.053653941955417395, 0.05355076293926686, 0.05362606490962207, 0.053862033993937075, 0.0533931499812752, 0.05403634696267545, 0.05369338602758944, 0.05377267301082611, 0.05344494804739952, 0.05359690904151648, 0.05361075897235423, 0.05343695590272546, 0.05361105804331601, 0.053102253936231136, 0.05430825299117714, 0.05346565297804773, 0.052820296958088875, 0.0527422649320215, 0.11448183306492865, 0.05209341295994818, 0.05346553202252835, 0.052968806005083025, 0.05298732593655586, 0.05298487900290638, 0.054734466946683824, 0.053639560006558895, 0.052211900940164924, 0.05218490201514214, 0.16641477693337947, 0.0566941270371899, 0.057067345012910664, 0.05662172404117882, 0.05643514695111662, 0.056820429977960885, 0.05662986706010997, 0.05786630790680647, 0.05753389303572476, 0.05705309903714806, 0.06133687391411513, 0.05643662402871996, 0.05498942802660167, 0.05619203392416239, 0.05591164203360677, 0.05610878497827798, 0.056392794009298086, 0.05827114707790315, 0.05792045290581882, 0.05244221503380686, 0.052289364975877106, 0.10972724098246545, 0.05493302003014833, 0.05139134905766696, 0.05126256309449673, 0.05149779899511486, 0.051931486930698156, 0.0530587820103392, 0.05273240094538778, 0.05237314000260085, 0.05218571191653609, 0.056026083999313414, 0.05232475895900279, 0.05266276001930237, 0.052380420034751296, 0.052454533986747265]
[0.0012211278636558827, 0.0011810760003175926, 0.001182377886090597, 0.0011872926605230366, 0.001179977203719318, 0.001177000318421051, 0.001172775635495782, 0.0011764673637861217, 0.0011753181143748489, 0.00118132220284844, 0.001189729249083691, 0.0011891013180667703, 0.0011829898655626246, 0.0011742799304722046, 0.001180985318073495, 0.001175985795932568, 0.0011772683858659796, 0.0011835892959921198, 0.0011821185445031997, 0.0011932889994403179, 0.0011923788194756278, 0.001200764477041296, 0.0011947252496611327, 0.0012262275902850722, 0.001207580250179903, 0.0011981317260175604, 0.0012064291592899033, 0.0011963841600597582, 0.002750367296605625, 0.0011666549332651564, 0.0011666086581747302, 0.0011766395685051314, 0.001177710544487292, 0.001183071909260682, 0.0011860800441354513, 0.0012098067725839262, 0.0011992854097942736, 0.0013032428184735843, 0.0012039995450653475, 0.0043959379783535205, 0.0014456321607047523, 0.0012928532510572536, 0.0012951951833780515, 0.0012918752274179662, 0.00131768802318468, 0.001302332138452171, 0.0013006093186876651, 0.0012958200452637604, 0.0021102225900077346, 0.001263091795739125, 0.0012667725439479743, 0.0012580358650831674, 0.001274846592092548, 0.0012629235226830299, 0.0011866832739377226, 0.0011626172054093331, 0.001175410725409165, 0.0011675356363411993, 0.0011687541369941425, 0.0011631195904390718, 0.0011628375214058906, 0.0012350998850623992, 0.0012543073416137222, 0.0012376478883776474, 0.0012443393193693323, 0.0012450290007770739, 0.0012478666824542663, 0.001245491749035533, 0.0012748828872149302, 0.0011349425476510078, 0.0011651953179600903, 0.0011534571372480555, 0.0038302619094875727, 0.0011733039097056132, 0.0011642221361398697, 0.0012019658170174807, 0.0011680161829148842, 0.0011727746591945602, 0.0012033434309573336, 0.0012075491381851448, 0.0011740175700238483, 0.001191800931172276, 0.004024162954671986, 0.0011799227266403084, 0.0011777350895995783, 0.0011740746346979656, 0.0011924580665601586, 0.001189822090302848, 0.0012195195701100272, 0.0012098407261708583, 0.001196779318640686, 0.001196230613541874, 0.0015370306818195704, 0.0012998666577252814, 0.001287406114649705, 0.001282453682506457, 0.001290412384233522, 0.001302636180877347, 0.0013531182061838495, 0.0013045003844044086, 0.0012914393843278628, 0.0013286163395440037, 0.0013211502942298962, 0.0013194754084741528, 0.001319347044707022, 0.0013044499765700575, 0.0013078116356733847, 0.0013056788408324462, 0.0013120869089933958, 0.001316030136711726, 0.0013018728165082973, 0.0011673343725242587, 0.0011449256494944526, 0.0011575127908483493, 0.001156016301666928, 0.0014661834169135883, 0.0011439529534559264, 0.0011424720233176337, 0.0011471256743683371, 0.0011544494868017906, 0.0011486005346658965, 0.0011735932798623, 0.0011618843025982726, 0.0011935593495362026, 0.0011892516279679744, 0.0011868773022839843, 0.0012252238838998384, 0.0015091416290636326, 0.0012721423720291189, 0.001261334698430674, 0.0012771472778864378, 0.0012800958370356712, 0.0012711167665804888, 0.0012829556985390048, 0.0012698053019554463, 0.0011956910927628363, 0.001216759699461765, 0.0014933424888092072, 0.001165353092040087, 0.0011807802582679446, 0.001178703162559243, 0.0012057556061420677, 0.0011852823717649593, 0.0012052936051690647, 0.0011850883723994673, 0.0011827657892650298, 0.0011764164163925966, 0.0012740703721985567, 0.0012682975583904704, 0.0011590883964239511, 0.001155730510173842, 0.0011631103725237555, 0.0011575301394386346, 0.0011718718600351103, 0.001162676836450606, 0.0011671652779156386, 0.0011665997891361977, 0.0011605296045715033, 0.0011677651146296845, 0.0011592317686611136, 0.0011604749787122357, 0.0011699788602675463, 0.0011631633252511884, 0.0011681332307066335, 0.001163182000434676, 0.0011643283718893694, 0.0011650527432171065, 0.001158714023700287, 0.0011649602553049146, 0.0011621870013863542, 0.0011676636058837175, 0.0011644640932032882, 0.001164880139904833, 0.0011625722575889423, 0.0011625905104284716, 0.001174155814941366, 0.0011703298849508512, 0.0011628113475866443, 0.0011578723030208156, 0.00115694995254798, 0.001164610118626855, 0.0011661148841254586, 0.0011633409993982938, 0.0011620446958384195, 0.0011688092788464802, 0.0011752058134609183, 0.001174525328002177, 0.0011713212318068674, 0.001172811467048907, 0.0011755697440009477, 0.0011759254171751267, 0.0011729319298336672, 0.001178563139293083, 0.0011774296980611113, 0.001173066045699078, 0.001169673860246359, 0.0011797694890045148, 0.0011775376042351127, 0.001177973067929405, 0.0011733228822650259, 0.0011794312537626126, 0.0011792310004577387, 0.0011707495594787043, 0.0011721142556864856, 0.0011623053280853254, 0.0011613226257437884, 0.0011699778368956474, 0.001166651279903775, 0.001168319140560925, 0.001176993860754856, 0.0011868871163663475, 0.0011731626270988652, 0.0011872933246195316, 0.001177494741738016, 0.0011781176286857836, 0.0011756873965739858, 0.0011849683482026638, 0.0011753724904211109, 0.0011780893478845788, 0.0011778087219829823, 0.0011788237904913205, 0.0011817441175713441, 0.001172790046629691, 0.0013009374419790368, 0.0012597109293998327, 0.0012551722317111008, 0.0012539899772639538, 0.0012430002328095047, 0.0012559381849673945, 0.0012639015588129675, 0.001253029442565559, 0.0012567493723445507, 0.0012593857218446427, 0.0012541807900984274, 0.0012581807691170726, 0.0012658594885494472, 0.0012612349304998683, 0.0012548977460408973, 0.001268551419597379, 0.0012568111401484456, 0.001259915649804265, 0.0012605984202521139, 0.001264813326320849, 0.0012581023945321525, 0.0012701647193712551, 0.0012535313008959557, 0.0012520343243945823, 0.0012459668363336213, 0.0012514970920503485, 0.0012519321171566844, 0.0012616179314940128, 0.0012551118392324031, 0.0012455613238650353, 0.001251260024430447, 0.0012510853716670427, 0.0012392826963129433, 0.0012609585821845156, 0.0012507695125329287, 0.0012541255577965531, 0.0012488440491345732, 0.0012512587655205713, 0.001256665463970844, 0.0012440803043847514, 0.001244436673343528, 0.001247766091986451, 0.0012453665799829503, 0.001247117788595862, 0.001252605441719467, 0.0012417011623552373, 0.0012566592316901268, 0.001248683395990452, 0.0012505272793215374, 0.001242905768544175, 0.0012464397451515462, 0.0012467618365663775, 0.0012427199047145455, 0.0012467687917050235, 0.0012349361380518868, 0.001262982627701794, 0.0012433872785592495, 0.0012283789990253228, 0.001226564300744686, 0.0026623682108122943, 0.0012114747199987949, 0.001243384465640194, 0.0012318326977926286, 0.0012322633938733922, 0.0012322064884396832, 0.0012728945801554377, 0.0012474316280595091, 0.00121423025442244, 0.0012136023724451661, 0.003870111091473941, 0.0013184680706323233, 0.0013271475584397828, 0.0013167842800274145, 0.0013124452779329446, 0.0013214053483246717, 0.001316973652560697, 0.0013457280908559645, 0.0013379975124587153, 0.0013268162566778619, 0.0014264389282352356, 0.0013124796285748828, 0.0012788239075953876, 0.0013067914866084277, 0.0013002707449675992, 0.0013048554646111158, 0.00131146032579763, 0.0013551429553000734, 0.0013469872768795074, 0.0012195863961350433, 0.001216031743625049, 0.002551796301917801, 0.0012775120937243798, 0.0011951476525038827, 0.001192152630104575, 0.0011976232324445316, 0.0012077089983883293, 0.0012339251630311442, 0.0012263349057066925, 0.0012179800000604848, 0.0012136212073613046, 0.0013029321860305446, 0.0012168548595116928, 0.0012247153492861015, 0.0012181493031337511, 0.0012198728834127272]
[818.9150618561291, 846.685564460796, 845.7533008388634, 842.2523218154748, 847.47399936878, 849.6174421953451, 852.6780142198791, 850.0023296709122, 850.8334788423639, 846.5091044498865, 840.5273727364296, 840.9712316405388, 845.3157792052637, 851.5857029063567, 846.7505774172276, 850.3504068320744, 849.4239818258741, 844.8876678643585, 845.9388482229273, 838.0199603524585, 838.6596471411408, 832.8027844927733, 837.0125267576258, 815.5092969059039, 828.1023144018974, 834.6327689058652, 828.8924320998622, 835.8519223039956, 363.5878019761773, 857.1514776878082, 857.185477745892, 849.8779292884531, 849.1050748257866, 845.2571582271054, 843.1134179724882, 826.5782789958951, 833.8298722166066, 767.3167162902492, 830.5650978844221, 227.48273631798273, 691.7388995500041, 773.4829913466453, 772.0844030564251, 774.068562332193, 758.904977813436, 767.8532768057968, 768.870394538627, 771.712093554204, 473.883657930292, 791.7080954633457, 789.4076997307177, 794.8898976213933, 784.4081054165023, 791.813583355816, 842.6848359307711, 860.1283340271237, 850.7664413661838, 856.5049056093746, 855.611944674564, 859.7568196942716, 859.9653705626756, 809.6511157471919, 797.2527679806574, 807.9842493092565, 803.6393164099559, 803.1941419644513, 801.3676573472018, 802.8957243388937, 784.3857738059133, 881.1018690502893, 858.2252130490036, 866.9589599019023, 261.0787522187442, 852.294100213903, 858.9426097975, 831.9704153329151, 856.1525213669681, 852.678724049837, 831.0179573627112, 828.1236501091165, 851.7760087523108, 839.0663019673786, 248.4988831873761, 847.5131272768876, 849.0873786735802, 851.7346090670404, 838.603912408144, 840.4617868083689, 819.9950410880068, 826.5550814816729, 835.5759365359105, 835.9592111082476, 650.6050997083404, 769.3096780787986, 776.7556706627059, 779.7552563813275, 774.9460654734642, 767.6740556419088, 739.0337336604641, 766.5770067645988, 774.329799861614, 752.6627290638405, 756.9161543296661, 757.8769513835839, 757.9506878132, 766.6066295845369, 764.6361086893876, 765.8851232991123, 762.1446362628357, 759.8610184555736, 768.1241879541362, 856.6525783333076, 873.4191608350768, 863.9213388450704, 865.0397045076623, 682.0429070907549, 874.1618236824872, 875.2949565417733, 871.7440663601644, 866.2137334136055, 870.6247035579509, 852.0839520462592, 860.670892759066, 837.8301425803278, 840.864941012239, 842.5470754859291, 816.1773641051137, 662.6283317228904, 786.0755383888043, 792.8109812916261, 782.9950525791425, 781.1915100948289, 786.7097864582205, 779.4501409041426, 787.5223063410134, 836.336413353502, 821.8549648236633, 669.6387516552891, 858.1090202020943, 846.8976280708432, 848.3900202904043, 829.3554638320093, 843.6808171802452, 829.673363993109, 843.8189280140215, 845.475925222186, 850.039140958636, 784.886001449342, 788.4585075359187, 862.746968294416, 865.2536133614597, 859.7636334634062, 863.908390743906, 853.3356197921154, 860.08422000801, 856.7766870051449, 857.1919944717669, 861.6755626576413, 856.3365932686854, 862.6402649014505, 861.7161234356704, 854.7162978409061, 859.7244929331375, 856.0667342671816, 859.7106898372779, 858.8642380819838, 858.3302394007161, 863.025716049036, 858.3983835038748, 860.4467257051715, 856.4110373579508, 858.7641352247548, 858.457420418977, 860.161588643014, 860.1480839813934, 851.6757207815192, 854.4599372013777, 859.9847275961394, 863.6530966247861, 864.3416232462562, 858.6564585056668, 857.5484402207605, 859.5931893720092, 860.552097162232, 855.5715787839388, 850.914783220016, 851.407778239199, 853.7367656671014, 852.6519633341028, 850.6513587161476, 850.3940687005946, 852.5643940324903, 848.4908161982842, 849.3076076191325, 852.4669209090091, 854.9391706414453, 847.6232088726047, 849.2297795020866, 848.9158430062928, 852.2803186703076, 847.8662887809762, 848.0102707712339, 854.1536419157541, 853.1591482217052, 860.3591292550535, 861.0871585831142, 854.7170454556157, 857.1541618524428, 855.9305118632972, 849.6221036859596, 842.5401086680407, 852.3967409982347, 842.2518507130075, 849.2606926838343, 848.8116769082917, 850.5662329238639, 843.9043975451158, 850.7941168860617, 848.8320531847922, 849.0342967713638, 848.3032053358979, 846.2068777250571, 852.6675365925497, 768.6764695455003, 793.832915680451, 796.7034122773416, 797.4545396143217, 804.5050786030338, 796.2175304240479, 791.2008597720071, 798.0658442889538, 795.7036001016118, 794.0379048726103, 797.3332137558259, 794.7983505595538, 789.9770938604753, 792.873695310411, 796.8776764122181, 788.300722029373, 795.6644940956579, 793.7039278425946, 793.2740386902949, 790.6305058540527, 794.8478632153527, 787.2994618328012, 797.7463341244488, 798.7001478442272, 802.5895801068007, 799.0430072527641, 798.7653534052166, 792.6329953283052, 796.741747421948, 802.8508760186556, 799.1943964286589, 799.3059647620393, 806.9183915624369, 793.0474593920248, 799.5078149729632, 797.3683286998463, 800.7404933330004, 799.1952005099137, 795.7567297506323, 803.8066324782313, 803.576446612763, 801.4322607597022, 802.9764216201229, 801.8488783853419, 798.3359856933782, 805.3467535644545, 795.7606762296757, 800.8435150263233, 799.6626835222189, 804.5662232071766, 802.2850714523844, 802.0778072210105, 804.6865558411582, 802.073332804911, 809.7584718651939, 791.7765280902285, 804.2546495720386, 814.0809968205792, 815.2854272644886, 375.60544628607096, 825.4402535126732, 804.2564690440456, 811.7985516961362, 811.5148149103779, 811.5522920726368, 785.6110125615323, 801.6471424214159, 823.5670264003257, 823.9931156241892, 258.3905155082118, 758.4559856048775, 753.4957161625772, 759.4258339560225, 761.9365293271236, 756.7700564159501, 759.3166332945386, 743.0921646020926, 747.3855449569496, 753.6838616251522, 701.0464873089112, 761.9165876774944, 781.9684900013568, 765.2330232081196, 769.0705984659514, 766.3684041036902, 762.5087700550912, 737.9295269837912, 742.3975097349442, 819.9501102743288, 822.3469537225665, 391.8808093139921, 782.7714546988451, 836.716700154127, 838.8187676206196, 834.9871419568635, 828.0140342868075, 810.4219201944908, 815.4379324494039, 821.0315439911493, 823.9803275803273, 767.4996524927024, 821.7906944146866, 816.5162628058101, 820.9174338707489, 819.7575449028683]
Elapsed: 0.05524124732424176~0.015163984612986401
Time per graph: 0.0012742333184081996~0.00034518550146845993
Speed: 806.8188013124071~86.55214596994193
Total Time: 0.0534
best val loss: 0.46984779834747314 test_score: 0.7674

Testing...
Test loss: 0.5705 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.16021681309212, 0.15685589390341192, 0.15652737708296627, 0.2788927850779146, 0.1561157020041719, 0.15497915796004236, 0.1559180358890444, 0.15587775316089392, 0.15454333100933582, 0.1562916268594563, 0.15670433710329235, 0.16056136786937714, 0.1564342019846663, 0.15479549602605402, 0.15583424095530063, 0.15574299602303654, 0.27261229208670557, 0.15674111992120743, 0.15654971299227327, 0.15678246296010911, 0.158056540065445, 0.15846228308510035, 0.15926994488108903, 0.1612274720100686, 0.16060875891707838, 0.15883929701521993, 0.15842107799835503, 0.15672101988457143, 0.238232230884023, 0.15486107289325446, 0.1543803330278024, 0.15670443209819496, 0.15804807608947158, 0.15683557803276926, 0.1576765220379457, 0.16023721499368548, 0.16074118204414845, 0.1639973388519138, 0.1620076799299568, 0.2963076781015843, 0.17450952995568514, 0.17716361198108643, 0.16706866712775081, 0.16689290013164282, 0.1678136111004278, 0.16992040001787245, 0.16803808510303497, 0.1688688270514831, 0.20216740283649415, 0.20954329194501042, 0.1655278541147709, 0.16685671999584883, 0.16700412798672915, 0.1674432649742812, 0.16063704900443554, 0.15564836794510484, 0.15641297900583595, 0.1536013449076563, 0.15443786489777267, 0.1533470608992502, 0.15391807502601296, 0.15452825999818742, 0.2896203740965575, 0.1648231450235471, 0.1652707220055163, 0.16485186095815152, 0.16340827208478004, 0.16500008397269994, 0.1672619441524148, 0.1530680648284033, 0.15519097505602986, 0.15395190403796732, 0.2713588820770383, 0.15503247501328588, 0.15560446912422776, 0.15796708990819752, 0.15595784795004874, 0.15888554707635194, 0.157831309014, 0.16326620511244982, 0.15832796995528042, 0.15763569506816566, 0.28249417908955365, 0.1568998059956357, 0.15750484296586365, 0.1558745780494064, 0.1573934480547905, 0.1577274069422856, 0.15858727891463786, 0.16230981203261763, 0.16188045486342162, 0.1610671429662034, 0.1701701529091224, 0.2675013979896903, 0.170392706990242, 0.1697855609236285, 0.17104206699877977, 0.17308881203643978, 0.17418881703633815, 0.17512535897549242, 0.17273606196977198, 0.1735314279794693, 0.2707431298913434, 0.17786680406425148, 0.17646702227648348, 0.17441067495383322, 0.17503174708690494, 0.17651119304355234, 0.17731734993867576, 0.17513375903945416, 0.17349251895211637, 0.16215820307843387, 0.1583408780861646, 0.15699056792072952, 0.16054726508446038, 0.17127713095396757, 0.23440205492079258, 0.16089982993435115, 0.1598442478571087, 0.1597170631866902, 0.16055251588113606, 0.1646557878702879, 0.16229770507197827, 0.164038922986947, 0.16514957905746996, 0.16492094204295427, 0.16793307394254953, 0.3158312179148197, 0.17646109801717103, 0.1764936710242182, 0.17580543912481517, 0.17650182696525007, 0.17755637899972498, 0.17820630909409374, 0.17851502704434097, 0.174034386058338, 0.1682174460729584, 0.31556502310559154, 0.17124186898581684, 0.16381038294639438, 0.16355802898760885, 0.16486578504554927, 0.16507109999656677, 0.16686916293110698, 0.16857338312547654, 0.16584319702815264, 0.16412229603156447, 0.31990997202228755, 0.1772251770598814, 0.16446705698035657, 0.15945338609162718, 0.1616436009062454, 0.16138972993940115, 0.1632301559438929, 0.16384022508282214, 0.16349957801867276, 0.16362597909756005, 0.16282683005556464, 0.16333063994534314, 0.1636822809232399, 0.16274163615889847, 0.1650585001334548, 0.16365717386361212, 0.1641768729314208, 0.16322189895436168, 0.1635964959859848, 0.16391069593373686, 0.16258306696545333, 0.16250347916502506, 0.16268397914245725, 0.16515595593955368, 0.162553969072178, 0.16328626405447721, 0.1638244919013232, 0.16418176412116736, 0.1632087449543178, 0.16483688598964363, 0.16386238299310207, 0.16328785999212414, 0.1640547178685665, 0.16402216698043048, 0.16557773191016167, 0.16471126105170697, 0.16380064096301794, 0.1658118338091299, 0.1642929099034518, 0.16534039191901684, 0.16406437091063708, 0.1660593090346083, 0.1661218989174813, 0.16507345996797085, 0.16605539584998041, 0.16547445312608033, 0.1654845270095393, 0.16562540491577238, 0.16495470807421952, 0.1650526140583679, 0.1652098021004349, 0.16626774589531124, 0.16572622687090188, 0.166394277010113, 0.16574326099362224, 0.1646992889000103, 0.16404591605532914, 0.16441310103982687, 0.16538823989685625, 0.16570137708913535, 0.1649768529459834, 0.16547526407521218, 0.16546165791805834, 0.1657206870149821, 0.16572249005548656, 0.1667115440359339, 0.16676822293084115, 0.16584616003092378, 0.1653691640822217, 0.16556449397467077, 0.16661518590990454, 0.16635727416723967, 0.1657386670121923, 0.16612827696371824, 0.16505992983002216, 0.16529381391592324, 0.17439425515476614, 0.174196254927665, 0.17032824002671987, 0.16999012301675975, 0.16938231990206987, 0.16762192791793495, 0.16947311989497393, 0.16810768493451178, 0.16983181599061936, 0.1694300000090152, 0.1697383119026199, 0.1690938560059294, 0.1694671749137342, 0.17108680901583284, 0.1702995280502364, 0.1697635221062228, 0.16997534409165382, 0.17019364691805094, 0.17076194484252483, 0.16988980513997376, 0.17051250801887363, 0.17042174784000963, 0.16906381607986987, 0.1691765720024705, 0.16816591704264283, 0.16913341789040715, 0.16875599697232246, 0.1693983421428129, 0.1680060391081497, 0.16976093605626374, 0.16855060495436192, 0.1689140701200813, 0.1687043469864875, 0.16930865100584924, 0.16956237715203315, 0.1707375820260495, 0.16802155296318233, 0.16946336394175887, 0.169423102051951, 0.16839733393862844, 0.16918994300067425, 0.16833122179377824, 0.1680605161236599, 0.1675420900573954, 0.16934639809187502, 0.16896563698537648, 0.16804468201007694, 0.1695439130999148, 0.16889330407138914, 0.16928980906959623, 0.16942880698479712, 0.16901970002800226, 0.1685252538882196, 0.16953001799993217, 0.16758201399352401, 0.17028253595344722, 0.16906684485729784, 0.16714118304662406, 0.1659172479994595, 0.25429468997754157, 0.16367430693935603, 0.16544233786407858, 0.1661480920156464, 0.16493454517330974, 0.16711909894365817, 0.16810760798398405, 0.1697333820629865, 0.16674517199862748, 0.16381058690603822, 0.2841666708700359, 0.17660818493459374, 0.17747854499612004, 0.17852637195028365, 0.17846688686404377, 0.17906113411299884, 0.1791474639903754, 0.1808838180731982, 0.18291687103919685, 0.1796089590061456, 0.1816701019415632, 0.2869503969559446, 0.17055828403681517, 0.17463963595218956, 0.17599334591068327, 0.17562255705706775, 0.17629175202455372, 0.17791814706288278, 0.18173185002524406, 0.16695089195854962, 0.164335579960607, 0.22000692901201546, 0.20557234005536884, 0.16099746304098517, 0.1594975289190188, 0.16000780498143286, 0.15989916608668864, 0.16185150120873004, 0.16732992697507143, 0.16609502607025206, 0.16377472796011716, 0.1659781188936904, 0.2778894418152049, 0.16402335499878973, 0.1638998140115291, 0.16426542797125876]
Total Epoch List: [111, 112, 105]
Total Time List: [0.057831665966659784, 0.051170891034416854, 0.053428727900609374]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7adf8cca0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.7012;  Loss pred: 0.7012; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.7008;  Loss pred: 0.7008; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.5000 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6968;  Loss pred: 0.6968; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.5000 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6969;  Loss pred: 0.6969; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6950 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6937;  Loss pred: 0.6937; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.5000 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6915;  Loss pred: 0.6915; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6877;  Loss pred: 0.6877; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6849;  Loss pred: 0.6849; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5116 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6830;  Loss pred: 0.6830; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6805;  Loss pred: 0.6805; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6763;  Loss pred: 0.6763; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6740;  Loss pred: 0.6740; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6717;  Loss pred: 0.6717; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6678;  Loss pred: 0.6678; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6665;  Loss pred: 0.6665; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6612;  Loss pred: 0.6612; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6572;  Loss pred: 0.6572; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6542;  Loss pred: 0.6542; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5116 time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6482;  Loss pred: 0.6482; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6448;  Loss pred: 0.6448; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6391;  Loss pred: 0.6391; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6336;  Loss pred: 0.6336; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6269;  Loss pred: 0.6269; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6247;  Loss pred: 0.6247; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6109;  Loss pred: 0.6109; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.6039;  Loss pred: 0.6039; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.6039;  Loss pred: 0.6039; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5000 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5892;  Loss pred: 0.5892; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5000 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5811;  Loss pred: 0.5811; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5116 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5753;  Loss pred: 0.5753; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6895 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5000 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5664;  Loss pred: 0.5664; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6888 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5000 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5535;  Loss pred: 0.5535; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6881 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.5000 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5402;  Loss pred: 0.5402; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6874 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5000 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5286;  Loss pred: 0.5286; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6866 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5000 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.5232;  Loss pred: 0.5232; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6857 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6891 score: 0.5000 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.5053;  Loss pred: 0.5053; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6846 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6883 score: 0.5000 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4996;  Loss pred: 0.4996; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6830 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.5000 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4762;  Loss pred: 0.4762; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6815 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6863 score: 0.5000 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4713;  Loss pred: 0.4713; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6800 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6853 score: 0.5000 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4524;  Loss pred: 0.4524; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6782 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6841 score: 0.5000 time: 0.14s
Epoch 43/1000, LR 0.000269
Train loss: 0.4405;  Loss pred: 0.4405; Loss self: 0.0000; time: 0.07s
Val loss: 0.6763 score: 0.5349 time: 0.05s
Test loss: 0.6829 score: 0.5227 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4236;  Loss pred: 0.4236; Loss self: 0.0000; time: 0.07s
Val loss: 0.6742 score: 0.5349 time: 0.05s
Test loss: 0.6815 score: 0.5227 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4109;  Loss pred: 0.4109; Loss self: 0.0000; time: 0.07s
Val loss: 0.6718 score: 0.5349 time: 0.05s
Test loss: 0.6799 score: 0.5227 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3944;  Loss pred: 0.3944; Loss self: 0.0000; time: 0.07s
Val loss: 0.6691 score: 0.5349 time: 0.05s
Test loss: 0.6781 score: 0.5227 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3840;  Loss pred: 0.3840; Loss self: 0.0000; time: 0.07s
Val loss: 0.6659 score: 0.5349 time: 0.05s
Test loss: 0.6759 score: 0.5227 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3658;  Loss pred: 0.3658; Loss self: 0.0000; time: 0.07s
Val loss: 0.6625 score: 0.5349 time: 0.05s
Test loss: 0.6736 score: 0.5227 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3545;  Loss pred: 0.3545; Loss self: 0.0000; time: 0.07s
Val loss: 0.6587 score: 0.5581 time: 0.05s
Test loss: 0.6710 score: 0.5227 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3334;  Loss pred: 0.3334; Loss self: 0.0000; time: 0.07s
Val loss: 0.6547 score: 0.5814 time: 0.05s
Test loss: 0.6682 score: 0.5455 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3203;  Loss pred: 0.3203; Loss self: 0.0000; time: 0.07s
Val loss: 0.6502 score: 0.6047 time: 0.05s
Test loss: 0.6651 score: 0.5455 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3043;  Loss pred: 0.3043; Loss self: 0.0000; time: 0.07s
Val loss: 0.6456 score: 0.6047 time: 0.19s
Test loss: 0.6618 score: 0.5455 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2882;  Loss pred: 0.2882; Loss self: 0.0000; time: 0.07s
Val loss: 0.6405 score: 0.6047 time: 0.05s
Test loss: 0.6582 score: 0.5455 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2713;  Loss pred: 0.2713; Loss self: 0.0000; time: 0.07s
Val loss: 0.6350 score: 0.6047 time: 0.05s
Test loss: 0.6544 score: 0.5455 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2611;  Loss pred: 0.2611; Loss self: 0.0000; time: 0.07s
Val loss: 0.6291 score: 0.6047 time: 0.05s
Test loss: 0.6504 score: 0.5455 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2484;  Loss pred: 0.2484; Loss self: 0.0000; time: 0.07s
Val loss: 0.6228 score: 0.6279 time: 0.05s
Test loss: 0.6460 score: 0.5682 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2289;  Loss pred: 0.2289; Loss self: 0.0000; time: 0.07s
Val loss: 0.6160 score: 0.6279 time: 0.05s
Test loss: 0.6413 score: 0.5909 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2177;  Loss pred: 0.2177; Loss self: 0.0000; time: 0.08s
Val loss: 0.6089 score: 0.6744 time: 0.05s
Test loss: 0.6364 score: 0.5909 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2032;  Loss pred: 0.2032; Loss self: 0.0000; time: 0.07s
Val loss: 0.6011 score: 0.6744 time: 0.05s
Test loss: 0.6311 score: 0.5909 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1887;  Loss pred: 0.1887; Loss self: 0.0000; time: 0.07s
Val loss: 0.5925 score: 0.7442 time: 0.05s
Test loss: 0.6252 score: 0.5909 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1735;  Loss pred: 0.1735; Loss self: 0.0000; time: 0.07s
Val loss: 0.5832 score: 0.7674 time: 0.05s
Test loss: 0.6187 score: 0.6136 time: 0.11s
Epoch 62/1000, LR 0.000268
Train loss: 0.1702;  Loss pred: 0.1702; Loss self: 0.0000; time: 0.12s
Val loss: 0.5730 score: 0.7674 time: 0.07s
Test loss: 0.6116 score: 0.6136 time: 0.06s
Epoch 63/1000, LR 0.000268
Train loss: 0.1593;  Loss pred: 0.1593; Loss self: 0.0000; time: 0.07s
Val loss: 0.5622 score: 0.7674 time: 0.05s
Test loss: 0.6041 score: 0.6364 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1504;  Loss pred: 0.1504; Loss self: 0.0000; time: 0.07s
Val loss: 0.5513 score: 0.7907 time: 0.05s
Test loss: 0.5964 score: 0.6364 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1343;  Loss pred: 0.1343; Loss self: 0.0000; time: 0.07s
Val loss: 0.5396 score: 0.7907 time: 0.05s
Test loss: 0.5881 score: 0.7045 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1143;  Loss pred: 0.1143; Loss self: 0.0000; time: 0.07s
Val loss: 0.5269 score: 0.7907 time: 0.05s
Test loss: 0.5790 score: 0.7045 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1105;  Loss pred: 0.1105; Loss self: 0.0000; time: 0.07s
Val loss: 0.5136 score: 0.8140 time: 0.05s
Test loss: 0.5692 score: 0.7273 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1006;  Loss pred: 0.1006; Loss self: 0.0000; time: 0.07s
Val loss: 0.5000 score: 0.8372 time: 0.05s
Test loss: 0.5590 score: 0.7500 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0986;  Loss pred: 0.0986; Loss self: 0.0000; time: 0.07s
Val loss: 0.4862 score: 0.8837 time: 0.05s
Test loss: 0.5484 score: 0.7273 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0844;  Loss pred: 0.0844; Loss self: 0.0000; time: 0.07s
Val loss: 0.4719 score: 0.8837 time: 0.05s
Test loss: 0.5374 score: 0.7273 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0795;  Loss pred: 0.0795; Loss self: 0.0000; time: 0.07s
Val loss: 0.4572 score: 0.9070 time: 0.05s
Test loss: 0.5262 score: 0.7727 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0760;  Loss pred: 0.0760; Loss self: 0.0000; time: 0.08s
Val loss: 0.4430 score: 0.9070 time: 0.15s
Test loss: 0.5152 score: 0.7955 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0649;  Loss pred: 0.0649; Loss self: 0.0000; time: 0.07s
Val loss: 0.4286 score: 0.8837 time: 0.05s
Test loss: 0.5038 score: 0.7955 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0644;  Loss pred: 0.0644; Loss self: 0.0000; time: 0.07s
Val loss: 0.4145 score: 0.9070 time: 0.06s
Test loss: 0.4928 score: 0.7727 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0533;  Loss pred: 0.0533; Loss self: 0.0000; time: 0.07s
Val loss: 0.4007 score: 0.9070 time: 0.05s
Test loss: 0.4816 score: 0.7955 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0521;  Loss pred: 0.0521; Loss self: 0.0000; time: 0.07s
Val loss: 0.3872 score: 0.9070 time: 0.06s
Test loss: 0.4708 score: 0.8182 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0596;  Loss pred: 0.0596; Loss self: 0.0000; time: 0.08s
Val loss: 0.3743 score: 0.9070 time: 0.06s
Test loss: 0.4612 score: 0.8182 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0419;  Loss pred: 0.0419; Loss self: 0.0000; time: 0.07s
Val loss: 0.3618 score: 0.9070 time: 0.06s
Test loss: 0.4517 score: 0.8182 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0431;  Loss pred: 0.0431; Loss self: 0.0000; time: 0.08s
Val loss: 0.3498 score: 0.9070 time: 0.06s
Test loss: 0.4417 score: 0.8182 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0379;  Loss pred: 0.0379; Loss self: 0.0000; time: 0.07s
Val loss: 0.3382 score: 0.9070 time: 0.05s
Test loss: 0.4318 score: 0.8182 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0345;  Loss pred: 0.0345; Loss self: 0.0000; time: 0.07s
Val loss: 0.3268 score: 0.9070 time: 0.05s
Test loss: 0.4220 score: 0.8182 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0301;  Loss pred: 0.0301; Loss self: 0.0000; time: 0.10s
Val loss: 0.3164 score: 0.9070 time: 0.08s
Test loss: 0.4120 score: 0.8182 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0341;  Loss pred: 0.0341; Loss self: 0.0000; time: 0.07s
Val loss: 0.3071 score: 0.9070 time: 0.05s
Test loss: 0.4033 score: 0.8182 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.07s
Val loss: 0.2987 score: 0.9070 time: 0.05s
Test loss: 0.3945 score: 0.8182 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0246;  Loss pred: 0.0246; Loss self: 0.0000; time: 0.07s
Val loss: 0.2909 score: 0.9070 time: 0.05s
Test loss: 0.3853 score: 0.8409 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0216;  Loss pred: 0.0216; Loss self: 0.0000; time: 0.07s
Val loss: 0.2839 score: 0.9070 time: 0.05s
Test loss: 0.3769 score: 0.8409 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0195;  Loss pred: 0.0195; Loss self: 0.0000; time: 0.07s
Val loss: 0.2774 score: 0.8837 time: 0.05s
Test loss: 0.3688 score: 0.8409 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.07s
Val loss: 0.2718 score: 0.8837 time: 0.05s
Test loss: 0.3616 score: 0.8636 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.07s
Val loss: 0.2665 score: 0.8837 time: 0.05s
Test loss: 0.3557 score: 0.8636 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0189;  Loss pred: 0.0189; Loss self: 0.0000; time: 0.07s
Val loss: 0.2616 score: 0.8837 time: 0.05s
Test loss: 0.3507 score: 0.8636 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.07s
Val loss: 0.2576 score: 0.8837 time: 0.05s
Test loss: 0.3465 score: 0.8636 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.07s
Val loss: 0.2547 score: 0.8837 time: 0.18s
Test loss: 0.3428 score: 0.8864 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.07s
Val loss: 0.2527 score: 0.8837 time: 0.05s
Test loss: 0.3403 score: 0.8864 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0121;  Loss pred: 0.0121; Loss self: 0.0000; time: 0.07s
Val loss: 0.2510 score: 0.8837 time: 0.05s
Test loss: 0.3385 score: 0.8636 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.07s
Val loss: 0.2494 score: 0.8837 time: 0.05s
Test loss: 0.3377 score: 0.8636 time: 0.05s
Epoch 96/1000, LR 0.000265
Train loss: 0.0099;  Loss pred: 0.0099; Loss self: 0.0000; time: 0.07s
Val loss: 0.2488 score: 0.8837 time: 0.05s
Test loss: 0.3378 score: 0.8636 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0120;  Loss pred: 0.0120; Loss self: 0.0000; time: 0.07s
Val loss: 0.2481 score: 0.8837 time: 0.05s
Test loss: 0.3383 score: 0.8636 time: 0.05s
Epoch 98/1000, LR 0.000265
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.07s
Val loss: 0.2470 score: 0.8837 time: 0.05s
Test loss: 0.3383 score: 0.8636 time: 0.05s
Epoch 99/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.2466 score: 0.8837 time: 0.05s
Test loss: 0.3387 score: 0.8636 time: 0.05s
Epoch 100/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.2464 score: 0.8837 time: 0.05s
Test loss: 0.3396 score: 0.8636 time: 0.05s
Epoch 101/1000, LR 0.000265
Train loss: 0.0081;  Loss pred: 0.0081; Loss self: 0.0000; time: 0.07s
Val loss: 0.2471 score: 0.8837 time: 0.05s
Test loss: 0.3408 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.2483 score: 0.8837 time: 0.05s
Test loss: 0.3420 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.07s
Val loss: 0.2487 score: 0.8837 time: 0.05s
Test loss: 0.3430 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.07s
Val loss: 0.2486 score: 0.8837 time: 0.18s
Test loss: 0.3442 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.2482 score: 0.8837 time: 0.05s
Test loss: 0.3459 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.07s
Val loss: 0.2482 score: 0.8837 time: 0.05s
Test loss: 0.3475 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.2488 score: 0.8837 time: 0.05s
Test loss: 0.3493 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.07s
Val loss: 0.2490 score: 0.8837 time: 0.05s
Test loss: 0.3513 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.2494 score: 0.8837 time: 0.05s
Test loss: 0.3536 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0065;  Loss pred: 0.0065; Loss self: 0.0000; time: 0.07s
Val loss: 0.2501 score: 0.8837 time: 0.05s
Test loss: 0.3559 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.07s
Val loss: 0.2514 score: 0.8837 time: 0.05s
Test loss: 0.3580 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.07s
Val loss: 0.2521 score: 0.8837 time: 0.05s
Test loss: 0.3600 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.2521 score: 0.8837 time: 0.05s
Test loss: 0.3617 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.2528 score: 0.8837 time: 0.05s
Test loss: 0.3633 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.13s
Val loss: 0.2526 score: 0.8837 time: 0.08s
Test loss: 0.3653 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0044;  Loss pred: 0.0044; Loss self: 0.0000; time: 0.07s
Val loss: 0.2530 score: 0.8837 time: 0.05s
Test loss: 0.3670 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.2534 score: 0.8837 time: 0.05s
Test loss: 0.3688 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 118/1000, LR 0.000262
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.2529 score: 0.9070 time: 0.05s
Test loss: 0.3707 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 119/1000, LR 0.000262
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.07s
Val loss: 0.2527 score: 0.9070 time: 0.05s
Test loss: 0.3731 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 120/1000, LR 0.000262
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.2523 score: 0.9070 time: 0.05s
Test loss: 0.3758 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 099,   Train_Loss: 0.0089,   Val_Loss: 0.2464,   Val_Precision: 0.9474,   Val_Recall: 0.8182,   Val_accuracy: 0.8780,   Val_Score: 0.8837,   Val_Loss: 0.2464,   Test_Precision: 0.8636,   Test_Recall: 0.8636,   Test_accuracy: 0.8636,   Test_Score: 0.8636,   Test_loss: 0.3396


[0.05243536701891571, 0.052393713966012, 0.05252082098741084, 0.053163295960985124, 0.053010753937996924, 0.05424494901672006, 0.053367046057246625, 0.05291198706254363, 0.053371179034002125, 0.056223251041956246, 0.05649519001599401, 0.05661716696340591, 0.05692584894131869, 0.057410484994761646, 0.05699764098972082, 0.05699408508371562, 0.056776468991301954, 0.05622285092249513, 0.0571935570333153, 0.05286205105949193, 0.05270314298104495, 0.05324682698119432, 0.052550161024555564, 0.05254666798282415, 0.052582112955860794, 0.05189745407551527, 0.052792060072533786, 0.05268872599117458, 0.05226173996925354, 0.053783460054546595, 0.05871976201888174, 0.058864727965556085, 0.05520308006089181, 0.05275802395772189, 0.05242797709070146, 0.05340432992670685, 0.05238886398728937, 0.058588232030160725, 0.05830680695362389, 0.05839498504064977, 0.05821737798396498, 0.14516043895855546, 0.055965595995076, 0.05256399302743375, 0.052559328032657504, 0.053053568000905216, 0.052795498981140554, 0.05372864694800228, 0.052990262978710234, 0.051390209002420306, 0.05126896710135043, 0.05578691908158362, 0.05542581400368363, 0.055624327971599996, 0.05566171009559184, 0.05612452304922044, 0.055970989051274955, 0.05784195801243186, 0.056823901017196476, 0.05354483099654317, 0.11903268797323108, 0.06581443699542433, 0.05601441801991314, 0.05112423200625926, 0.05181457300204784, 0.05241505603771657, 0.05232769704889506, 0.05378702201414853, 0.05357530398759991, 0.052526494953781366, 0.052428902010433376, 0.05756401002872735, 0.057189750019460917, 0.05864419799763709, 0.058348097023554146, 0.0585207570111379, 0.059253243962302804, 0.059320745058357716, 0.056914764922112226, 0.0561768600018695, 0.05770650506019592, 0.05535919696558267, 0.055351927992887795, 0.05521258898079395, 0.05512788495980203, 0.05543037096504122, 0.05591615510638803, 0.056866992032155395, 0.05626723088789731, 0.05530652904417366, 0.0554718739585951, 0.05203265999443829, 0.05181859794538468, 0.05215694394428283, 0.052222142927348614, 0.052366137970238924, 0.052908163983374834, 0.053087662905454636, 0.05248832097277045, 0.05333411099854857, 0.05215921893250197, 0.05169277801178396, 0.05144234199542552, 0.05665780010167509, 0.05710018193349242, 0.05083872203249484, 0.05095139006152749, 0.05156508192885667, 0.05148033506702632, 0.050502334954217076, 0.05122747889254242, 0.05134032899513841, 0.05116498994175345, 0.05036704905796796, 0.05133798299357295, 0.05146087799221277, 0.050738760037347674, 0.0516788880340755, 0.051444106036797166, 0.052277021924965084]
[0.001191712886793539, 0.0011907662265002728, 0.0011936550224411556, 0.0012082567263860255, 0.0012047898622272028, 0.0012328397503800013, 0.0012128874103919688, 0.0012025451605123553, 0.0012129813416818665, 0.0012778011600444602, 0.0012839815912725912, 0.0012867537946228615, 0.0012937692941208793, 0.0013047837498809465, 0.0012954009315845642, 0.0012953201155389913, 0.0012903742952568625, 0.0012777920664203439, 0.0012998535689389842, 0.0012014102513520893, 0.001197798704114658, 0.0012101551586635071, 0.001194321841467172, 0.0011942424541550943, 0.001195048021724109, 0.0011794875926253471, 0.0011998195471030406, 0.0011974710452539678, 0.001187766817483035, 0.001222351364876059, 0.001334540045883676, 0.001337834726489911, 0.0012546154559293593, 0.001199045999039134, 0.0011915449338795786, 0.0012137347710615193, 0.001190655999711122, 0.0013315507279581982, 0.001325154703491452, 0.0013271587509238584, 0.001323122226908295, 0.003299100885421715, 0.0012719453635244545, 0.001194636205168949, 0.0011945301825603979, 0.0012057629091114823, 0.0011998977041168307, 0.0012211056124545973, 0.0012043241586070508, 0.0011679592955095525, 0.0011652037977579641, 0.001267884524581446, 0.0012596775909928097, 0.001264189272081818, 0.0012650388658089055, 0.0012755573420277374, 0.0012720679329835218, 0.0013145899548279967, 0.0012914522958453745, 0.0012169279771941629, 0.002705288363027979, 0.0014957826589869167, 0.0012730549549980258, 0.0011619143637786196, 0.0011776039318647236, 0.0011912512735844675, 0.0011892658420203422, 0.0012224323185033757, 0.0012176205451727253, 0.0011937839762223039, 0.0011915659547825767, 0.0013082729551983489, 0.001299767045896839, 0.0013328226817644793, 0.001326093114171685, 0.0013300172047985886, 0.001346664635506882, 0.0013481987513263118, 0.0012935173845934596, 0.0012767468182243067, 0.0013115114786408164, 0.0012581635673996061, 0.0012579983634747225, 0.0012548315677453172, 0.001252906476359137, 0.0012597811582963914, 0.0012708217069633645, 0.0012924316370944407, 0.0012788007019976662, 0.001256966569185765, 0.0012607244081498886, 0.0011825604544190521, 0.001177695407849652, 0.0011853850896427916, 0.0011868668847124684, 0.001190139499323612, 0.001202458272349428, 0.001206537793305787, 0.001192916385744783, 0.0012121388863306493, 0.0011854367939204994, 0.0011748358639041808, 0.0011691441362596709, 0.0012876772750380703, 0.0012977314075793731, 0.001155425500738519, 0.0011579861377619884, 0.0011719336802012879, 0.001170007615159689, 0.0011477803398685699, 0.0011642608839214188, 0.0011668256589804184, 0.0011628406804943966, 0.0011447056604083627, 0.0011667723407630217, 0.0011695654089139266, 0.0011531536372124472, 0.001174520182592625, 0.0011691842281090264, 0.0011881141346582974]
[839.1282926298063, 839.7954004280544, 837.7629894731982, 827.6386782394045, 830.0202644064224, 811.135429151897, 824.4788357369708, 831.569601572336, 824.4149894452985, 782.5943748284011, 778.8273654366579, 777.1494470650408, 772.9353328635793, 766.4105259520927, 771.9617730834708, 772.0099363884991, 774.968940156189, 782.5999442940969, 769.3174245898006, 832.3551416966698, 834.8648204116575, 826.3403191243657, 837.2952459544271, 837.3509051874082, 836.7864569637035, 847.8257899891622, 833.4586666924172, 835.0932608879184, 841.9160943720194, 818.095376447995, 749.3218379504247, 747.476485846431, 797.056974927228, 833.9963611082135, 839.2465710412422, 823.9032314493312, 839.8731457638653, 751.0040579027743, 754.6288726631309, 753.489361618482, 755.7880743464448, 303.11288885370743, 786.197291705269, 837.0749150856157, 837.149211128818, 829.3504406574363, 833.4043781974207, 818.9299842704487, 830.3412273624264, 856.194221703355, 858.2189672949553, 788.715360596518, 793.8539251236931, 791.0207926011258, 790.4895470231806, 783.971027449313, 786.1215380648653, 760.6934742863159, 774.3220583656231, 821.7413180898941, 369.6463614254854, 668.5463252243433, 785.5120441376002, 860.6486253840053, 849.1819472923382, 839.4534571963196, 840.8548910319204, 818.0411993886911, 821.273921472921, 837.6724934476606, 839.2317655487803, 764.3664848581914, 769.3686366005688, 750.287351559874, 754.09485903607, 751.8699731041713, 742.5753774425078, 741.7304006669895, 773.0858602370394, 783.2406438974292, 762.479029948216, 794.8092171090417, 794.9135937171617, 796.9197027747725, 798.144170270341, 793.7886619548312, 786.8924448808052, 773.7353151212963, 781.9826798952015, 795.566106939326, 793.1947644826665, 845.6227301218717, 849.1159881704006, 843.6077092055746, 842.5544708345797, 840.2376364857454, 831.6296897738879, 828.8178004437844, 838.2817202864239, 824.9879706666043, 843.5709142220741, 851.1827317535478, 855.3265324489439, 776.592100664691, 770.5754782226282, 865.4820231688022, 863.568196017161, 853.2906058542859, 854.695291759716, 871.2468451189084, 858.9140233173845, 857.0260623800543, 859.9630342953235, 873.5870141877866, 857.0652260629016, 855.0184473467052, 867.1871359807094, 851.4115081382504, 855.2972029201458, 841.6699800373984]
Elapsed: 0.055611655225705665~0.010437585946386045
Time per graph: 0.0012639012551296743~0.00023721786241786462
Speed: 804.0285295156614~71.8857961793471
Total Time: 0.0528
best val loss: 0.24638858437538147 test_score: 0.8636

Testing...
Test loss: 0.5262 score: 0.7727 time: 0.05s
test Score 0.7727
Epoch Time List: [0.1693561039865017, 0.16734645108226687, 0.16796225891448557, 0.16796781006269157, 0.16896327200811356, 0.16903425799682736, 0.1729934139875695, 0.16779766511172056, 0.16708074405323714, 0.28698095702566206, 0.1795014028903097, 0.180441256146878, 0.18046044511720538, 0.1799975250614807, 0.18174047605134547, 0.18176476401276886, 0.1811340191634372, 0.17901885497849435, 0.17863019194919616, 0.23985710996203125, 0.169497906928882, 0.17129224014934152, 0.16641444305423647, 0.16716931387782097, 0.16675634495913982, 0.16786151204723865, 0.16804075799882412, 0.1695880921324715, 0.16717001690994948, 0.16761679691262543, 0.26442258688621223, 0.18581364187411964, 0.1796168830478564, 0.16891609400045127, 0.168103989912197, 0.16792448388878256, 0.1663594781421125, 0.1830545050324872, 0.18173756904434413, 0.18290685897227377, 0.1820213319733739, 0.280726729077287, 0.17728690314106643, 0.17297155898995697, 0.1665343518834561, 0.16696050995960832, 0.16711985308211297, 0.16805569897405803, 0.1693274840945378, 0.1658047630917281, 0.16353903303388506, 0.30743979290127754, 0.17612704599741846, 0.17636339098680764, 0.17764286301098764, 0.17701782088261098, 0.17853250191546977, 0.1852696801070124, 0.1812716490821913, 0.17045548697933555, 0.23258531896863133, 0.2460017759585753, 0.1793978230562061, 0.17307644104585052, 0.16707798896823078, 0.1666552119422704, 0.16742642410099506, 0.16943088499829173, 0.1707886578515172, 0.16710314201191068, 0.16766056406777352, 0.28457572089973837, 0.17848186218179762, 0.18024890590459108, 0.18127747299149632, 0.18100732297170907, 0.18539051886182278, 0.18486536492127925, 0.1843906290596351, 0.17778556409757584, 0.17900698201265186, 0.23158326919656247, 0.17660819506272674, 0.1748082529520616, 0.17517003999091685, 0.17562346998602152, 0.17610822489950806, 0.17790659295860678, 0.17839546396862715, 0.17701481701806188, 0.17461727908812463, 0.29832737997639924, 0.16555594897363335, 0.1664872580440715, 0.16755682800430804, 0.16774164012167603, 0.16869402793236077, 0.1693783231312409, 0.16906843695323914, 0.16949558700434864, 0.16657601203769445, 0.16312495002057403, 0.1626480099512264, 0.30435283097904176, 0.17943979799747467, 0.17287575209047645, 0.1597127909772098, 0.16421720595099032, 0.164980539935641, 0.16002715681679547, 0.16668203403241932, 0.16442993900272995, 0.16184295690618455, 0.16099935804959387, 0.2567708040587604, 0.1622085189446807, 0.16299479000736028, 0.16387098806444556, 0.16497813595924526, 0.16584601299837232]
Total Epoch List: [120]
Total Time List: [0.052817174000665545]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7adf68b50>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6942;  Loss pred: 0.6942; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6946;  Loss pred: 0.6946; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6937;  Loss pred: 0.6937; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6917;  Loss pred: 0.6917; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6899;  Loss pred: 0.6899; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6900;  Loss pred: 0.6900; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6861;  Loss pred: 0.6861; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6820;  Loss pred: 0.6820; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6792;  Loss pred: 0.6792; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6725;  Loss pred: 0.6725; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6677;  Loss pred: 0.6677; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6937 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6632;  Loss pred: 0.6632; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6618;  Loss pred: 0.6618; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6525;  Loss pred: 0.6525; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6451;  Loss pred: 0.6451; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6408;  Loss pred: 0.6408; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6371;  Loss pred: 0.6371; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6253;  Loss pred: 0.6253; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6153;  Loss pred: 0.6153; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6093;  Loss pred: 0.6093; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6039;  Loss pred: 0.6039; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.5934;  Loss pred: 0.5934; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5846;  Loss pred: 0.5846; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5732;  Loss pred: 0.5732; Loss self: 0.0000; time: 0.07s
Val loss: 0.6918 score: 0.5455 time: 0.05s
Test loss: 0.6916 score: 0.5581 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5588;  Loss pred: 0.5588; Loss self: 0.0000; time: 0.07s
Val loss: 0.6915 score: 0.6818 time: 0.05s
Test loss: 0.6912 score: 0.7442 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5484;  Loss pred: 0.5484; Loss self: 0.0000; time: 0.07s
Val loss: 0.6913 score: 0.7273 time: 0.05s
Test loss: 0.6908 score: 0.7674 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5393;  Loss pred: 0.5393; Loss self: 0.0000; time: 0.07s
Val loss: 0.6910 score: 0.5909 time: 0.05s
Test loss: 0.6904 score: 0.5814 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5310;  Loss pred: 0.5310; Loss self: 0.0000; time: 0.07s
Val loss: 0.6907 score: 0.5227 time: 0.05s
Test loss: 0.6900 score: 0.5349 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5104;  Loss pred: 0.5104; Loss self: 0.0000; time: 0.07s
Val loss: 0.6903 score: 0.5227 time: 0.05s
Test loss: 0.6895 score: 0.5349 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5023;  Loss pred: 0.5023; Loss self: 0.0000; time: 0.07s
Val loss: 0.6899 score: 0.5227 time: 0.05s
Test loss: 0.6889 score: 0.5349 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.4898;  Loss pred: 0.4898; Loss self: 0.0000; time: 0.07s
Val loss: 0.6895 score: 0.5227 time: 0.05s
Test loss: 0.6883 score: 0.5349 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.4785;  Loss pred: 0.4785; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6890 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4587;  Loss pred: 0.4587; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6870 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4538;  Loss pred: 0.4538; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6879 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6862 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4305;  Loss pred: 0.4305; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6872 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6854 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4111;  Loss pred: 0.4111; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6865 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6845 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.3962;  Loss pred: 0.3962; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6856 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6835 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.3869;  Loss pred: 0.3869; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6847 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6824 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.3732;  Loss pred: 0.3732; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6837 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6813 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3536;  Loss pred: 0.3536; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6826 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6800 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3369;  Loss pred: 0.3369; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6814 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6787 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3180;  Loss pred: 0.3180; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6800 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6772 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.2986;  Loss pred: 0.2986; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6784 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6755 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.2922;  Loss pred: 0.2922; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6767 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6736 score: 0.5116 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.2712;  Loss pred: 0.2712; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6746 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6715 score: 0.5116 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2590;  Loss pred: 0.2590; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6723 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6691 score: 0.5116 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2491;  Loss pred: 0.2491; Loss self: 0.0000; time: 0.07s
Val loss: 0.6698 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6666 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2210;  Loss pred: 0.2210; Loss self: 0.0000; time: 0.07s
Val loss: 0.6671 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6638 score: 0.5116 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2110;  Loss pred: 0.2110; Loss self: 0.0000; time: 0.07s
Val loss: 0.6641 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6609 score: 0.5116 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.1945;  Loss pred: 0.1945; Loss self: 0.0000; time: 0.07s
Val loss: 0.6608 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6576 score: 0.5116 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.1856;  Loss pred: 0.1856; Loss self: 0.0000; time: 0.07s
Val loss: 0.6574 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6542 score: 0.5116 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.1665;  Loss pred: 0.1665; Loss self: 0.0000; time: 0.07s
Val loss: 0.6536 score: 0.5227 time: 0.05s
Test loss: 0.6504 score: 0.5349 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.1557;  Loss pred: 0.1557; Loss self: 0.0000; time: 0.07s
Val loss: 0.6492 score: 0.5227 time: 0.05s
Test loss: 0.6461 score: 0.5349 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1432;  Loss pred: 0.1432; Loss self: 0.0000; time: 0.07s
Val loss: 0.6445 score: 0.5227 time: 0.05s
Test loss: 0.6414 score: 0.5349 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1317;  Loss pred: 0.1317; Loss self: 0.0000; time: 0.07s
Val loss: 0.6393 score: 0.5455 time: 0.05s
Test loss: 0.6364 score: 0.5581 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1192;  Loss pred: 0.1192; Loss self: 0.0000; time: 0.07s
Val loss: 0.6339 score: 0.5682 time: 0.05s
Test loss: 0.6311 score: 0.5581 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1134;  Loss pred: 0.1134; Loss self: 0.0000; time: 0.07s
Val loss: 0.6281 score: 0.5909 time: 0.05s
Test loss: 0.6253 score: 0.5581 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1036;  Loss pred: 0.1036; Loss self: 0.0000; time: 0.07s
Val loss: 0.6221 score: 0.5909 time: 0.05s
Test loss: 0.6194 score: 0.5814 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.0953;  Loss pred: 0.0953; Loss self: 0.0000; time: 0.07s
Val loss: 0.6154 score: 0.5909 time: 0.05s
Test loss: 0.6127 score: 0.5814 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.0832;  Loss pred: 0.0832; Loss self: 0.0000; time: 0.07s
Val loss: 0.6080 score: 0.6364 time: 0.05s
Test loss: 0.6055 score: 0.5814 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.0761;  Loss pred: 0.0761; Loss self: 0.0000; time: 0.07s
Val loss: 0.6007 score: 0.6364 time: 0.05s
Test loss: 0.5981 score: 0.5814 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.0700;  Loss pred: 0.0700; Loss self: 0.0000; time: 0.07s
Val loss: 0.5929 score: 0.6364 time: 0.05s
Test loss: 0.5904 score: 0.6047 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0623;  Loss pred: 0.0623; Loss self: 0.0000; time: 0.07s
Val loss: 0.5849 score: 0.6591 time: 0.05s
Test loss: 0.5826 score: 0.6047 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0557;  Loss pred: 0.0557; Loss self: 0.0000; time: 0.07s
Val loss: 0.5762 score: 0.6591 time: 0.05s
Test loss: 0.5741 score: 0.6047 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0517;  Loss pred: 0.0517; Loss self: 0.0000; time: 0.07s
Val loss: 0.5674 score: 0.6591 time: 0.05s
Test loss: 0.5653 score: 0.6279 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0492;  Loss pred: 0.0492; Loss self: 0.0000; time: 0.07s
Val loss: 0.5581 score: 0.6591 time: 0.05s
Test loss: 0.5560 score: 0.6279 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0430;  Loss pred: 0.0430; Loss self: 0.0000; time: 0.07s
Val loss: 0.5485 score: 0.6591 time: 0.05s
Test loss: 0.5463 score: 0.6744 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0376;  Loss pred: 0.0376; Loss self: 0.0000; time: 0.07s
Val loss: 0.5389 score: 0.6591 time: 0.05s
Test loss: 0.5363 score: 0.6977 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0341;  Loss pred: 0.0341; Loss self: 0.0000; time: 0.07s
Val loss: 0.5288 score: 0.7045 time: 0.05s
Test loss: 0.5255 score: 0.7209 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0319;  Loss pred: 0.0319; Loss self: 0.0000; time: 0.07s
Val loss: 0.5187 score: 0.7273 time: 0.05s
Test loss: 0.5147 score: 0.7442 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0267;  Loss pred: 0.0267; Loss self: 0.0000; time: 0.07s
Val loss: 0.5085 score: 0.7045 time: 0.05s
Test loss: 0.5039 score: 0.7442 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0269;  Loss pred: 0.0269; Loss self: 0.0000; time: 0.07s
Val loss: 0.4983 score: 0.7273 time: 0.05s
Test loss: 0.4927 score: 0.7674 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0248;  Loss pred: 0.0248; Loss self: 0.0000; time: 0.07s
Val loss: 0.4882 score: 0.7273 time: 0.05s
Test loss: 0.4816 score: 0.7674 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.07s
Val loss: 0.4785 score: 0.7727 time: 0.05s
Test loss: 0.4707 score: 0.8140 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0220;  Loss pred: 0.0220; Loss self: 0.0000; time: 0.07s
Val loss: 0.4691 score: 0.7955 time: 0.05s
Test loss: 0.4597 score: 0.8140 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0194;  Loss pred: 0.0194; Loss self: 0.0000; time: 0.07s
Val loss: 0.4604 score: 0.7955 time: 0.05s
Test loss: 0.4492 score: 0.8140 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0168;  Loss pred: 0.0168; Loss self: 0.0000; time: 0.07s
Val loss: 0.4520 score: 0.7955 time: 0.05s
Test loss: 0.4386 score: 0.8140 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.07s
Val loss: 0.4445 score: 0.7955 time: 0.05s
Test loss: 0.4287 score: 0.8140 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.07s
Val loss: 0.4378 score: 0.7727 time: 0.05s
Test loss: 0.4192 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0141;  Loss pred: 0.0141; Loss self: 0.0000; time: 0.07s
Val loss: 0.4320 score: 0.7727 time: 0.05s
Test loss: 0.4104 score: 0.8140 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0118;  Loss pred: 0.0118; Loss self: 0.0000; time: 0.07s
Val loss: 0.4271 score: 0.7727 time: 0.05s
Test loss: 0.4023 score: 0.8140 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.07s
Val loss: 0.4229 score: 0.7727 time: 0.05s
Test loss: 0.3948 score: 0.8372 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.07s
Val loss: 0.4195 score: 0.7727 time: 0.05s
Test loss: 0.3879 score: 0.8372 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.07s
Val loss: 0.4168 score: 0.7727 time: 0.05s
Test loss: 0.3816 score: 0.8372 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.07s
Val loss: 0.4151 score: 0.7955 time: 0.05s
Test loss: 0.3766 score: 0.8605 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.07s
Val loss: 0.4143 score: 0.7955 time: 0.05s
Test loss: 0.3724 score: 0.8605 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.07s
Val loss: 0.4143 score: 0.7955 time: 0.05s
Test loss: 0.3690 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 89/1000, LR 0.000266
Train loss: 0.0076;  Loss pred: 0.0076; Loss self: 0.0000; time: 0.07s
Val loss: 0.4151 score: 0.7955 time: 0.05s
Test loss: 0.3666 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.4171 score: 0.8182 time: 0.05s
Test loss: 0.3651 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.07s
Val loss: 0.4197 score: 0.8636 time: 0.05s
Test loss: 0.3644 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.4233 score: 0.8636 time: 0.05s
Test loss: 0.3646 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.07s
Val loss: 0.4280 score: 0.8636 time: 0.05s
Test loss: 0.3659 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.07s
Val loss: 0.4335 score: 0.8636 time: 0.05s
Test loss: 0.3681 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.07s
Val loss: 0.4399 score: 0.8636 time: 0.05s
Test loss: 0.3713 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.4478 score: 0.8409 time: 0.05s
Test loss: 0.3754 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.4561 score: 0.8182 time: 0.05s
Test loss: 0.3802 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.4651 score: 0.8182 time: 0.05s
Test loss: 0.3857 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.4748 score: 0.8182 time: 0.05s
Test loss: 0.3920 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.4852 score: 0.8182 time: 0.05s
Test loss: 0.3990 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.4956 score: 0.8182 time: 0.05s
Test loss: 0.4062 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0046;  Loss pred: 0.0046; Loss self: 0.0000; time: 0.07s
Val loss: 0.5060 score: 0.8182 time: 0.05s
Test loss: 0.4135 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.07s
Val loss: 0.5168 score: 0.8182 time: 0.05s
Test loss: 0.4211 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0042;  Loss pred: 0.0042; Loss self: 0.0000; time: 0.07s
Val loss: 0.5277 score: 0.8182 time: 0.05s
Test loss: 0.4288 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.07s
Val loss: 0.5385 score: 0.8182 time: 0.05s
Test loss: 0.4364 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.07s
Val loss: 0.5487 score: 0.8182 time: 0.05s
Test loss: 0.4438 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0036;  Loss pred: 0.0036; Loss self: 0.0000; time: 0.07s
Val loss: 0.5587 score: 0.8182 time: 0.05s
Test loss: 0.4509 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 086,   Train_Loss: 0.0082,   Val_Loss: 0.4143,   Val_Precision: 0.8095,   Val_Recall: 0.7727,   Val_accuracy: 0.7907,   Val_Score: 0.7955,   Val_Loss: 0.4143,   Test_Precision: 0.8636,   Test_Recall: 0.8636,   Test_accuracy: 0.8636,   Test_Score: 0.8605,   Test_loss: 0.3724


[0.05243536701891571, 0.052393713966012, 0.05252082098741084, 0.053163295960985124, 0.053010753937996924, 0.05424494901672006, 0.053367046057246625, 0.05291198706254363, 0.053371179034002125, 0.056223251041956246, 0.05649519001599401, 0.05661716696340591, 0.05692584894131869, 0.057410484994761646, 0.05699764098972082, 0.05699408508371562, 0.056776468991301954, 0.05622285092249513, 0.0571935570333153, 0.05286205105949193, 0.05270314298104495, 0.05324682698119432, 0.052550161024555564, 0.05254666798282415, 0.052582112955860794, 0.05189745407551527, 0.052792060072533786, 0.05268872599117458, 0.05226173996925354, 0.053783460054546595, 0.05871976201888174, 0.058864727965556085, 0.05520308006089181, 0.05275802395772189, 0.05242797709070146, 0.05340432992670685, 0.05238886398728937, 0.058588232030160725, 0.05830680695362389, 0.05839498504064977, 0.05821737798396498, 0.14516043895855546, 0.055965595995076, 0.05256399302743375, 0.052559328032657504, 0.053053568000905216, 0.052795498981140554, 0.05372864694800228, 0.052990262978710234, 0.051390209002420306, 0.05126896710135043, 0.05578691908158362, 0.05542581400368363, 0.055624327971599996, 0.05566171009559184, 0.05612452304922044, 0.055970989051274955, 0.05784195801243186, 0.056823901017196476, 0.05354483099654317, 0.11903268797323108, 0.06581443699542433, 0.05601441801991314, 0.05112423200625926, 0.05181457300204784, 0.05241505603771657, 0.05232769704889506, 0.05378702201414853, 0.05357530398759991, 0.052526494953781366, 0.052428902010433376, 0.05756401002872735, 0.057189750019460917, 0.05864419799763709, 0.058348097023554146, 0.0585207570111379, 0.059253243962302804, 0.059320745058357716, 0.056914764922112226, 0.0561768600018695, 0.05770650506019592, 0.05535919696558267, 0.055351927992887795, 0.05521258898079395, 0.05512788495980203, 0.05543037096504122, 0.05591615510638803, 0.056866992032155395, 0.05626723088789731, 0.05530652904417366, 0.0554718739585951, 0.05203265999443829, 0.05181859794538468, 0.05215694394428283, 0.052222142927348614, 0.052366137970238924, 0.052908163983374834, 0.053087662905454636, 0.05248832097277045, 0.05333411099854857, 0.05215921893250197, 0.05169277801178396, 0.05144234199542552, 0.05665780010167509, 0.05710018193349242, 0.05083872203249484, 0.05095139006152749, 0.05156508192885667, 0.05148033506702632, 0.050502334954217076, 0.05122747889254242, 0.05134032899513841, 0.05116498994175345, 0.05036704905796796, 0.05133798299357295, 0.05146087799221277, 0.050738760037347674, 0.0516788880340755, 0.051444106036797166, 0.052277021924965084, 0.05200374301057309, 0.05221675103530288, 0.05320293304976076, 0.05344987800344825, 0.05309860489796847, 0.05321546003688127, 0.05364453105721623, 0.05356428597588092, 0.05374692496843636, 0.05337790597695857, 0.05294501897878945, 0.053113206988200545, 0.053204279975034297, 0.0536570199765265, 0.053366324049420655, 0.05337634007446468, 0.05340219009667635, 0.05337673204485327, 0.0532384350663051, 0.05206185509450734, 0.051558853941969573, 0.052869284991174936, 0.05277073394972831, 0.052908329060301185, 0.052313453052192926, 0.0525170509936288, 0.05253149999771267, 0.05254759907256812, 0.05243929103016853, 0.05265906802378595, 0.05228554003406316, 0.0527666179696098, 0.05286584596615285, 0.052661941037513316, 0.05286513105966151, 0.053598843049257994, 0.05299180292058736, 0.052694814978167415, 0.05265626101754606, 0.05335208005271852, 0.05299293005373329, 0.05352915695402771, 0.053390442044474185, 0.05310786992777139, 0.05270543904043734, 0.05302642798051238, 0.05278330703731626, 0.052848797058686614, 0.05305726907681674, 0.052955421968363225, 0.05286267201881856, 0.05293812300078571, 0.05299417697824538, 0.05270486604422331, 0.05268543493002653, 0.0530080480966717, 0.053110516048036516, 0.052974247955717146, 0.053318658960051835, 0.053175703971646726, 0.0528043870581314, 0.053007054957561195, 0.053255766979418695, 0.05312917404808104, 0.05301479704212397, 0.053496718988753855, 0.05331684893462807, 0.0531779850134626, 0.05332226003520191, 0.053648689994588494, 0.053255410050041974, 0.0533650410361588, 0.05366610595956445, 0.05379050294868648, 0.05310892092529684, 0.05329737195279449, 0.053260987042449415, 0.05313176102936268, 0.053416118025779724, 0.053307001013308764, 0.052966534974984825, 0.053326701978221536, 0.053261925000697374, 0.05313857307191938, 0.05321989196818322, 0.053178646019659936, 0.053177590016275644, 0.0531178469536826, 0.053422443103045225, 0.05285257601644844, 0.05310373893007636, 0.053429713007062674, 0.052903210977092385, 0.052862136042676866, 0.05305991810746491, 0.053207805030979216, 0.05283087398856878, 0.05305537790991366, 0.05337291909381747, 0.05295802094042301, 0.05313831998500973, 0.053358559031039476, 0.05319250305183232, 0.05287764605600387, 0.053627499961294234, 0.053054354968480766, 0.053480254020541906]
[0.001191712886793539, 0.0011907662265002728, 0.0011936550224411556, 0.0012082567263860255, 0.0012047898622272028, 0.0012328397503800013, 0.0012128874103919688, 0.0012025451605123553, 0.0012129813416818665, 0.0012778011600444602, 0.0012839815912725912, 0.0012867537946228615, 0.0012937692941208793, 0.0013047837498809465, 0.0012954009315845642, 0.0012953201155389913, 0.0012903742952568625, 0.0012777920664203439, 0.0012998535689389842, 0.0012014102513520893, 0.001197798704114658, 0.0012101551586635071, 0.001194321841467172, 0.0011942424541550943, 0.001195048021724109, 0.0011794875926253471, 0.0011998195471030406, 0.0011974710452539678, 0.001187766817483035, 0.001222351364876059, 0.001334540045883676, 0.001337834726489911, 0.0012546154559293593, 0.001199045999039134, 0.0011915449338795786, 0.0012137347710615193, 0.001190655999711122, 0.0013315507279581982, 0.001325154703491452, 0.0013271587509238584, 0.001323122226908295, 0.003299100885421715, 0.0012719453635244545, 0.001194636205168949, 0.0011945301825603979, 0.0012057629091114823, 0.0011998977041168307, 0.0012211056124545973, 0.0012043241586070508, 0.0011679592955095525, 0.0011652037977579641, 0.001267884524581446, 0.0012596775909928097, 0.001264189272081818, 0.0012650388658089055, 0.0012755573420277374, 0.0012720679329835218, 0.0013145899548279967, 0.0012914522958453745, 0.0012169279771941629, 0.002705288363027979, 0.0014957826589869167, 0.0012730549549980258, 0.0011619143637786196, 0.0011776039318647236, 0.0011912512735844675, 0.0011892658420203422, 0.0012224323185033757, 0.0012176205451727253, 0.0011937839762223039, 0.0011915659547825767, 0.0013082729551983489, 0.001299767045896839, 0.0013328226817644793, 0.001326093114171685, 0.0013300172047985886, 0.001346664635506882, 0.0013481987513263118, 0.0012935173845934596, 0.0012767468182243067, 0.0013115114786408164, 0.0012581635673996061, 0.0012579983634747225, 0.0012548315677453172, 0.001252906476359137, 0.0012597811582963914, 0.0012708217069633645, 0.0012924316370944407, 0.0012788007019976662, 0.001256966569185765, 0.0012607244081498886, 0.0011825604544190521, 0.001177695407849652, 0.0011853850896427916, 0.0011868668847124684, 0.001190139499323612, 0.001202458272349428, 0.001206537793305787, 0.001192916385744783, 0.0012121388863306493, 0.0011854367939204994, 0.0011748358639041808, 0.0011691441362596709, 0.0012876772750380703, 0.0012977314075793731, 0.001155425500738519, 0.0011579861377619884, 0.0011719336802012879, 0.001170007615159689, 0.0011477803398685699, 0.0011642608839214188, 0.0011668256589804184, 0.0011628406804943966, 0.0011447056604083627, 0.0011667723407630217, 0.0011695654089139266, 0.0011531536372124472, 0.001174520182592625, 0.0011691842281090264, 0.0011881141346582974, 0.001209389372338909, 0.0012143430473326251, 0.001237277512785134, 0.001243020418684843, 0.001234851276696941, 0.0012375688380670063, 0.0012475472338887494, 0.001245681069206533, 0.001249928487638055, 0.0012413466506269435, 0.0012312795111346384, 0.0012351908601907103, 0.0012373088366287046, 0.0012478376738727093, 0.001241077303474899, 0.0012413102342898762, 0.0012419113975971243, 0.0012413193498803086, 0.0012381031410768628, 0.0012107408161513334, 0.001199043114929525, 0.0012295182556087195, 0.0012272263709239143, 0.0012304262572163066, 0.001216591931446347, 0.001221326767293693, 0.0012216627906444808, 0.0012220371877341423, 0.0012195183960504311, 0.0012246294889252545, 0.001215942791489841, 0.0012271306504560418, 0.0012294382782826244, 0.001224696303197984, 0.0012294216525502676, 0.0012464847220757672, 0.0012323675097811015, 0.0012254608134457537, 0.0012245642097103735, 0.00124074604773764, 0.001232393722179844, 0.0012448641152099469, 0.001241638187080795, 0.0012350667425063114, 0.0012257078846613335, 0.001233172743732846, 0.0012275187683096806, 0.0012290417920624794, 0.0012338899785306217, 0.0012315214411247261, 0.00122936446555392, 0.001231119139553156, 0.001232422720424311, 0.0012256945591679839, 0.0012252426727913147, 0.0012327453045737605, 0.0012351282801868957, 0.0012319592547841197, 0.0012399688130244613, 0.001236644278410389, 0.001228009001351893, 0.0012327222083153766, 0.0012385062088236907, 0.0012355621871646754, 0.0012329022567935807, 0.0012441097439245083, 0.0012399267194099551, 0.001236697325894479, 0.001240052558958184, 0.0012476439533625231, 0.001238497908140511, 0.0012410474659571814, 0.0012480489758038243, 0.0012509419290392205, 0.001235091184309229, 0.001239473766344058, 0.0012386276056383584, 0.0012356223495200622, 0.0012422353029251099, 0.0012396976979839247, 0.001231779883139182, 0.0012401558599586403, 0.0012386494186208692, 0.0012357807691144042, 0.001237671906236819, 0.0012367126981316263, 0.001236688139913387, 0.0012352987663647116, 0.0012423823977452378, 0.0012291296748011265, 0.0012349706727924736, 0.0012425514652805274, 0.0012303072320254042, 0.0012293520009924854, 0.0012339515838945328, 0.0012373908146739352, 0.0012286249764783437, 0.0012338459979049689, 0.0012412306766004064, 0.001231581882335419, 0.0012357748833723193, 0.0012408967216520808, 0.001237034954693775, 0.001229712698976834, 0.0012471511618905636, 0.00123382220856932, 0.001243726837687021]
[839.1282926298063, 839.7954004280544, 837.7629894731982, 827.6386782394045, 830.0202644064224, 811.135429151897, 824.4788357369708, 831.569601572336, 824.4149894452985, 782.5943748284011, 778.8273654366579, 777.1494470650408, 772.9353328635793, 766.4105259520927, 771.9617730834708, 772.0099363884991, 774.968940156189, 782.5999442940969, 769.3174245898006, 832.3551416966698, 834.8648204116575, 826.3403191243657, 837.2952459544271, 837.3509051874082, 836.7864569637035, 847.8257899891622, 833.4586666924172, 835.0932608879184, 841.9160943720194, 818.095376447995, 749.3218379504247, 747.476485846431, 797.056974927228, 833.9963611082135, 839.2465710412422, 823.9032314493312, 839.8731457638653, 751.0040579027743, 754.6288726631309, 753.489361618482, 755.7880743464448, 303.11288885370743, 786.197291705269, 837.0749150856157, 837.149211128818, 829.3504406574363, 833.4043781974207, 818.9299842704487, 830.3412273624264, 856.194221703355, 858.2189672949553, 788.715360596518, 793.8539251236931, 791.0207926011258, 790.4895470231806, 783.971027449313, 786.1215380648653, 760.6934742863159, 774.3220583656231, 821.7413180898941, 369.6463614254854, 668.5463252243433, 785.5120441376002, 860.6486253840053, 849.1819472923382, 839.4534571963196, 840.8548910319204, 818.0411993886911, 821.273921472921, 837.6724934476606, 839.2317655487803, 764.3664848581914, 769.3686366005688, 750.287351559874, 754.09485903607, 751.8699731041713, 742.5753774425078, 741.7304006669895, 773.0858602370394, 783.2406438974292, 762.479029948216, 794.8092171090417, 794.9135937171617, 796.9197027747725, 798.144170270341, 793.7886619548312, 786.8924448808052, 773.7353151212963, 781.9826798952015, 795.566106939326, 793.1947644826665, 845.6227301218717, 849.1159881704006, 843.6077092055746, 842.5544708345797, 840.2376364857454, 831.6296897738879, 828.8178004437844, 838.2817202864239, 824.9879706666043, 843.5709142220741, 851.1827317535478, 855.3265324489439, 776.592100664691, 770.5754782226282, 865.4820231688022, 863.568196017161, 853.2906058542859, 854.695291759716, 871.2468451189084, 858.9140233173845, 857.0260623800543, 859.9630342953235, 873.5870141877866, 857.0652260629016, 855.0184473467052, 867.1871359807094, 851.4115081382504, 855.2972029201458, 841.6699800373984, 826.8635584799636, 823.4905302884206, 808.2261171537677, 804.4920139429676, 809.8141200249343, 808.0358596956338, 801.5728565906751, 802.773699239866, 800.0457705301718, 805.5767496492208, 812.1632748347192, 809.5914827653457, 808.2056560144676, 801.3862868048084, 805.7515814688535, 805.6003828664766, 805.210421560524, 805.594466964865, 807.6871520818788, 825.9406031910033, 833.9983671552762, 813.3266793219856, 814.845593031995, 812.726479246616, 821.9682986152543, 818.7816944484682, 818.5564851921667, 818.3057029992387, 819.995830516891, 816.5735098193729, 822.4071124059581, 814.909153828378, 813.3795877877483, 816.5289610075195, 813.3905872941447, 802.2561225898565, 811.4462545167427, 816.0195650713607, 816.6170398173845, 805.9667019076038, 811.4289954603237, 803.3005271674568, 805.3876003532813, 809.6728424333634, 815.8550764942682, 810.9163984382058, 814.6514952085183, 813.6419822810745, 810.4450294594744, 812.0037269401645, 813.4284242138281, 812.2690711826294, 811.4099029720174, 815.8639462989963, 816.1648481617336, 811.1975736510832, 809.6325021791932, 811.7151570692436, 806.4718963058893, 808.6399763118809, 814.3262784711823, 811.2127722324302, 807.4242929712728, 809.3481739634367, 811.0943057243713, 803.7876118914791, 806.4992747925222, 808.6052901236117, 806.4174318870312, 801.5107173043252, 807.4297045050376, 805.7709535136362, 801.2506074578806, 799.3976193347719, 809.6568194349857, 806.794001739619, 807.3451580183572, 809.3087668642589, 805.0004678222275, 806.6482672560122, 811.8333589370751, 806.3502599047109, 807.3309404314056, 809.2050183922416, 807.9685698292466, 808.5952392263441, 808.6112963532069, 809.5207630967215, 804.9051578764072, 813.5838069012533, 809.7358277657187, 804.7956386049835, 812.8051058870401, 813.4366716714791, 810.4045677739258, 808.152111799464, 813.9180133439412, 810.4739178941036, 805.6520184780555, 811.963876980493, 809.2088724696275, 805.8688386803371, 808.3845943120886, 813.198075316321, 801.8274212117914, 810.4895446480502, 804.035074019723]
Elapsed: 0.05441248053756629~0.0076988332898231095
Time per graph: 0.0012498683466255493~0.00017322009636381924
Speed: 806.9983520806111~52.51449477662105
Total Time: 0.0543
best val loss: 0.41425275802612305 test_score: 0.8605

Testing...
Test loss: 0.3644 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.1693561039865017, 0.16734645108226687, 0.16796225891448557, 0.16796781006269157, 0.16896327200811356, 0.16903425799682736, 0.1729934139875695, 0.16779766511172056, 0.16708074405323714, 0.28698095702566206, 0.1795014028903097, 0.180441256146878, 0.18046044511720538, 0.1799975250614807, 0.18174047605134547, 0.18176476401276886, 0.1811340191634372, 0.17901885497849435, 0.17863019194919616, 0.23985710996203125, 0.169497906928882, 0.17129224014934152, 0.16641444305423647, 0.16716931387782097, 0.16675634495913982, 0.16786151204723865, 0.16804075799882412, 0.1695880921324715, 0.16717001690994948, 0.16761679691262543, 0.26442258688621223, 0.18581364187411964, 0.1796168830478564, 0.16891609400045127, 0.168103989912197, 0.16792448388878256, 0.1663594781421125, 0.1830545050324872, 0.18173756904434413, 0.18290685897227377, 0.1820213319733739, 0.280726729077287, 0.17728690314106643, 0.17297155898995697, 0.1665343518834561, 0.16696050995960832, 0.16711985308211297, 0.16805569897405803, 0.1693274840945378, 0.1658047630917281, 0.16353903303388506, 0.30743979290127754, 0.17612704599741846, 0.17636339098680764, 0.17764286301098764, 0.17701782088261098, 0.17853250191546977, 0.1852696801070124, 0.1812716490821913, 0.17045548697933555, 0.23258531896863133, 0.2460017759585753, 0.1793978230562061, 0.17307644104585052, 0.16707798896823078, 0.1666552119422704, 0.16742642410099506, 0.16943088499829173, 0.1707886578515172, 0.16710314201191068, 0.16766056406777352, 0.28457572089973837, 0.17848186218179762, 0.18024890590459108, 0.18127747299149632, 0.18100732297170907, 0.18539051886182278, 0.18486536492127925, 0.1843906290596351, 0.17778556409757584, 0.17900698201265186, 0.23158326919656247, 0.17660819506272674, 0.1748082529520616, 0.17517003999091685, 0.17562346998602152, 0.17610822489950806, 0.17790659295860678, 0.17839546396862715, 0.17701481701806188, 0.17461727908812463, 0.29832737997639924, 0.16555594897363335, 0.1664872580440715, 0.16755682800430804, 0.16774164012167603, 0.16869402793236077, 0.1693783231312409, 0.16906843695323914, 0.16949558700434864, 0.16657601203769445, 0.16312495002057403, 0.1626480099512264, 0.30435283097904176, 0.17943979799747467, 0.17287575209047645, 0.1597127909772098, 0.16421720595099032, 0.164980539935641, 0.16002715681679547, 0.16668203403241932, 0.16442993900272995, 0.16184295690618455, 0.16099935804959387, 0.2567708040587604, 0.1622085189446807, 0.16299479000736028, 0.16387098806444556, 0.16497813595924526, 0.16584601299837232, 0.16058981092646718, 0.16183841705787927, 0.16396226698998362, 0.16467535600531846, 0.16643291793297976, 0.16582758910953999, 0.1650081560947001, 0.16582708992064, 0.16607219900470227, 0.16576886002440006, 0.16546255198772997, 0.1656409320421517, 0.16578650590963662, 0.16573784698266536, 0.16570552589837462, 0.16625829401891679, 0.16629180393647403, 0.16555554990191013, 0.16534019995015115, 0.16457034496124834, 0.16078074602410197, 0.16329969197977334, 0.1627874739933759, 0.16343488497659564, 0.16333569400012493, 0.1637033720035106, 0.16452942288015038, 0.164690992096439, 0.16406585206277668, 0.16448263404890895, 0.16443630203139037, 0.16414578806143254, 0.16366474807728082, 0.1638292910065502, 0.1649926631944254, 0.16556729411240667, 0.16514499904587865, 0.16553059790749103, 0.16465282207354903, 0.16593520995229483, 0.16668416804168373, 0.16767643811181188, 0.16731540695764124, 0.16601842001546174, 0.16644470591563731, 0.16585726314224303, 0.1645987619413063, 0.16508629301097244, 0.16537718917243183, 0.16579297196585685, 0.16610947297886014, 0.16699144814629108, 0.16592536494135857, 0.1658343099988997, 0.16517645388375968, 0.16593114903662354, 0.16636689298320562, 0.1662482999963686, 0.16702713805716485, 0.16723636304959655, 0.1654527799692005, 0.16665763000492007, 0.16686486708931625, 0.16539487789850682, 0.1663842749549076, 0.16762273106724024, 0.16664406610652804, 0.1662347010569647, 0.16693269496317953, 0.16742988908663392, 0.1668893020832911, 0.16769012296572328, 0.1669898061081767, 0.1670936110895127, 0.16671971301548183, 0.16652553610038012, 0.1657628370448947, 0.16685861896257848, 0.16712674510199577, 0.166577072115615, 0.16773606091737747, 0.16629856696818024, 0.1668716788990423, 0.16828750795684755, 0.1682352269999683, 0.16691766295116395, 0.16777145094238222, 0.16811946406960487, 0.16816599597223103, 0.16657337278593332, 0.1679536879528314, 0.1686727600172162, 0.16726214601658285, 0.16635336505714804, 0.16662993095815182, 0.1675920650595799, 0.16677012795116752, 0.1683424860239029, 0.16742456599604338, 0.1666585539933294, 0.16795691091101617, 0.16735222202260047, 0.1675584560725838, 0.1673145149834454, 0.1682838249253109, 0.167613536817953, 0.16847118001896888]
Total Epoch List: [120, 107]
Total Time List: [0.052817174000665545, 0.05425599601585418]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNT
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x72b7adf588b0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6894;  Loss pred: 0.6894; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6895;  Loss pred: 0.6895; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6884;  Loss pred: 0.6884; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6887;  Loss pred: 0.6887; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6859;  Loss pred: 0.6859; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6861;  Loss pred: 0.6861; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6816;  Loss pred: 0.6816; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6779;  Loss pred: 0.6779; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6712;  Loss pred: 0.6712; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6691;  Loss pred: 0.6691; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6621;  Loss pred: 0.6621; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6615;  Loss pred: 0.6615; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6546;  Loss pred: 0.6546; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6517;  Loss pred: 0.6517; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6466;  Loss pred: 0.6466; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6337;  Loss pred: 0.6337; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6287;  Loss pred: 0.6287; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6257;  Loss pred: 0.6257; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6179;  Loss pred: 0.6179; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6052;  Loss pred: 0.6052; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6005;  Loss pred: 0.6005; Loss self: 0.0000; time: 0.07s
Val loss: 0.6917 score: 0.7273 time: 0.05s
Test loss: 0.6918 score: 0.6977 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.5992;  Loss pred: 0.5992; Loss self: 0.0000; time: 0.07s
Val loss: 0.6915 score: 0.8182 time: 0.05s
Test loss: 0.6917 score: 0.8837 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5809;  Loss pred: 0.5809; Loss self: 0.0000; time: 0.07s
Val loss: 0.6912 score: 0.6136 time: 0.05s
Test loss: 0.6915 score: 0.5581 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5762;  Loss pred: 0.5762; Loss self: 0.0000; time: 0.07s
Val loss: 0.6909 score: 0.5227 time: 0.05s
Test loss: 0.6913 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5658;  Loss pred: 0.5658; Loss self: 0.0000; time: 0.07s
Val loss: 0.6905 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5578;  Loss pred: 0.5578; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5000 time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6908 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5462;  Loss pred: 0.5462; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6897 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6905 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5356;  Loss pred: 0.5356; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5226;  Loss pred: 0.5226; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6887 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6897 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5101;  Loss pred: 0.5101; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6880 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6892 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.4986;  Loss pred: 0.4986; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6873 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6886 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.4836;  Loss pred: 0.4836; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6864 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.4884 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4685;  Loss pred: 0.4685; Loss self: 0.0000; time: 0.07s
Val loss: 0.6855 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4603;  Loss pred: 0.4603; Loss self: 0.0000; time: 0.07s
Val loss: 0.6845 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.4884 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4454;  Loss pred: 0.4454; Loss self: 0.0000; time: 0.07s
Val loss: 0.6833 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6855 score: 0.4884 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4336;  Loss pred: 0.4336; Loss self: 0.0000; time: 0.07s
Val loss: 0.6821 score: 0.5227 time: 0.05s
Test loss: 0.6845 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4164;  Loss pred: 0.4164; Loss self: 0.0000; time: 0.07s
Val loss: 0.6806 score: 0.5227 time: 0.05s
Test loss: 0.6833 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4017;  Loss pred: 0.4017; Loss self: 0.0000; time: 0.18s
Val loss: 0.6791 score: 0.5227 time: 0.05s
Test loss: 0.6820 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.3968;  Loss pred: 0.3968; Loss self: 0.0000; time: 0.07s
Val loss: 0.6773 score: 0.5227 time: 0.05s
Test loss: 0.6805 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3791;  Loss pred: 0.3791; Loss self: 0.0000; time: 0.07s
Val loss: 0.6755 score: 0.5227 time: 0.05s
Test loss: 0.6790 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3727;  Loss pred: 0.3727; Loss self: 0.0000; time: 0.07s
Val loss: 0.6734 score: 0.5227 time: 0.05s
Test loss: 0.6774 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3481;  Loss pred: 0.3481; Loss self: 0.0000; time: 0.07s
Val loss: 0.6712 score: 0.5455 time: 0.05s
Test loss: 0.6756 score: 0.5349 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3409;  Loss pred: 0.3409; Loss self: 0.0000; time: 0.07s
Val loss: 0.6687 score: 0.5682 time: 0.05s
Test loss: 0.6735 score: 0.5581 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3168;  Loss pred: 0.3168; Loss self: 0.0000; time: 0.07s
Val loss: 0.6659 score: 0.5682 time: 0.05s
Test loss: 0.6711 score: 0.5581 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3149;  Loss pred: 0.3149; Loss self: 0.0000; time: 0.07s
Val loss: 0.6626 score: 0.5682 time: 0.05s
Test loss: 0.6683 score: 0.5581 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2909;  Loss pred: 0.2909; Loss self: 0.0000; time: 0.07s
Val loss: 0.6589 score: 0.5909 time: 0.05s
Test loss: 0.6651 score: 0.5581 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2861;  Loss pred: 0.2861; Loss self: 0.0000; time: 0.07s
Val loss: 0.6548 score: 0.7045 time: 0.05s
Test loss: 0.6614 score: 0.5814 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2680;  Loss pred: 0.2680; Loss self: 0.0000; time: 0.08s
Val loss: 0.6502 score: 0.7273 time: 0.11s
Test loss: 0.6573 score: 0.6744 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2545;  Loss pred: 0.2545; Loss self: 0.0000; time: 0.07s
Val loss: 0.6452 score: 0.7955 time: 0.05s
Test loss: 0.6529 score: 0.7442 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2496;  Loss pred: 0.2496; Loss self: 0.0000; time: 0.07s
Val loss: 0.6397 score: 0.7727 time: 0.05s
Test loss: 0.6480 score: 0.8140 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2365;  Loss pred: 0.2365; Loss self: 0.0000; time: 0.07s
Val loss: 0.6340 score: 0.7955 time: 0.05s
Test loss: 0.6429 score: 0.8372 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2296;  Loss pred: 0.2296; Loss self: 0.0000; time: 0.07s
Val loss: 0.6279 score: 0.7955 time: 0.05s
Test loss: 0.6374 score: 0.8605 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2200;  Loss pred: 0.2200; Loss self: 0.0000; time: 0.07s
Val loss: 0.6216 score: 0.8636 time: 0.05s
Test loss: 0.6318 score: 0.8372 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2063;  Loss pred: 0.2063; Loss self: 0.0000; time: 0.08s
Val loss: 0.6148 score: 0.8636 time: 0.05s
Test loss: 0.6257 score: 0.8837 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1948;  Loss pred: 0.1948; Loss self: 0.0000; time: 0.08s
Val loss: 0.6076 score: 0.9091 time: 0.05s
Test loss: 0.6192 score: 0.8837 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1880;  Loss pred: 0.1880; Loss self: 0.0000; time: 0.07s
Val loss: 0.6000 score: 0.9318 time: 0.05s
Test loss: 0.6123 score: 0.9070 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1769;  Loss pred: 0.1769; Loss self: 0.0000; time: 0.07s
Val loss: 0.5920 score: 0.9091 time: 0.18s
Test loss: 0.6050 score: 0.9070 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1592;  Loss pred: 0.1592; Loss self: 0.0000; time: 0.08s
Val loss: 0.5836 score: 0.9091 time: 0.05s
Test loss: 0.5973 score: 0.8837 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1494;  Loss pred: 0.1494; Loss self: 0.0000; time: 0.07s
Val loss: 0.5749 score: 0.9091 time: 0.05s
Test loss: 0.5892 score: 0.8837 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1498;  Loss pred: 0.1498; Loss self: 0.0000; time: 0.07s
Val loss: 0.5658 score: 0.8864 time: 0.05s
Test loss: 0.5806 score: 0.9070 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1361;  Loss pred: 0.1361; Loss self: 0.0000; time: 0.07s
Val loss: 0.5563 score: 0.8864 time: 0.05s
Test loss: 0.5716 score: 0.9070 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1347;  Loss pred: 0.1347; Loss self: 0.0000; time: 0.07s
Val loss: 0.5465 score: 0.8636 time: 0.05s
Test loss: 0.5622 score: 0.9070 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1187;  Loss pred: 0.1187; Loss self: 0.0000; time: 0.07s
Val loss: 0.5364 score: 0.8636 time: 0.05s
Test loss: 0.5530 score: 0.9070 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1149;  Loss pred: 0.1149; Loss self: 0.0000; time: 0.07s
Val loss: 0.5260 score: 0.8636 time: 0.05s
Test loss: 0.5435 score: 0.9070 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1060;  Loss pred: 0.1060; Loss self: 0.0000; time: 0.07s
Val loss: 0.5155 score: 0.8636 time: 0.05s
Test loss: 0.5341 score: 0.9070 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0967;  Loss pred: 0.0967; Loss self: 0.0000; time: 0.07s
Val loss: 0.5048 score: 0.8636 time: 0.05s
Test loss: 0.5244 score: 0.8837 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0931;  Loss pred: 0.0931; Loss self: 0.0000; time: 0.07s
Val loss: 0.4943 score: 0.8409 time: 0.05s
Test loss: 0.5148 score: 0.8605 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0834;  Loss pred: 0.0834; Loss self: 0.0000; time: 0.07s
Val loss: 0.4839 score: 0.8409 time: 0.05s
Test loss: 0.5054 score: 0.8605 time: 0.17s
Epoch 70/1000, LR 0.000268
Train loss: 0.0778;  Loss pred: 0.0778; Loss self: 0.0000; time: 0.07s
Val loss: 0.4742 score: 0.8409 time: 0.05s
Test loss: 0.4965 score: 0.8605 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0757;  Loss pred: 0.0757; Loss self: 0.0000; time: 0.07s
Val loss: 0.4643 score: 0.8182 time: 0.05s
Test loss: 0.4873 score: 0.8605 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0709;  Loss pred: 0.0709; Loss self: 0.0000; time: 0.07s
Val loss: 0.4552 score: 0.8182 time: 0.05s
Test loss: 0.4790 score: 0.8140 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0624;  Loss pred: 0.0624; Loss self: 0.0000; time: 0.07s
Val loss: 0.4472 score: 0.8182 time: 0.05s
Test loss: 0.4717 score: 0.8140 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0571;  Loss pred: 0.0571; Loss self: 0.0000; time: 0.07s
Val loss: 0.4392 score: 0.8182 time: 0.05s
Test loss: 0.4642 score: 0.8140 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0571;  Loss pred: 0.0571; Loss self: 0.0000; time: 0.07s
Val loss: 0.4321 score: 0.8182 time: 0.05s
Test loss: 0.4577 score: 0.8140 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0509;  Loss pred: 0.0509; Loss self: 0.0000; time: 0.07s
Val loss: 0.4250 score: 0.8182 time: 0.05s
Test loss: 0.4511 score: 0.8140 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0457;  Loss pred: 0.0457; Loss self: 0.0000; time: 0.07s
Val loss: 0.4182 score: 0.8182 time: 0.05s
Test loss: 0.4446 score: 0.8140 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0430;  Loss pred: 0.0430; Loss self: 0.0000; time: 0.07s
Val loss: 0.4117 score: 0.8182 time: 0.05s
Test loss: 0.4383 score: 0.8140 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0401;  Loss pred: 0.0401; Loss self: 0.0000; time: 0.07s
Val loss: 0.4058 score: 0.8182 time: 0.06s
Test loss: 0.4325 score: 0.8140 time: 0.11s
Epoch 80/1000, LR 0.000267
Train loss: 0.0373;  Loss pred: 0.0373; Loss self: 0.0000; time: 0.07s
Val loss: 0.4001 score: 0.8182 time: 0.05s
Test loss: 0.4268 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0346;  Loss pred: 0.0346; Loss self: 0.0000; time: 0.07s
Val loss: 0.3945 score: 0.8182 time: 0.05s
Test loss: 0.4211 score: 0.8140 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0316;  Loss pred: 0.0316; Loss self: 0.0000; time: 0.07s
Val loss: 0.3892 score: 0.8182 time: 0.05s
Test loss: 0.4154 score: 0.8140 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0313;  Loss pred: 0.0313; Loss self: 0.0000; time: 0.07s
Val loss: 0.3849 score: 0.8182 time: 0.05s
Test loss: 0.4106 score: 0.8140 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0278;  Loss pred: 0.0278; Loss self: 0.0000; time: 0.07s
Val loss: 0.3804 score: 0.8182 time: 0.05s
Test loss: 0.4053 score: 0.8140 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0279;  Loss pred: 0.0279; Loss self: 0.0000; time: 0.07s
Val loss: 0.3768 score: 0.8182 time: 0.05s
Test loss: 0.4010 score: 0.8140 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0252;  Loss pred: 0.0252; Loss self: 0.0000; time: 0.07s
Val loss: 0.3742 score: 0.8182 time: 0.05s
Test loss: 0.3977 score: 0.8140 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0216;  Loss pred: 0.0216; Loss self: 0.0000; time: 0.07s
Val loss: 0.3719 score: 0.8182 time: 0.05s
Test loss: 0.3945 score: 0.8140 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0252;  Loss pred: 0.0252; Loss self: 0.0000; time: 0.07s
Val loss: 0.3704 score: 0.8182 time: 0.05s
Test loss: 0.3923 score: 0.8140 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0209;  Loss pred: 0.0209; Loss self: 0.0000; time: 0.07s
Val loss: 0.3694 score: 0.8182 time: 0.05s
Test loss: 0.3905 score: 0.8140 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0190;  Loss pred: 0.0190; Loss self: 0.0000; time: 0.20s
Val loss: 0.3688 score: 0.8182 time: 0.05s
Test loss: 0.3889 score: 0.8140 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.07s
Val loss: 0.3688 score: 0.8182 time: 0.05s
Test loss: 0.3879 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.07s
Val loss: 0.3690 score: 0.8182 time: 0.05s
Test loss: 0.3866 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0171;  Loss pred: 0.0171; Loss self: 0.0000; time: 0.07s
Val loss: 0.3699 score: 0.8182 time: 0.05s
Test loss: 0.3860 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0135;  Loss pred: 0.0135; Loss self: 0.0000; time: 0.07s
Val loss: 0.3712 score: 0.8182 time: 0.05s
Test loss: 0.3858 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.07s
Val loss: 0.3738 score: 0.8182 time: 0.05s
Test loss: 0.3872 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.07s
Val loss: 0.3771 score: 0.8182 time: 0.05s
Test loss: 0.3894 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0133;  Loss pred: 0.0133; Loss self: 0.0000; time: 0.07s
Val loss: 0.3802 score: 0.8182 time: 0.05s
Test loss: 0.3908 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0110;  Loss pred: 0.0110; Loss self: 0.0000; time: 0.07s
Val loss: 0.3836 score: 0.8182 time: 0.05s
Test loss: 0.3925 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.07s
Val loss: 0.3878 score: 0.8182 time: 0.05s
Test loss: 0.3953 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.07s
Val loss: 0.3927 score: 0.8182 time: 0.05s
Test loss: 0.3988 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.17s
Val loss: 0.3978 score: 0.8182 time: 0.05s
Test loss: 0.4025 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.4030 score: 0.8182 time: 0.05s
Test loss: 0.4065 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.4080 score: 0.8182 time: 0.05s
Test loss: 0.4102 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.07s
Val loss: 0.4136 score: 0.8409 time: 0.05s
Test loss: 0.4149 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.07s
Val loss: 0.4189 score: 0.8409 time: 0.05s
Test loss: 0.4187 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.4248 score: 0.8409 time: 0.05s
Test loss: 0.4235 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.4305 score: 0.8409 time: 0.05s
Test loss: 0.4280 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.4352 score: 0.8409 time: 0.05s
Test loss: 0.4314 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.07s
Val loss: 0.4398 score: 0.8409 time: 0.05s
Test loss: 0.4346 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0068;  Loss pred: 0.0068; Loss self: 0.0000; time: 0.07s
Val loss: 0.4445 score: 0.8409 time: 0.05s
Test loss: 0.4379 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 089,   Train_Loss: 0.0190,   Val_Loss: 0.3688,   Val_Precision: 0.9375,   Val_Recall: 0.6818,   Val_accuracy: 0.7895,   Val_Score: 0.8182,   Val_Loss: 0.3688,   Test_Precision: 1.0000,   Test_Recall: 0.6190,   Test_accuracy: 0.7647,   Test_Score: 0.8140,   Test_loss: 0.3889


[0.05243536701891571, 0.052393713966012, 0.05252082098741084, 0.053163295960985124, 0.053010753937996924, 0.05424494901672006, 0.053367046057246625, 0.05291198706254363, 0.053371179034002125, 0.056223251041956246, 0.05649519001599401, 0.05661716696340591, 0.05692584894131869, 0.057410484994761646, 0.05699764098972082, 0.05699408508371562, 0.056776468991301954, 0.05622285092249513, 0.0571935570333153, 0.05286205105949193, 0.05270314298104495, 0.05324682698119432, 0.052550161024555564, 0.05254666798282415, 0.052582112955860794, 0.05189745407551527, 0.052792060072533786, 0.05268872599117458, 0.05226173996925354, 0.053783460054546595, 0.05871976201888174, 0.058864727965556085, 0.05520308006089181, 0.05275802395772189, 0.05242797709070146, 0.05340432992670685, 0.05238886398728937, 0.058588232030160725, 0.05830680695362389, 0.05839498504064977, 0.05821737798396498, 0.14516043895855546, 0.055965595995076, 0.05256399302743375, 0.052559328032657504, 0.053053568000905216, 0.052795498981140554, 0.05372864694800228, 0.052990262978710234, 0.051390209002420306, 0.05126896710135043, 0.05578691908158362, 0.05542581400368363, 0.055624327971599996, 0.05566171009559184, 0.05612452304922044, 0.055970989051274955, 0.05784195801243186, 0.056823901017196476, 0.05354483099654317, 0.11903268797323108, 0.06581443699542433, 0.05601441801991314, 0.05112423200625926, 0.05181457300204784, 0.05241505603771657, 0.05232769704889506, 0.05378702201414853, 0.05357530398759991, 0.052526494953781366, 0.052428902010433376, 0.05756401002872735, 0.057189750019460917, 0.05864419799763709, 0.058348097023554146, 0.0585207570111379, 0.059253243962302804, 0.059320745058357716, 0.056914764922112226, 0.0561768600018695, 0.05770650506019592, 0.05535919696558267, 0.055351927992887795, 0.05521258898079395, 0.05512788495980203, 0.05543037096504122, 0.05591615510638803, 0.056866992032155395, 0.05626723088789731, 0.05530652904417366, 0.0554718739585951, 0.05203265999443829, 0.05181859794538468, 0.05215694394428283, 0.052222142927348614, 0.052366137970238924, 0.052908163983374834, 0.053087662905454636, 0.05248832097277045, 0.05333411099854857, 0.05215921893250197, 0.05169277801178396, 0.05144234199542552, 0.05665780010167509, 0.05710018193349242, 0.05083872203249484, 0.05095139006152749, 0.05156508192885667, 0.05148033506702632, 0.050502334954217076, 0.05122747889254242, 0.05134032899513841, 0.05116498994175345, 0.05036704905796796, 0.05133798299357295, 0.05146087799221277, 0.050738760037347674, 0.0516788880340755, 0.051444106036797166, 0.052277021924965084, 0.05200374301057309, 0.05221675103530288, 0.05320293304976076, 0.05344987800344825, 0.05309860489796847, 0.05321546003688127, 0.05364453105721623, 0.05356428597588092, 0.05374692496843636, 0.05337790597695857, 0.05294501897878945, 0.053113206988200545, 0.053204279975034297, 0.0536570199765265, 0.053366324049420655, 0.05337634007446468, 0.05340219009667635, 0.05337673204485327, 0.0532384350663051, 0.05206185509450734, 0.051558853941969573, 0.052869284991174936, 0.05277073394972831, 0.052908329060301185, 0.052313453052192926, 0.0525170509936288, 0.05253149999771267, 0.05254759907256812, 0.05243929103016853, 0.05265906802378595, 0.05228554003406316, 0.0527666179696098, 0.05286584596615285, 0.052661941037513316, 0.05286513105966151, 0.053598843049257994, 0.05299180292058736, 0.052694814978167415, 0.05265626101754606, 0.05335208005271852, 0.05299293005373329, 0.05352915695402771, 0.053390442044474185, 0.05310786992777139, 0.05270543904043734, 0.05302642798051238, 0.05278330703731626, 0.052848797058686614, 0.05305726907681674, 0.052955421968363225, 0.05286267201881856, 0.05293812300078571, 0.05299417697824538, 0.05270486604422331, 0.05268543493002653, 0.0530080480966717, 0.053110516048036516, 0.052974247955717146, 0.053318658960051835, 0.053175703971646726, 0.0528043870581314, 0.053007054957561195, 0.053255766979418695, 0.05312917404808104, 0.05301479704212397, 0.053496718988753855, 0.05331684893462807, 0.0531779850134626, 0.05332226003520191, 0.053648689994588494, 0.053255410050041974, 0.0533650410361588, 0.05366610595956445, 0.05379050294868648, 0.05310892092529684, 0.05329737195279449, 0.053260987042449415, 0.05313176102936268, 0.053416118025779724, 0.053307001013308764, 0.052966534974984825, 0.053326701978221536, 0.053261925000697374, 0.05313857307191938, 0.05321989196818322, 0.053178646019659936, 0.053177590016275644, 0.0531178469536826, 0.053422443103045225, 0.05285257601644844, 0.05310373893007636, 0.053429713007062674, 0.052903210977092385, 0.052862136042676866, 0.05305991810746491, 0.053207805030979216, 0.05283087398856878, 0.05305537790991366, 0.05337291909381747, 0.05295802094042301, 0.05313831998500973, 0.053358559031039476, 0.05319250305183232, 0.05287764605600387, 0.053627499961294234, 0.053054354968480766, 0.053480254020541906, 0.05331720900721848, 0.052946317940950394, 0.05313829192891717, 0.05308195005636662, 0.052862495998851955, 0.05294209695421159, 0.05295988800935447, 0.05333972699008882, 0.0540183229604736, 0.05313614697661251, 0.053544608992524445, 0.05337657604832202, 0.053107223007828, 0.0530246359994635, 0.0532480189576745, 0.0533028090139851, 0.053556410945020616, 0.05320030800066888, 0.05297687998972833, 0.053193639032542706, 0.05302111606579274, 0.05261478398460895, 0.05441905406769365, 0.05253448407165706, 0.05230229999870062, 0.05316558398772031, 0.05803341208957136, 0.051223961054347456, 0.05169666500296444, 0.05156462802551687, 0.0514187099179253, 0.05166513693984598, 0.051862620981410146, 0.052784934057854116, 0.05305211909580976, 0.05210717907175422, 0.051720340037718415, 0.06208887696266174, 0.05619020503945649, 0.05633916601072997, 0.056499605998396873, 0.05188741604797542, 0.05254733597394079, 0.05359491996932775, 0.05372604099102318, 0.052139460924081504, 0.05213401699438691, 0.053557585924863815, 0.05620963592082262, 0.05611674499232322, 0.05633654200937599, 0.056579289957880974, 0.056640997994691133, 0.05659974203445017, 0.057720611919648945, 0.05702777300029993, 0.05693709396291524, 0.05714511405676603, 0.052649254095740616, 0.05210934090428054, 0.05201304901856929, 0.052308583981357515, 0.052473969059064984, 0.05285167205147445, 0.052780022961087525, 0.05345429899170995, 0.05198678909800947, 0.05221998004708439, 0.17885177698917687, 0.05226996901910752, 0.05283441208302975, 0.053097859025001526, 0.05313343706075102, 0.053292672033421695, 0.05370409297756851, 0.054203353938646615, 0.05350034299772233, 0.05339538096450269, 0.11645754310302436, 0.05169613391626626, 0.05158417404163629, 0.05178694403730333, 0.05130857590120286, 0.051513400045223534, 0.052986825932748616, 0.05375395901501179, 0.05272136093117297, 0.05266481707803905, 0.054569150088354945, 0.05328150698915124, 0.05282177007757127, 0.05245883099269122, 0.05274584190919995, 0.05305240896996111, 0.05294410104397684, 0.052607421996071935, 0.05376930092461407, 0.05346083210315555, 0.05269693792797625, 0.053470588056370616, 0.05315070692449808, 0.0529083349974826, 0.05302584602031857, 0.0527704069390893, 0.05306257796473801, 0.05323543900158256, 0.05354349594563246, 0.05324117699638009, 0.05265751399565488, 0.05404757091309875]
[0.001191712886793539, 0.0011907662265002728, 0.0011936550224411556, 0.0012082567263860255, 0.0012047898622272028, 0.0012328397503800013, 0.0012128874103919688, 0.0012025451605123553, 0.0012129813416818665, 0.0012778011600444602, 0.0012839815912725912, 0.0012867537946228615, 0.0012937692941208793, 0.0013047837498809465, 0.0012954009315845642, 0.0012953201155389913, 0.0012903742952568625, 0.0012777920664203439, 0.0012998535689389842, 0.0012014102513520893, 0.001197798704114658, 0.0012101551586635071, 0.001194321841467172, 0.0011942424541550943, 0.001195048021724109, 0.0011794875926253471, 0.0011998195471030406, 0.0011974710452539678, 0.001187766817483035, 0.001222351364876059, 0.001334540045883676, 0.001337834726489911, 0.0012546154559293593, 0.001199045999039134, 0.0011915449338795786, 0.0012137347710615193, 0.001190655999711122, 0.0013315507279581982, 0.001325154703491452, 0.0013271587509238584, 0.001323122226908295, 0.003299100885421715, 0.0012719453635244545, 0.001194636205168949, 0.0011945301825603979, 0.0012057629091114823, 0.0011998977041168307, 0.0012211056124545973, 0.0012043241586070508, 0.0011679592955095525, 0.0011652037977579641, 0.001267884524581446, 0.0012596775909928097, 0.001264189272081818, 0.0012650388658089055, 0.0012755573420277374, 0.0012720679329835218, 0.0013145899548279967, 0.0012914522958453745, 0.0012169279771941629, 0.002705288363027979, 0.0014957826589869167, 0.0012730549549980258, 0.0011619143637786196, 0.0011776039318647236, 0.0011912512735844675, 0.0011892658420203422, 0.0012224323185033757, 0.0012176205451727253, 0.0011937839762223039, 0.0011915659547825767, 0.0013082729551983489, 0.001299767045896839, 0.0013328226817644793, 0.001326093114171685, 0.0013300172047985886, 0.001346664635506882, 0.0013481987513263118, 0.0012935173845934596, 0.0012767468182243067, 0.0013115114786408164, 0.0012581635673996061, 0.0012579983634747225, 0.0012548315677453172, 0.001252906476359137, 0.0012597811582963914, 0.0012708217069633645, 0.0012924316370944407, 0.0012788007019976662, 0.001256966569185765, 0.0012607244081498886, 0.0011825604544190521, 0.001177695407849652, 0.0011853850896427916, 0.0011868668847124684, 0.001190139499323612, 0.001202458272349428, 0.001206537793305787, 0.001192916385744783, 0.0012121388863306493, 0.0011854367939204994, 0.0011748358639041808, 0.0011691441362596709, 0.0012876772750380703, 0.0012977314075793731, 0.001155425500738519, 0.0011579861377619884, 0.0011719336802012879, 0.001170007615159689, 0.0011477803398685699, 0.0011642608839214188, 0.0011668256589804184, 0.0011628406804943966, 0.0011447056604083627, 0.0011667723407630217, 0.0011695654089139266, 0.0011531536372124472, 0.001174520182592625, 0.0011691842281090264, 0.0011881141346582974, 0.001209389372338909, 0.0012143430473326251, 0.001237277512785134, 0.001243020418684843, 0.001234851276696941, 0.0012375688380670063, 0.0012475472338887494, 0.001245681069206533, 0.001249928487638055, 0.0012413466506269435, 0.0012312795111346384, 0.0012351908601907103, 0.0012373088366287046, 0.0012478376738727093, 0.001241077303474899, 0.0012413102342898762, 0.0012419113975971243, 0.0012413193498803086, 0.0012381031410768628, 0.0012107408161513334, 0.001199043114929525, 0.0012295182556087195, 0.0012272263709239143, 0.0012304262572163066, 0.001216591931446347, 0.001221326767293693, 0.0012216627906444808, 0.0012220371877341423, 0.0012195183960504311, 0.0012246294889252545, 0.001215942791489841, 0.0012271306504560418, 0.0012294382782826244, 0.001224696303197984, 0.0012294216525502676, 0.0012464847220757672, 0.0012323675097811015, 0.0012254608134457537, 0.0012245642097103735, 0.00124074604773764, 0.001232393722179844, 0.0012448641152099469, 0.001241638187080795, 0.0012350667425063114, 0.0012257078846613335, 0.001233172743732846, 0.0012275187683096806, 0.0012290417920624794, 0.0012338899785306217, 0.0012315214411247261, 0.00122936446555392, 0.001231119139553156, 0.001232422720424311, 0.0012256945591679839, 0.0012252426727913147, 0.0012327453045737605, 0.0012351282801868957, 0.0012319592547841197, 0.0012399688130244613, 0.001236644278410389, 0.001228009001351893, 0.0012327222083153766, 0.0012385062088236907, 0.0012355621871646754, 0.0012329022567935807, 0.0012441097439245083, 0.0012399267194099551, 0.001236697325894479, 0.001240052558958184, 0.0012476439533625231, 0.001238497908140511, 0.0012410474659571814, 0.0012480489758038243, 0.0012509419290392205, 0.001235091184309229, 0.001239473766344058, 0.0012386276056383584, 0.0012356223495200622, 0.0012422353029251099, 0.0012396976979839247, 0.001231779883139182, 0.0012401558599586403, 0.0012386494186208692, 0.0012357807691144042, 0.001237671906236819, 0.0012367126981316263, 0.001236688139913387, 0.0012352987663647116, 0.0012423823977452378, 0.0012291296748011265, 0.0012349706727924736, 0.0012425514652805274, 0.0012303072320254042, 0.0012293520009924854, 0.0012339515838945328, 0.0012373908146739352, 0.0012286249764783437, 0.0012338459979049689, 0.0012412306766004064, 0.001231581882335419, 0.0012357748833723193, 0.0012408967216520808, 0.001237034954693775, 0.001229712698976834, 0.0012471511618905636, 0.00123382220856932, 0.001243726837687021, 0.0012399350931911275, 0.001231309719556986, 0.0012357742309050505, 0.0012344639547992237, 0.0012293603720663245, 0.001231211557074688, 0.0012316253025431274, 0.0012404587672113678, 0.0012562400688482232, 0.0012357243482933142, 0.001245223464942429, 0.0012413157220540006, 0.0012350516978564651, 0.001233131069754965, 0.0012383260222715, 0.0012396002096275603, 0.0012454979289539677, 0.0012372164651318345, 0.001232020464877403, 0.0012370613728498305, 0.0012330492108323893, 0.0012235996275490454, 0.0012655593969231082, 0.0012217321877129549, 0.0012163325581093167, 0.001236408929946984, 0.0013496142346411943, 0.0011912549082406384, 0.0012022480233247544, 0.0011991773959422528, 0.0011957839515796581, 0.0012015148125545576, 0.0012061074646839568, 0.0012275566059966074, 0.0012337702115304595, 0.001211794862133819, 0.0012027986055283353, 0.0014439273712246916, 0.0013067489544059648, 0.0013102131630402319, 0.0013139443255441134, 0.0012066840941389633, 0.0012220310691614137, 0.0012463934876587848, 0.0012494428137447252, 0.0012125456028856164, 0.001212418999869463, 0.0012455252540666004, 0.0013072008353679678, 0.001305040581216819, 0.00131015213975293, 0.001315797440880953, 0.001317232511504445, 0.0013162730705686086, 0.0013423398120848591, 0.0013262272790767425, 0.0013241184642538428, 0.001328956140855024, 0.0012244012580404794, 0.0012118451373088499, 0.0012096057911295183, 0.0012164786972408725, 0.0012203248618387205, 0.001229108652359871, 0.001227442394443896, 0.0012431232323653477, 0.0012089950953025458, 0.0012144181406298696, 0.00415934365091109, 0.0012155806748629656, 0.0012287072577448778, 0.0012348339308139889, 0.0012356613269942098, 0.0012393644658935277, 0.0012489323948271746, 0.0012605431148522469, 0.001244194023202845, 0.0012417530456861091, 0.0027083149558842874, 0.0012022356724713085, 0.0011996319544566579, 0.0012043475357512402, 0.0011932226953768107, 0.001197986047563338, 0.0012322517658778748, 0.0012500920701165531, 0.001226078161190069, 0.0012247631878613732, 0.0012690500020547662, 0.0012391048137011917, 0.0012284132576179366, 0.0012199728137835166, 0.001226647486260464, 0.0012337769527897933, 0.001231258163813415, 0.0012234284185133008, 0.0012504488587119552, 0.001243275165189664, 0.0012255101843715408, 0.0012435020478225726, 0.0012360629517325136, 0.001230426395290293, 0.0012331592097748504, 0.0012272187660253325, 0.0012340134410404188, 0.0012380334651530829, 0.0012451975801309875, 0.0012381669068925601, 0.0012245933487361601, 0.0012569202537929943]
[839.1282926298063, 839.7954004280544, 837.7629894731982, 827.6386782394045, 830.0202644064224, 811.135429151897, 824.4788357369708, 831.569601572336, 824.4149894452985, 782.5943748284011, 778.8273654366579, 777.1494470650408, 772.9353328635793, 766.4105259520927, 771.9617730834708, 772.0099363884991, 774.968940156189, 782.5999442940969, 769.3174245898006, 832.3551416966698, 834.8648204116575, 826.3403191243657, 837.2952459544271, 837.3509051874082, 836.7864569637035, 847.8257899891622, 833.4586666924172, 835.0932608879184, 841.9160943720194, 818.095376447995, 749.3218379504247, 747.476485846431, 797.056974927228, 833.9963611082135, 839.2465710412422, 823.9032314493312, 839.8731457638653, 751.0040579027743, 754.6288726631309, 753.489361618482, 755.7880743464448, 303.11288885370743, 786.197291705269, 837.0749150856157, 837.149211128818, 829.3504406574363, 833.4043781974207, 818.9299842704487, 830.3412273624264, 856.194221703355, 858.2189672949553, 788.715360596518, 793.8539251236931, 791.0207926011258, 790.4895470231806, 783.971027449313, 786.1215380648653, 760.6934742863159, 774.3220583656231, 821.7413180898941, 369.6463614254854, 668.5463252243433, 785.5120441376002, 860.6486253840053, 849.1819472923382, 839.4534571963196, 840.8548910319204, 818.0411993886911, 821.273921472921, 837.6724934476606, 839.2317655487803, 764.3664848581914, 769.3686366005688, 750.287351559874, 754.09485903607, 751.8699731041713, 742.5753774425078, 741.7304006669895, 773.0858602370394, 783.2406438974292, 762.479029948216, 794.8092171090417, 794.9135937171617, 796.9197027747725, 798.144170270341, 793.7886619548312, 786.8924448808052, 773.7353151212963, 781.9826798952015, 795.566106939326, 793.1947644826665, 845.6227301218717, 849.1159881704006, 843.6077092055746, 842.5544708345797, 840.2376364857454, 831.6296897738879, 828.8178004437844, 838.2817202864239, 824.9879706666043, 843.5709142220741, 851.1827317535478, 855.3265324489439, 776.592100664691, 770.5754782226282, 865.4820231688022, 863.568196017161, 853.2906058542859, 854.695291759716, 871.2468451189084, 858.9140233173845, 857.0260623800543, 859.9630342953235, 873.5870141877866, 857.0652260629016, 855.0184473467052, 867.1871359807094, 851.4115081382504, 855.2972029201458, 841.6699800373984, 826.8635584799636, 823.4905302884206, 808.2261171537677, 804.4920139429676, 809.8141200249343, 808.0358596956338, 801.5728565906751, 802.773699239866, 800.0457705301718, 805.5767496492208, 812.1632748347192, 809.5914827653457, 808.2056560144676, 801.3862868048084, 805.7515814688535, 805.6003828664766, 805.210421560524, 805.594466964865, 807.6871520818788, 825.9406031910033, 833.9983671552762, 813.3266793219856, 814.845593031995, 812.726479246616, 821.9682986152543, 818.7816944484682, 818.5564851921667, 818.3057029992387, 819.995830516891, 816.5735098193729, 822.4071124059581, 814.909153828378, 813.3795877877483, 816.5289610075195, 813.3905872941447, 802.2561225898565, 811.4462545167427, 816.0195650713607, 816.6170398173845, 805.9667019076038, 811.4289954603237, 803.3005271674568, 805.3876003532813, 809.6728424333634, 815.8550764942682, 810.9163984382058, 814.6514952085183, 813.6419822810745, 810.4450294594744, 812.0037269401645, 813.4284242138281, 812.2690711826294, 811.4099029720174, 815.8639462989963, 816.1648481617336, 811.1975736510832, 809.6325021791932, 811.7151570692436, 806.4718963058893, 808.6399763118809, 814.3262784711823, 811.2127722324302, 807.4242929712728, 809.3481739634367, 811.0943057243713, 803.7876118914791, 806.4992747925222, 808.6052901236117, 806.4174318870312, 801.5107173043252, 807.4297045050376, 805.7709535136362, 801.2506074578806, 799.3976193347719, 809.6568194349857, 806.794001739619, 807.3451580183572, 809.3087668642589, 805.0004678222275, 806.6482672560122, 811.8333589370751, 806.3502599047109, 807.3309404314056, 809.2050183922416, 807.9685698292466, 808.5952392263441, 808.6112963532069, 809.5207630967215, 804.9051578764072, 813.5838069012533, 809.7358277657187, 804.7956386049835, 812.8051058870401, 813.4366716714791, 810.4045677739258, 808.152111799464, 813.9180133439412, 810.4739178941036, 805.6520184780555, 811.963876980493, 809.2088724696275, 805.8688386803371, 808.3845943120886, 813.198075316321, 801.8274212117914, 810.4895446480502, 804.035074019723, 806.4938281780343, 812.1433495707246, 809.2092997178172, 810.0682049988592, 813.4311327435968, 812.208100430735, 811.9352516834018, 806.153357477625, 796.0261933985631, 809.2419651527639, 803.06870867249, 805.5968213673341, 809.6827053762877, 810.9438035639712, 807.5417798017914, 806.7117061076098, 802.8917405264982, 808.265997246846, 811.6748288751103, 808.3673307948256, 810.9976400089777, 817.260791426579, 790.1644145910894, 818.5099893880747, 822.1435768803337, 808.7938996387538, 740.9524694779601, 839.4508959269663, 831.7751250981906, 833.904978015576, 836.2714674996073, 832.2827064228079, 829.1135154047286, 814.626384734525, 810.5237025941211, 825.2221817801119, 831.3943792450151, 692.5556090482812, 765.257930093076, 763.234585187337, 761.0672541897034, 828.7173128883878, 818.3098001642653, 802.3148467169799, 800.3567582280008, 824.711250133768, 824.7973679954426, 802.8741261849423, 764.993391178875, 766.2596967426106, 763.2701345574882, 759.995398175026, 759.1674144588751, 759.7207770633917, 744.9678471853166, 754.0185726658807, 755.2194361729654, 752.4702804387659, 816.7257207824099, 825.1879462261198, 826.7156187026928, 822.0448103761508, 819.4539267955691, 813.5977222843679, 814.7021844174277, 804.4254776714728, 827.1332149199119, 823.439609919974, 240.42254834628858, 822.6521041992804, 813.8635087379248, 809.8254955958417, 809.28323817703, 806.8651534873912, 800.6838513772225, 793.3088430039253, 803.7331648851418, 805.3131043036559, 369.23327467040906, 831.7836701221867, 833.5889989300293, 830.325109916239, 838.0665267887882, 834.7342625850821, 811.5224726722829, 799.9410794652623, 815.608687646283, 816.4843701304865, 787.9910156265416, 807.0342306338167, 814.0582933296719, 819.6903969512957, 815.2301384064157, 810.519273956949, 812.1773559680049, 817.3751605469415, 799.7128335420819, 804.3271739023662, 815.9866908921808, 804.180420732756, 809.0202837957091, 812.7263880453988, 810.9252982691339, 814.8506425132011, 810.3639447856274, 807.7326083235964, 803.0854026353038, 807.6455560500401, 816.597608530251, 795.5954222094132]
Elapsed: 0.05465352402389249~0.009923066000787486
Time per graph: 0.0012605458177790496~0.0002281297201103412
Speed: 803.5176313720177~59.61406485062122
Total Time: 0.0552
best val loss: 0.36875781416893005 test_score: 0.8140

Testing...
Test loss: 0.6123 score: 0.9070 time: 0.07s
test Score 0.9070
Epoch Time List: [0.1693561039865017, 0.16734645108226687, 0.16796225891448557, 0.16796781006269157, 0.16896327200811356, 0.16903425799682736, 0.1729934139875695, 0.16779766511172056, 0.16708074405323714, 0.28698095702566206, 0.1795014028903097, 0.180441256146878, 0.18046044511720538, 0.1799975250614807, 0.18174047605134547, 0.18176476401276886, 0.1811340191634372, 0.17901885497849435, 0.17863019194919616, 0.23985710996203125, 0.169497906928882, 0.17129224014934152, 0.16641444305423647, 0.16716931387782097, 0.16675634495913982, 0.16786151204723865, 0.16804075799882412, 0.1695880921324715, 0.16717001690994948, 0.16761679691262543, 0.26442258688621223, 0.18581364187411964, 0.1796168830478564, 0.16891609400045127, 0.168103989912197, 0.16792448388878256, 0.1663594781421125, 0.1830545050324872, 0.18173756904434413, 0.18290685897227377, 0.1820213319733739, 0.280726729077287, 0.17728690314106643, 0.17297155898995697, 0.1665343518834561, 0.16696050995960832, 0.16711985308211297, 0.16805569897405803, 0.1693274840945378, 0.1658047630917281, 0.16353903303388506, 0.30743979290127754, 0.17612704599741846, 0.17636339098680764, 0.17764286301098764, 0.17701782088261098, 0.17853250191546977, 0.1852696801070124, 0.1812716490821913, 0.17045548697933555, 0.23258531896863133, 0.2460017759585753, 0.1793978230562061, 0.17307644104585052, 0.16707798896823078, 0.1666552119422704, 0.16742642410099506, 0.16943088499829173, 0.1707886578515172, 0.16710314201191068, 0.16766056406777352, 0.28457572089973837, 0.17848186218179762, 0.18024890590459108, 0.18127747299149632, 0.18100732297170907, 0.18539051886182278, 0.18486536492127925, 0.1843906290596351, 0.17778556409757584, 0.17900698201265186, 0.23158326919656247, 0.17660819506272674, 0.1748082529520616, 0.17517003999091685, 0.17562346998602152, 0.17610822489950806, 0.17790659295860678, 0.17839546396862715, 0.17701481701806188, 0.17461727908812463, 0.29832737997639924, 0.16555594897363335, 0.1664872580440715, 0.16755682800430804, 0.16774164012167603, 0.16869402793236077, 0.1693783231312409, 0.16906843695323914, 0.16949558700434864, 0.16657601203769445, 0.16312495002057403, 0.1626480099512264, 0.30435283097904176, 0.17943979799747467, 0.17287575209047645, 0.1597127909772098, 0.16421720595099032, 0.164980539935641, 0.16002715681679547, 0.16668203403241932, 0.16442993900272995, 0.16184295690618455, 0.16099935804959387, 0.2567708040587604, 0.1622085189446807, 0.16299479000736028, 0.16387098806444556, 0.16497813595924526, 0.16584601299837232, 0.16058981092646718, 0.16183841705787927, 0.16396226698998362, 0.16467535600531846, 0.16643291793297976, 0.16582758910953999, 0.1650081560947001, 0.16582708992064, 0.16607219900470227, 0.16576886002440006, 0.16546255198772997, 0.1656409320421517, 0.16578650590963662, 0.16573784698266536, 0.16570552589837462, 0.16625829401891679, 0.16629180393647403, 0.16555554990191013, 0.16534019995015115, 0.16457034496124834, 0.16078074602410197, 0.16329969197977334, 0.1627874739933759, 0.16343488497659564, 0.16333569400012493, 0.1637033720035106, 0.16452942288015038, 0.164690992096439, 0.16406585206277668, 0.16448263404890895, 0.16443630203139037, 0.16414578806143254, 0.16366474807728082, 0.1638292910065502, 0.1649926631944254, 0.16556729411240667, 0.16514499904587865, 0.16553059790749103, 0.16465282207354903, 0.16593520995229483, 0.16668416804168373, 0.16767643811181188, 0.16731540695764124, 0.16601842001546174, 0.16644470591563731, 0.16585726314224303, 0.1645987619413063, 0.16508629301097244, 0.16537718917243183, 0.16579297196585685, 0.16610947297886014, 0.16699144814629108, 0.16592536494135857, 0.1658343099988997, 0.16517645388375968, 0.16593114903662354, 0.16636689298320562, 0.1662482999963686, 0.16702713805716485, 0.16723636304959655, 0.1654527799692005, 0.16665763000492007, 0.16686486708931625, 0.16539487789850682, 0.1663842749549076, 0.16762273106724024, 0.16664406610652804, 0.1662347010569647, 0.16693269496317953, 0.16742988908663392, 0.1668893020832911, 0.16769012296572328, 0.1669898061081767, 0.1670936110895127, 0.16671971301548183, 0.16652553610038012, 0.1657628370448947, 0.16685861896257848, 0.16712674510199577, 0.166577072115615, 0.16773606091737747, 0.16629856696818024, 0.1668716788990423, 0.16828750795684755, 0.1682352269999683, 0.16691766295116395, 0.16777145094238222, 0.16811946406960487, 0.16816599597223103, 0.16657337278593332, 0.1679536879528314, 0.1686727600172162, 0.16726214601658285, 0.16635336505714804, 0.16662993095815182, 0.1675920650595799, 0.16677012795116752, 0.1683424860239029, 0.16742456599604338, 0.1666585539933294, 0.16795691091101617, 0.16735222202260047, 0.1675584560725838, 0.1673145149834454, 0.1682838249253109, 0.167613536817953, 0.16847118001896888, 0.169601792935282, 0.16731894202530384, 0.16859005286823958, 0.16763825993984938, 0.16737497318536043, 0.16812779393512756, 0.16812165000010282, 0.168173092068173, 0.1690520429983735, 0.16748003894463181, 0.16873059619683772, 0.16907172312494367, 0.16943385696504265, 0.17010252398904413, 0.17062511411495507, 0.1681753540178761, 0.17009857401717454, 0.16778351494576782, 0.16824545513372868, 0.16824242495931685, 0.1688203359954059, 0.16856031701900065, 0.1701885738875717, 0.1671071118908003, 0.16535836004186422, 0.16480155114550143, 0.25507131090853363, 0.1660287369741127, 0.16271451709326357, 0.1598669149680063, 0.16128389292862266, 0.16194701509084553, 0.16381167282816023, 0.16370294603984803, 0.17194124311208725, 0.1648779670940712, 0.16432332014665008, 0.17198443703819066, 0.2847887980751693, 0.17589168611448258, 0.17752363125327975, 0.1641597601119429, 0.16702414606697857, 0.16824211494531482, 0.1700020730495453, 0.16626734496094286, 0.16398536588530988, 0.16505871806293726, 0.23998379986733198, 0.17628060898277909, 0.17532031307928264, 0.17527715500909835, 0.1762983340304345, 0.17711387190502137, 0.18198264192324132, 0.17992247000802308, 0.1784046902321279, 0.30682200205046684, 0.1723930719308555, 0.16616044600959867, 0.16567573510110378, 0.16387113300152123, 0.16447943192906678, 0.166422164067626, 0.16741851717233658, 0.16964551398996264, 0.16790444497019053, 0.16507157194428146, 0.2920971649000421, 0.16266257385723293, 0.16648802196141332, 0.16892943193670362, 0.16847226093523204, 0.17059760598931462, 0.17061116511467844, 0.1715737689519301, 0.1709433380747214, 0.1695980040822178, 0.24664986389689147, 0.16391311294864863, 0.16461668303236365, 0.16448998206760734, 0.16389232990331948, 0.16215272690169513, 0.16537517786491662, 0.17120869376230985, 0.16989214392378926, 0.16709813103079796, 0.16729974001646042, 0.291742101078853, 0.1661674837814644, 0.165165388956666, 0.1666803149273619, 0.1660338300280273, 0.16680278803687543, 0.16704141290392727, 0.1697204209631309, 0.16780111601110548, 0.1670443151379004, 0.1663161520846188, 0.2704929180908948, 0.1645210519200191, 0.1673393298406154, 0.1650805379031226, 0.16573984106071293, 0.1666637040907517, 0.17126614192966372, 0.16802191908936948, 0.1659872749587521, 0.16690298612229526]
Total Epoch List: [120, 107, 110]
Total Time List: [0.052817174000665545, 0.05425599601585418, 0.055247235926799476]
T-times Epoch Time: 0.1740827313092581 ~ 0.0013688158045441132
T-times Total Epoch: 111.33333333333333 ~ 1.4142135623730951
T-times Total Time: 0.05385198133687178 ~ 0.0003867996429865722
T-times Inference Elapsed: 0.054799063803412255 ~ 0.0003186981867818306
T-times Time Per Graph: 0.001264107507416861 ~ 7.264190031752418e-06
T-times Speed: 806.4466975609056 ~ 2.255064437140824
T-times cross validation test micro f1 score:0.8132728110669287 ~ 0.009482514865839512
T-times cross validation test precision:0.9131076850375096 ~ 0.020025245114954
T-times cross validation test recall:0.7472342472342471 ~ 0.031954871549211596
T-times cross validation test f1_score:0.8132728110669287 ~ 0.015765458322713508
