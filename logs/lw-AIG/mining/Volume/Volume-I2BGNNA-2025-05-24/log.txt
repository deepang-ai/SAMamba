Namespace(seed=15, model='I2BGNNA', dataset='mining/Volume', num_heads=8, num_layers=2, dim_hidden=64, dropout=0.1, epochs=1000, lr=0.0003, weight_decay=0.0001, batch_size=64, abs_pe=None, abs_pe_dim=20, num_class=2, outdir='./outdir/mining/Volume/seed15/khopgnn_gat_1_0.1_0.0003_0.0001_2_8_64_BN', warmup=10, layer_norm=False, use_edge_attr=False, edge_dim=128, gnn_type='gat', k_hop=1, global_pool='mean', se='khopgnn', ie='mamba', aggr='add', not_extract_node_feature=False, profile=False, k_ford=3, early_stop=1, early_stop_mindelta=-0.0, patience=20, training_times=3, Lambda=0.01, order='sd', use_cuda=True, batch_norm=True, save_logs=True)
Data(edge_index=[2, 132], edge_attr=[132, 2], x=[32, 14887], y=[1, 1], num_nodes=32)
Data(edge_index=[2, 132], edge_attr=[132, 2], x=[32, 14887], y=[1, 1], num_nodes=32)
Data(edge_index=[2, 124], edge_attr=[124, 2], x=[30, 14887], y=[1, 1], num_nodes=32)
========================training times:0========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a260b4f0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6883;  Loss pred: 0.6883; Loss self: 0.0000; time: 0.25s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6935 score: 0.5000 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6903;  Loss pred: 0.6903; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6857;  Loss pred: 0.6857; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6851;  Loss pred: 0.6851; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.5000 time: 0.07s
Epoch 8/1000, LR 0.000180
Train loss: 0.6817;  Loss pred: 0.6817; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6783;  Loss pred: 0.6783; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6741;  Loss pred: 0.6741; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6720;  Loss pred: 0.6720; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6682;  Loss pred: 0.6682; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6641;  Loss pred: 0.6641; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6573;  Loss pred: 0.6573; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6572;  Loss pred: 0.6572; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6492;  Loss pred: 0.6492; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6457;  Loss pred: 0.6457; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6390;  Loss pred: 0.6390; Loss self: 0.0000; time: 0.19s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6327;  Loss pred: 0.6327; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6228;  Loss pred: 0.6228; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6179;  Loss pred: 0.6179; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6071;  Loss pred: 0.6071; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.4884 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6024;  Loss pred: 0.6024; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5931;  Loss pred: 0.5931; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5862;  Loss pred: 0.5862; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5783;  Loss pred: 0.5783; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5682;  Loss pred: 0.5682; Loss self: 0.0000; time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.4884 time: 0.05s
Test loss: 0.6916 score: 0.5227 time: 0.04s
Epoch 28/1000, LR 0.000270
Train loss: 0.5586;  Loss pred: 0.5586; Loss self: 0.0000; time: 0.06s
Val loss: 0.6914 score: 0.6279 time: 0.05s
Test loss: 0.6914 score: 0.6136 time: 0.04s
Epoch 29/1000, LR 0.000270
Train loss: 0.5506;  Loss pred: 0.5506; Loss self: 0.0000; time: 0.06s
Val loss: 0.6910 score: 0.7442 time: 0.22s
Test loss: 0.6911 score: 0.7500 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5416;  Loss pred: 0.5416; Loss self: 0.0000; time: 0.06s
Val loss: 0.6906 score: 0.8140 time: 0.05s
Test loss: 0.6908 score: 0.8182 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5298;  Loss pred: 0.5298; Loss self: 0.0000; time: 0.06s
Val loss: 0.6902 score: 0.7674 time: 0.05s
Test loss: 0.6905 score: 0.7500 time: 0.04s
Epoch 32/1000, LR 0.000270
Train loss: 0.5180;  Loss pred: 0.5180; Loss self: 0.0000; time: 0.06s
Val loss: 0.6898 score: 0.7209 time: 0.05s
Test loss: 0.6901 score: 0.6364 time: 0.04s
Epoch 33/1000, LR 0.000270
Train loss: 0.5088;  Loss pred: 0.5088; Loss self: 0.0000; time: 0.06s
Val loss: 0.6893 score: 0.5814 time: 0.05s
Test loss: 0.6898 score: 0.6136 time: 0.04s
Epoch 34/1000, LR 0.000270
Train loss: 0.4999;  Loss pred: 0.4999; Loss self: 0.0000; time: 0.06s
Val loss: 0.6887 score: 0.6047 time: 0.05s
Test loss: 0.6893 score: 0.6136 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4884;  Loss pred: 0.4884; Loss self: 0.0000; time: 0.06s
Val loss: 0.6881 score: 0.5814 time: 0.05s
Test loss: 0.6888 score: 0.6136 time: 0.04s
Epoch 36/1000, LR 0.000270
Train loss: 0.4731;  Loss pred: 0.4731; Loss self: 0.0000; time: 0.06s
Val loss: 0.6874 score: 0.5814 time: 0.05s
Test loss: 0.6882 score: 0.5909 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4618;  Loss pred: 0.4618; Loss self: 0.0000; time: 0.06s
Val loss: 0.6866 score: 0.5814 time: 0.05s
Test loss: 0.6875 score: 0.5682 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4558;  Loss pred: 0.4558; Loss self: 0.0000; time: 0.06s
Val loss: 0.6856 score: 0.5814 time: 0.05s
Test loss: 0.6867 score: 0.5682 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4449;  Loss pred: 0.4449; Loss self: 0.0000; time: 0.06s
Val loss: 0.6845 score: 0.5814 time: 0.05s
Test loss: 0.6857 score: 0.5682 time: 0.04s
Epoch 40/1000, LR 0.000269
Train loss: 0.4245;  Loss pred: 0.4245; Loss self: 0.0000; time: 0.06s
Val loss: 0.6832 score: 0.5814 time: 0.05s
Test loss: 0.6846 score: 0.5682 time: 0.04s
Epoch 41/1000, LR 0.000269
Train loss: 0.4105;  Loss pred: 0.4105; Loss self: 0.0000; time: 0.06s
Val loss: 0.6817 score: 0.5814 time: 0.05s
Test loss: 0.6833 score: 0.5682 time: 0.04s
Epoch 42/1000, LR 0.000269
Train loss: 0.3963;  Loss pred: 0.3963; Loss self: 0.0000; time: 0.06s
Val loss: 0.6799 score: 0.5814 time: 0.05s
Test loss: 0.6818 score: 0.5682 time: 0.04s
Epoch 43/1000, LR 0.000269
Train loss: 0.3819;  Loss pred: 0.3819; Loss self: 0.0000; time: 0.06s
Val loss: 0.6779 score: 0.5814 time: 0.05s
Test loss: 0.6802 score: 0.5682 time: 0.04s
Epoch 44/1000, LR 0.000269
Train loss: 0.3766;  Loss pred: 0.3766; Loss self: 0.0000; time: 0.06s
Val loss: 0.6759 score: 0.5814 time: 0.05s
Test loss: 0.6784 score: 0.5909 time: 0.04s
Epoch 45/1000, LR 0.000269
Train loss: 0.3616;  Loss pred: 0.3616; Loss self: 0.0000; time: 0.06s
Val loss: 0.6737 score: 0.5814 time: 0.05s
Test loss: 0.6766 score: 0.5909 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3468;  Loss pred: 0.3468; Loss self: 0.0000; time: 0.06s
Val loss: 0.6713 score: 0.5814 time: 0.05s
Test loss: 0.6746 score: 0.5909 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3357;  Loss pred: 0.3357; Loss self: 0.0000; time: 0.06s
Val loss: 0.6687 score: 0.5814 time: 0.05s
Test loss: 0.6724 score: 0.5909 time: 0.04s
Epoch 48/1000, LR 0.000269
Train loss: 0.3150;  Loss pred: 0.3150; Loss self: 0.0000; time: 0.06s
Val loss: 0.6660 score: 0.6047 time: 0.05s
Test loss: 0.6701 score: 0.5909 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3032;  Loss pred: 0.3032; Loss self: 0.0000; time: 0.06s
Val loss: 0.6629 score: 0.6047 time: 0.05s
Test loss: 0.6674 score: 0.5909 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2983;  Loss pred: 0.2983; Loss self: 0.0000; time: 0.06s
Val loss: 0.6595 score: 0.6047 time: 0.05s
Test loss: 0.6646 score: 0.5909 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2748;  Loss pred: 0.2748; Loss self: 0.0000; time: 0.06s
Val loss: 0.6559 score: 0.6279 time: 0.05s
Test loss: 0.6615 score: 0.6136 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2658;  Loss pred: 0.2658; Loss self: 0.0000; time: 0.06s
Val loss: 0.6518 score: 0.6279 time: 0.05s
Test loss: 0.6580 score: 0.6364 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2450;  Loss pred: 0.2450; Loss self: 0.0000; time: 0.06s
Val loss: 0.6476 score: 0.6279 time: 0.05s
Test loss: 0.6544 score: 0.6818 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2374;  Loss pred: 0.2374; Loss self: 0.0000; time: 0.06s
Val loss: 0.6429 score: 0.6047 time: 0.05s
Test loss: 0.6505 score: 0.6818 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2172;  Loss pred: 0.2172; Loss self: 0.0000; time: 0.06s
Val loss: 0.6378 score: 0.6279 time: 0.05s
Test loss: 0.6461 score: 0.6818 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2169;  Loss pred: 0.2169; Loss self: 0.0000; time: 0.06s
Val loss: 0.6321 score: 0.6512 time: 0.05s
Test loss: 0.6412 score: 0.7045 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1962;  Loss pred: 0.1962; Loss self: 0.0000; time: 0.06s
Val loss: 0.6257 score: 0.6512 time: 0.05s
Test loss: 0.6357 score: 0.7045 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1875;  Loss pred: 0.1875; Loss self: 0.0000; time: 0.06s
Val loss: 0.6187 score: 0.6512 time: 0.05s
Test loss: 0.6298 score: 0.6818 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1743;  Loss pred: 0.1743; Loss self: 0.0000; time: 0.06s
Val loss: 0.6112 score: 0.7209 time: 0.05s
Test loss: 0.6234 score: 0.7727 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1669;  Loss pred: 0.1669; Loss self: 0.0000; time: 0.06s
Val loss: 0.6033 score: 0.7209 time: 0.05s
Test loss: 0.6168 score: 0.7500 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1572;  Loss pred: 0.1572; Loss self: 0.0000; time: 0.06s
Val loss: 0.5952 score: 0.7442 time: 0.05s
Test loss: 0.6101 score: 0.7727 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1450;  Loss pred: 0.1450; Loss self: 0.0000; time: 0.06s
Val loss: 0.5868 score: 0.7907 time: 0.05s
Test loss: 0.6031 score: 0.7727 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1399;  Loss pred: 0.1399; Loss self: 0.0000; time: 0.06s
Val loss: 0.5776 score: 0.7907 time: 0.05s
Test loss: 0.5955 score: 0.7500 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1281;  Loss pred: 0.1281; Loss self: 0.0000; time: 0.06s
Val loss: 0.5683 score: 0.8140 time: 0.05s
Test loss: 0.5878 score: 0.7273 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1155;  Loss pred: 0.1155; Loss self: 0.0000; time: 0.06s
Val loss: 0.5588 score: 0.8140 time: 0.05s
Test loss: 0.5801 score: 0.7273 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1064;  Loss pred: 0.1064; Loss self: 0.0000; time: 0.06s
Val loss: 0.5494 score: 0.8140 time: 0.05s
Test loss: 0.5723 score: 0.7273 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1065;  Loss pred: 0.1065; Loss self: 0.0000; time: 0.06s
Val loss: 0.5400 score: 0.8140 time: 0.05s
Test loss: 0.5647 score: 0.7273 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0896;  Loss pred: 0.0896; Loss self: 0.0000; time: 0.06s
Val loss: 0.5305 score: 0.8140 time: 0.06s
Test loss: 0.5570 score: 0.7273 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0832;  Loss pred: 0.0832; Loss self: 0.0000; time: 0.08s
Val loss: 0.5202 score: 0.8140 time: 0.06s
Test loss: 0.5488 score: 0.7273 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0755;  Loss pred: 0.0755; Loss self: 0.0000; time: 0.08s
Val loss: 0.5100 score: 0.8372 time: 0.05s
Test loss: 0.5407 score: 0.7500 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0689;  Loss pred: 0.0689; Loss self: 0.0000; time: 0.07s
Val loss: 0.4999 score: 0.8605 time: 0.05s
Test loss: 0.5328 score: 0.7500 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0679;  Loss pred: 0.0679; Loss self: 0.0000; time: 0.07s
Val loss: 0.4893 score: 0.9070 time: 0.05s
Test loss: 0.5248 score: 0.7500 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0622;  Loss pred: 0.0622; Loss self: 0.0000; time: 0.07s
Val loss: 0.4784 score: 0.9302 time: 0.05s
Test loss: 0.5168 score: 0.7045 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0512;  Loss pred: 0.0512; Loss self: 0.0000; time: 0.07s
Val loss: 0.4677 score: 0.9302 time: 0.05s
Test loss: 0.5093 score: 0.7045 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0521;  Loss pred: 0.0521; Loss self: 0.0000; time: 0.07s
Val loss: 0.4571 score: 0.9070 time: 0.05s
Test loss: 0.5021 score: 0.7500 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0446;  Loss pred: 0.0446; Loss self: 0.0000; time: 0.07s
Val loss: 0.4465 score: 0.8837 time: 0.05s
Test loss: 0.4952 score: 0.7500 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0445;  Loss pred: 0.0445; Loss self: 0.0000; time: 0.07s
Val loss: 0.4364 score: 0.8837 time: 0.05s
Test loss: 0.4889 score: 0.7727 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0396;  Loss pred: 0.0396; Loss self: 0.0000; time: 0.07s
Val loss: 0.4265 score: 0.8837 time: 0.05s
Test loss: 0.4828 score: 0.7727 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0362;  Loss pred: 0.0362; Loss self: 0.0000; time: 0.07s
Val loss: 0.4171 score: 0.8837 time: 0.05s
Test loss: 0.4770 score: 0.7727 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0327;  Loss pred: 0.0327; Loss self: 0.0000; time: 0.07s
Val loss: 0.4080 score: 0.8837 time: 0.05s
Test loss: 0.4718 score: 0.7727 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0298;  Loss pred: 0.0298; Loss self: 0.0000; time: 0.07s
Val loss: 0.3991 score: 0.8837 time: 0.05s
Test loss: 0.4671 score: 0.7727 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0259;  Loss pred: 0.0259; Loss self: 0.0000; time: 0.07s
Val loss: 0.3908 score: 0.8837 time: 0.05s
Test loss: 0.4630 score: 0.7500 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0280;  Loss pred: 0.0280; Loss self: 0.0000; time: 0.07s
Val loss: 0.3835 score: 0.8837 time: 0.05s
Test loss: 0.4596 score: 0.7727 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0240;  Loss pred: 0.0240; Loss self: 0.0000; time: 0.07s
Val loss: 0.3764 score: 0.8837 time: 0.05s
Test loss: 0.4568 score: 0.7727 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0224;  Loss pred: 0.0224; Loss self: 0.0000; time: 0.07s
Val loss: 0.3699 score: 0.8837 time: 0.05s
Test loss: 0.4542 score: 0.7727 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0198;  Loss pred: 0.0198; Loss self: 0.0000; time: 0.07s
Val loss: 0.3642 score: 0.8837 time: 0.05s
Test loss: 0.4526 score: 0.7727 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0209;  Loss pred: 0.0209; Loss self: 0.0000; time: 0.07s
Val loss: 0.3592 score: 0.8837 time: 0.05s
Test loss: 0.4517 score: 0.7727 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.07s
Val loss: 0.3547 score: 0.8837 time: 0.05s
Test loss: 0.4516 score: 0.7727 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0158;  Loss pred: 0.0158; Loss self: 0.0000; time: 0.07s
Val loss: 0.3509 score: 0.8837 time: 0.05s
Test loss: 0.4527 score: 0.7727 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0166;  Loss pred: 0.0166; Loss self: 0.0000; time: 0.07s
Val loss: 0.3473 score: 0.8837 time: 0.05s
Test loss: 0.4542 score: 0.7727 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0133;  Loss pred: 0.0133; Loss self: 0.0000; time: 0.07s
Val loss: 0.3437 score: 0.8837 time: 0.05s
Test loss: 0.4567 score: 0.7500 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0127;  Loss pred: 0.0127; Loss self: 0.0000; time: 0.07s
Val loss: 0.3404 score: 0.8837 time: 0.05s
Test loss: 0.4600 score: 0.7500 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.07s
Val loss: 0.3375 score: 0.8837 time: 0.05s
Test loss: 0.4638 score: 0.7273 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0106;  Loss pred: 0.0106; Loss self: 0.0000; time: 0.07s
Val loss: 0.3351 score: 0.8837 time: 0.05s
Test loss: 0.4678 score: 0.7500 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0112;  Loss pred: 0.0112; Loss self: 0.0000; time: 0.07s
Val loss: 0.3337 score: 0.8837 time: 0.05s
Test loss: 0.4730 score: 0.7500 time: 0.05s
Epoch 96/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.07s
Val loss: 0.3326 score: 0.9070 time: 0.05s
Test loss: 0.4788 score: 0.7500 time: 0.05s
Epoch 97/1000, LR 0.000265
Train loss: 0.0104;  Loss pred: 0.0104; Loss self: 0.0000; time: 0.07s
Val loss: 0.3321 score: 0.9070 time: 0.05s
Test loss: 0.4851 score: 0.7273 time: 0.05s
Epoch 98/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.3323 score: 0.9070 time: 0.05s
Test loss: 0.4919 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.07s
Val loss: 0.3327 score: 0.9070 time: 0.05s
Test loss: 0.4986 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.3336 score: 0.9070 time: 0.05s
Test loss: 0.5055 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.07s
Val loss: 0.3346 score: 0.9070 time: 0.05s
Test loss: 0.5105 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.07s
Val loss: 0.3358 score: 0.9070 time: 0.05s
Test loss: 0.5139 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0086;  Loss pred: 0.0086; Loss self: 0.0000; time: 0.07s
Val loss: 0.3381 score: 0.9070 time: 0.05s
Test loss: 0.5168 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.3409 score: 0.8837 time: 0.05s
Test loss: 0.5207 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.07s
Val loss: 0.3441 score: 0.8837 time: 0.05s
Test loss: 0.5253 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.07s
Val loss: 0.3477 score: 0.8837 time: 0.05s
Test loss: 0.5303 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.3520 score: 0.8837 time: 0.05s
Test loss: 0.5358 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.3567 score: 0.8837 time: 0.05s
Test loss: 0.5424 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.07s
Val loss: 0.3605 score: 0.8837 time: 0.05s
Test loss: 0.5483 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0049;  Loss pred: 0.0049; Loss self: 0.0000; time: 0.07s
Val loss: 0.3640 score: 0.8837 time: 0.05s
Test loss: 0.5551 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.07s
Val loss: 0.3673 score: 0.8837 time: 0.05s
Test loss: 0.5619 score: 0.7500 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.07s
Val loss: 0.3706 score: 0.8837 time: 0.05s
Test loss: 0.5687 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0039;  Loss pred: 0.0039; Loss self: 0.0000; time: 0.07s
Val loss: 0.3736 score: 0.8837 time: 0.05s
Test loss: 0.5755 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0041;  Loss pred: 0.0041; Loss self: 0.0000; time: 0.07s
Val loss: 0.3767 score: 0.8837 time: 0.05s
Test loss: 0.5823 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.07s
Val loss: 0.3796 score: 0.8837 time: 0.05s
Test loss: 0.5882 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 116/1000, LR 0.000263
Train loss: 0.0040;  Loss pred: 0.0040; Loss self: 0.0000; time: 0.07s
Val loss: 0.3818 score: 0.8837 time: 0.05s
Test loss: 0.5946 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 117/1000, LR 0.000262
Train loss: 0.0033;  Loss pred: 0.0033; Loss self: 0.0000; time: 0.07s
Val loss: 0.3841 score: 0.8837 time: 0.05s
Test loss: 0.6003 score: 0.7273 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 096,   Train_Loss: 0.0104,   Val_Loss: 0.3321,   Val_Precision: 0.9500,   Val_Recall: 0.8636,   Val_accuracy: 0.9048,   Val_Score: 0.9070,   Val_Loss: 0.3321,   Test_Precision: 0.8125,   Test_Recall: 0.5909,   Test_accuracy: 0.6842,   Test_Score: 0.7273,   Test_loss: 0.4851


[0.05775591207202524, 0.05359948589466512, 0.058479216997511685, 0.05361822503618896, 0.05360437708441168, 0.05346168705727905, 0.07194340403657407, 0.05354044702835381, 0.05369101802352816, 0.05352530092932284, 0.053370058070868254, 0.05982807790860534, 0.05314507195726037, 0.05429645499680191, 0.053897040081210434, 0.05420777597464621, 0.056658855988644063, 0.055614140001125634, 0.054045421071350574, 0.05444849201012403, 0.05424701806623489, 0.05262869398575276, 0.051000187057070434, 0.050600798917002976, 0.051715445006266236, 0.05019457300659269, 0.049281792948022485, 0.04935475590173155, 0.0514626819640398, 0.052954538026824594, 0.04963234392926097, 0.048351110075600445, 0.048638900043442845, 0.05031943810172379, 0.04953060601837933, 0.05786329403053969, 0.051811764016747475, 0.05019128299318254, 0.049652848043479025, 0.04913053894415498, 0.049621244077570736, 0.049457750050351024, 0.04937041597440839, 0.04934713302645832, 0.05011046503204852, 0.05027827003505081, 0.04997221694793552, 0.050276862108148634, 0.050727955996990204, 0.05080898990854621, 0.050731780007481575, 0.05091238999739289, 0.05080021300818771, 0.05070057697594166, 0.0506290050689131, 0.05079451994970441, 0.05046582093928009, 0.05052453500684351, 0.051319786929525435, 0.05090394010767341, 0.0503916519228369, 0.050938365049660206, 0.05171476199757308, 0.050810597953386605, 0.050811744993552566, 0.05028629908338189, 0.050570244900882244, 0.0613625809783116, 0.06158307800069451, 0.05481155798770487, 0.0530098540475592, 0.05195475497748703, 0.051354544004425406, 0.051855984958820045, 0.05159217503387481, 0.05322317103855312, 0.054429793963208795, 0.0518860180163756, 0.05140044307336211, 0.05162172205746174, 0.0527161048958078, 0.05294246401172131, 0.052234027069061995, 0.05160117009654641, 0.05165586096700281, 0.05351801810320467, 0.05355968093499541, 0.05183371505700052, 0.052106825984083116, 0.05362348596099764, 0.054190390976145864, 0.052865498000755906, 0.053682493045926094, 0.05305943498387933, 0.05257492407690734, 0.05298588192090392, 0.05437744501978159, 0.05520981003064662, 0.054550384054891765, 0.05408240493852645, 0.05453777499496937, 0.05421528092119843, 0.0555086019448936, 0.05406082095578313, 0.05444905301555991, 0.054887667996808887, 0.05531877209432423, 0.054384888033382595, 0.05542822799179703, 0.05501288699451834, 0.05421394994482398, 0.05387270206119865, 0.0542924830224365, 0.0545275789918378, 0.06009978405199945, 0.05916835996322334, 0.05394879204686731]
[0.001312634365273301, 0.001218170133969662, 0.001329073113579811, 0.0012185960235497491, 0.0012182812973729926, 0.0012150383422108875, 0.0016350773644675924, 0.0012168283415534956, 0.00122025040962564, 0.0012164841120300646, 0.0012129558652470057, 0.001359729043377394, 0.0012078425444831903, 0.001234010340836407, 0.001224932729118419, 0.0012319949085146866, 0.0012877012724691833, 0.00126395772729831, 0.0012283050243488767, 0.0012374657275028187, 0.001232886774232611, 0.0011961066814943808, 0.0011590951603879644, 0.001150018157204613, 0.001175351022869687, 0.0011407857501498338, 0.001120040748818693, 0.0011216989977666262, 0.0011696064082736318, 0.0012035122278823771, 0.001128007816574113, 0.0010988888653545555, 0.0011054295464418828, 0.0011436235932209952, 0.001125695591326803, 0.0013150748643304476, 0.0011775400912897153, 0.001140710977117785, 0.0011284738191699778, 0.0011166031578217041, 0.0011277555472175168, 0.0011240397738716142, 0.0011220549085092816, 0.0011215257506013256, 0.00113887420527383, 0.0011426879553420638, 0.001135732203362171, 0.001142655957003378, 0.0011529080908406865, 0.0011547497706487775, 0.0011529950001700358, 0.0011570997726680203, 0.0011545502956406299, 0.0011522858403623104, 0.0011506592061116614, 0.0011544209079478276, 0.0011469504758927294, 0.0011482848865191706, 0.0011663587938528508, 0.00115690772971985, 0.0011452648164281113, 0.0011576901147650046, 0.0011753354999448427, 0.0011547863171224228, 0.0011548123862171037, 0.0011428704337132249, 0.0011493237477473237, 0.0013946041131434454, 0.0013996154091066935, 0.0012457172269932926, 0.0012047694101718, 0.001180789885851978, 0.0011671487273733046, 0.0011785451127004555, 0.0011725494325880638, 0.0012096175236034799, 0.001237040771891109, 0.0011792276821903545, 0.001168191888030957, 0.0011732209558514032, 0.001198093293086541, 0.0012032378184482116, 0.001187136978842318, 0.0011727538658306003, 0.0011739968401591548, 0.0012163185932546514, 0.0012172654757953503, 0.0011780389785681937, 0.0011842460450927981, 0.0012187155900226737, 0.001231599794912406, 0.0012014885909262705, 0.0012200566601346839, 0.001205896249633621, 0.0011948846381115304, 0.0012042245891114528, 0.0012358510231768544, 0.0012547684097874233, 0.0012397814557929946, 0.0012291455667846922, 0.0012394948862493038, 0.0012321654754817825, 0.0012615591351112182, 0.001228655021722344, 0.0012374784776263616, 0.0012474469999274747, 0.0012572448203255508, 0.0012360201825768772, 0.0012597324543590234, 0.0012502928862390531, 0.0012321352260187268, 0.0012243795922999693, 0.0012339200686917386, 0.0012392631589054045, 0.0013659041829999876, 0.0013447354537096214, 0.0012261089101560753]
[761.8267710001575, 820.9033960973013, 752.4040549631884, 820.616496915046, 820.8284918732007, 823.0192951610045, 611.5918559765618, 821.8086034414056, 819.5039248598076, 822.0411513071086, 824.432305124606, 735.4406415532077, 827.9224842405915, 810.3659806628558, 816.3713616499557, 811.6916661657446, 776.5776281967071, 791.1656999300797, 814.1300248528244, 808.1031884559584, 811.1044914261755, 836.04582724229, 862.7419336866931, 869.5514881527896, 850.8096564704921, 876.5887896729577, 892.8246593302075, 891.5047637477286, 854.9884755471072, 830.9014041008422, 886.5186794867369, 910.010130712673, 904.6257205796284, 874.4135797194582, 888.3396254766783, 760.4129826548973, 849.2279858639357, 876.6462496281774, 886.15259212263, 895.5733225319045, 886.716986200844, 889.6482342040489, 891.2219824683634, 891.6424785287655, 878.0601012554856, 875.1295533701935, 880.489253575486, 875.1540600396517, 867.3718295018749, 865.988481156542, 867.306449596509, 864.2297091582842, 866.1381005018288, 867.8402224274251, 869.0670484262903, 866.2351774082679, 871.8772266271127, 870.8640266365685, 857.3691091200888, 864.3731684999235, 873.1605002228498, 863.7890116242259, 850.8208933082758, 865.9610745058617, 865.9415260307061, 874.9898243066505, 870.0768621200089, 717.0493694773311, 714.4819880471675, 802.7503981891906, 830.034354754575, 846.8907228812075, 856.788836372656, 848.5037944017715, 852.8425089872665, 826.7076001189001, 808.3807928749703, 848.0126570150995, 856.023749390648, 852.3543625883351, 834.659542600217, 831.0908987964467, 842.3627751661718, 852.6938423620137, 851.7910489984226, 822.1530161141238, 821.5134823786972, 848.8683466275583, 844.419117246568, 820.5359873843868, 811.9520676528873, 832.3008703969999, 819.634065101213, 829.258736233588, 836.9008757033331, 830.409882875634, 809.1590177507154, 796.9598152135621, 806.5937712871947, 813.5732878375737, 806.7802546777644, 811.5793048080619, 792.6699368807953, 813.898109982237, 808.0948623188381, 801.6372639944935, 795.3900336937241, 809.0482777677481, 793.8193515136669, 799.8125967172801, 811.5992294378258, 816.7401729732546, 810.425266087331, 806.9311129068527, 732.1157753567031, 743.6406895061588, 815.5882334079987]
Elapsed: 0.05295687122767966~0.003146428416569754
Time per graph: 0.0012035652551745375~7.15097367402217e-05
Speed: 833.4924130449624~44.60234533816648
Total Time: 0.0546
best val loss: 0.33210471272468567 test_score: 0.7273

Testing...
Test loss: 0.5168 score: 0.7045 time: 0.05s
test Score 0.7045
Epoch Time List: [0.35890098207164556, 0.16082897002343088, 0.16636574896983802, 0.16065964789595455, 0.1614601460751146, 0.16127869102638215, 0.24576117796823382, 0.1606318639824167, 0.16292597295250744, 0.16322241898160428, 0.16659043997060508, 0.16848912497516721, 0.1618235979694873, 0.16833637899253517, 0.1691056250128895, 0.16355837997980416, 0.16573192505165935, 0.2883282779948786, 0.16419883107300848, 0.16457441297825426, 0.1636042131576687, 0.16829396691173315, 0.15477779298089445, 0.15865328907966614, 0.1594326940830797, 0.15194046997930855, 0.1502665289444849, 0.15103698591701686, 0.32625001890119165, 0.1593839490087703, 0.1603139250073582, 0.1460407719714567, 0.14611548010725528, 0.1534580740844831, 0.1497112869983539, 0.15785658301319927, 0.1607895529596135, 0.15268008888233453, 0.15031242207624018, 0.15044066892005503, 0.15038914198521525, 0.1506671371171251, 0.1507208429975435, 0.1508489049738273, 0.15163708198815584, 0.1536174169741571, 0.15323511813767254, 0.1534463269636035, 0.15415604307781905, 0.1565780220553279, 0.15563324803952128, 0.1559544950723648, 0.1546470158500597, 0.15571379894390702, 0.15634406404569745, 0.15538087103050202, 0.15579770191106945, 0.15496027714107186, 0.15587609016802162, 0.15509353298693895, 0.15429107984527946, 0.15655685518868268, 0.15620486810803413, 0.1552270749816671, 0.1575823340099305, 0.15294350811745971, 0.1546233140397817, 0.17071180592756718, 0.1856070008361712, 0.17368701985105872, 0.16414544091094285, 0.16044963605236262, 0.1607903129188344, 0.1680959949735552, 0.16276724508497864, 0.16332835401408374, 0.16307869600132108, 0.16370383405592293, 0.16080276912543923, 0.16020175605081022, 0.16483162203803658, 0.16496506007388234, 0.1618539250921458, 0.16164659801870584, 0.16165050817653537, 0.16744064900558442, 0.16467659489717335, 0.164486585999839, 0.16351418499834836, 0.16494295198936015, 0.16682387795299292, 0.16699730802793056, 0.16865504498127848, 0.16700583696365356, 0.1647903029806912, 0.16587480914313346, 0.17005455994512886, 0.17114951310213655, 0.17061400704551488, 0.16905844793654978, 0.17007258301600814, 0.17078441800549626, 0.17214696598239243, 0.16950324713252485, 0.17167594702914357, 0.17142352310474962, 0.17159456200897694, 0.17134131700731814, 0.1713174021570012, 0.17205643095076084, 0.17060901201330125, 0.16871638188604265, 0.1699189339997247, 0.17125481297262013, 0.1746454609092325, 0.17561490007210523, 0.1690606219926849]
Total Epoch List: [117]
Total Time List: [0.05459188902750611]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a26ecd60>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6908;  Loss pred: 0.6908; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6907;  Loss pred: 0.6907; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6879;  Loss pred: 0.6879; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6912;  Loss pred: 0.6912; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6855;  Loss pred: 0.6855; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6821;  Loss pred: 0.6821; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6837;  Loss pred: 0.6837; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6771;  Loss pred: 0.6771; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6759;  Loss pred: 0.6759; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6704;  Loss pred: 0.6704; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6658;  Loss pred: 0.6658; Loss self: 0.0000; time: 0.07s
Val loss: 0.6930 score: 0.6818 time: 0.05s
Test loss: 0.6930 score: 0.6744 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6608;  Loss pred: 0.6608; Loss self: 0.0000; time: 0.07s
Val loss: 0.6929 score: 0.5227 time: 0.05s
Test loss: 0.6929 score: 0.5349 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6573;  Loss pred: 0.6573; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6517;  Loss pred: 0.6517; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6447;  Loss pred: 0.6447; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6388;  Loss pred: 0.6388; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6323;  Loss pred: 0.6323; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6281;  Loss pred: 0.6281; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6167;  Loss pred: 0.6167; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6125;  Loss pred: 0.6125; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6023;  Loss pred: 0.6023; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5936;  Loss pred: 0.5936; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5867;  Loss pred: 0.5867; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5745;  Loss pred: 0.5745; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6915 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6911 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5694;  Loss pred: 0.5694; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5546;  Loss pred: 0.5546; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5435;  Loss pred: 0.5435; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5272;  Loss pred: 0.5272; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6903 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5178;  Loss pred: 0.5178; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5039;  Loss pred: 0.5039; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6894 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.4898;  Loss pred: 0.4898; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6889 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6884 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.4788;  Loss pred: 0.4788; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6877 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4621;  Loss pred: 0.4621; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6877 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6871 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4422;  Loss pred: 0.4422; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4300;  Loss pred: 0.4300; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6862 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6856 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4165;  Loss pred: 0.4165; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6853 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6847 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4065;  Loss pred: 0.4065; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6844 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6837 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.3859;  Loss pred: 0.3859; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6832 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6826 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.3665;  Loss pred: 0.3665; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6819 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6813 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3548;  Loss pred: 0.3548; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6803 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6799 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3357;  Loss pred: 0.3357; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6786 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6783 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3229;  Loss pred: 0.3229; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6767 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6766 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.2997;  Loss pred: 0.2997; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6746 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6747 score: 0.5116 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.2900;  Loss pred: 0.2900; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6722 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6725 score: 0.5116 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.2730;  Loss pred: 0.2730; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6695 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6700 score: 0.5116 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.2616;  Loss pred: 0.2616; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6667 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6674 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.2431;  Loss pred: 0.2431; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6634 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6644 score: 0.5116 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2322;  Loss pred: 0.2322; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6599 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6612 score: 0.5116 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2170;  Loss pred: 0.2170; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6562 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6578 score: 0.5116 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2043;  Loss pred: 0.2043; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6520 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6540 score: 0.5116 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.1848;  Loss pred: 0.1848; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6476 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6500 score: 0.5116 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.1756;  Loss pred: 0.1756; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6426 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6455 score: 0.5116 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.1636;  Loss pred: 0.1636; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6372 score: 0.5000 time: 0.05s
Test loss: 0.6407 score: 0.5349 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.1551;  Loss pred: 0.1551; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6313 score: 0.5000 time: 0.05s
Test loss: 0.6355 score: 0.5349 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1494;  Loss pred: 0.1494; Loss self: 0.0000; time: 0.07s
Val loss: 0.6245 score: 0.5227 time: 0.05s
Test loss: 0.6295 score: 0.5349 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.1364;  Loss pred: 0.1364; Loss self: 0.0000; time: 0.09s
Val loss: 0.6172 score: 0.5227 time: 0.13s
Test loss: 0.6229 score: 0.5581 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1270;  Loss pred: 0.1270; Loss self: 0.0000; time: 0.07s
Val loss: 0.6091 score: 0.5455 time: 0.05s
Test loss: 0.6156 score: 0.5581 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1226;  Loss pred: 0.1226; Loss self: 0.0000; time: 0.07s
Val loss: 0.6012 score: 0.5682 time: 0.05s
Test loss: 0.6084 score: 0.5581 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1124;  Loss pred: 0.1124; Loss self: 0.0000; time: 0.07s
Val loss: 0.5922 score: 0.5682 time: 0.05s
Test loss: 0.6003 score: 0.6047 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1052;  Loss pred: 0.1052; Loss self: 0.0000; time: 0.07s
Val loss: 0.5834 score: 0.6136 time: 0.05s
Test loss: 0.5922 score: 0.6279 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.0984;  Loss pred: 0.0984; Loss self: 0.0000; time: 0.07s
Val loss: 0.5732 score: 0.6136 time: 0.05s
Test loss: 0.5830 score: 0.6279 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.0905;  Loss pred: 0.0905; Loss self: 0.0000; time: 0.07s
Val loss: 0.5637 score: 0.6364 time: 0.05s
Test loss: 0.5743 score: 0.6279 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.0863;  Loss pred: 0.0863; Loss self: 0.0000; time: 0.08s
Val loss: 0.5535 score: 0.6364 time: 0.05s
Test loss: 0.5648 score: 0.6279 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0789;  Loss pred: 0.0789; Loss self: 0.0000; time: 0.07s
Val loss: 0.5431 score: 0.6364 time: 0.05s
Test loss: 0.5551 score: 0.6512 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.0747;  Loss pred: 0.0747; Loss self: 0.0000; time: 0.07s
Val loss: 0.5325 score: 0.6364 time: 0.05s
Test loss: 0.5451 score: 0.6512 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.0715;  Loss pred: 0.0715; Loss self: 0.0000; time: 0.07s
Val loss: 0.5219 score: 0.7045 time: 0.05s
Test loss: 0.5350 score: 0.6744 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0668;  Loss pred: 0.0668; Loss self: 0.0000; time: 0.18s
Val loss: 0.5119 score: 0.7045 time: 0.05s
Test loss: 0.5255 score: 0.6744 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0680;  Loss pred: 0.0680; Loss self: 0.0000; time: 0.07s
Val loss: 0.5016 score: 0.7273 time: 0.05s
Test loss: 0.5157 score: 0.7209 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0608;  Loss pred: 0.0608; Loss self: 0.0000; time: 0.07s
Val loss: 0.4911 score: 0.7500 time: 0.05s
Test loss: 0.5057 score: 0.7209 time: 0.06s
Epoch 72/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.09s
Val loss: 0.4812 score: 0.7500 time: 0.06s
Test loss: 0.4963 score: 0.7209 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0549;  Loss pred: 0.0549; Loss self: 0.0000; time: 0.07s
Val loss: 0.4702 score: 0.7273 time: 0.05s
Test loss: 0.4857 score: 0.7209 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0514;  Loss pred: 0.0514; Loss self: 0.0000; time: 0.08s
Val loss: 0.4595 score: 0.7500 time: 0.05s
Test loss: 0.4755 score: 0.7442 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0484;  Loss pred: 0.0484; Loss self: 0.0000; time: 0.07s
Val loss: 0.4479 score: 0.7500 time: 0.05s
Test loss: 0.4642 score: 0.7674 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0473;  Loss pred: 0.0473; Loss self: 0.0000; time: 0.08s
Val loss: 0.4356 score: 0.7500 time: 0.05s
Test loss: 0.4522 score: 0.7674 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0419;  Loss pred: 0.0419; Loss self: 0.0000; time: 0.08s
Val loss: 0.4247 score: 0.7727 time: 0.05s
Test loss: 0.4415 score: 0.7674 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0435;  Loss pred: 0.0435; Loss self: 0.0000; time: 0.08s
Val loss: 0.4140 score: 0.7727 time: 0.05s
Test loss: 0.4310 score: 0.7674 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0428;  Loss pred: 0.0428; Loss self: 0.0000; time: 0.14s
Val loss: 0.4029 score: 0.7727 time: 0.07s
Test loss: 0.4198 score: 0.7907 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0336;  Loss pred: 0.0336; Loss self: 0.0000; time: 0.07s
Val loss: 0.3917 score: 0.7955 time: 0.05s
Test loss: 0.4084 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0342;  Loss pred: 0.0342; Loss self: 0.0000; time: 0.08s
Val loss: 0.3815 score: 0.7955 time: 0.05s
Test loss: 0.3977 score: 0.8372 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0333;  Loss pred: 0.0333; Loss self: 0.0000; time: 0.07s
Val loss: 0.3721 score: 0.8182 time: 0.05s
Test loss: 0.3875 score: 0.8372 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0290;  Loss pred: 0.0290; Loss self: 0.0000; time: 0.08s
Val loss: 0.3641 score: 0.8636 time: 0.05s
Test loss: 0.3787 score: 0.8605 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0262;  Loss pred: 0.0262; Loss self: 0.0000; time: 0.08s
Val loss: 0.3568 score: 0.8636 time: 0.05s
Test loss: 0.3703 score: 0.8837 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0298;  Loss pred: 0.0298; Loss self: 0.0000; time: 0.08s
Val loss: 0.3510 score: 0.8864 time: 0.05s
Test loss: 0.3631 score: 0.8837 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0274;  Loss pred: 0.0274; Loss self: 0.0000; time: 0.08s
Val loss: 0.3465 score: 0.8864 time: 0.05s
Test loss: 0.3570 score: 0.8837 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0277;  Loss pred: 0.0277; Loss self: 0.0000; time: 0.08s
Val loss: 0.3428 score: 0.8409 time: 0.05s
Test loss: 0.3510 score: 0.9070 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0223;  Loss pred: 0.0223; Loss self: 0.0000; time: 0.08s
Val loss: 0.3405 score: 0.8409 time: 0.05s
Test loss: 0.3456 score: 0.9070 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0200;  Loss pred: 0.0200; Loss self: 0.0000; time: 0.08s
Val loss: 0.3396 score: 0.8409 time: 0.05s
Test loss: 0.3412 score: 0.8837 time: 0.17s
Epoch 90/1000, LR 0.000266
Train loss: 0.0199;  Loss pred: 0.0199; Loss self: 0.0000; time: 0.07s
Val loss: 0.3404 score: 0.8409 time: 0.05s
Test loss: 0.3378 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.07s
Val loss: 0.3424 score: 0.8409 time: 0.05s
Test loss: 0.3355 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0167;  Loss pred: 0.0167; Loss self: 0.0000; time: 0.07s
Val loss: 0.3459 score: 0.8409 time: 0.05s
Test loss: 0.3343 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.07s
Val loss: 0.3506 score: 0.8409 time: 0.05s
Test loss: 0.3337 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0161;  Loss pred: 0.0161; Loss self: 0.0000; time: 0.07s
Val loss: 0.3564 score: 0.8409 time: 0.05s
Test loss: 0.3338 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0143;  Loss pred: 0.0143; Loss self: 0.0000; time: 0.08s
Val loss: 0.3636 score: 0.8409 time: 0.05s
Test loss: 0.3349 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.08s
Val loss: 0.3726 score: 0.8409 time: 0.05s
Test loss: 0.3376 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0128;  Loss pred: 0.0128; Loss self: 0.0000; time: 0.08s
Val loss: 0.3815 score: 0.8409 time: 0.05s
Test loss: 0.3407 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0137;  Loss pred: 0.0137; Loss self: 0.0000; time: 0.08s
Val loss: 0.3914 score: 0.8409 time: 0.05s
Test loss: 0.3447 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0127;  Loss pred: 0.0127; Loss self: 0.0000; time: 0.07s
Val loss: 0.4018 score: 0.8409 time: 0.05s
Test loss: 0.3492 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.20s
Val loss: 0.4122 score: 0.8409 time: 0.05s
Test loss: 0.3537 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.07s
Val loss: 0.4224 score: 0.8409 time: 0.05s
Test loss: 0.3584 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.07s
Val loss: 0.4334 score: 0.8409 time: 0.05s
Test loss: 0.3639 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.07s
Val loss: 0.4432 score: 0.8409 time: 0.05s
Test loss: 0.3688 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.07s
Val loss: 0.4528 score: 0.8409 time: 0.05s
Test loss: 0.3738 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.08s
Val loss: 0.4628 score: 0.8409 time: 0.05s
Test loss: 0.3793 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.08s
Val loss: 0.4730 score: 0.8409 time: 0.05s
Test loss: 0.3850 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.08s
Val loss: 0.4830 score: 0.8409 time: 0.05s
Test loss: 0.3905 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.08s
Val loss: 0.4926 score: 0.8409 time: 0.05s
Test loss: 0.3958 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.08s
Val loss: 0.5018 score: 0.8409 time: 0.16s
Test loss: 0.4007 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 088,   Train_Loss: 0.0200,   Val_Loss: 0.3396,   Val_Precision: 0.9412,   Val_Recall: 0.7273,   Val_accuracy: 0.8205,   Val_Score: 0.8409,   Val_Loss: 0.3396,   Test_Precision: 0.9048,   Test_Recall: 0.8636,   Test_accuracy: 0.8837,   Test_Score: 0.8837,   Test_loss: 0.3412


[0.05775591207202524, 0.05359948589466512, 0.058479216997511685, 0.05361822503618896, 0.05360437708441168, 0.05346168705727905, 0.07194340403657407, 0.05354044702835381, 0.05369101802352816, 0.05352530092932284, 0.053370058070868254, 0.05982807790860534, 0.05314507195726037, 0.05429645499680191, 0.053897040081210434, 0.05420777597464621, 0.056658855988644063, 0.055614140001125634, 0.054045421071350574, 0.05444849201012403, 0.05424701806623489, 0.05262869398575276, 0.051000187057070434, 0.050600798917002976, 0.051715445006266236, 0.05019457300659269, 0.049281792948022485, 0.04935475590173155, 0.0514626819640398, 0.052954538026824594, 0.04963234392926097, 0.048351110075600445, 0.048638900043442845, 0.05031943810172379, 0.04953060601837933, 0.05786329403053969, 0.051811764016747475, 0.05019128299318254, 0.049652848043479025, 0.04913053894415498, 0.049621244077570736, 0.049457750050351024, 0.04937041597440839, 0.04934713302645832, 0.05011046503204852, 0.05027827003505081, 0.04997221694793552, 0.050276862108148634, 0.050727955996990204, 0.05080898990854621, 0.050731780007481575, 0.05091238999739289, 0.05080021300818771, 0.05070057697594166, 0.0506290050689131, 0.05079451994970441, 0.05046582093928009, 0.05052453500684351, 0.051319786929525435, 0.05090394010767341, 0.0503916519228369, 0.050938365049660206, 0.05171476199757308, 0.050810597953386605, 0.050811744993552566, 0.05028629908338189, 0.050570244900882244, 0.0613625809783116, 0.06158307800069451, 0.05481155798770487, 0.0530098540475592, 0.05195475497748703, 0.051354544004425406, 0.051855984958820045, 0.05159217503387481, 0.05322317103855312, 0.054429793963208795, 0.0518860180163756, 0.05140044307336211, 0.05162172205746174, 0.0527161048958078, 0.05294246401172131, 0.052234027069061995, 0.05160117009654641, 0.05165586096700281, 0.05351801810320467, 0.05355968093499541, 0.05183371505700052, 0.052106825984083116, 0.05362348596099764, 0.054190390976145864, 0.052865498000755906, 0.053682493045926094, 0.05305943498387933, 0.05257492407690734, 0.05298588192090392, 0.05437744501978159, 0.05520981003064662, 0.054550384054891765, 0.05408240493852645, 0.05453777499496937, 0.05421528092119843, 0.0555086019448936, 0.05406082095578313, 0.05444905301555991, 0.054887667996808887, 0.05531877209432423, 0.054384888033382595, 0.05542822799179703, 0.05501288699451834, 0.05421394994482398, 0.05387270206119865, 0.0542924830224365, 0.0545275789918378, 0.06009978405199945, 0.05916835996322334, 0.05394879204686731, 0.05407370498869568, 0.053571533993817866, 0.05458223703317344, 0.055705277947708964, 0.05366932100150734, 0.053664433071389794, 0.0534320849692449, 0.05284168408252299, 0.05344905401580036, 0.053548756055533886, 0.05538983503356576, 0.05483476410154253, 0.054427111987024546, 0.05436625797301531, 0.05590093205682933, 0.05574353993870318, 0.05559063400141895, 0.05443549691699445, 0.054879168048501015, 0.055502975010313094, 0.05516633309889585, 0.05608291598036885, 0.05571976792998612, 0.05675233399961144, 0.055976629024371505, 0.056589637068100274, 0.05656610301230103, 0.05570142902433872, 0.05656223697587848, 0.05572343000676483, 0.055979682016186416, 0.05621137795969844, 0.05690049298573285, 0.05649693903978914, 0.056320114992558956, 0.05630762700457126, 0.05633364396635443, 0.05614445102401078, 0.05609320499934256, 0.05674717610236257, 0.055939794052392244, 0.0558538360055536, 0.056624497985467315, 0.056389026110991836, 0.05604862002655864, 0.05621725204400718, 0.05606035701930523, 0.055939760990440845, 0.055581443943083286, 0.05504307395312935, 0.055994360940530896, 0.05643053399398923, 0.056191695970483124, 0.05551775102503598, 0.05467254901304841, 0.05452210293151438, 0.056296969996765256, 0.05430228298064321, 0.054672165075317025, 0.05387045303359628, 0.054589121020399034, 0.05484581901691854, 0.054804671090096235, 0.05514049902558327, 0.05580507300328463, 0.05494451196864247, 0.05548016296233982, 0.06182254001032561, 0.055464185075834394, 0.05414158396888524, 0.07198656792752445, 0.055064729996956885, 0.055831480072811246, 0.056341432966291904, 0.05800697801169008, 0.05752694699913263, 0.0568748019868508, 0.05820183199830353, 0.05703747796360403, 0.055915214004926383, 0.05525913694873452, 0.05548601900227368, 0.055127414991147816, 0.056982898036949337, 0.05796898005064577, 0.05697246303316206, 0.056312279077246785, 0.05594885896425694, 0.17400268698111176, 0.055122236954048276, 0.05473537102807313, 0.05499452305957675, 0.05458216997794807, 0.055705334059894085, 0.05523016199003905, 0.0566660639597103, 0.055618211976252496, 0.0547816320322454, 0.054674273007549345, 0.054459860897623, 0.05463881301693618, 0.05516334599815309, 0.054783129948191345, 0.055030064075253904, 0.05799950996879488, 0.0558403879404068, 0.054824287071824074, 0.05563935299869627, 0.056147439987398684]
[0.001312634365273301, 0.001218170133969662, 0.001329073113579811, 0.0012185960235497491, 0.0012182812973729926, 0.0012150383422108875, 0.0016350773644675924, 0.0012168283415534956, 0.00122025040962564, 0.0012164841120300646, 0.0012129558652470057, 0.001359729043377394, 0.0012078425444831903, 0.001234010340836407, 0.001224932729118419, 0.0012319949085146866, 0.0012877012724691833, 0.00126395772729831, 0.0012283050243488767, 0.0012374657275028187, 0.001232886774232611, 0.0011961066814943808, 0.0011590951603879644, 0.001150018157204613, 0.001175351022869687, 0.0011407857501498338, 0.001120040748818693, 0.0011216989977666262, 0.0011696064082736318, 0.0012035122278823771, 0.001128007816574113, 0.0010988888653545555, 0.0011054295464418828, 0.0011436235932209952, 0.001125695591326803, 0.0013150748643304476, 0.0011775400912897153, 0.001140710977117785, 0.0011284738191699778, 0.0011166031578217041, 0.0011277555472175168, 0.0011240397738716142, 0.0011220549085092816, 0.0011215257506013256, 0.00113887420527383, 0.0011426879553420638, 0.001135732203362171, 0.001142655957003378, 0.0011529080908406865, 0.0011547497706487775, 0.0011529950001700358, 0.0011570997726680203, 0.0011545502956406299, 0.0011522858403623104, 0.0011506592061116614, 0.0011544209079478276, 0.0011469504758927294, 0.0011482848865191706, 0.0011663587938528508, 0.00115690772971985, 0.0011452648164281113, 0.0011576901147650046, 0.0011753354999448427, 0.0011547863171224228, 0.0011548123862171037, 0.0011428704337132249, 0.0011493237477473237, 0.0013946041131434454, 0.0013996154091066935, 0.0012457172269932926, 0.0012047694101718, 0.001180789885851978, 0.0011671487273733046, 0.0011785451127004555, 0.0011725494325880638, 0.0012096175236034799, 0.001237040771891109, 0.0011792276821903545, 0.001168191888030957, 0.0011732209558514032, 0.001198093293086541, 0.0012032378184482116, 0.001187136978842318, 0.0011727538658306003, 0.0011739968401591548, 0.0012163185932546514, 0.0012172654757953503, 0.0011780389785681937, 0.0011842460450927981, 0.0012187155900226737, 0.001231599794912406, 0.0012014885909262705, 0.0012200566601346839, 0.001205896249633621, 0.0011948846381115304, 0.0012042245891114528, 0.0012358510231768544, 0.0012547684097874233, 0.0012397814557929946, 0.0012291455667846922, 0.0012394948862493038, 0.0012321654754817825, 0.0012615591351112182, 0.001228655021722344, 0.0012374784776263616, 0.0012474469999274747, 0.0012572448203255508, 0.0012360201825768772, 0.0012597324543590234, 0.0012502928862390531, 0.0012321352260187268, 0.0012243795922999693, 0.0012339200686917386, 0.0012392631589054045, 0.0013659041829999876, 0.0013447354537096214, 0.0012261089101560753, 0.0012575280229929228, 0.0012458496277632063, 0.0012693543496086848, 0.0012954715801792782, 0.001248123744221101, 0.0012480100714276697, 0.0012426066271917417, 0.0012288763740121624, 0.0012430012561814037, 0.0012453199082682299, 0.0012881356984550177, 0.001275227072128896, 0.0012657467903959196, 0.0012643315807677978, 0.001300021675740217, 0.0012963613939233297, 0.0012928054418934638, 0.0012659417887673128, 0.0012762597220581631, 0.0012907668607049557, 0.0012829379790440896, 0.001304253860008578, 0.001295808556511305, 0.0013198217209211963, 0.0013017820703342211, 0.0013160380713511692, 0.0013154907677279308, 0.0012953820703334588, 0.0013154008599041507, 0.0012958937210875543, 0.00130185307014387, 0.0013072413478999636, 0.0013232672787379734, 0.0013138823032509102, 0.0013097701161060222, 0.001309479697780727, 0.0013100847434035915, 0.0013056849075351344, 0.0013044931395195943, 0.0013197017698223855, 0.0013009254430788894, 0.0012989264187338047, 0.001316848790359705, 0.001311372700255624, 0.00130345627968741, 0.0013073779545117949, 0.0013037292330070984, 0.0013009246741962988, 0.0012925917196065881, 0.001280071487282078, 0.0013021944404774627, 0.0013123379998602146, 0.0013067836272205378, 0.001291110488954325, 0.0012714546282104281, 0.0012679558821282414, 0.0013092318603898897, 0.0012628437902475166, 0.0012714456994259774, 0.0012528012333394482, 0.0012695144423348612, 0.001275484163184152, 0.0012745272346534008, 0.0012823371866414713, 0.0012977923954252241, 0.0012777793481079645, 0.0012902363479613912, 0.0014377334886122234, 0.001289864769205451, 0.0012591066039275638, 0.0016741062308726616, 0.0012805751162082997, 0.0012984065133211918, 0.001310265882937021, 0.0013489994886439554, 0.0013378359767240147, 0.001322669813647693, 0.0013535309767047333, 0.0013264529758977683, 0.0013003538140680553, 0.0012850962081101052, 0.001290372534936597, 0.0012820329067708795, 0.0013251836752778915, 0.0013481158151312969, 0.0013249410007712106, 0.0013095878855173672, 0.0013011362549827197, 0.004046574115839808, 0.0012819124873034483, 0.0012729156053040264, 0.001278942396734343, 0.0012693527901848389, 0.001295472885113816, 0.0012844223718613732, 0.0013178154409234954, 0.001293446790145407, 0.001273991442610358, 0.0012714947211057987, 0.001266508392967977, 0.0012706700701613067, 0.0012828685115849555, 0.001274026277864915, 0.001279768931982649, 0.001348825813227788, 0.0012986136730327163, 0.0012749834202749784, 0.0012939384418301457, 0.0013057544183115973]
[761.8267710001575, 820.9033960973013, 752.4040549631884, 820.616496915046, 820.8284918732007, 823.0192951610045, 611.5918559765618, 821.8086034414056, 819.5039248598076, 822.0411513071086, 824.432305124606, 735.4406415532077, 827.9224842405915, 810.3659806628558, 816.3713616499557, 811.6916661657446, 776.5776281967071, 791.1656999300797, 814.1300248528244, 808.1031884559584, 811.1044914261755, 836.04582724229, 862.7419336866931, 869.5514881527896, 850.8096564704921, 876.5887896729577, 892.8246593302075, 891.5047637477286, 854.9884755471072, 830.9014041008422, 886.5186794867369, 910.010130712673, 904.6257205796284, 874.4135797194582, 888.3396254766783, 760.4129826548973, 849.2279858639357, 876.6462496281774, 886.15259212263, 895.5733225319045, 886.716986200844, 889.6482342040489, 891.2219824683634, 891.6424785287655, 878.0601012554856, 875.1295533701935, 880.489253575486, 875.1540600396517, 867.3718295018749, 865.988481156542, 867.306449596509, 864.2297091582842, 866.1381005018288, 867.8402224274251, 869.0670484262903, 866.2351774082679, 871.8772266271127, 870.8640266365685, 857.3691091200888, 864.3731684999235, 873.1605002228498, 863.7890116242259, 850.8208933082758, 865.9610745058617, 865.9415260307061, 874.9898243066505, 870.0768621200089, 717.0493694773311, 714.4819880471675, 802.7503981891906, 830.034354754575, 846.8907228812075, 856.788836372656, 848.5037944017715, 852.8425089872665, 826.7076001189001, 808.3807928749703, 848.0126570150995, 856.023749390648, 852.3543625883351, 834.659542600217, 831.0908987964467, 842.3627751661718, 852.6938423620137, 851.7910489984226, 822.1530161141238, 821.5134823786972, 848.8683466275583, 844.419117246568, 820.5359873843868, 811.9520676528873, 832.3008703969999, 819.634065101213, 829.258736233588, 836.9008757033331, 830.409882875634, 809.1590177507154, 796.9598152135621, 806.5937712871947, 813.5732878375737, 806.7802546777644, 811.5793048080619, 792.6699368807953, 813.898109982237, 808.0948623188381, 801.6372639944935, 795.3900336937241, 809.0482777677481, 793.8193515136669, 799.8125967172801, 811.5992294378258, 816.7401729732546, 810.425266087331, 806.9311129068527, 732.1157753567031, 743.6406895061588, 815.5882334079987, 795.2109072050698, 802.6650871144027, 787.8020824589123, 771.9196741171362, 801.2026088198938, 801.2755849446337, 804.7599120406863, 813.7515059672737, 804.5044162482004, 803.006515322334, 776.315726052305, 784.1740673922292, 790.0474309614522, 790.931758101561, 769.2179435628346, 771.3898336432122, 773.5115954767206, 789.9257366120534, 783.5395748346173, 774.7332461369882, 779.460906399462, 766.7219018185793, 771.7189356213945, 757.6780895089602, 768.177733269332, 759.8564371115081, 760.1725717369835, 771.9730131377987, 760.2245296333979, 771.6682191814072, 768.1358387774807, 764.9696833767262, 755.7052275589556, 761.1031806469437, 763.4927593042235, 763.662087846627, 763.3094004300872, 765.88156470905, 766.581264174582, 757.7469568253947, 768.6835593232064, 769.8665494653665, 759.3886308896894, 762.5597206690908, 767.191056258378, 764.889752461386, 767.0304344510739, 768.6840136365254, 773.6394909789141, 781.2063700623924, 767.9344719313499, 761.9988144110101, 765.2376255485761, 774.5270513679302, 786.5007353093673, 788.6709735685107, 763.8066489630031, 791.8635762575201, 786.506258546057, 798.211219296468, 787.7027363003633, 784.0160065206719, 784.6046540323191, 779.8260944292416, 770.5392661607855, 782.6077338632226, 775.0517969672978, 695.5391996643641, 775.2750705920854, 794.2139266688572, 597.3336587360587, 780.899134570829, 770.1748179328689, 763.2038756580108, 741.2901253248232, 747.4757873149141, 756.0465882578617, 738.8083591810883, 753.8902759241663, 769.0214687582436, 778.1518564050742, 774.9699973652456, 780.0111796808321, 754.6123746131265, 741.7760319817976, 754.7505884548281, 763.5990001579306, 768.5590161449163, 247.12262061026513, 780.0844518673331, 785.5980363766203, 781.8960436008723, 787.8030502886305, 771.9188965596477, 778.5600919974705, 758.8316003485454, 773.1280541409684, 784.9346287217122, 786.475935291588, 789.5723435804224, 786.9863495510317, 779.5031142860637, 784.9131665289168, 781.3910581895248, 741.3855741735581, 770.0519567645172, 784.3239246078414, 772.8342923219752, 765.8407936256863]
Elapsed: 0.05483464303218339~0.008489088135681501
Time per graph: 0.0012607339154577098~0.00020077730240052388
Speed: 801.4700946585524~60.014507091037515
Total Time: 0.0570
best val loss: 0.3396272361278534 test_score: 0.8837

Testing...
Test loss: 0.3631 score: 0.8837 time: 0.05s
test Score 0.8837
Epoch Time List: [0.35890098207164556, 0.16082897002343088, 0.16636574896983802, 0.16065964789595455, 0.1614601460751146, 0.16127869102638215, 0.24576117796823382, 0.1606318639824167, 0.16292597295250744, 0.16322241898160428, 0.16659043997060508, 0.16848912497516721, 0.1618235979694873, 0.16833637899253517, 0.1691056250128895, 0.16355837997980416, 0.16573192505165935, 0.2883282779948786, 0.16419883107300848, 0.16457441297825426, 0.1636042131576687, 0.16829396691173315, 0.15477779298089445, 0.15865328907966614, 0.1594326940830797, 0.15194046997930855, 0.1502665289444849, 0.15103698591701686, 0.32625001890119165, 0.1593839490087703, 0.1603139250073582, 0.1460407719714567, 0.14611548010725528, 0.1534580740844831, 0.1497112869983539, 0.15785658301319927, 0.1607895529596135, 0.15268008888233453, 0.15031242207624018, 0.15044066892005503, 0.15038914198521525, 0.1506671371171251, 0.1507208429975435, 0.1508489049738273, 0.15163708198815584, 0.1536174169741571, 0.15323511813767254, 0.1534463269636035, 0.15415604307781905, 0.1565780220553279, 0.15563324803952128, 0.1559544950723648, 0.1546470158500597, 0.15571379894390702, 0.15634406404569745, 0.15538087103050202, 0.15579770191106945, 0.15496027714107186, 0.15587609016802162, 0.15509353298693895, 0.15429107984527946, 0.15655685518868268, 0.15620486810803413, 0.1552270749816671, 0.1575823340099305, 0.15294350811745971, 0.1546233140397817, 0.17071180592756718, 0.1856070008361712, 0.17368701985105872, 0.16414544091094285, 0.16044963605236262, 0.1607903129188344, 0.1680959949735552, 0.16276724508497864, 0.16332835401408374, 0.16307869600132108, 0.16370383405592293, 0.16080276912543923, 0.16020175605081022, 0.16483162203803658, 0.16496506007388234, 0.1618539250921458, 0.16164659801870584, 0.16165050817653537, 0.16744064900558442, 0.16467659489717335, 0.164486585999839, 0.16351418499834836, 0.16494295198936015, 0.16682387795299292, 0.16699730802793056, 0.16865504498127848, 0.16700583696365356, 0.1647903029806912, 0.16587480914313346, 0.17005455994512886, 0.17114951310213655, 0.17061400704551488, 0.16905844793654978, 0.17007258301600814, 0.17078441800549626, 0.17214696598239243, 0.16950324713252485, 0.17167594702914357, 0.17142352310474962, 0.17159456200897694, 0.17134131700731814, 0.1713174021570012, 0.17205643095076084, 0.17060901201330125, 0.16871638188604265, 0.1699189339997247, 0.17125481297262013, 0.1746454609092325, 0.17561490007210523, 0.1690606219926849, 0.1716832099482417, 0.1676314331125468, 0.1710571520961821, 0.17077979701571167, 0.1671042658854276, 0.16934680799022317, 0.16671776992734522, 0.16662407713010907, 0.16845533100422472, 0.16724878014065325, 0.1696370649151504, 0.16991343791596591, 0.17111712007317692, 0.17051683005411178, 0.17292274988722056, 0.17374916188418865, 0.1748663019388914, 0.17042893101461232, 0.1726187509484589, 0.17267771891783923, 0.17367515992373228, 0.17493835790082812, 0.17472467420157045, 0.17487886804156005, 0.17328545299824327, 0.17455522809177637, 0.17713827302213758, 0.1743362011620775, 0.1740123899653554, 0.1733863370027393, 0.17633222788572311, 0.17544041306246072, 0.17663133703172207, 0.17517400498036295, 0.17563873808830976, 0.17671078606508672, 0.17532745597418398, 0.17496259789913893, 0.17559363297186792, 0.1749391461489722, 0.17434989695902914, 0.17639759799931198, 0.17652683204505593, 0.17725964996498078, 0.17524755711201578, 0.17480506584979594, 0.1763786340598017, 0.17525423096958548, 0.17379264207556844, 0.17361263581551611, 0.17355987301561981, 0.17535355302970856, 0.1773257169406861, 0.17605229222681373, 0.17336334707215428, 0.17103395599406213, 0.17169920704327524, 0.2633961980463937, 0.17203844001051039, 0.16873078304342926, 0.17096674698404968, 0.17137467407155782, 0.17057727195788175, 0.1725856369594112, 0.17720172298140824, 0.17243531008716673, 0.17294665705412626, 0.1778205280425027, 0.2789942149538547, 0.17209707107394934, 0.18279143807012588, 0.20523500815033913, 0.17259487393312156, 0.1766542779514566, 0.1777146439999342, 0.1798663609661162, 0.17913465097080916, 0.18011458904948086, 0.2538916760822758, 0.1756726821186021, 0.17539548699278384, 0.17264850111678243, 0.1751579298870638, 0.1769987849984318, 0.17823807103559375, 0.18203981593251228, 0.1795184969669208, 0.17858729301951826, 0.29568888095673174, 0.17325244203675538, 0.17279410199262202, 0.1729202379938215, 0.17321936693042517, 0.17407596099656075, 0.17563028598669916, 0.1809167789760977, 0.17536515602841973, 0.17384780698921531, 0.17251833307091147, 0.30118115979712456, 0.17032224603462964, 0.17190127715002745, 0.17155589303001761, 0.1730565361212939, 0.17796276498120278, 0.1793932159198448, 0.1757605461170897, 0.1739935229998082, 0.2888692191336304]
Total Epoch List: [117, 109]
Total Time List: [0.05459188902750611, 0.056990524055436254]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a26ec820>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6952;  Loss pred: 0.6952; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.15s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6963;  Loss pred: 0.6963; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6964;  Loss pred: 0.6964; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6938;  Loss pred: 0.6938; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6942;  Loss pred: 0.6942; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6922;  Loss pred: 0.6922; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6897;  Loss pred: 0.6897; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6892;  Loss pred: 0.6892; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6892;  Loss pred: 0.6892; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6848;  Loss pred: 0.6848; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6815;  Loss pred: 0.6815; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.08s
Epoch 12/1000, LR 0.000270
Train loss: 0.6776;  Loss pred: 0.6776; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6768;  Loss pred: 0.6768; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6749;  Loss pred: 0.6749; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6681;  Loss pred: 0.6681; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6673;  Loss pred: 0.6673; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6607;  Loss pred: 0.6607; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6568;  Loss pred: 0.6568; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6500;  Loss pred: 0.6500; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6450;  Loss pred: 0.6450; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6430;  Loss pred: 0.6430; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.10s
Epoch 22/1000, LR 0.000270
Train loss: 0.6339;  Loss pred: 0.6339; Loss self: 0.0000; time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6269;  Loss pred: 0.6269; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6222;  Loss pred: 0.6222; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6166;  Loss pred: 0.6166; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6081;  Loss pred: 0.6081; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6921 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5982;  Loss pred: 0.5982; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6919 score: 0.5116 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5890;  Loss pred: 0.5890; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5845;  Loss pred: 0.5845; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6920 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6915 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5672;  Loss pred: 0.5672; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6918 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5596;  Loss pred: 0.5596; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5116 time: 0.18s
Epoch 32/1000, LR 0.000270
Train loss: 0.5599;  Loss pred: 0.5599; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5389;  Loss pred: 0.5389; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6909 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5286;  Loss pred: 0.5286; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6905 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6896 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5234;  Loss pred: 0.5234; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6899 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5098;  Loss pred: 0.5098; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6880 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4995;  Loss pred: 0.4995; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6885 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6872 score: 0.5116 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4899;  Loss pred: 0.4899; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6878 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6863 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4757;  Loss pred: 0.4757; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6869 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6852 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4621;  Loss pred: 0.4621; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6840 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4472;  Loss pred: 0.4472; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6849 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6826 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4352;  Loss pred: 0.4352; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6838 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6811 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4236;  Loss pred: 0.4236; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6795 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4154;  Loss pred: 0.4154; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6777 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.4078;  Loss pred: 0.4078; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6792 score: 0.5000 time: 0.05s
Test loss: 0.6756 score: 0.5349 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3768;  Loss pred: 0.3768; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6775 score: 0.5000 time: 0.05s
Test loss: 0.6734 score: 0.5349 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3705;  Loss pred: 0.3705; Loss self: 0.0000; time: 0.08s
Val loss: 0.6755 score: 0.5227 time: 0.05s
Test loss: 0.6709 score: 0.5349 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3548;  Loss pred: 0.3548; Loss self: 0.0000; time: 0.08s
Val loss: 0.6733 score: 0.5455 time: 0.05s
Test loss: 0.6681 score: 0.5581 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3404;  Loss pred: 0.3404; Loss self: 0.0000; time: 0.09s
Val loss: 0.6709 score: 0.5455 time: 0.05s
Test loss: 0.6651 score: 0.5814 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3216;  Loss pred: 0.3216; Loss self: 0.0000; time: 0.08s
Val loss: 0.6682 score: 0.5682 time: 0.05s
Test loss: 0.6619 score: 0.6279 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3112;  Loss pred: 0.3112; Loss self: 0.0000; time: 0.08s
Val loss: 0.6654 score: 0.5909 time: 0.05s
Test loss: 0.6584 score: 0.6744 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.3021;  Loss pred: 0.3021; Loss self: 0.0000; time: 0.09s
Val loss: 0.6623 score: 0.5909 time: 0.15s
Test loss: 0.6545 score: 0.6977 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2862;  Loss pred: 0.2862; Loss self: 0.0000; time: 0.08s
Val loss: 0.6588 score: 0.6136 time: 0.05s
Test loss: 0.6503 score: 0.7209 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2689;  Loss pred: 0.2689; Loss self: 0.0000; time: 0.08s
Val loss: 0.6552 score: 0.6364 time: 0.05s
Test loss: 0.6458 score: 0.7674 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2456;  Loss pred: 0.2456; Loss self: 0.0000; time: 0.08s
Val loss: 0.6513 score: 0.6364 time: 0.05s
Test loss: 0.6410 score: 0.7907 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2327;  Loss pred: 0.2327; Loss self: 0.0000; time: 0.08s
Val loss: 0.6469 score: 0.6364 time: 0.05s
Test loss: 0.6358 score: 0.7907 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2268;  Loss pred: 0.2268; Loss self: 0.0000; time: 0.08s
Val loss: 0.6422 score: 0.6591 time: 0.05s
Test loss: 0.6303 score: 0.8140 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2164;  Loss pred: 0.2164; Loss self: 0.0000; time: 0.08s
Val loss: 0.6373 score: 0.6591 time: 0.05s
Test loss: 0.6244 score: 0.8140 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1973;  Loss pred: 0.1973; Loss self: 0.0000; time: 0.08s
Val loss: 0.6321 score: 0.6591 time: 0.05s
Test loss: 0.6182 score: 0.8140 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1868;  Loss pred: 0.1868; Loss self: 0.0000; time: 0.08s
Val loss: 0.6266 score: 0.6818 time: 0.05s
Test loss: 0.6114 score: 0.8140 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1772;  Loss pred: 0.1772; Loss self: 0.0000; time: 0.08s
Val loss: 0.6206 score: 0.6818 time: 0.05s
Test loss: 0.6042 score: 0.8140 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1590;  Loss pred: 0.1590; Loss self: 0.0000; time: 0.21s
Val loss: 0.6139 score: 0.6818 time: 0.05s
Test loss: 0.5962 score: 0.8140 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1470;  Loss pred: 0.1470; Loss self: 0.0000; time: 0.08s
Val loss: 0.6070 score: 0.6818 time: 0.05s
Test loss: 0.5878 score: 0.8140 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1378;  Loss pred: 0.1378; Loss self: 0.0000; time: 0.08s
Val loss: 0.5998 score: 0.6818 time: 0.05s
Test loss: 0.5788 score: 0.8140 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1298;  Loss pred: 0.1298; Loss self: 0.0000; time: 0.08s
Val loss: 0.5921 score: 0.6818 time: 0.05s
Test loss: 0.5691 score: 0.8140 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1193;  Loss pred: 0.1193; Loss self: 0.0000; time: 0.08s
Val loss: 0.5844 score: 0.6818 time: 0.05s
Test loss: 0.5589 score: 0.8140 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1020;  Loss pred: 0.1020; Loss self: 0.0000; time: 0.08s
Val loss: 0.5764 score: 0.7045 time: 0.05s
Test loss: 0.5482 score: 0.8372 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1004;  Loss pred: 0.1004; Loss self: 0.0000; time: 0.09s
Val loss: 0.5686 score: 0.7045 time: 0.05s
Test loss: 0.5374 score: 0.8372 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0921;  Loss pred: 0.0921; Loss self: 0.0000; time: 0.08s
Val loss: 0.5610 score: 0.7045 time: 0.05s
Test loss: 0.5266 score: 0.8372 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0776;  Loss pred: 0.0776; Loss self: 0.0000; time: 0.08s
Val loss: 0.5540 score: 0.7045 time: 0.05s
Test loss: 0.5161 score: 0.8372 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0732;  Loss pred: 0.0732; Loss self: 0.0000; time: 0.08s
Val loss: 0.5470 score: 0.7045 time: 0.05s
Test loss: 0.5053 score: 0.8372 time: 0.09s
Epoch 72/1000, LR 0.000267
Train loss: 0.0719;  Loss pred: 0.0719; Loss self: 0.0000; time: 0.12s
Val loss: 0.5403 score: 0.7045 time: 0.05s
Test loss: 0.4945 score: 0.8372 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0605;  Loss pred: 0.0605; Loss self: 0.0000; time: 0.08s
Val loss: 0.5336 score: 0.7045 time: 0.05s
Test loss: 0.4838 score: 0.8372 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0573;  Loss pred: 0.0573; Loss self: 0.0000; time: 0.08s
Val loss: 0.5272 score: 0.7045 time: 0.05s
Test loss: 0.4735 score: 0.8372 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0537;  Loss pred: 0.0537; Loss self: 0.0000; time: 0.08s
Val loss: 0.5208 score: 0.7045 time: 0.05s
Test loss: 0.4631 score: 0.8372 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0463;  Loss pred: 0.0463; Loss self: 0.0000; time: 0.08s
Val loss: 0.5142 score: 0.7045 time: 0.05s
Test loss: 0.4527 score: 0.8372 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0442;  Loss pred: 0.0442; Loss self: 0.0000; time: 0.08s
Val loss: 0.5069 score: 0.7045 time: 0.05s
Test loss: 0.4422 score: 0.8605 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0408;  Loss pred: 0.0408; Loss self: 0.0000; time: 0.08s
Val loss: 0.4996 score: 0.7045 time: 0.05s
Test loss: 0.4322 score: 0.8837 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0367;  Loss pred: 0.0367; Loss self: 0.0000; time: 0.08s
Val loss: 0.4917 score: 0.7045 time: 0.05s
Test loss: 0.4220 score: 0.8837 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0344;  Loss pred: 0.0344; Loss self: 0.0000; time: 0.08s
Val loss: 0.4854 score: 0.7045 time: 0.05s
Test loss: 0.4133 score: 0.8837 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0311;  Loss pred: 0.0311; Loss self: 0.0000; time: 0.08s
Val loss: 0.4811 score: 0.7045 time: 0.05s
Test loss: 0.4064 score: 0.8837 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0273;  Loss pred: 0.0273; Loss self: 0.0000; time: 0.19s
Val loss: 0.4763 score: 0.7045 time: 0.05s
Test loss: 0.3997 score: 0.8837 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0260;  Loss pred: 0.0260; Loss self: 0.0000; time: 0.08s
Val loss: 0.4720 score: 0.7500 time: 0.05s
Test loss: 0.3938 score: 0.8837 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0239;  Loss pred: 0.0239; Loss self: 0.0000; time: 0.08s
Val loss: 0.4676 score: 0.7727 time: 0.05s
Test loss: 0.3885 score: 0.8837 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0201;  Loss pred: 0.0201; Loss self: 0.0000; time: 0.08s
Val loss: 0.4647 score: 0.7727 time: 0.05s
Test loss: 0.3846 score: 0.8837 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0212;  Loss pred: 0.0212; Loss self: 0.0000; time: 0.08s
Val loss: 0.4621 score: 0.7727 time: 0.05s
Test loss: 0.3814 score: 0.8837 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0189;  Loss pred: 0.0189; Loss self: 0.0000; time: 0.08s
Val loss: 0.4604 score: 0.7727 time: 0.05s
Test loss: 0.3793 score: 0.8837 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0169;  Loss pred: 0.0169; Loss self: 0.0000; time: 0.08s
Val loss: 0.4570 score: 0.7727 time: 0.05s
Test loss: 0.3770 score: 0.8605 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0167;  Loss pred: 0.0167; Loss self: 0.0000; time: 0.08s
Val loss: 0.4531 score: 0.7955 time: 0.05s
Test loss: 0.3753 score: 0.8605 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0145;  Loss pred: 0.0145; Loss self: 0.0000; time: 0.08s
Val loss: 0.4517 score: 0.7955 time: 0.05s
Test loss: 0.3755 score: 0.8605 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0139;  Loss pred: 0.0139; Loss self: 0.0000; time: 0.09s
Val loss: 0.4501 score: 0.7727 time: 0.15s
Test loss: 0.3763 score: 0.8605 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0145;  Loss pred: 0.0145; Loss self: 0.0000; time: 0.08s
Val loss: 0.4509 score: 0.7727 time: 0.05s
Test loss: 0.3789 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0110;  Loss pred: 0.0110; Loss self: 0.0000; time: 0.08s
Val loss: 0.4521 score: 0.7955 time: 0.05s
Test loss: 0.3821 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0119;  Loss pred: 0.0119; Loss self: 0.0000; time: 0.08s
Val loss: 0.4540 score: 0.7955 time: 0.05s
Test loss: 0.3860 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0107;  Loss pred: 0.0107; Loss self: 0.0000; time: 0.08s
Val loss: 0.4562 score: 0.7955 time: 0.05s
Test loss: 0.3905 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.08s
Val loss: 0.4584 score: 0.7955 time: 0.05s
Test loss: 0.3955 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.08s
Val loss: 0.4598 score: 0.7955 time: 0.05s
Test loss: 0.4003 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0094;  Loss pred: 0.0094; Loss self: 0.0000; time: 0.08s
Val loss: 0.4625 score: 0.8182 time: 0.05s
Test loss: 0.4062 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.08s
Val loss: 0.4648 score: 0.8182 time: 0.05s
Test loss: 0.4123 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.08s
Val loss: 0.4674 score: 0.8182 time: 0.05s
Test loss: 0.4186 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 9 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.18s
Val loss: 0.4691 score: 0.8182 time: 0.05s
Test loss: 0.4250 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.08s
Val loss: 0.4696 score: 0.8182 time: 0.05s
Test loss: 0.4309 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.08s
Val loss: 0.4706 score: 0.8182 time: 0.05s
Test loss: 0.4371 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0066;  Loss pred: 0.0066; Loss self: 0.0000; time: 0.08s
Val loss: 0.4720 score: 0.8182 time: 0.05s
Test loss: 0.4435 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.08s
Val loss: 0.4742 score: 0.8182 time: 0.05s
Test loss: 0.4497 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0060;  Loss pred: 0.0060; Loss self: 0.0000; time: 0.08s
Val loss: 0.4759 score: 0.8182 time: 0.05s
Test loss: 0.4558 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0062;  Loss pred: 0.0062; Loss self: 0.0000; time: 0.08s
Val loss: 0.4785 score: 0.8182 time: 0.05s
Test loss: 0.4625 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.08s
Val loss: 0.4803 score: 0.8182 time: 0.05s
Test loss: 0.4687 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.08s
Val loss: 0.4821 score: 0.8182 time: 0.05s
Test loss: 0.4749 score: 0.8605 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0053;  Loss pred: 0.0053; Loss self: 0.0000; time: 0.08s
Val loss: 0.4824 score: 0.8636 time: 0.17s
Test loss: 0.4799 score: 0.8605 time: 0.07s
     INFO: Early stopping counter 19 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.09s
Val loss: 0.4831 score: 0.8636 time: 0.05s
Test loss: 0.4850 score: 0.8605 time: 0.06s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 090,   Train_Loss: 0.0139,   Val_Loss: 0.4501,   Val_Precision: 0.9286,   Val_Recall: 0.5909,   Val_accuracy: 0.7222,   Val_Score: 0.7727,   Val_Loss: 0.4501,   Test_Precision: 0.9412,   Test_Recall: 0.7619,   Test_accuracy: 0.8421,   Test_Score: 0.8605,   Test_loss: 0.3763


[0.05775591207202524, 0.05359948589466512, 0.058479216997511685, 0.05361822503618896, 0.05360437708441168, 0.05346168705727905, 0.07194340403657407, 0.05354044702835381, 0.05369101802352816, 0.05352530092932284, 0.053370058070868254, 0.05982807790860534, 0.05314507195726037, 0.05429645499680191, 0.053897040081210434, 0.05420777597464621, 0.056658855988644063, 0.055614140001125634, 0.054045421071350574, 0.05444849201012403, 0.05424701806623489, 0.05262869398575276, 0.051000187057070434, 0.050600798917002976, 0.051715445006266236, 0.05019457300659269, 0.049281792948022485, 0.04935475590173155, 0.0514626819640398, 0.052954538026824594, 0.04963234392926097, 0.048351110075600445, 0.048638900043442845, 0.05031943810172379, 0.04953060601837933, 0.05786329403053969, 0.051811764016747475, 0.05019128299318254, 0.049652848043479025, 0.04913053894415498, 0.049621244077570736, 0.049457750050351024, 0.04937041597440839, 0.04934713302645832, 0.05011046503204852, 0.05027827003505081, 0.04997221694793552, 0.050276862108148634, 0.050727955996990204, 0.05080898990854621, 0.050731780007481575, 0.05091238999739289, 0.05080021300818771, 0.05070057697594166, 0.0506290050689131, 0.05079451994970441, 0.05046582093928009, 0.05052453500684351, 0.051319786929525435, 0.05090394010767341, 0.0503916519228369, 0.050938365049660206, 0.05171476199757308, 0.050810597953386605, 0.050811744993552566, 0.05028629908338189, 0.050570244900882244, 0.0613625809783116, 0.06158307800069451, 0.05481155798770487, 0.0530098540475592, 0.05195475497748703, 0.051354544004425406, 0.051855984958820045, 0.05159217503387481, 0.05322317103855312, 0.054429793963208795, 0.0518860180163756, 0.05140044307336211, 0.05162172205746174, 0.0527161048958078, 0.05294246401172131, 0.052234027069061995, 0.05160117009654641, 0.05165586096700281, 0.05351801810320467, 0.05355968093499541, 0.05183371505700052, 0.052106825984083116, 0.05362348596099764, 0.054190390976145864, 0.052865498000755906, 0.053682493045926094, 0.05305943498387933, 0.05257492407690734, 0.05298588192090392, 0.05437744501978159, 0.05520981003064662, 0.054550384054891765, 0.05408240493852645, 0.05453777499496937, 0.05421528092119843, 0.0555086019448936, 0.05406082095578313, 0.05444905301555991, 0.054887667996808887, 0.05531877209432423, 0.054384888033382595, 0.05542822799179703, 0.05501288699451834, 0.05421394994482398, 0.05387270206119865, 0.0542924830224365, 0.0545275789918378, 0.06009978405199945, 0.05916835996322334, 0.05394879204686731, 0.05407370498869568, 0.053571533993817866, 0.05458223703317344, 0.055705277947708964, 0.05366932100150734, 0.053664433071389794, 0.0534320849692449, 0.05284168408252299, 0.05344905401580036, 0.053548756055533886, 0.05538983503356576, 0.05483476410154253, 0.054427111987024546, 0.05436625797301531, 0.05590093205682933, 0.05574353993870318, 0.05559063400141895, 0.05443549691699445, 0.054879168048501015, 0.055502975010313094, 0.05516633309889585, 0.05608291598036885, 0.05571976792998612, 0.05675233399961144, 0.055976629024371505, 0.056589637068100274, 0.05656610301230103, 0.05570142902433872, 0.05656223697587848, 0.05572343000676483, 0.055979682016186416, 0.05621137795969844, 0.05690049298573285, 0.05649693903978914, 0.056320114992558956, 0.05630762700457126, 0.05633364396635443, 0.05614445102401078, 0.05609320499934256, 0.05674717610236257, 0.055939794052392244, 0.0558538360055536, 0.056624497985467315, 0.056389026110991836, 0.05604862002655864, 0.05621725204400718, 0.05606035701930523, 0.055939760990440845, 0.055581443943083286, 0.05504307395312935, 0.055994360940530896, 0.05643053399398923, 0.056191695970483124, 0.05551775102503598, 0.05467254901304841, 0.05452210293151438, 0.056296969996765256, 0.05430228298064321, 0.054672165075317025, 0.05387045303359628, 0.054589121020399034, 0.05484581901691854, 0.054804671090096235, 0.05514049902558327, 0.05580507300328463, 0.05494451196864247, 0.05548016296233982, 0.06182254001032561, 0.055464185075834394, 0.05414158396888524, 0.07198656792752445, 0.055064729996956885, 0.055831480072811246, 0.056341432966291904, 0.05800697801169008, 0.05752694699913263, 0.0568748019868508, 0.05820183199830353, 0.05703747796360403, 0.055915214004926383, 0.05525913694873452, 0.05548601900227368, 0.055127414991147816, 0.056982898036949337, 0.05796898005064577, 0.05697246303316206, 0.056312279077246785, 0.05594885896425694, 0.17400268698111176, 0.055122236954048276, 0.05473537102807313, 0.05499452305957675, 0.05458216997794807, 0.055705334059894085, 0.05523016199003905, 0.0566660639597103, 0.055618211976252496, 0.0547816320322454, 0.054674273007549345, 0.054459860897623, 0.05463881301693618, 0.05516334599815309, 0.054783129948191345, 0.055030064075253904, 0.05799950996879488, 0.0558403879404068, 0.054824287071824074, 0.05563935299869627, 0.056147439987398684, 0.052160907071083784, 0.05254088097717613, 0.052417879924178123, 0.051962634082883596, 0.05273389501962811, 0.05272851896006614, 0.05450614495202899, 0.052622680901549757, 0.051829307922162116, 0.05176978395320475, 0.08174691197928041, 0.05290949810296297, 0.05252532404847443, 0.0529752530856058, 0.05289500893559307, 0.052427408983930945, 0.05376798298675567, 0.05167171498760581, 0.05091060802806169, 0.051300292019732296, 0.10738566995132715, 0.051618524943478405, 0.05151350796222687, 0.05665176094044, 0.05578325595706701, 0.05331724893767387, 0.05276526801753789, 0.053043088992126286, 0.05207656603306532, 0.052861365024000406, 0.1825494560180232, 0.052275444963015616, 0.052285749930888414, 0.052461409009993076, 0.052087171003222466, 0.05226935108657926, 0.05255674500949681, 0.055296667967922986, 0.054564571008086205, 0.05420620599761605, 0.05637007299810648, 0.05437514209188521, 0.054442275082692504, 0.05446549691259861, 0.054170074057765305, 0.05371772893704474, 0.0539433240192011, 0.05531654809601605, 0.05416107107885182, 0.053928136941976845, 0.054449180024676025, 0.05377834604587406, 0.05348182504530996, 0.053404941922053695, 0.05398902704473585, 0.05412521900143474, 0.05357250198721886, 0.05680272390600294, 0.05390309903305024, 0.053431915934197605, 0.05359426001086831, 0.053473970969207585, 0.05346660304348916, 0.05359303904697299, 0.053901628009043634, 0.05438104597851634, 0.05365785909816623, 0.05444857606198639, 0.05312178598251194, 0.05282084399368614, 0.0956551720155403, 0.05344806506764144, 0.052744911052286625, 0.05260839906986803, 0.05276589305140078, 0.05292583501432091, 0.053856806945987046, 0.053758766036480665, 0.05297673097811639, 0.05260087503120303, 0.061203548102639616, 0.05297861690632999, 0.0519971459871158, 0.0526305710664019, 0.05244472192134708, 0.05345478293020278, 0.05507967493031174, 0.053472399013116956, 0.05328647093847394, 0.052977785002440214, 0.052794139948673546, 0.05252707505133003, 0.05231010203715414, 0.052627437049522996, 0.052864436991512775, 0.05273218103684485, 0.053295781021006405, 0.052631281898356974, 0.052413415047340095, 0.0671525220386684, 0.05332463001832366, 0.05206874303985387, 0.05183894501533359, 0.05338345596101135, 0.05280803295318037, 0.056964103947393596, 0.0531855640001595, 0.05266234604641795, 0.05272920697461814, 0.07124526205006987, 0.06090523093007505]
[0.001312634365273301, 0.001218170133969662, 0.001329073113579811, 0.0012185960235497491, 0.0012182812973729926, 0.0012150383422108875, 0.0016350773644675924, 0.0012168283415534956, 0.00122025040962564, 0.0012164841120300646, 0.0012129558652470057, 0.001359729043377394, 0.0012078425444831903, 0.001234010340836407, 0.001224932729118419, 0.0012319949085146866, 0.0012877012724691833, 0.00126395772729831, 0.0012283050243488767, 0.0012374657275028187, 0.001232886774232611, 0.0011961066814943808, 0.0011590951603879644, 0.001150018157204613, 0.001175351022869687, 0.0011407857501498338, 0.001120040748818693, 0.0011216989977666262, 0.0011696064082736318, 0.0012035122278823771, 0.001128007816574113, 0.0010988888653545555, 0.0011054295464418828, 0.0011436235932209952, 0.001125695591326803, 0.0013150748643304476, 0.0011775400912897153, 0.001140710977117785, 0.0011284738191699778, 0.0011166031578217041, 0.0011277555472175168, 0.0011240397738716142, 0.0011220549085092816, 0.0011215257506013256, 0.00113887420527383, 0.0011426879553420638, 0.001135732203362171, 0.001142655957003378, 0.0011529080908406865, 0.0011547497706487775, 0.0011529950001700358, 0.0011570997726680203, 0.0011545502956406299, 0.0011522858403623104, 0.0011506592061116614, 0.0011544209079478276, 0.0011469504758927294, 0.0011482848865191706, 0.0011663587938528508, 0.00115690772971985, 0.0011452648164281113, 0.0011576901147650046, 0.0011753354999448427, 0.0011547863171224228, 0.0011548123862171037, 0.0011428704337132249, 0.0011493237477473237, 0.0013946041131434454, 0.0013996154091066935, 0.0012457172269932926, 0.0012047694101718, 0.001180789885851978, 0.0011671487273733046, 0.0011785451127004555, 0.0011725494325880638, 0.0012096175236034799, 0.001237040771891109, 0.0011792276821903545, 0.001168191888030957, 0.0011732209558514032, 0.001198093293086541, 0.0012032378184482116, 0.001187136978842318, 0.0011727538658306003, 0.0011739968401591548, 0.0012163185932546514, 0.0012172654757953503, 0.0011780389785681937, 0.0011842460450927981, 0.0012187155900226737, 0.001231599794912406, 0.0012014885909262705, 0.0012200566601346839, 0.001205896249633621, 0.0011948846381115304, 0.0012042245891114528, 0.0012358510231768544, 0.0012547684097874233, 0.0012397814557929946, 0.0012291455667846922, 0.0012394948862493038, 0.0012321654754817825, 0.0012615591351112182, 0.001228655021722344, 0.0012374784776263616, 0.0012474469999274747, 0.0012572448203255508, 0.0012360201825768772, 0.0012597324543590234, 0.0012502928862390531, 0.0012321352260187268, 0.0012243795922999693, 0.0012339200686917386, 0.0012392631589054045, 0.0013659041829999876, 0.0013447354537096214, 0.0012261089101560753, 0.0012575280229929228, 0.0012458496277632063, 0.0012693543496086848, 0.0012954715801792782, 0.001248123744221101, 0.0012480100714276697, 0.0012426066271917417, 0.0012288763740121624, 0.0012430012561814037, 0.0012453199082682299, 0.0012881356984550177, 0.001275227072128896, 0.0012657467903959196, 0.0012643315807677978, 0.001300021675740217, 0.0012963613939233297, 0.0012928054418934638, 0.0012659417887673128, 0.0012762597220581631, 0.0012907668607049557, 0.0012829379790440896, 0.001304253860008578, 0.001295808556511305, 0.0013198217209211963, 0.0013017820703342211, 0.0013160380713511692, 0.0013154907677279308, 0.0012953820703334588, 0.0013154008599041507, 0.0012958937210875543, 0.00130185307014387, 0.0013072413478999636, 0.0013232672787379734, 0.0013138823032509102, 0.0013097701161060222, 0.001309479697780727, 0.0013100847434035915, 0.0013056849075351344, 0.0013044931395195943, 0.0013197017698223855, 0.0013009254430788894, 0.0012989264187338047, 0.001316848790359705, 0.001311372700255624, 0.00130345627968741, 0.0013073779545117949, 0.0013037292330070984, 0.0013009246741962988, 0.0012925917196065881, 0.001280071487282078, 0.0013021944404774627, 0.0013123379998602146, 0.0013067836272205378, 0.001291110488954325, 0.0012714546282104281, 0.0012679558821282414, 0.0013092318603898897, 0.0012628437902475166, 0.0012714456994259774, 0.0012528012333394482, 0.0012695144423348612, 0.001275484163184152, 0.0012745272346534008, 0.0012823371866414713, 0.0012977923954252241, 0.0012777793481079645, 0.0012902363479613912, 0.0014377334886122234, 0.001289864769205451, 0.0012591066039275638, 0.0016741062308726616, 0.0012805751162082997, 0.0012984065133211918, 0.001310265882937021, 0.0013489994886439554, 0.0013378359767240147, 0.001322669813647693, 0.0013535309767047333, 0.0013264529758977683, 0.0013003538140680553, 0.0012850962081101052, 0.001290372534936597, 0.0012820329067708795, 0.0013251836752778915, 0.0013481158151312969, 0.0013249410007712106, 0.0013095878855173672, 0.0013011362549827197, 0.004046574115839808, 0.0012819124873034483, 0.0012729156053040264, 0.001278942396734343, 0.0012693527901848389, 0.001295472885113816, 0.0012844223718613732, 0.0013178154409234954, 0.001293446790145407, 0.001273991442610358, 0.0012714947211057987, 0.001266508392967977, 0.0012706700701613067, 0.0012828685115849555, 0.001274026277864915, 0.001279768931982649, 0.001348825813227788, 0.0012986136730327163, 0.0012749834202749784, 0.0012939384418301457, 0.0013057544183115973, 0.0012130443504903205, 0.0012218809529575844, 0.0012190204633529796, 0.0012084333507647348, 0.0012263696516192583, 0.0012262446269782823, 0.0012675847663262555, 0.001223783276780227, 0.0012053327423758632, 0.0012039484640280174, 0.001901090976262335, 0.0012304534442549528, 0.00122151916391801, 0.0012319826298978092, 0.0012301164868742573, 0.0012192420693937429, 0.0012504182089943178, 0.0012016677904094373, 0.0011839676285595741, 0.0011930300469705185, 0.0024973411616587707, 0.0012004308126390326, 0.00119798855726109, 0.001317482812568372, 0.0012972850222573724, 0.001239936021806369, 0.0012270992562218115, 0.001233560209119216, 0.001211082931001519, 0.001229334070325591, 0.004245336186465656, 0.001215708022395712, 0.0012159476728113585, 0.0012200327676742575, 0.0012113295582144759, 0.0012155663043390526, 0.0012222498839417862, 0.001285969022509837, 0.0012689435118159583, 0.0012606094418050244, 0.0013109319301885228, 0.001264538188183377, 0.0012660994205277326, 0.0012666394630836885, 0.0012597691641340768, 0.0012492495101638311, 0.0012544959074232815, 0.0012864313510701406, 0.0012595597925314376, 0.001254142719580857, 0.001266260000573861, 0.0012506592103691642, 0.0012437633731467433, 0.0012419753935361325, 0.001255558768482229, 0.00125872602328918, 0.0012458721392376478, 0.0013209935792093707, 0.0012535604426290752, 0.0012426026961441304, 0.001246378139787635, 0.0012435807202141299, 0.001243409373104399, 0.0012463497452784417, 0.0012535262327684567, 0.001264675487872473, 0.001247857188329447, 0.001266245954929916, 0.0012353903716863241, 0.0012283917207833986, 0.002224538884082333, 0.0012429782573870102, 0.0012266258384252703, 0.0012234511411597217, 0.0012271137918930413, 0.0012308333724260676, 0.001252483882464815, 0.0012502038613135039, 0.001232016999491079, 0.0012232761635163495, 0.001423338327968363, 0.0012320608582867439, 0.0012092359531887394, 0.0012239667689860907, 0.001219644695845281, 0.001243134486748902, 0.0012809226727979474, 0.0012435441630957431, 0.001239220254383115, 0.0012320415116846561, 0.0012277706964807802, 0.0012215598849146519, 0.0012165140008640496, 0.0012238938848726278, 0.0012294055114305297, 0.0012263297915545313, 0.0012394367679303816, 0.00122398329996179, 0.0012189166290079091, 0.0015616865590388, 0.0012401076748447364, 0.0012109010009268343, 0.0012055568608217114, 0.0012414757200235197, 0.001228093789608846, 0.001324746603427758, 0.0012368735813990581, 0.0012247057220097198, 0.0012262606273167008, 0.0016568665593039505, 0.001416400719304071]
[761.8267710001575, 820.9033960973013, 752.4040549631884, 820.616496915046, 820.8284918732007, 823.0192951610045, 611.5918559765618, 821.8086034414056, 819.5039248598076, 822.0411513071086, 824.432305124606, 735.4406415532077, 827.9224842405915, 810.3659806628558, 816.3713616499557, 811.6916661657446, 776.5776281967071, 791.1656999300797, 814.1300248528244, 808.1031884559584, 811.1044914261755, 836.04582724229, 862.7419336866931, 869.5514881527896, 850.8096564704921, 876.5887896729577, 892.8246593302075, 891.5047637477286, 854.9884755471072, 830.9014041008422, 886.5186794867369, 910.010130712673, 904.6257205796284, 874.4135797194582, 888.3396254766783, 760.4129826548973, 849.2279858639357, 876.6462496281774, 886.15259212263, 895.5733225319045, 886.716986200844, 889.6482342040489, 891.2219824683634, 891.6424785287655, 878.0601012554856, 875.1295533701935, 880.489253575486, 875.1540600396517, 867.3718295018749, 865.988481156542, 867.306449596509, 864.2297091582842, 866.1381005018288, 867.8402224274251, 869.0670484262903, 866.2351774082679, 871.8772266271127, 870.8640266365685, 857.3691091200888, 864.3731684999235, 873.1605002228498, 863.7890116242259, 850.8208933082758, 865.9610745058617, 865.9415260307061, 874.9898243066505, 870.0768621200089, 717.0493694773311, 714.4819880471675, 802.7503981891906, 830.034354754575, 846.8907228812075, 856.788836372656, 848.5037944017715, 852.8425089872665, 826.7076001189001, 808.3807928749703, 848.0126570150995, 856.023749390648, 852.3543625883351, 834.659542600217, 831.0908987964467, 842.3627751661718, 852.6938423620137, 851.7910489984226, 822.1530161141238, 821.5134823786972, 848.8683466275583, 844.419117246568, 820.5359873843868, 811.9520676528873, 832.3008703969999, 819.634065101213, 829.258736233588, 836.9008757033331, 830.409882875634, 809.1590177507154, 796.9598152135621, 806.5937712871947, 813.5732878375737, 806.7802546777644, 811.5793048080619, 792.6699368807953, 813.898109982237, 808.0948623188381, 801.6372639944935, 795.3900336937241, 809.0482777677481, 793.8193515136669, 799.8125967172801, 811.5992294378258, 816.7401729732546, 810.425266087331, 806.9311129068527, 732.1157753567031, 743.6406895061588, 815.5882334079987, 795.2109072050698, 802.6650871144027, 787.8020824589123, 771.9196741171362, 801.2026088198938, 801.2755849446337, 804.7599120406863, 813.7515059672737, 804.5044162482004, 803.006515322334, 776.315726052305, 784.1740673922292, 790.0474309614522, 790.931758101561, 769.2179435628346, 771.3898336432122, 773.5115954767206, 789.9257366120534, 783.5395748346173, 774.7332461369882, 779.460906399462, 766.7219018185793, 771.7189356213945, 757.6780895089602, 768.177733269332, 759.8564371115081, 760.1725717369835, 771.9730131377987, 760.2245296333979, 771.6682191814072, 768.1358387774807, 764.9696833767262, 755.7052275589556, 761.1031806469437, 763.4927593042235, 763.662087846627, 763.3094004300872, 765.88156470905, 766.581264174582, 757.7469568253947, 768.6835593232064, 769.8665494653665, 759.3886308896894, 762.5597206690908, 767.191056258378, 764.889752461386, 767.0304344510739, 768.6840136365254, 773.6394909789141, 781.2063700623924, 767.9344719313499, 761.9988144110101, 765.2376255485761, 774.5270513679302, 786.5007353093673, 788.6709735685107, 763.8066489630031, 791.8635762575201, 786.506258546057, 798.211219296468, 787.7027363003633, 784.0160065206719, 784.6046540323191, 779.8260944292416, 770.5392661607855, 782.6077338632226, 775.0517969672978, 695.5391996643641, 775.2750705920854, 794.2139266688572, 597.3336587360587, 780.899134570829, 770.1748179328689, 763.2038756580108, 741.2901253248232, 747.4757873149141, 756.0465882578617, 738.8083591810883, 753.8902759241663, 769.0214687582436, 778.1518564050742, 774.9699973652456, 780.0111796808321, 754.6123746131265, 741.7760319817976, 754.7505884548281, 763.5990001579306, 768.5590161449163, 247.12262061026513, 780.0844518673331, 785.5980363766203, 781.8960436008723, 787.8030502886305, 771.9188965596477, 778.5600919974705, 758.8316003485454, 773.1280541409684, 784.9346287217122, 786.475935291588, 789.5723435804224, 786.9863495510317, 779.5031142860637, 784.9131665289168, 781.3910581895248, 741.3855741735581, 770.0519567645172, 784.3239246078414, 772.8342923219752, 765.8407936256863, 824.3721670982544, 818.4103349671524, 820.3307738160913, 827.517710734455, 815.4148291908829, 815.497966718276, 788.9018758865523, 817.1381477208934, 829.6464244627368, 830.6003370396165, 526.0137534112455, 812.7085219429056, 818.6527314008815, 811.6997559315818, 812.9311416197773, 820.1816727807309, 799.7324357618534, 832.1767529936669, 844.6176870702193, 838.2018563063998, 400.4258670592628, 833.0342652581496, 834.7325138783106, 759.023184560978, 770.8406270350101, 806.4932241771439, 814.9300025484158, 810.6616868859752, 825.7072859354383, 813.4485361941922, 235.5526055128567, 822.5659299585511, 822.403810920521, 819.6501163704767, 825.5391715810354, 822.6618296594986, 818.163301251439, 777.6237082665423, 788.0571441426271, 793.2671030673334, 762.8161134622694, 790.802531188552, 789.8273893713515, 789.4906397164168, 793.7962195537359, 800.4806020447079, 797.1329313094271, 777.3442392927786, 793.9281691345675, 797.3574174510273, 789.727227857475, 799.5783277403157, 804.0114555471933, 805.1689310468672, 796.4581388801427, 794.4540602941516, 802.6505838808647, 757.0059504744232, 797.727788779545, 804.7624579465819, 802.324726403165, 804.1295460320516, 804.2403585098583, 802.3430050740648, 797.749559489844, 790.716677589973, 801.3737544267683, 789.7359877886819, 809.4607363945914, 814.0725658442705, 449.5313645247969, 804.5193019725066, 815.2445258154595, 817.3599797798954, 814.9203493649289, 812.4576586909751, 798.4134678300678, 799.8695500343186, 811.677111933585, 817.476895099031, 702.5736470030807, 811.648217922093, 826.9684649741127, 817.0156456358532, 819.9109161926416, 804.4181950218776, 780.6872508671254, 804.1531854490381, 806.9590506312383, 811.660963138028, 814.4843356062736, 818.6254414124512, 822.0209543743294, 817.0642997403907, 813.4012664677299, 815.4413330629201, 806.8180853387186, 817.0046111178295, 820.400654320314, 640.3333589651232, 806.3815911188533, 825.8313431358891, 829.4921894587343, 805.492998269072, 814.2700569461434, 754.8613428504123, 808.4900632034482, 816.5226813499477, 815.4873260411177, 603.5489064491107, 706.0148913870478]
Elapsed: 0.05521133625347897~0.010700803562410302
Time per graph: 0.0012742670059048369~0.00025108217108807255
Speed: 797.0085808574864~69.02311832608757
Total Time: 0.0620
best val loss: 0.4500737190246582 test_score: 0.8605

Testing...
Test loss: 0.4799 score: 0.8605 time: 0.05s
test Score 0.8605
Epoch Time List: [0.35890098207164556, 0.16082897002343088, 0.16636574896983802, 0.16065964789595455, 0.1614601460751146, 0.16127869102638215, 0.24576117796823382, 0.1606318639824167, 0.16292597295250744, 0.16322241898160428, 0.16659043997060508, 0.16848912497516721, 0.1618235979694873, 0.16833637899253517, 0.1691056250128895, 0.16355837997980416, 0.16573192505165935, 0.2883282779948786, 0.16419883107300848, 0.16457441297825426, 0.1636042131576687, 0.16829396691173315, 0.15477779298089445, 0.15865328907966614, 0.1594326940830797, 0.15194046997930855, 0.1502665289444849, 0.15103698591701686, 0.32625001890119165, 0.1593839490087703, 0.1603139250073582, 0.1460407719714567, 0.14611548010725528, 0.1534580740844831, 0.1497112869983539, 0.15785658301319927, 0.1607895529596135, 0.15268008888233453, 0.15031242207624018, 0.15044066892005503, 0.15038914198521525, 0.1506671371171251, 0.1507208429975435, 0.1508489049738273, 0.15163708198815584, 0.1536174169741571, 0.15323511813767254, 0.1534463269636035, 0.15415604307781905, 0.1565780220553279, 0.15563324803952128, 0.1559544950723648, 0.1546470158500597, 0.15571379894390702, 0.15634406404569745, 0.15538087103050202, 0.15579770191106945, 0.15496027714107186, 0.15587609016802162, 0.15509353298693895, 0.15429107984527946, 0.15655685518868268, 0.15620486810803413, 0.1552270749816671, 0.1575823340099305, 0.15294350811745971, 0.1546233140397817, 0.17071180592756718, 0.1856070008361712, 0.17368701985105872, 0.16414544091094285, 0.16044963605236262, 0.1607903129188344, 0.1680959949735552, 0.16276724508497864, 0.16332835401408374, 0.16307869600132108, 0.16370383405592293, 0.16080276912543923, 0.16020175605081022, 0.16483162203803658, 0.16496506007388234, 0.1618539250921458, 0.16164659801870584, 0.16165050817653537, 0.16744064900558442, 0.16467659489717335, 0.164486585999839, 0.16351418499834836, 0.16494295198936015, 0.16682387795299292, 0.16699730802793056, 0.16865504498127848, 0.16700583696365356, 0.1647903029806912, 0.16587480914313346, 0.17005455994512886, 0.17114951310213655, 0.17061400704551488, 0.16905844793654978, 0.17007258301600814, 0.17078441800549626, 0.17214696598239243, 0.16950324713252485, 0.17167594702914357, 0.17142352310474962, 0.17159456200897694, 0.17134131700731814, 0.1713174021570012, 0.17205643095076084, 0.17060901201330125, 0.16871638188604265, 0.1699189339997247, 0.17125481297262013, 0.1746454609092325, 0.17561490007210523, 0.1690606219926849, 0.1716832099482417, 0.1676314331125468, 0.1710571520961821, 0.17077979701571167, 0.1671042658854276, 0.16934680799022317, 0.16671776992734522, 0.16662407713010907, 0.16845533100422472, 0.16724878014065325, 0.1696370649151504, 0.16991343791596591, 0.17111712007317692, 0.17051683005411178, 0.17292274988722056, 0.17374916188418865, 0.1748663019388914, 0.17042893101461232, 0.1726187509484589, 0.17267771891783923, 0.17367515992373228, 0.17493835790082812, 0.17472467420157045, 0.17487886804156005, 0.17328545299824327, 0.17455522809177637, 0.17713827302213758, 0.1743362011620775, 0.1740123899653554, 0.1733863370027393, 0.17633222788572311, 0.17544041306246072, 0.17663133703172207, 0.17517400498036295, 0.17563873808830976, 0.17671078606508672, 0.17532745597418398, 0.17496259789913893, 0.17559363297186792, 0.1749391461489722, 0.17434989695902914, 0.17639759799931198, 0.17652683204505593, 0.17725964996498078, 0.17524755711201578, 0.17480506584979594, 0.1763786340598017, 0.17525423096958548, 0.17379264207556844, 0.17361263581551611, 0.17355987301561981, 0.17535355302970856, 0.1773257169406861, 0.17605229222681373, 0.17336334707215428, 0.17103395599406213, 0.17169920704327524, 0.2633961980463937, 0.17203844001051039, 0.16873078304342926, 0.17096674698404968, 0.17137467407155782, 0.17057727195788175, 0.1725856369594112, 0.17720172298140824, 0.17243531008716673, 0.17294665705412626, 0.1778205280425027, 0.2789942149538547, 0.17209707107394934, 0.18279143807012588, 0.20523500815033913, 0.17259487393312156, 0.1766542779514566, 0.1777146439999342, 0.1798663609661162, 0.17913465097080916, 0.18011458904948086, 0.2538916760822758, 0.1756726821186021, 0.17539548699278384, 0.17264850111678243, 0.1751579298870638, 0.1769987849984318, 0.17823807103559375, 0.18203981593251228, 0.1795184969669208, 0.17858729301951826, 0.29568888095673174, 0.17325244203675538, 0.17279410199262202, 0.1729202379938215, 0.17321936693042517, 0.17407596099656075, 0.17563028598669916, 0.1809167789760977, 0.17536515602841973, 0.17384780698921531, 0.17251833307091147, 0.30118115979712456, 0.17032224603462964, 0.17190127715002745, 0.17155589303001761, 0.1730565361212939, 0.17796276498120278, 0.1793932159198448, 0.1757605461170897, 0.1739935229998082, 0.2888692191336304, 0.2927256762050092, 0.17656194104347378, 0.17783046688418835, 0.1775340661406517, 0.17794269602745771, 0.17832420812919736, 0.17954393394757062, 0.18275657994672656, 0.17645785806234926, 0.1759413251420483, 0.26799197995569557, 0.17795019503682852, 0.17681321897543967, 0.17743329994846135, 0.1760425119427964, 0.17650335398502648, 0.1778824010398239, 0.1775476799812168, 0.17495170305483043, 0.17343739792704582, 0.2281357190804556, 0.21411516889929771, 0.17384602187667042, 0.18588434590492398, 0.18864012195263058, 0.18257601279765368, 0.17767954315058887, 0.1842159730149433, 0.17871480504982173, 0.17861199099570513, 0.3087158708367497, 0.17713675496634096, 0.17518280493095517, 0.17593098699580878, 0.17575807496905327, 0.1763299850281328, 0.17773473798297346, 0.17901771806646138, 0.18683986808173358, 0.1797773709986359, 0.18031464505475014, 0.22202301013749093, 0.1822092990623787, 0.18121809279546142, 0.18109763611573726, 0.18054394191130996, 0.17970555601641536, 0.18460597295779735, 0.18676151195541024, 0.18085816595703363, 0.18025505996774882, 0.28695147996768355, 0.1792786568403244, 0.17815627495292574, 0.1788016048958525, 0.17994562210515141, 0.1791932040359825, 0.1864200100535527, 0.1812575429212302, 0.17811586090829223, 0.17722842504736036, 0.3060161641333252, 0.18004166090395302, 0.18047597107943147, 0.18009370705112815, 0.1819954669335857, 0.17960920394398272, 0.18625300494022667, 0.18082210514694452, 0.17682244803290814, 0.21887324005365372, 0.21737407008185983, 0.179885252029635, 0.1762181520462036, 0.17794348299503326, 0.1782182150054723, 0.17896072508301586, 0.18659596389625221, 0.17957038804888725, 0.17710524797439575, 0.18181756208650768, 0.281681137974374, 0.1756401889724657, 0.17598564899526536, 0.17566082999110222, 0.1769964681006968, 0.17864199879113585, 0.18282207404263318, 0.17996354296337813, 0.17947384214494377, 0.2859075888991356, 0.17752602498512715, 0.17654022993519902, 0.1777223739773035, 0.17762888700235635, 0.17812462407164276, 0.18408177106175572, 0.1795634268783033, 0.17706583405379206, 0.18753965699579567, 0.27355419693049043, 0.17685520998202264, 0.17516779084689915, 0.17839395196642727, 0.17872840503696352, 0.18243454210460186, 0.17990134400315583, 0.1786035109544173, 0.17715987702831626, 0.3147997361375019, 0.19657740893308073]
Total Epoch List: [117, 109, 111]
Total Time List: [0.05459188902750611, 0.056990524055436254, 0.06199871189892292]
========================training times:1========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a25c67d0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6994;  Loss pred: 0.6994; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6987;  Loss pred: 0.6987; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6999;  Loss pred: 0.6999; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6998;  Loss pred: 0.6998; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6992;  Loss pred: 0.6992; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6954;  Loss pred: 0.6954; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6963;  Loss pred: 0.6963; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6975 score: 0.5000 time: 0.06s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6936;  Loss pred: 0.6936; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6953 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.5000 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6974 score: 0.5000 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6873;  Loss pred: 0.6873; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6952 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6973 score: 0.5000 time: 0.06s
Epoch 11/1000, LR 0.000270
Train loss: 0.6847;  Loss pred: 0.6847; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6951 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6972 score: 0.5000 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6819;  Loss pred: 0.6819; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6971 score: 0.5000 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6794;  Loss pred: 0.6794; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6950 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6970 score: 0.5000 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6765;  Loss pred: 0.6765; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6949 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6969 score: 0.5000 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6731;  Loss pred: 0.6731; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6968 score: 0.5000 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6697;  Loss pred: 0.6697; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6948 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6967 score: 0.5000 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6663;  Loss pred: 0.6663; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6947 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6966 score: 0.5000 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6605;  Loss pred: 0.6605; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6946 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6965 score: 0.5000 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6527;  Loss pred: 0.6527; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6964 score: 0.5000 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6484;  Loss pred: 0.6484; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6945 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6963 score: 0.5000 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6437;  Loss pred: 0.6437; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6944 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6962 score: 0.5000 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6372;  Loss pred: 0.6372; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6961 score: 0.5000 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6319;  Loss pred: 0.6319; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5000 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6255;  Loss pred: 0.6255; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6960 score: 0.5000 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6168;  Loss pred: 0.6168; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6016;  Loss pred: 0.6016; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5958;  Loss pred: 0.5958; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5901;  Loss pred: 0.5901; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5844;  Loss pred: 0.5844; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5688;  Loss pred: 0.5688; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5635;  Loss pred: 0.5635; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5509;  Loss pred: 0.5509; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5337;  Loss pred: 0.5337; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.06s
Epoch 34/1000, LR 0.000270
Train loss: 0.5249;  Loss pred: 0.5249; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5115;  Loss pred: 0.5115; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5094;  Loss pred: 0.5094; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4914;  Loss pred: 0.4914; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4754;  Loss pred: 0.4754; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4681;  Loss pred: 0.4681; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4544;  Loss pred: 0.4544; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6959 score: 0.5000 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4381;  Loss pred: 0.4381; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6958 score: 0.5000 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4237;  Loss pred: 0.4237; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6956 score: 0.5000 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4123;  Loss pred: 0.4123; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.5000 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3953;  Loss pred: 0.3953; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.5000 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3916;  Loss pred: 0.3916; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.5000 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3747;  Loss pred: 0.3747; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6908 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.5000 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3549;  Loss pred: 0.3549; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.5000 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3465;  Loss pred: 0.3465; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6893 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6938 score: 0.5000 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3326;  Loss pred: 0.3326; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6883 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3215;  Loss pred: 0.3215; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6871 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5000 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3115;  Loss pred: 0.3115; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6858 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6917 score: 0.5000 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2935;  Loss pred: 0.2935; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6842 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5000 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2866;  Loss pred: 0.2866; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5000 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2708;  Loss pred: 0.2708; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6802 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6881 score: 0.5000 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2618;  Loss pred: 0.2618; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6777 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6864 score: 0.5000 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2453;  Loss pred: 0.2453; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6748 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6845 score: 0.5000 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2381;  Loss pred: 0.2381; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6714 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6821 score: 0.5000 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2312;  Loss pred: 0.2312; Loss self: 0.0000; time: 0.07s
Val loss: 0.6673 score: 0.5349 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6792 score: 0.5000 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2113;  Loss pred: 0.2113; Loss self: 0.0000; time: 0.07s
Val loss: 0.6625 score: 0.5581 time: 0.05s
Test loss: 0.6756 score: 0.5227 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.2046;  Loss pred: 0.2046; Loss self: 0.0000; time: 0.07s
Val loss: 0.6574 score: 0.5581 time: 0.05s
Test loss: 0.6720 score: 0.5227 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1936;  Loss pred: 0.1936; Loss self: 0.0000; time: 0.07s
Val loss: 0.6512 score: 0.5581 time: 0.05s
Test loss: 0.6674 score: 0.5455 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1836;  Loss pred: 0.1836; Loss self: 0.0000; time: 0.07s
Val loss: 0.6442 score: 0.5581 time: 0.05s
Test loss: 0.6621 score: 0.5455 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1757;  Loss pred: 0.1757; Loss self: 0.0000; time: 0.07s
Val loss: 0.6368 score: 0.5814 time: 0.05s
Test loss: 0.6565 score: 0.5455 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1579;  Loss pred: 0.1579; Loss self: 0.0000; time: 0.07s
Val loss: 0.6285 score: 0.5814 time: 0.05s
Test loss: 0.6501 score: 0.5909 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1524;  Loss pred: 0.1524; Loss self: 0.0000; time: 0.07s
Val loss: 0.6195 score: 0.6047 time: 0.05s
Test loss: 0.6431 score: 0.5909 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1459;  Loss pred: 0.1459; Loss self: 0.0000; time: 0.07s
Val loss: 0.6097 score: 0.6279 time: 0.05s
Test loss: 0.6354 score: 0.5909 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1380;  Loss pred: 0.1380; Loss self: 0.0000; time: 0.07s
Val loss: 0.5991 score: 0.6512 time: 0.05s
Test loss: 0.6268 score: 0.5909 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1266;  Loss pred: 0.1266; Loss self: 0.0000; time: 0.07s
Val loss: 0.5879 score: 0.6512 time: 0.05s
Test loss: 0.6179 score: 0.5909 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1205;  Loss pred: 0.1205; Loss self: 0.0000; time: 0.07s
Val loss: 0.5759 score: 0.6977 time: 0.05s
Test loss: 0.6082 score: 0.5909 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.1117;  Loss pred: 0.1117; Loss self: 0.0000; time: 0.07s
Val loss: 0.5639 score: 0.6977 time: 0.05s
Test loss: 0.5985 score: 0.5909 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.1066;  Loss pred: 0.1066; Loss self: 0.0000; time: 0.07s
Val loss: 0.5512 score: 0.6977 time: 0.05s
Test loss: 0.5881 score: 0.6136 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0977;  Loss pred: 0.0977; Loss self: 0.0000; time: 0.07s
Val loss: 0.5382 score: 0.7209 time: 0.05s
Test loss: 0.5771 score: 0.6364 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0917;  Loss pred: 0.0917; Loss self: 0.0000; time: 0.07s
Val loss: 0.5245 score: 0.7209 time: 0.05s
Test loss: 0.5653 score: 0.6364 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0854;  Loss pred: 0.0854; Loss self: 0.0000; time: 0.07s
Val loss: 0.5103 score: 0.7209 time: 0.05s
Test loss: 0.5528 score: 0.6364 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0811;  Loss pred: 0.0811; Loss self: 0.0000; time: 0.07s
Val loss: 0.4962 score: 0.7209 time: 0.05s
Test loss: 0.5400 score: 0.6818 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0732;  Loss pred: 0.0732; Loss self: 0.0000; time: 0.07s
Val loss: 0.4815 score: 0.7442 time: 0.05s
Test loss: 0.5266 score: 0.6591 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0682;  Loss pred: 0.0682; Loss self: 0.0000; time: 0.07s
Val loss: 0.4664 score: 0.7442 time: 0.05s
Test loss: 0.5124 score: 0.7273 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0633;  Loss pred: 0.0633; Loss self: 0.0000; time: 0.07s
Val loss: 0.4518 score: 0.7442 time: 0.05s
Test loss: 0.4984 score: 0.7727 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0597;  Loss pred: 0.0597; Loss self: 0.0000; time: 0.07s
Val loss: 0.4370 score: 0.7442 time: 0.05s
Test loss: 0.4838 score: 0.7727 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0548;  Loss pred: 0.0548; Loss self: 0.0000; time: 0.07s
Val loss: 0.4233 score: 0.7674 time: 0.05s
Test loss: 0.4700 score: 0.7727 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0494;  Loss pred: 0.0494; Loss self: 0.0000; time: 0.07s
Val loss: 0.4099 score: 0.8372 time: 0.05s
Test loss: 0.4557 score: 0.7500 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0472;  Loss pred: 0.0472; Loss self: 0.0000; time: 0.07s
Val loss: 0.3971 score: 0.8140 time: 0.05s
Test loss: 0.4416 score: 0.7727 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0429;  Loss pred: 0.0429; Loss self: 0.0000; time: 0.07s
Val loss: 0.3858 score: 0.8372 time: 0.05s
Test loss: 0.4284 score: 0.7727 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0416;  Loss pred: 0.0416; Loss self: 0.0000; time: 0.07s
Val loss: 0.3754 score: 0.8372 time: 0.05s
Test loss: 0.4153 score: 0.8182 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0360;  Loss pred: 0.0360; Loss self: 0.0000; time: 0.07s
Val loss: 0.3666 score: 0.8372 time: 0.05s
Test loss: 0.4030 score: 0.8409 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0335;  Loss pred: 0.0335; Loss self: 0.0000; time: 0.07s
Val loss: 0.3592 score: 0.8605 time: 0.05s
Test loss: 0.3917 score: 0.8636 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0302;  Loss pred: 0.0302; Loss self: 0.0000; time: 0.07s
Val loss: 0.3533 score: 0.8605 time: 0.05s
Test loss: 0.3813 score: 0.8409 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0292;  Loss pred: 0.0292; Loss self: 0.0000; time: 0.07s
Val loss: 0.3489 score: 0.8605 time: 0.05s
Test loss: 0.3718 score: 0.8182 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0261;  Loss pred: 0.0261; Loss self: 0.0000; time: 0.07s
Val loss: 0.3458 score: 0.8605 time: 0.05s
Test loss: 0.3633 score: 0.8182 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0271;  Loss pred: 0.0271; Loss self: 0.0000; time: 0.07s
Val loss: 0.3442 score: 0.8837 time: 0.05s
Test loss: 0.3559 score: 0.8182 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0226;  Loss pred: 0.0226; Loss self: 0.0000; time: 0.07s
Val loss: 0.3439 score: 0.8837 time: 0.05s
Test loss: 0.3494 score: 0.8182 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0221;  Loss pred: 0.0221; Loss self: 0.0000; time: 0.07s
Val loss: 0.3451 score: 0.8837 time: 0.05s
Test loss: 0.3439 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0213;  Loss pred: 0.0213; Loss self: 0.0000; time: 0.07s
Val loss: 0.3475 score: 0.8837 time: 0.05s
Test loss: 0.3397 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0191;  Loss pred: 0.0191; Loss self: 0.0000; time: 0.07s
Val loss: 0.3511 score: 0.8837 time: 0.05s
Test loss: 0.3364 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0168;  Loss pred: 0.0168; Loss self: 0.0000; time: 0.07s
Val loss: 0.3562 score: 0.8837 time: 0.05s
Test loss: 0.3341 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0167;  Loss pred: 0.0167; Loss self: 0.0000; time: 0.07s
Val loss: 0.3619 score: 0.8605 time: 0.05s
Test loss: 0.3328 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0146;  Loss pred: 0.0146; Loss self: 0.0000; time: 0.07s
Val loss: 0.3693 score: 0.8605 time: 0.05s
Test loss: 0.3324 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0146;  Loss pred: 0.0146; Loss self: 0.0000; time: 0.07s
Val loss: 0.3774 score: 0.8605 time: 0.05s
Test loss: 0.3328 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0136;  Loss pred: 0.0136; Loss self: 0.0000; time: 0.07s
Val loss: 0.3870 score: 0.8605 time: 0.05s
Test loss: 0.3342 score: 0.8182 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0129;  Loss pred: 0.0129; Loss self: 0.0000; time: 0.07s
Val loss: 0.3966 score: 0.8605 time: 0.05s
Test loss: 0.3360 score: 0.8409 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0117;  Loss pred: 0.0117; Loss self: 0.0000; time: 0.07s
Val loss: 0.4071 score: 0.8605 time: 0.05s
Test loss: 0.3384 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.07s
Val loss: 0.4176 score: 0.8605 time: 0.05s
Test loss: 0.3413 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0105;  Loss pred: 0.0105; Loss self: 0.0000; time: 0.07s
Val loss: 0.4287 score: 0.8605 time: 0.05s
Test loss: 0.3448 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.07s
Val loss: 0.4394 score: 0.8605 time: 0.05s
Test loss: 0.3483 score: 0.8636 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0091;  Loss pred: 0.0091; Loss self: 0.0000; time: 0.07s
Val loss: 0.4498 score: 0.8605 time: 0.05s
Test loss: 0.3520 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.07s
Val loss: 0.4598 score: 0.8605 time: 0.05s
Test loss: 0.3556 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0083;  Loss pred: 0.0083; Loss self: 0.0000; time: 0.07s
Val loss: 0.4707 score: 0.8605 time: 0.05s
Test loss: 0.3598 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0075;  Loss pred: 0.0075; Loss self: 0.0000; time: 0.07s
Val loss: 0.4817 score: 0.8605 time: 0.05s
Test loss: 0.3640 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.07s
Val loss: 0.4924 score: 0.8605 time: 0.05s
Test loss: 0.3683 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.5034 score: 0.8605 time: 0.05s
Test loss: 0.3729 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.07s
Val loss: 0.5138 score: 0.8372 time: 0.05s
Test loss: 0.3773 score: 0.8864 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 090,   Train_Loss: 0.0226,   Val_Loss: 0.3439,   Val_Precision: 0.9474,   Val_Recall: 0.8182,   Val_accuracy: 0.8780,   Val_Score: 0.8837,   Val_Loss: 0.3439,   Test_Precision: 0.8182,   Test_Recall: 0.8182,   Test_accuracy: 0.8182,   Test_Score: 0.8182,   Test_loss: 0.3494


[0.05605938797816634, 0.05476786196231842, 0.05484617000911385, 0.05577514704782516, 0.05464150500483811, 0.054743563989177346, 0.06313436396885663, 0.054621313931420445, 0.05506728496402502, 0.0643071549711749, 0.0593585999449715, 0.05419068597257137, 0.05465309601277113, 0.054941043024882674, 0.05465252394787967, 0.05467178602702916, 0.054880928015336394, 0.05502084200270474, 0.05489306803792715, 0.05456621793564409, 0.055174501962028444, 0.05496311804745346, 0.054647968034259975, 0.05580954207107425, 0.05478014692198485, 0.054778678924776614, 0.054560287040658295, 0.05495190294459462, 0.05735509400255978, 0.05495201295707375, 0.054536856012418866, 0.056072756997309625, 0.06091322400607169, 0.05557666893582791, 0.05573429598007351, 0.05498210701625794, 0.05469521810300648, 0.054984115064144135, 0.05512681999243796, 0.05496833601500839, 0.05562824697699398, 0.05506066093221307, 0.054800827987492085, 0.054795410949736834, 0.054742748965509236, 0.05510793800931424, 0.055080748978070915, 0.05485160497482866, 0.05483319493941963, 0.05509228503797203, 0.055081159924156964, 0.0549893289571628, 0.05539087799843401, 0.05503234011121094, 0.05516512494068593, 0.05519423901569098, 0.05506596202030778, 0.05500388506334275, 0.05522568104788661, 0.055166949052363634, 0.05515616503544152, 0.05485223501455039, 0.05516809597611427, 0.05521084205247462, 0.05488913890440017, 0.05469115206506103, 0.05500620906241238, 0.05499410000629723, 0.05491086794063449, 0.05507417593616992, 0.055300222942605615, 0.054720325977541506, 0.05480531696230173, 0.0549129550345242, 0.055401296936906874, 0.05478937295265496, 0.05495519598480314, 0.05475806596223265, 0.055268432945013046, 0.055750002968125045, 0.05467670608777553, 0.05484902998432517, 0.05525489000137895, 0.05499524902552366, 0.05472368106711656, 0.05472908902447671, 0.05473870097193867, 0.05486018699593842, 0.05511214805301279, 0.055250686942599714, 0.05486640706658363, 0.0546898830216378, 0.0548831180203706, 0.05511243606451899, 0.05469064903445542, 0.0546749250497669, 0.055032021016813815, 0.05543344502802938, 0.055045197950676084, 0.0551261599175632, 0.055113900918513536, 0.05498415697365999, 0.05494699999690056, 0.054943945026025176, 0.0550080529646948, 0.055092668044380844, 0.055022831074893475, 0.05502410407643765, 0.05570583697408438, 0.054781766957603395, 0.05508683901280165]
[0.0012740769995037806, 0.0012447241355072367, 0.0012465038638434965, 0.0012676169783596627, 0.0012418523864735935, 0.0012441719088449397, 0.0014348719083831054, 0.0012413934984413738, 0.0012515292037278414, 0.001461526249344884, 0.0013490590896584433, 0.0012316064993766222, 0.0012421158184720712, 0.0012486600687473335, 0.0012421028169972653, 0.0012425405915233898, 0.0012472938185303726, 0.0012504736818796532, 0.001247569728134708, 0.0012401413167191838, 0.0012539659536824647, 0.0012491617738057605, 0.0012419992735059086, 0.0012683986834335055, 0.0012450033391360193, 0.0012449699755631048, 0.0012400065236513249, 0.0012489068851044233, 0.0013035248636945405, 0.0012489093853880397, 0.001239474000282247, 0.001274380840847946, 0.0013843914546834474, 0.001263106112177907, 0.0012666885450016707, 0.0012495933412785896, 0.0012430731387046928, 0.0012496389787305486, 0.0012528822725554082, 0.0012492803639774634, 0.0012642783403862268, 0.001251378657550297, 0.0012454733633520928, 0.0012453502488576553, 0.0012441533855797554, 0.0012524531365753237, 0.0012518352040470663, 0.0012466273857915605, 0.0012462089758959007, 0.001252097387226637, 0.00125184454373084, 0.0012497574762991544, 0.0012588835908735002, 0.0012507350025275214, 0.0012537528395610439, 0.001254414523083886, 0.0012514991368251767, 0.0012500882968941535, 0.0012551291147246957, 0.001253794296644628, 0.0012535492053509436, 0.0012466417048761452, 0.001253820363093506, 0.0012547918648289685, 0.0012474804296454583, 0.001242980728751387, 0.0012501411150548267, 0.0012498659092340279, 0.0012479742713780565, 0.0012516858167311345, 0.0012568232486955822, 0.0012436437722168523, 0.0012455753855068576, 0.0012480217053300955, 0.0012591203849297017, 0.001245213021651249, 0.0012489817269273442, 0.001244501499141651, 0.0012561007487502966, 0.0012670455220028418, 0.0012426524110858074, 0.0012465688632801175, 0.0012557929545767945, 0.0012498920233073559, 0.001243720024252649, 0.0012438429323744706, 0.0012440613857258788, 0.0012468224317258732, 0.0012525488193866543, 0.0012556974305136298, 0.00124696379696781, 0.0012429518868554044, 0.0012473435913720591, 0.0012525553651027042, 0.0012429692962376232, 0.0012426119329492476, 0.0012507277503821322, 0.0012598510233643042, 0.0012510272261517291, 0.001252867270853709, 0.001252588657238944, 0.0012496399312195454, 0.0012487954544750128, 0.001248726023318754, 0.0012501830219248818, 0.0012521060919177464, 0.0012505188880657608, 0.0012505478199190375, 0.0012660417494110086, 0.00124504015812735, 0.0012519736139273102]
[784.8819187454712, 803.390865071071, 802.2438028523865, 788.8818287161413, 805.2486840562703, 803.7474507267865, 696.9263208496823, 805.5463487246757, 799.0225054448357, 684.2162434292514, 741.257375355724, 811.9476476505688, 805.0779042731311, 800.8584762410226, 805.0863312728496, 804.8026815558369, 801.735713865922, 799.6969584332611, 801.5584038698506, 806.3597160406831, 797.4698173130981, 800.5368247487662, 805.1534500315814, 788.3956464642797, 803.2106971648434, 803.2322221647923, 806.4473701762461, 800.7002058575314, 767.1506910621795, 800.6986028768589, 806.7938494654062, 784.6947850648957, 722.3390440738153, 791.6991219967679, 789.460048364676, 800.2603462793708, 804.4578946030642, 800.2311203639428, 798.1595892169314, 800.4608323596765, 790.9650652517769, 799.1186312523528, 802.907576689219, 802.9869515963785, 803.7594171188275, 798.4330677109205, 798.8271912845184, 802.16431260656, 802.433636205436, 798.6599207071055, 798.8212314443819, 800.1552452890708, 794.3546228179296, 799.5298748169446, 797.6053720046718, 797.184647975514, 799.04170172807, 799.9434939791868, 796.7307811350894, 797.5789989443837, 797.7349399061204, 802.1550988456228, 797.5624175800875, 796.9449181409083, 801.6157818878218, 804.5177023818633, 799.9096965594508, 800.0858272971406, 801.2985707596081, 798.9225304250632, 795.6568284664284, 804.0887771403011, 802.8418124151302, 801.2681155537315, 794.2052340418834, 803.0754438095439, 800.6522260819049, 803.5345884996627, 796.1144844431524, 789.2376261424939, 804.730261719943, 802.2019717135267, 796.3096116724136, 800.0691110531985, 804.0394787411255, 803.9600290134869, 803.8188561061437, 802.0388265037731, 798.3720750219366, 796.3701889482727, 801.9479013197164, 804.5363706956844, 801.7037221476522, 798.3679028176165, 804.5251021299774, 804.7564758424409, 799.5345107634113, 793.744642386051, 799.3431150783895, 798.1691462963956, 798.3466832633467, 800.2305104191754, 800.7716527286648, 800.8161769082766, 799.8828831160417, 798.6543683917258, 799.6680494340628, 799.6495488391172, 789.8633678275007, 803.1869441898871, 798.7388782604648]
Elapsed: 0.05527689454653342~0.001390219869311327
Time per graph: 0.0012562930578757599~3.159590612071198e-05
Speed: 796.4415501000886~17.865606860644792
Total Time: 0.0556
best val loss: 0.34393319487571716 test_score: 0.8182

Testing...
Test loss: 0.3559 score: 0.8182 time: 0.05s
test Score 0.8182
Epoch Time List: [0.17416391905862838, 0.1662289429223165, 0.1667760421987623, 0.16714738903101534, 0.16583566705230623, 0.16803856601472944, 0.17538854503072798, 0.1692471110727638, 0.16876224894076586, 0.17481354298070073, 0.19191436504479498, 0.1705856800545007, 0.1694756291108206, 0.166002290090546, 0.1670925960643217, 0.16571160696912557, 0.16629792505409569, 0.1675507149193436, 0.1657487970078364, 0.16606899700127542, 0.16728305292781442, 0.1667379600694403, 0.16676358506083488, 0.1668009030399844, 0.1654514839174226, 0.1657724060351029, 0.16651317290961742, 0.16509151994250715, 0.17723409889731556, 0.16721378185320646, 0.16572747996542603, 0.17144367576111108, 0.1733564439928159, 0.17107939103152603, 0.17462804506067187, 0.16787672485224903, 0.1677376281004399, 0.16726452705916017, 0.16574953694362193, 0.16632346890401095, 0.1674699210561812, 0.16696450510062277, 0.16717754502315074, 0.1675423220731318, 0.16773859516251832, 0.16666803299449384, 0.16610269714146852, 0.16827845806255937, 0.16769641893915832, 0.1685347140301019, 0.16687704587820917, 0.16800815903116018, 0.16763456887565553, 0.16716203407850116, 0.1682756330119446, 0.16731810790952295, 0.16872109204996377, 0.16844974900595844, 0.1687218361767009, 0.16789336293004453, 0.16913865495007485, 0.16827536409255117, 0.16743544209748507, 0.16799596999771893, 0.17006412101909518, 0.1688115200959146, 0.16888731205835938, 0.1692244311561808, 0.17105668399017304, 0.1696013188920915, 0.1703454969683662, 0.1701142778620124, 0.16979105595964938, 0.17068958503659815, 0.17052213998977095, 0.16970460605807602, 0.16944034304469824, 0.16964918817393482, 0.17001892905682325, 0.17096456291619688, 0.16916687309276313, 0.1689689529594034, 0.17092058213893324, 0.16915106098167598, 0.17013870098162442, 0.16848658095113933, 0.1697368489112705, 0.1699685329804197, 0.16952783009037375, 0.1695229740580544, 0.17024746409151703, 0.17004889505915344, 0.16984104691073298, 0.1705647560302168, 0.16965015907771885, 0.1697356681106612, 0.16989184799604118, 0.17197396187111735, 0.16942163521889597, 0.1690064910799265, 0.17018617212306708, 0.16995368199422956, 0.16904993099160492, 0.17055233183782548, 0.1699315841542557, 0.16885710204951465, 0.1691651149885729, 0.1702925229910761, 0.17049144499469548, 0.1691775229992345, 0.16882856702432036]
Total Epoch List: [111]
Total Time List: [0.05564188398420811]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a2743af0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6943;  Loss pred: 0.6943; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6952;  Loss pred: 0.6952; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6957;  Loss pred: 0.6957; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6939;  Loss pred: 0.6939; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6943;  Loss pred: 0.6943; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6909;  Loss pred: 0.6909; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6900;  Loss pred: 0.6900; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6872;  Loss pred: 0.6872; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6952 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6865;  Loss pred: 0.6865; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6811;  Loss pred: 0.6811; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6802;  Loss pred: 0.6802; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6947 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6782;  Loss pred: 0.6782; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6726;  Loss pred: 0.6726; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.10s
Epoch 15/1000, LR 0.000270
Train loss: 0.6675;  Loss pred: 0.6675; Loss self: 0.0000; time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6663;  Loss pred: 0.6663; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6605;  Loss pred: 0.6605; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6936 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6611;  Loss pred: 0.6611; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6547;  Loss pred: 0.6547; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6484;  Loss pred: 0.6484; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6401;  Loss pred: 0.6401; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6349;  Loss pred: 0.6349; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6282;  Loss pred: 0.6282; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6242;  Loss pred: 0.6242; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6922 score: 0.5000 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6195;  Loss pred: 0.6195; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6062;  Loss pred: 0.6062; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6917 score: 0.5000 time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6910 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5986;  Loss pred: 0.5986; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6914 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.4884 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5892;  Loss pred: 0.5892; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6911 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6901 score: 0.4884 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5760;  Loss pred: 0.5760; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6907 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.4884 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5684;  Loss pred: 0.5684; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6902 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6889 score: 0.4884 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5617;  Loss pred: 0.5617; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6898 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6882 score: 0.4884 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5501;  Loss pred: 0.5501; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6892 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6874 score: 0.4884 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5411;  Loss pred: 0.5411; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6886 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6865 score: 0.4884 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5328;  Loss pred: 0.5328; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6878 score: 0.5000 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6854 score: 0.4884 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5161;  Loss pred: 0.5161; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6870 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6841 score: 0.4884 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5064;  Loss pred: 0.5064; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6860 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6827 score: 0.4884 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4920;  Loss pred: 0.4920; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6850 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6812 score: 0.4884 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4758;  Loss pred: 0.4758; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6838 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6795 score: 0.4884 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4638;  Loss pred: 0.4638; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6824 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6777 score: 0.4884 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4586;  Loss pred: 0.4586; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6809 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6756 score: 0.4884 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4383;  Loss pred: 0.4383; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6793 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6733 score: 0.4884 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4313;  Loss pred: 0.4313; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6774 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6707 score: 0.4884 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4116;  Loss pred: 0.4116; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6754 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6680 score: 0.4884 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.4003;  Loss pred: 0.4003; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6732 score: 0.5000 time: 0.11s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6649 score: 0.4884 time: 0.06s
Epoch 45/1000, LR 0.000269
Train loss: 0.3890;  Loss pred: 0.3890; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6706 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6616 score: 0.4884 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3792;  Loss pred: 0.3792; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6679 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6579 score: 0.4884 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3605;  Loss pred: 0.3605; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6647 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6538 score: 0.4884 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3415;  Loss pred: 0.3415; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6613 score: 0.5000 time: 0.05s
Test loss: 0.6494 score: 0.5116 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3390;  Loss pred: 0.3390; Loss self: 0.0000; time: 0.07s
Val loss: 0.6576 score: 0.5455 time: 0.05s
Test loss: 0.6446 score: 0.5349 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3148;  Loss pred: 0.3148; Loss self: 0.0000; time: 0.07s
Val loss: 0.6535 score: 0.5682 time: 0.05s
Test loss: 0.6393 score: 0.5814 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3076;  Loss pred: 0.3076; Loss self: 0.0000; time: 0.07s
Val loss: 0.6489 score: 0.6136 time: 0.05s
Test loss: 0.6336 score: 0.6047 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2836;  Loss pred: 0.2836; Loss self: 0.0000; time: 0.07s
Val loss: 0.6439 score: 0.6818 time: 0.05s
Test loss: 0.6273 score: 0.6512 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2781;  Loss pred: 0.2781; Loss self: 0.0000; time: 0.07s
Val loss: 0.6387 score: 0.7273 time: 0.05s
Test loss: 0.6208 score: 0.7209 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2633;  Loss pred: 0.2633; Loss self: 0.0000; time: 0.07s
Val loss: 0.6332 score: 0.7273 time: 0.05s
Test loss: 0.6139 score: 0.7442 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2448;  Loss pred: 0.2448; Loss self: 0.0000; time: 0.07s
Val loss: 0.6272 score: 0.7273 time: 0.05s
Test loss: 0.6066 score: 0.7442 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2414;  Loss pred: 0.2414; Loss self: 0.0000; time: 0.08s
Val loss: 0.6209 score: 0.7727 time: 0.14s
Test loss: 0.5988 score: 0.7907 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2244;  Loss pred: 0.2244; Loss self: 0.0000; time: 0.07s
Val loss: 0.6139 score: 0.7727 time: 0.06s
Test loss: 0.5902 score: 0.8140 time: 0.05s
Epoch 58/1000, LR 0.000269
Train loss: 0.2075;  Loss pred: 0.2075; Loss self: 0.0000; time: 0.07s
Val loss: 0.6067 score: 0.7727 time: 0.06s
Test loss: 0.5814 score: 0.8372 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2013;  Loss pred: 0.2013; Loss self: 0.0000; time: 0.07s
Val loss: 0.5992 score: 0.7727 time: 0.06s
Test loss: 0.5723 score: 0.8837 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1901;  Loss pred: 0.1901; Loss self: 0.0000; time: 0.08s
Val loss: 0.5911 score: 0.8182 time: 0.06s
Test loss: 0.5625 score: 0.8837 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1802;  Loss pred: 0.1802; Loss self: 0.0000; time: 0.07s
Val loss: 0.5827 score: 0.8182 time: 0.06s
Test loss: 0.5527 score: 0.8837 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1657;  Loss pred: 0.1657; Loss self: 0.0000; time: 0.08s
Val loss: 0.5741 score: 0.8182 time: 0.06s
Test loss: 0.5428 score: 0.8837 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1563;  Loss pred: 0.1563; Loss self: 0.0000; time: 0.08s
Val loss: 0.5653 score: 0.8182 time: 0.06s
Test loss: 0.5327 score: 0.8837 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1429;  Loss pred: 0.1429; Loss self: 0.0000; time: 0.08s
Val loss: 0.5566 score: 0.8182 time: 0.05s
Test loss: 0.5227 score: 0.8837 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1350;  Loss pred: 0.1350; Loss self: 0.0000; time: 0.07s
Val loss: 0.5480 score: 0.8182 time: 0.05s
Test loss: 0.5129 score: 0.8837 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1214;  Loss pred: 0.1214; Loss self: 0.0000; time: 0.07s
Val loss: 0.5389 score: 0.8182 time: 0.17s
Test loss: 0.5024 score: 0.8837 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1120;  Loss pred: 0.1120; Loss self: 0.0000; time: 0.07s
Val loss: 0.5296 score: 0.8182 time: 0.05s
Test loss: 0.4915 score: 0.8837 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1045;  Loss pred: 0.1045; Loss self: 0.0000; time: 0.07s
Val loss: 0.5202 score: 0.8182 time: 0.05s
Test loss: 0.4807 score: 0.8837 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0978;  Loss pred: 0.0978; Loss self: 0.0000; time: 0.07s
Val loss: 0.5108 score: 0.8182 time: 0.05s
Test loss: 0.4696 score: 0.8837 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0846;  Loss pred: 0.0846; Loss self: 0.0000; time: 0.07s
Val loss: 0.5009 score: 0.8182 time: 0.05s
Test loss: 0.4579 score: 0.8837 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0866;  Loss pred: 0.0866; Loss self: 0.0000; time: 0.07s
Val loss: 0.4919 score: 0.8182 time: 0.05s
Test loss: 0.4472 score: 0.8837 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0753;  Loss pred: 0.0753; Loss self: 0.0000; time: 0.07s
Val loss: 0.4831 score: 0.8182 time: 0.05s
Test loss: 0.4367 score: 0.8837 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0733;  Loss pred: 0.0733; Loss self: 0.0000; time: 0.07s
Val loss: 0.4736 score: 0.8409 time: 0.05s
Test loss: 0.4253 score: 0.8837 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0670;  Loss pred: 0.0670; Loss self: 0.0000; time: 0.07s
Val loss: 0.4650 score: 0.8409 time: 0.05s
Test loss: 0.4147 score: 0.8837 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0611;  Loss pred: 0.0611; Loss self: 0.0000; time: 0.07s
Val loss: 0.4577 score: 0.8409 time: 0.05s
Test loss: 0.4056 score: 0.8837 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0554;  Loss pred: 0.0554; Loss self: 0.0000; time: 0.07s
Val loss: 0.4519 score: 0.8409 time: 0.19s
Test loss: 0.3981 score: 0.8837 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0515;  Loss pred: 0.0515; Loss self: 0.0000; time: 0.07s
Val loss: 0.4468 score: 0.8409 time: 0.05s
Test loss: 0.3914 score: 0.8837 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0446;  Loss pred: 0.0446; Loss self: 0.0000; time: 0.07s
Val loss: 0.4416 score: 0.8409 time: 0.05s
Test loss: 0.3847 score: 0.8837 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0440;  Loss pred: 0.0440; Loss self: 0.0000; time: 0.07s
Val loss: 0.4360 score: 0.8409 time: 0.05s
Test loss: 0.3774 score: 0.8837 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0396;  Loss pred: 0.0396; Loss self: 0.0000; time: 0.07s
Val loss: 0.4317 score: 0.8182 time: 0.05s
Test loss: 0.3713 score: 0.8837 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0387;  Loss pred: 0.0387; Loss self: 0.0000; time: 0.07s
Val loss: 0.4280 score: 0.8182 time: 0.05s
Test loss: 0.3658 score: 0.8837 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0328;  Loss pred: 0.0328; Loss self: 0.0000; time: 0.07s
Val loss: 0.4231 score: 0.8182 time: 0.05s
Test loss: 0.3588 score: 0.8837 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0281;  Loss pred: 0.0281; Loss self: 0.0000; time: 0.07s
Val loss: 0.4179 score: 0.8409 time: 0.05s
Test loss: 0.3515 score: 0.8837 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0254;  Loss pred: 0.0254; Loss self: 0.0000; time: 0.07s
Val loss: 0.4119 score: 0.8636 time: 0.05s
Test loss: 0.3433 score: 0.8837 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.07s
Val loss: 0.4066 score: 0.8864 time: 0.05s
Test loss: 0.3362 score: 0.8837 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0244;  Loss pred: 0.0244; Loss self: 0.0000; time: 0.07s
Val loss: 0.4008 score: 0.8636 time: 0.18s
Test loss: 0.3288 score: 0.8837 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0222;  Loss pred: 0.0222; Loss self: 0.0000; time: 0.07s
Val loss: 0.3957 score: 0.8636 time: 0.06s
Test loss: 0.3219 score: 0.8837 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0187;  Loss pred: 0.0187; Loss self: 0.0000; time: 0.07s
Val loss: 0.3918 score: 0.8636 time: 0.05s
Test loss: 0.3161 score: 0.8837 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0180;  Loss pred: 0.0180; Loss self: 0.0000; time: 0.07s
Val loss: 0.3884 score: 0.8636 time: 0.05s
Test loss: 0.3111 score: 0.8837 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.07s
Val loss: 0.3857 score: 0.8636 time: 0.05s
Test loss: 0.3069 score: 0.8837 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0151;  Loss pred: 0.0151; Loss self: 0.0000; time: 0.07s
Val loss: 0.3837 score: 0.8636 time: 0.05s
Test loss: 0.3035 score: 0.8837 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0150;  Loss pred: 0.0150; Loss self: 0.0000; time: 0.07s
Val loss: 0.3824 score: 0.8636 time: 0.05s
Test loss: 0.3008 score: 0.8837 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.07s
Val loss: 0.3813 score: 0.8636 time: 0.05s
Test loss: 0.2981 score: 0.8837 time: 0.05s
Epoch 94/1000, LR 0.000265
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.07s
Val loss: 0.3804 score: 0.8636 time: 0.05s
Test loss: 0.2955 score: 0.8837 time: 0.05s
Epoch 95/1000, LR 0.000265
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.07s
Val loss: 0.3801 score: 0.8636 time: 0.05s
Test loss: 0.2933 score: 0.8837 time: 0.05s
Epoch 96/1000, LR 0.000265
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.07s
Val loss: 0.3808 score: 0.8636 time: 0.05s
Test loss: 0.2918 score: 0.8837 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0111;  Loss pred: 0.0111; Loss self: 0.0000; time: 0.17s
Val loss: 0.3822 score: 0.8636 time: 0.05s
Test loss: 0.2914 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.07s
Val loss: 0.3840 score: 0.8636 time: 0.05s
Test loss: 0.2915 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0102;  Loss pred: 0.0102; Loss self: 0.0000; time: 0.07s
Val loss: 0.3870 score: 0.8636 time: 0.05s
Test loss: 0.2918 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0089;  Loss pred: 0.0089; Loss self: 0.0000; time: 0.07s
Val loss: 0.3902 score: 0.8636 time: 0.05s
Test loss: 0.2926 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.07s
Val loss: 0.3939 score: 0.8636 time: 0.05s
Test loss: 0.2938 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0082;  Loss pred: 0.0082; Loss self: 0.0000; time: 0.07s
Val loss: 0.3975 score: 0.8636 time: 0.05s
Test loss: 0.2950 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.07s
Val loss: 0.4016 score: 0.8636 time: 0.05s
Test loss: 0.2967 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0071;  Loss pred: 0.0071; Loss self: 0.0000; time: 0.07s
Val loss: 0.4059 score: 0.8636 time: 0.05s
Test loss: 0.2986 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0069;  Loss pred: 0.0069; Loss self: 0.0000; time: 0.07s
Val loss: 0.4102 score: 0.8636 time: 0.05s
Test loss: 0.3002 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.4146 score: 0.8636 time: 0.05s
Test loss: 0.3024 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0070;  Loss pred: 0.0070; Loss self: 0.0000; time: 0.07s
Val loss: 0.4186 score: 0.8636 time: 0.05s
Test loss: 0.3036 score: 0.9070 time: 0.18s
     INFO: Early stopping counter 12 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0072;  Loss pred: 0.0072; Loss self: 0.0000; time: 0.07s
Val loss: 0.4230 score: 0.8636 time: 0.05s
Test loss: 0.3048 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0073;  Loss pred: 0.0073; Loss self: 0.0000; time: 0.07s
Val loss: 0.4285 score: 0.8636 time: 0.06s
Test loss: 0.3057 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0061;  Loss pred: 0.0061; Loss self: 0.0000; time: 0.07s
Val loss: 0.4334 score: 0.8636 time: 0.05s
Test loss: 0.3062 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0048;  Loss pred: 0.0048; Loss self: 0.0000; time: 0.07s
Val loss: 0.4388 score: 0.8636 time: 0.06s
Test loss: 0.3074 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.4439 score: 0.8636 time: 0.05s
Test loss: 0.3077 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 113/1000, LR 0.000263
Train loss: 0.0051;  Loss pred: 0.0051; Loss self: 0.0000; time: 0.07s
Val loss: 0.4486 score: 0.8636 time: 0.05s
Test loss: 0.3078 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 114/1000, LR 0.000263
Train loss: 0.0045;  Loss pred: 0.0045; Loss self: 0.0000; time: 0.07s
Val loss: 0.4531 score: 0.8636 time: 0.05s
Test loss: 0.3078 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 115/1000, LR 0.000263
Train loss: 0.0043;  Loss pred: 0.0043; Loss self: 0.0000; time: 0.07s
Val loss: 0.4578 score: 0.8636 time: 0.05s
Test loss: 0.3082 score: 0.9070 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 094,   Train_Loss: 0.0122,   Val_Loss: 0.3801,   Val_Precision: 0.9444,   Val_Recall: 0.7727,   Val_accuracy: 0.8500,   Val_Score: 0.8636,   Val_Loss: 0.3801,   Test_Precision: 1.0000,   Test_Recall: 0.7727,   Test_accuracy: 0.8718,   Test_Score: 0.8837,   Test_loss: 0.2933


[0.05605938797816634, 0.05476786196231842, 0.05484617000911385, 0.05577514704782516, 0.05464150500483811, 0.054743563989177346, 0.06313436396885663, 0.054621313931420445, 0.05506728496402502, 0.0643071549711749, 0.0593585999449715, 0.05419068597257137, 0.05465309601277113, 0.054941043024882674, 0.05465252394787967, 0.05467178602702916, 0.054880928015336394, 0.05502084200270474, 0.05489306803792715, 0.05456621793564409, 0.055174501962028444, 0.05496311804745346, 0.054647968034259975, 0.05580954207107425, 0.05478014692198485, 0.054778678924776614, 0.054560287040658295, 0.05495190294459462, 0.05735509400255978, 0.05495201295707375, 0.054536856012418866, 0.056072756997309625, 0.06091322400607169, 0.05557666893582791, 0.05573429598007351, 0.05498210701625794, 0.05469521810300648, 0.054984115064144135, 0.05512681999243796, 0.05496833601500839, 0.05562824697699398, 0.05506066093221307, 0.054800827987492085, 0.054795410949736834, 0.054742748965509236, 0.05510793800931424, 0.055080748978070915, 0.05485160497482866, 0.05483319493941963, 0.05509228503797203, 0.055081159924156964, 0.0549893289571628, 0.05539087799843401, 0.05503234011121094, 0.05516512494068593, 0.05519423901569098, 0.05506596202030778, 0.05500388506334275, 0.05522568104788661, 0.055166949052363634, 0.05515616503544152, 0.05485223501455039, 0.05516809597611427, 0.05521084205247462, 0.05488913890440017, 0.05469115206506103, 0.05500620906241238, 0.05499410000629723, 0.05491086794063449, 0.05507417593616992, 0.055300222942605615, 0.054720325977541506, 0.05480531696230173, 0.0549129550345242, 0.055401296936906874, 0.05478937295265496, 0.05495519598480314, 0.05475806596223265, 0.055268432945013046, 0.055750002968125045, 0.05467670608777553, 0.05484902998432517, 0.05525489000137895, 0.05499524902552366, 0.05472368106711656, 0.05472908902447671, 0.05473870097193867, 0.05486018699593842, 0.05511214805301279, 0.055250686942599714, 0.05486640706658363, 0.0546898830216378, 0.0548831180203706, 0.05511243606451899, 0.05469064903445542, 0.0546749250497669, 0.055032021016813815, 0.05543344502802938, 0.055045197950676084, 0.0551261599175632, 0.055113900918513536, 0.05498415697365999, 0.05494699999690056, 0.054943945026025176, 0.0550080529646948, 0.055092668044380844, 0.055022831074893475, 0.05502410407643765, 0.05570583697408438, 0.054781766957603395, 0.05508683901280165, 0.05254832096397877, 0.05234099493827671, 0.05251458508428186, 0.05175453098490834, 0.052179376943968236, 0.052177570993080735, 0.05198464193381369, 0.05213740898761898, 0.052262049983255565, 0.05191285803448409, 0.05276494403369725, 0.05187765194568783, 0.05172313703224063, 0.10581669502425939, 0.05698871100321412, 0.056325521087273955, 0.055918785044923425, 0.05599945690482855, 0.05602825898677111, 0.053694973001256585, 0.05281385802663863, 0.057482045027427375, 0.05348531005438417, 0.052873644046485424, 0.05234360904432833, 0.05337998108007014, 0.05163475195877254, 0.05227033200208098, 0.05224631307646632, 0.052942469948902726, 0.05313042795751244, 0.05203821905888617, 0.05189004901330918, 0.051762035000137985, 0.05175084399525076, 0.05176861898507923, 0.05224263097625226, 0.05183264205697924, 0.05152995907701552, 0.05192885105498135, 0.052049002959392965, 0.05144030100200325, 0.05134593800175935, 0.06987058103550225, 0.05231500801164657, 0.052009679027833045, 0.05252508900593966, 0.05193165992386639, 0.05199080903548747, 0.052427925053052604, 0.052025580080226064, 0.05215162900276482, 0.05168507096823305, 0.051519216038286686, 0.051511220051907, 0.05666154599748552, 0.0568456839537248, 0.057134903967380524, 0.0572567320195958, 0.057519151945598423, 0.05698069406207651, 0.05850387807004154, 0.05775490100495517, 0.05342970206402242, 0.052867676015011966, 0.05192924395669252, 0.051995552028529346, 0.051484090043231845, 0.05191911302972585, 0.051898321020416915, 0.05208897695410997, 0.05294131103437394, 0.052585733006708324, 0.05183518398553133, 0.05164628103375435, 0.05754600989166647, 0.05157466104719788, 0.05274107703007758, 0.05257321603130549, 0.05348884698469192, 0.05277076701167971, 0.054880861076526344, 0.05295655608642846, 0.05274054198525846, 0.05128402600530535, 0.05680395395029336, 0.0513569179456681, 0.05112328298855573, 0.0509703760035336, 0.05123263201676309, 0.05133143102284521, 0.05275435897056013, 0.052654596976935863, 0.051511794910766184, 0.05101102695334703, 0.05900959298014641, 0.051705469959415495, 0.051270366995595396, 0.051299965009093285, 0.05227570200804621, 0.05132996500469744, 0.05185047199483961, 0.05316168593708426, 0.05365363205783069, 0.053359249024651945, 0.05206910101696849, 0.1870371230179444, 0.055588218034245074, 0.055058489087969065, 0.056803713901899755, 0.05562730797100812, 0.05297379510011524, 0.054347440018318594, 0.052574411034584045, 0.05178079893812537]
[0.0012740769995037806, 0.0012447241355072367, 0.0012465038638434965, 0.0012676169783596627, 0.0012418523864735935, 0.0012441719088449397, 0.0014348719083831054, 0.0012413934984413738, 0.0012515292037278414, 0.001461526249344884, 0.0013490590896584433, 0.0012316064993766222, 0.0012421158184720712, 0.0012486600687473335, 0.0012421028169972653, 0.0012425405915233898, 0.0012472938185303726, 0.0012504736818796532, 0.001247569728134708, 0.0012401413167191838, 0.0012539659536824647, 0.0012491617738057605, 0.0012419992735059086, 0.0012683986834335055, 0.0012450033391360193, 0.0012449699755631048, 0.0012400065236513249, 0.0012489068851044233, 0.0013035248636945405, 0.0012489093853880397, 0.001239474000282247, 0.001274380840847946, 0.0013843914546834474, 0.001263106112177907, 0.0012666885450016707, 0.0012495933412785896, 0.0012430731387046928, 0.0012496389787305486, 0.0012528822725554082, 0.0012492803639774634, 0.0012642783403862268, 0.001251378657550297, 0.0012454733633520928, 0.0012453502488576553, 0.0012441533855797554, 0.0012524531365753237, 0.0012518352040470663, 0.0012466273857915605, 0.0012462089758959007, 0.001252097387226637, 0.00125184454373084, 0.0012497574762991544, 0.0012588835908735002, 0.0012507350025275214, 0.0012537528395610439, 0.001254414523083886, 0.0012514991368251767, 0.0012500882968941535, 0.0012551291147246957, 0.001253794296644628, 0.0012535492053509436, 0.0012466417048761452, 0.001253820363093506, 0.0012547918648289685, 0.0012474804296454583, 0.001242980728751387, 0.0012501411150548267, 0.0012498659092340279, 0.0012479742713780565, 0.0012516858167311345, 0.0012568232486955822, 0.0012436437722168523, 0.0012455753855068576, 0.0012480217053300955, 0.0012591203849297017, 0.001245213021651249, 0.0012489817269273442, 0.001244501499141651, 0.0012561007487502966, 0.0012670455220028418, 0.0012426524110858074, 0.0012465688632801175, 0.0012557929545767945, 0.0012498920233073559, 0.001243720024252649, 0.0012438429323744706, 0.0012440613857258788, 0.0012468224317258732, 0.0012525488193866543, 0.0012556974305136298, 0.00124696379696781, 0.0012429518868554044, 0.0012473435913720591, 0.0012525553651027042, 0.0012429692962376232, 0.0012426119329492476, 0.0012507277503821322, 0.0012598510233643042, 0.0012510272261517291, 0.001252867270853709, 0.001252588657238944, 0.0012496399312195454, 0.0012487954544750128, 0.001248726023318754, 0.0012501830219248818, 0.0012521060919177464, 0.0012505188880657608, 0.0012505478199190375, 0.0012660417494110086, 0.00124504015812735, 0.0012519736139273102, 0.0012220539759064829, 0.0012172324404250397, 0.0012212694205646945, 0.0012035937438350777, 0.001213473882417866, 0.001213431883560017, 0.0012089451612514812, 0.0012124978834329996, 0.0012153965112385015, 0.001207275768243816, 0.0012270917217138894, 0.0012064570219927403, 0.0012028636519125727, 0.0024608533726571953, 0.0013253188605398634, 0.0013098958392389292, 0.001300436861509847, 0.0013023129512750825, 0.0013029827671342117, 0.0012487203023548042, 0.0012282292564334565, 0.0013367917448238924, 0.0012438444198693993, 0.001229619628988033, 0.001217293233589031, 0.0012413949088388404, 0.0012008081850877336, 0.0012155891163274646, 0.0012150305366620076, 0.001231220231369831, 0.0012355913478491265, 0.0012101911409043294, 0.0012067453258909112, 0.0012037682558171624, 0.0012035079998895526, 0.0012039213717460286, 0.0012149449064244712, 0.001205410280394866, 0.0011983711413259422, 0.0012076476989530546, 0.0012104419292882085, 0.001196286069814029, 0.001194091581436264, 0.0016248972333837734, 0.0012166280932941061, 0.0012095274192519313, 0.0012215136978125504, 0.001207713021485265, 0.001209088582220639, 0.0012192540710012233, 0.001209897211168048, 0.001212828581459647, 0.001201978394610071, 0.0011981213032159694, 0.001197935350044349, 0.001317710372034547, 0.0013219926500866233, 0.001328718696915826, 0.0013315519074324606, 0.0013376546964092657, 0.001325132420048291, 0.0013605553039544543, 0.0013431372326733761, 0.001242551210791219, 0.0012294808375584178, 0.0012076568362021515, 0.0012091988843844035, 0.0011973044196100428, 0.0012074212332494384, 0.0012069376981492306, 0.0012113715570723248, 0.0012311932798691613, 0.0012229240234118215, 0.0012054693950123566, 0.0012010763031105663, 0.001338279299806197, 0.0011994107220278576, 0.0012265366751180833, 0.0012226329309605929, 0.0012439266740626028, 0.001227227139806505, 0.0012762990948029381, 0.0012315478159634526, 0.001226524232215313, 0.0011926517675652406, 0.0013210221848905432, 0.0011943469289690256, 0.001188913557873389, 0.0011853575814775256, 0.0011914565585293743, 0.0011937542098336095, 0.0012268455574548868, 0.0012245255110915317, 0.0011979487188550275, 0.0011863029524034193, 0.0013723161158173583, 0.0012024527897538488, 0.001192334116176637, 0.0011930224420719367, 0.001215714000187121, 0.0011937201163883125, 0.0012058249301125491, 0.0012363182776066106, 0.00124775888506583, 0.0012409127680151615, 0.0012109093259760114, 0.004349700535301032, 0.0012927492566103505, 0.0012804299787899783, 0.0013210166023697617, 0.0012936583249071657, 0.001231948723258494, 0.001263893953914386, 0.0012226607217345126, 0.001204204626468032]
[784.8819187454712, 803.390865071071, 802.2438028523865, 788.8818287161413, 805.2486840562703, 803.7474507267865, 696.9263208496823, 805.5463487246757, 799.0225054448357, 684.2162434292514, 741.257375355724, 811.9476476505688, 805.0779042731311, 800.8584762410226, 805.0863312728496, 804.8026815558369, 801.735713865922, 799.6969584332611, 801.5584038698506, 806.3597160406831, 797.4698173130981, 800.5368247487662, 805.1534500315814, 788.3956464642797, 803.2106971648434, 803.2322221647923, 806.4473701762461, 800.7002058575314, 767.1506910621795, 800.6986028768589, 806.7938494654062, 784.6947850648957, 722.3390440738153, 791.6991219967679, 789.460048364676, 800.2603462793708, 804.4578946030642, 800.2311203639428, 798.1595892169314, 800.4608323596765, 790.9650652517769, 799.1186312523528, 802.907576689219, 802.9869515963785, 803.7594171188275, 798.4330677109205, 798.8271912845184, 802.16431260656, 802.433636205436, 798.6599207071055, 798.8212314443819, 800.1552452890708, 794.3546228179296, 799.5298748169446, 797.6053720046718, 797.184647975514, 799.04170172807, 799.9434939791868, 796.7307811350894, 797.5789989443837, 797.7349399061204, 802.1550988456228, 797.5624175800875, 796.9449181409083, 801.6157818878218, 804.5177023818633, 799.9096965594508, 800.0858272971406, 801.2985707596081, 798.9225304250632, 795.6568284664284, 804.0887771403011, 802.8418124151302, 801.2681155537315, 794.2052340418834, 803.0754438095439, 800.6522260819049, 803.5345884996627, 796.1144844431524, 789.2376261424939, 804.730261719943, 802.2019717135267, 796.3096116724136, 800.0691110531985, 804.0394787411255, 803.9600290134869, 803.8188561061437, 802.0388265037731, 798.3720750219366, 796.3701889482727, 801.9479013197164, 804.5363706956844, 801.7037221476522, 798.3679028176165, 804.5251021299774, 804.7564758424409, 799.5345107634113, 793.744642386051, 799.3431150783895, 798.1691462963956, 798.3466832633467, 800.2305104191754, 800.7716527286648, 800.8161769082766, 799.8828831160417, 798.6543683917258, 799.6680494340628, 799.6495488391172, 789.8633678275007, 803.1869441898871, 798.7388782604648, 818.2944613868058, 821.5357780399072, 818.8201416994596, 830.8451295315348, 824.0803650487179, 824.1088878150772, 827.1673786797869, 824.743707732219, 822.7767570115778, 828.3111665983877, 814.9350063280449, 828.8732891191356, 831.3494205348908, 406.3630979038032, 754.5354025918367, 763.4194796595555, 768.9723581343037, 767.8645897062678, 767.4698585610661, 800.8198458167341, 814.1802475083596, 748.0596763647272, 803.9590675697187, 813.2596263309425, 821.494749503889, 805.5454335118603, 832.772471422601, 822.6463914231134, 823.0245823674933, 812.2023781946956, 809.3290728692496, 826.3157498019183, 828.6752627458688, 830.7246807411141, 830.904323105265, 830.6190283421213, 823.0825897636425, 829.5930574546136, 834.466022682711, 828.0560637567805, 826.1445475439228, 835.9204585199733, 837.4567039466027, 615.4235353810938, 821.9438672441219, 826.7691861160785, 818.6563947590352, 828.0112760316055, 827.0692608504977, 820.1735994031359, 826.5164931115008, 824.5188275465058, 831.9617095317309, 834.6400296162193, 834.769589162703, 758.8921065074402, 756.4338575819428, 752.6047479584383, 751.0033926715113, 747.5770859881483, 754.6415625115849, 734.994010970006, 744.5255597669667, 804.7958034367293, 813.3514321263146, 828.0497986040535, 826.9938162480977, 835.2094785766312, 828.2113751708492, 828.5431812540468, 825.5105497249966, 812.2201577531919, 817.7122869907417, 829.5523753133107, 832.5865704037157, 747.2281758709225, 833.7427552000605, 815.3037901648773, 817.9069732845527, 803.9059060724613, 814.8450825147728, 783.5154033031739, 811.9863370612936, 815.312061298478, 838.467713037031, 756.989558114694, 837.2776583963018, 841.1040427436129, 843.6272865049879, 839.308821493508, 837.6933809007335, 815.0985215078889, 816.6428473250904, 834.7602733410638, 842.9549955801979, 728.6950786877519, 831.6334815978161, 838.6910903854872, 838.2071994079907, 822.5618853168437, 837.7173059842311, 829.3077834330911, 808.8532039952532, 801.4368897459235, 805.858417912404, 825.8256655129687, 229.90088441359615, 773.5452137269427, 780.9876499025835, 756.9927570979105, 773.0016347800035, 811.7220961559248, 791.2056204580423, 817.8883824626035, 830.423648954937]
Elapsed: 0.05506280166987099~0.009708827369276135
Time per graph: 0.0012661807622933357~0.00022589155477322848
Speed: 798.6492069046066~53.87694623825114
Total Time: 0.0526
best val loss: 0.38013410568237305 test_score: 0.8837

Testing...
Test loss: 0.3362 score: 0.8837 time: 0.05s
test Score 0.8837
Epoch Time List: [0.17416391905862838, 0.1662289429223165, 0.1667760421987623, 0.16714738903101534, 0.16583566705230623, 0.16803856601472944, 0.17538854503072798, 0.1692471110727638, 0.16876224894076586, 0.17481354298070073, 0.19191436504479498, 0.1705856800545007, 0.1694756291108206, 0.166002290090546, 0.1670925960643217, 0.16571160696912557, 0.16629792505409569, 0.1675507149193436, 0.1657487970078364, 0.16606899700127542, 0.16728305292781442, 0.1667379600694403, 0.16676358506083488, 0.1668009030399844, 0.1654514839174226, 0.1657724060351029, 0.16651317290961742, 0.16509151994250715, 0.17723409889731556, 0.16721378185320646, 0.16572747996542603, 0.17144367576111108, 0.1733564439928159, 0.17107939103152603, 0.17462804506067187, 0.16787672485224903, 0.1677376281004399, 0.16726452705916017, 0.16574953694362193, 0.16632346890401095, 0.1674699210561812, 0.16696450510062277, 0.16717754502315074, 0.1675423220731318, 0.16773859516251832, 0.16666803299449384, 0.16610269714146852, 0.16827845806255937, 0.16769641893915832, 0.1685347140301019, 0.16687704587820917, 0.16800815903116018, 0.16763456887565553, 0.16716203407850116, 0.1682756330119446, 0.16731810790952295, 0.16872109204996377, 0.16844974900595844, 0.1687218361767009, 0.16789336293004453, 0.16913865495007485, 0.16827536409255117, 0.16743544209748507, 0.16799596999771893, 0.17006412101909518, 0.1688115200959146, 0.16888731205835938, 0.1692244311561808, 0.17105668399017304, 0.1696013188920915, 0.1703454969683662, 0.1701142778620124, 0.16979105595964938, 0.17068958503659815, 0.17052213998977095, 0.16970460605807602, 0.16944034304469824, 0.16964918817393482, 0.17001892905682325, 0.17096456291619688, 0.16916687309276313, 0.1689689529594034, 0.17092058213893324, 0.16915106098167598, 0.17013870098162442, 0.16848658095113933, 0.1697368489112705, 0.1699685329804197, 0.16952783009037375, 0.1695229740580544, 0.17024746409151703, 0.17004889505915344, 0.16984104691073298, 0.1705647560302168, 0.16965015907771885, 0.1697356681106612, 0.16989184799604118, 0.17197396187111735, 0.16942163521889597, 0.1690064910799265, 0.17018617212306708, 0.16995368199422956, 0.16904993099160492, 0.17055233183782548, 0.1699315841542557, 0.16885710204951465, 0.1691651149885729, 0.1702925229910761, 0.17049144499469548, 0.1691775229992345, 0.16882856702432036, 0.1750306359026581, 0.17255921312607825, 0.17176428611855954, 0.17081757495179772, 0.17208024498540908, 0.17174573394004256, 0.17277993401512504, 0.1713310849154368, 0.17186393111478537, 0.17194350401405245, 0.17770277988165617, 0.1717863620724529, 0.1699111128691584, 0.22163875412661582, 0.2228130791336298, 0.18285903602372855, 0.17936196795199066, 0.18224800401367247, 0.18373244302347302, 0.17685088806319982, 0.17419957113452256, 0.1755754449404776, 0.17290977691300213, 0.25604094099253416, 0.16928542591631413, 0.18571392097510397, 0.16931230493355542, 0.1675651960540563, 0.16772795491851866, 0.17185737704858184, 0.17222598800435662, 0.16961909004021436, 0.1672889970941469, 0.2759817660553381, 0.1658636329229921, 0.16445120400749147, 0.1667872698744759, 0.16628411691635847, 0.166761502972804, 0.1661591959418729, 0.16940442589111626, 0.16767863591667265, 0.1660915520042181, 0.24514639202971011, 0.16823213500902057, 0.16774128412362188, 0.16770209884271026, 0.1677225719904527, 0.16719437204301357, 0.16785966407041997, 0.16857014293782413, 0.1716232899343595, 0.16905148013029248, 0.16527451912406832, 0.16656598600093275, 0.2703460808843374, 0.1822080999845639, 0.18097230303101242, 0.18199651991017163, 0.18452706700190902, 0.1833086300175637, 0.18628479493781924, 0.18625526723917574, 0.1760986380977556, 0.1693458448862657, 0.2877460819436237, 0.1686421527992934, 0.16671528108417988, 0.1672414292115718, 0.16596834000665694, 0.16886188392527401, 0.16922547097783536, 0.1689848928945139, 0.1686996570788324, 0.1668176898965612, 0.3108784219948575, 0.16700326988939196, 0.168460848974064, 0.1711525860009715, 0.16979574703145772, 0.1722560141934082, 0.17334068496711552, 0.17323157796636224, 0.16971423290669918, 0.1658350459765643, 0.3043046708917245, 0.17868848389480263, 0.16425466805230826, 0.1627806529868394, 0.16298040107358247, 0.16363442514557391, 0.1627722439588979, 0.1722801560536027, 0.16786513885017484, 0.16531711211428046, 0.1710014439886436, 0.26774329389445484, 0.16455153306014836, 0.16450049995910376, 0.16542145085986704, 0.16559776198118925, 0.16759412095416337, 0.17001018906012177, 0.17441178183071315, 0.17277681594714522, 0.1697765908902511, 0.3050448150606826, 0.1793278530240059, 0.17712561890948564, 0.1796356060076505, 0.17915960890240967, 0.17320158798247576, 0.1726364529458806, 0.17405390087515116, 0.17011107504367828]
Total Epoch List: [111, 115]
Total Time List: [0.05564188398420811, 0.05262176599353552]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a2743a60>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6952;  Loss pred: 0.6952; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5116 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6928;  Loss pred: 0.6928; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6947;  Loss pred: 0.6947; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6924;  Loss pred: 0.6924; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 5/1000, LR 0.000090
Train loss: 0.6901;  Loss pred: 0.6901; Loss self: 0.0000; time: 0.09s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.12s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5116 time: 0.05s
Epoch 6/1000, LR 0.000120
Train loss: 0.6889;  Loss pred: 0.6889; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6893;  Loss pred: 0.6893; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6842;  Loss pred: 0.6842; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6825;  Loss pred: 0.6825; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6793;  Loss pred: 0.6793; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.5116 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6763;  Loss pred: 0.6763; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6706;  Loss pred: 0.6706; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6646;  Loss pred: 0.6646; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6933 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6601;  Loss pred: 0.6601; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.5116 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6572;  Loss pred: 0.6572; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6512;  Loss pred: 0.6512; Loss self: 0.0000; time: 0.13s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.5116 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6482;  Loss pred: 0.6482; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6381;  Loss pred: 0.6381; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.5116 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6320;  Loss pred: 0.6320; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6925 score: 0.5116 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6281;  Loss pred: 0.6281; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.5116 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6210;  Loss pred: 0.6210; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6923 score: 0.5116 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6112;  Loss pred: 0.6112; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6922 score: 0.5116 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6039;  Loss pred: 0.6039; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6923 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6920 score: 0.5116 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.5977;  Loss pred: 0.5977; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6921 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6918 score: 0.5116 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.5893;  Loss pred: 0.5893; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6919 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6916 score: 0.5116 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.5787;  Loss pred: 0.5787; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6916 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6914 score: 0.5116 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.5687;  Loss pred: 0.5687; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6913 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6912 score: 0.5116 time: 0.10s
Epoch 28/1000, LR 0.000270
Train loss: 0.5626;  Loss pred: 0.5626; Loss self: 0.0000; time: 0.10s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6910 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6909 score: 0.5116 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5533;  Loss pred: 0.5533; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6906 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6906 score: 0.5116 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5403;  Loss pred: 0.5403; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6901 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6902 score: 0.5116 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5294;  Loss pred: 0.5294; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6896 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6898 score: 0.5116 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5180;  Loss pred: 0.5180; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6891 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6893 score: 0.5116 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5113;  Loss pred: 0.5113; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6884 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6887 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5031;  Loss pred: 0.5031; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6876 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6881 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.4836;  Loss pred: 0.4836; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6868 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6874 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.4796;  Loss pred: 0.4796; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6859 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6867 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4568;  Loss pred: 0.4568; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6848 score: 0.5000 time: 0.06s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6857 score: 0.5116 time: 0.12s
Epoch 38/1000, LR 0.000270
Train loss: 0.4552;  Loss pred: 0.4552; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6836 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6847 score: 0.5116 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4372;  Loss pred: 0.4372; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6822 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6835 score: 0.5116 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4261;  Loss pred: 0.4261; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6808 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6823 score: 0.5116 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4102;  Loss pred: 0.4102; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6791 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6809 score: 0.5116 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.3931;  Loss pred: 0.3931; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6773 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6793 score: 0.5116 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.3851;  Loss pred: 0.3851; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6752 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6775 score: 0.5116 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3721;  Loss pred: 0.3721; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6730 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6756 score: 0.5116 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3636;  Loss pred: 0.3636; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6705 score: 0.5000 time: 0.05s
Test loss: 0.6735 score: 0.5349 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3465;  Loss pred: 0.3465; Loss self: 0.0000; time: 0.07s
Val loss: 0.6677 score: 0.5682 time: 0.05s
Test loss: 0.6710 score: 0.5581 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3304;  Loss pred: 0.3304; Loss self: 0.0000; time: 0.07s
Val loss: 0.6645 score: 0.5682 time: 0.05s
Test loss: 0.6682 score: 0.5814 time: 0.05s
Epoch 48/1000, LR 0.000269
Train loss: 0.3196;  Loss pred: 0.3196; Loss self: 0.0000; time: 0.07s
Val loss: 0.6610 score: 0.5682 time: 0.15s
Test loss: 0.6651 score: 0.5814 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3030;  Loss pred: 0.3030; Loss self: 0.0000; time: 0.07s
Val loss: 0.6572 score: 0.6136 time: 0.05s
Test loss: 0.6616 score: 0.6047 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.2795;  Loss pred: 0.2795; Loss self: 0.0000; time: 0.07s
Val loss: 0.6530 score: 0.6591 time: 0.05s
Test loss: 0.6579 score: 0.6279 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.2718;  Loss pred: 0.2718; Loss self: 0.0000; time: 0.07s
Val loss: 0.6485 score: 0.6591 time: 0.05s
Test loss: 0.6538 score: 0.6744 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2558;  Loss pred: 0.2558; Loss self: 0.0000; time: 0.07s
Val loss: 0.6435 score: 0.6818 time: 0.05s
Test loss: 0.6492 score: 0.6977 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2447;  Loss pred: 0.2447; Loss self: 0.0000; time: 0.07s
Val loss: 0.6382 score: 0.7045 time: 0.05s
Test loss: 0.6444 score: 0.7209 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2289;  Loss pred: 0.2289; Loss self: 0.0000; time: 0.07s
Val loss: 0.6323 score: 0.7273 time: 0.05s
Test loss: 0.6389 score: 0.7442 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2134;  Loss pred: 0.2134; Loss self: 0.0000; time: 0.07s
Val loss: 0.6263 score: 0.7273 time: 0.05s
Test loss: 0.6332 score: 0.7674 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2011;  Loss pred: 0.2011; Loss self: 0.0000; time: 0.07s
Val loss: 0.6198 score: 0.7045 time: 0.05s
Test loss: 0.6270 score: 0.7674 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.1988;  Loss pred: 0.1988; Loss self: 0.0000; time: 0.07s
Val loss: 0.6127 score: 0.7273 time: 0.05s
Test loss: 0.6204 score: 0.7674 time: 0.06s
Epoch 58/1000, LR 0.000269
Train loss: 0.1780;  Loss pred: 0.1780; Loss self: 0.0000; time: 0.17s
Val loss: 0.6052 score: 0.7500 time: 0.06s
Test loss: 0.6132 score: 0.7674 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.1676;  Loss pred: 0.1676; Loss self: 0.0000; time: 0.07s
Val loss: 0.5974 score: 0.7273 time: 0.05s
Test loss: 0.6058 score: 0.7907 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1532;  Loss pred: 0.1532; Loss self: 0.0000; time: 0.07s
Val loss: 0.5891 score: 0.7273 time: 0.05s
Test loss: 0.5977 score: 0.7907 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1497;  Loss pred: 0.1497; Loss self: 0.0000; time: 0.07s
Val loss: 0.5802 score: 0.7500 time: 0.05s
Test loss: 0.5893 score: 0.8140 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1403;  Loss pred: 0.1403; Loss self: 0.0000; time: 0.07s
Val loss: 0.5710 score: 0.7727 time: 0.05s
Test loss: 0.5804 score: 0.8140 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1245;  Loss pred: 0.1245; Loss self: 0.0000; time: 0.07s
Val loss: 0.5614 score: 0.7727 time: 0.05s
Test loss: 0.5711 score: 0.8140 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1240;  Loss pred: 0.1240; Loss self: 0.0000; time: 0.07s
Val loss: 0.5515 score: 0.8182 time: 0.06s
Test loss: 0.5614 score: 0.8140 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1001;  Loss pred: 0.1001; Loss self: 0.0000; time: 0.07s
Val loss: 0.5415 score: 0.8182 time: 0.06s
Test loss: 0.5517 score: 0.8140 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.0976;  Loss pred: 0.0976; Loss self: 0.0000; time: 0.08s
Val loss: 0.5311 score: 0.8182 time: 0.06s
Test loss: 0.5419 score: 0.8140 time: 0.06s
Epoch 67/1000, LR 0.000268
Train loss: 0.0997;  Loss pred: 0.0997; Loss self: 0.0000; time: 0.07s
Val loss: 0.5206 score: 0.8182 time: 0.06s
Test loss: 0.5319 score: 0.8140 time: 0.21s
Epoch 68/1000, LR 0.000268
Train loss: 0.0781;  Loss pred: 0.0781; Loss self: 0.0000; time: 0.07s
Val loss: 0.5105 score: 0.8182 time: 0.05s
Test loss: 0.5225 score: 0.8140 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.0835;  Loss pred: 0.0835; Loss self: 0.0000; time: 0.07s
Val loss: 0.5004 score: 0.8182 time: 0.05s
Test loss: 0.5130 score: 0.8140 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0629;  Loss pred: 0.0629; Loss self: 0.0000; time: 0.07s
Val loss: 0.4904 score: 0.8182 time: 0.05s
Test loss: 0.5038 score: 0.8140 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0615;  Loss pred: 0.0615; Loss self: 0.0000; time: 0.07s
Val loss: 0.4806 score: 0.8182 time: 0.05s
Test loss: 0.4948 score: 0.8140 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0650;  Loss pred: 0.0650; Loss self: 0.0000; time: 0.07s
Val loss: 0.4708 score: 0.8182 time: 0.05s
Test loss: 0.4856 score: 0.8140 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0487;  Loss pred: 0.0487; Loss self: 0.0000; time: 0.07s
Val loss: 0.4615 score: 0.8182 time: 0.05s
Test loss: 0.4772 score: 0.8140 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0490;  Loss pred: 0.0490; Loss self: 0.0000; time: 0.07s
Val loss: 0.4532 score: 0.8182 time: 0.05s
Test loss: 0.4696 score: 0.8140 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0464;  Loss pred: 0.0464; Loss self: 0.0000; time: 0.07s
Val loss: 0.4456 score: 0.8182 time: 0.05s
Test loss: 0.4628 score: 0.8140 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0441;  Loss pred: 0.0441; Loss self: 0.0000; time: 0.07s
Val loss: 0.4382 score: 0.8182 time: 0.05s
Test loss: 0.4563 score: 0.8140 time: 0.06s
Epoch 77/1000, LR 0.000267
Train loss: 0.0378;  Loss pred: 0.0378; Loss self: 0.0000; time: 0.07s
Val loss: 0.4315 score: 0.8182 time: 0.06s
Test loss: 0.4507 score: 0.8140 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0321;  Loss pred: 0.0321; Loss self: 0.0000; time: 0.07s
Val loss: 0.4259 score: 0.8182 time: 0.05s
Test loss: 0.4461 score: 0.8140 time: 0.05s
Epoch 79/1000, LR 0.000267
Train loss: 0.0292;  Loss pred: 0.0292; Loss self: 0.0000; time: 0.06s
Val loss: 0.4216 score: 0.8182 time: 0.05s
Test loss: 0.4428 score: 0.8140 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0284;  Loss pred: 0.0284; Loss self: 0.0000; time: 0.06s
Val loss: 0.4185 score: 0.8182 time: 0.05s
Test loss: 0.4409 score: 0.8140 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0255;  Loss pred: 0.0255; Loss self: 0.0000; time: 0.06s
Val loss: 0.4167 score: 0.8182 time: 0.05s
Test loss: 0.4403 score: 0.8140 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0216;  Loss pred: 0.0216; Loss self: 0.0000; time: 0.06s
Val loss: 0.4155 score: 0.8182 time: 0.05s
Test loss: 0.4405 score: 0.8140 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0212;  Loss pred: 0.0212; Loss self: 0.0000; time: 0.06s
Val loss: 0.4146 score: 0.8182 time: 0.05s
Test loss: 0.4413 score: 0.8140 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0230;  Loss pred: 0.0230; Loss self: 0.0000; time: 0.06s
Val loss: 0.4139 score: 0.8182 time: 0.05s
Test loss: 0.4422 score: 0.8140 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0244;  Loss pred: 0.0244; Loss self: 0.0000; time: 0.06s
Val loss: 0.4115 score: 0.8182 time: 0.05s
Test loss: 0.4415 score: 0.7907 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0157;  Loss pred: 0.0157; Loss self: 0.0000; time: 0.06s
Val loss: 0.4102 score: 0.8182 time: 0.05s
Test loss: 0.4417 score: 0.7907 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.06s
Val loss: 0.4084 score: 0.8182 time: 0.05s
Test loss: 0.4415 score: 0.7907 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0174;  Loss pred: 0.0174; Loss self: 0.0000; time: 0.07s
Val loss: 0.4059 score: 0.8182 time: 0.05s
Test loss: 0.4404 score: 0.7907 time: 0.05s
Epoch 89/1000, LR 0.000266
Train loss: 0.0177;  Loss pred: 0.0177; Loss self: 0.0000; time: 0.06s
Val loss: 0.4045 score: 0.8409 time: 0.05s
Test loss: 0.4405 score: 0.7907 time: 0.05s
Epoch 90/1000, LR 0.000266
Train loss: 0.0114;  Loss pred: 0.0114; Loss self: 0.0000; time: 0.07s
Val loss: 0.4037 score: 0.8409 time: 0.05s
Test loss: 0.4411 score: 0.7907 time: 0.05s
Epoch 91/1000, LR 0.000266
Train loss: 0.0122;  Loss pred: 0.0122; Loss self: 0.0000; time: 0.06s
Val loss: 0.4023 score: 0.8409 time: 0.06s
Test loss: 0.4409 score: 0.7907 time: 0.05s
Epoch 92/1000, LR 0.000266
Train loss: 0.0125;  Loss pred: 0.0125; Loss self: 0.0000; time: 0.07s
Val loss: 0.4018 score: 0.8409 time: 0.05s
Test loss: 0.4415 score: 0.7907 time: 0.05s
Epoch 93/1000, LR 0.000265
Train loss: 0.0108;  Loss pred: 0.0108; Loss self: 0.0000; time: 0.06s
Val loss: 0.4027 score: 0.8409 time: 0.05s
Test loss: 0.4440 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0113;  Loss pred: 0.0113; Loss self: 0.0000; time: 0.07s
Val loss: 0.4047 score: 0.8409 time: 0.05s
Test loss: 0.4476 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0087;  Loss pred: 0.0087; Loss self: 0.0000; time: 0.07s
Val loss: 0.4082 score: 0.8409 time: 0.05s
Test loss: 0.4532 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0130;  Loss pred: 0.0130; Loss self: 0.0000; time: 0.07s
Val loss: 0.4100 score: 0.8409 time: 0.05s
Test loss: 0.4564 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0092;  Loss pred: 0.0092; Loss self: 0.0000; time: 0.07s
Val loss: 0.4132 score: 0.8409 time: 0.05s
Test loss: 0.4614 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0078;  Loss pred: 0.0078; Loss self: 0.0000; time: 0.07s
Val loss: 0.4177 score: 0.8409 time: 0.05s
Test loss: 0.4679 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0077;  Loss pred: 0.0077; Loss self: 0.0000; time: 0.07s
Val loss: 0.4234 score: 0.8409 time: 0.05s
Test loss: 0.4770 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0074;  Loss pred: 0.0074; Loss self: 0.0000; time: 0.07s
Val loss: 0.4294 score: 0.8409 time: 0.05s
Test loss: 0.4864 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0063;  Loss pred: 0.0063; Loss self: 0.0000; time: 0.07s
Val loss: 0.4358 score: 0.8409 time: 0.05s
Test loss: 0.4960 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0058;  Loss pred: 0.0058; Loss self: 0.0000; time: 0.07s
Val loss: 0.4428 score: 0.8409 time: 0.05s
Test loss: 0.5065 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0056;  Loss pred: 0.0056; Loss self: 0.0000; time: 0.07s
Val loss: 0.4492 score: 0.8409 time: 0.05s
Test loss: 0.5161 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0064;  Loss pred: 0.0064; Loss self: 0.0000; time: 0.07s
Val loss: 0.4554 score: 0.8409 time: 0.05s
Test loss: 0.5252 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0054;  Loss pred: 0.0054; Loss self: 0.0000; time: 0.07s
Val loss: 0.4606 score: 0.8409 time: 0.05s
Test loss: 0.5329 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0052;  Loss pred: 0.0052; Loss self: 0.0000; time: 0.07s
Val loss: 0.4664 score: 0.8409 time: 0.05s
Test loss: 0.5415 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.4723 score: 0.8409 time: 0.06s
Test loss: 0.5503 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0055;  Loss pred: 0.0055; Loss self: 0.0000; time: 0.07s
Val loss: 0.4776 score: 0.8409 time: 0.05s
Test loss: 0.5582 score: 0.7907 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 109/1000, LR 0.000264
Train loss: 0.0047;  Loss pred: 0.0047; Loss self: 0.0000; time: 0.07s
Val loss: 0.4826 score: 0.8409 time: 0.05s
Test loss: 0.5653 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 110/1000, LR 0.000263
Train loss: 0.0037;  Loss pred: 0.0037; Loss self: 0.0000; time: 0.07s
Val loss: 0.4876 score: 0.8409 time: 0.05s
Test loss: 0.5725 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 111/1000, LR 0.000263
Train loss: 0.0038;  Loss pred: 0.0038; Loss self: 0.0000; time: 0.07s
Val loss: 0.4926 score: 0.8409 time: 0.05s
Test loss: 0.5795 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 112/1000, LR 0.000263
Train loss: 0.0050;  Loss pred: 0.0050; Loss self: 0.0000; time: 0.07s
Val loss: 0.4957 score: 0.8409 time: 0.05s
Test loss: 0.5837 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 091,   Train_Loss: 0.0125,   Val_Loss: 0.4018,   Val_Precision: 0.8947,   Val_Recall: 0.7727,   Val_accuracy: 0.8293,   Val_Score: 0.8409,   Val_Loss: 0.4018,   Test_Precision: 0.9286,   Test_Recall: 0.6190,   Test_accuracy: 0.7429,   Test_Score: 0.7907,   Test_loss: 0.4415


[0.05605938797816634, 0.05476786196231842, 0.05484617000911385, 0.05577514704782516, 0.05464150500483811, 0.054743563989177346, 0.06313436396885663, 0.054621313931420445, 0.05506728496402502, 0.0643071549711749, 0.0593585999449715, 0.05419068597257137, 0.05465309601277113, 0.054941043024882674, 0.05465252394787967, 0.05467178602702916, 0.054880928015336394, 0.05502084200270474, 0.05489306803792715, 0.05456621793564409, 0.055174501962028444, 0.05496311804745346, 0.054647968034259975, 0.05580954207107425, 0.05478014692198485, 0.054778678924776614, 0.054560287040658295, 0.05495190294459462, 0.05735509400255978, 0.05495201295707375, 0.054536856012418866, 0.056072756997309625, 0.06091322400607169, 0.05557666893582791, 0.05573429598007351, 0.05498210701625794, 0.05469521810300648, 0.054984115064144135, 0.05512681999243796, 0.05496833601500839, 0.05562824697699398, 0.05506066093221307, 0.054800827987492085, 0.054795410949736834, 0.054742748965509236, 0.05510793800931424, 0.055080748978070915, 0.05485160497482866, 0.05483319493941963, 0.05509228503797203, 0.055081159924156964, 0.0549893289571628, 0.05539087799843401, 0.05503234011121094, 0.05516512494068593, 0.05519423901569098, 0.05506596202030778, 0.05500388506334275, 0.05522568104788661, 0.055166949052363634, 0.05515616503544152, 0.05485223501455039, 0.05516809597611427, 0.05521084205247462, 0.05488913890440017, 0.05469115206506103, 0.05500620906241238, 0.05499410000629723, 0.05491086794063449, 0.05507417593616992, 0.055300222942605615, 0.054720325977541506, 0.05480531696230173, 0.0549129550345242, 0.055401296936906874, 0.05478937295265496, 0.05495519598480314, 0.05475806596223265, 0.055268432945013046, 0.055750002968125045, 0.05467670608777553, 0.05484902998432517, 0.05525489000137895, 0.05499524902552366, 0.05472368106711656, 0.05472908902447671, 0.05473870097193867, 0.05486018699593842, 0.05511214805301279, 0.055250686942599714, 0.05486640706658363, 0.0546898830216378, 0.0548831180203706, 0.05511243606451899, 0.05469064903445542, 0.0546749250497669, 0.055032021016813815, 0.05543344502802938, 0.055045197950676084, 0.0551261599175632, 0.055113900918513536, 0.05498415697365999, 0.05494699999690056, 0.054943945026025176, 0.0550080529646948, 0.055092668044380844, 0.055022831074893475, 0.05502410407643765, 0.05570583697408438, 0.054781766957603395, 0.05508683901280165, 0.05254832096397877, 0.05234099493827671, 0.05251458508428186, 0.05175453098490834, 0.052179376943968236, 0.052177570993080735, 0.05198464193381369, 0.05213740898761898, 0.052262049983255565, 0.05191285803448409, 0.05276494403369725, 0.05187765194568783, 0.05172313703224063, 0.10581669502425939, 0.05698871100321412, 0.056325521087273955, 0.055918785044923425, 0.05599945690482855, 0.05602825898677111, 0.053694973001256585, 0.05281385802663863, 0.057482045027427375, 0.05348531005438417, 0.052873644046485424, 0.05234360904432833, 0.05337998108007014, 0.05163475195877254, 0.05227033200208098, 0.05224631307646632, 0.052942469948902726, 0.05313042795751244, 0.05203821905888617, 0.05189004901330918, 0.051762035000137985, 0.05175084399525076, 0.05176861898507923, 0.05224263097625226, 0.05183264205697924, 0.05152995907701552, 0.05192885105498135, 0.052049002959392965, 0.05144030100200325, 0.05134593800175935, 0.06987058103550225, 0.05231500801164657, 0.052009679027833045, 0.05252508900593966, 0.05193165992386639, 0.05199080903548747, 0.052427925053052604, 0.052025580080226064, 0.05215162900276482, 0.05168507096823305, 0.051519216038286686, 0.051511220051907, 0.05666154599748552, 0.0568456839537248, 0.057134903967380524, 0.0572567320195958, 0.057519151945598423, 0.05698069406207651, 0.05850387807004154, 0.05775490100495517, 0.05342970206402242, 0.052867676015011966, 0.05192924395669252, 0.051995552028529346, 0.051484090043231845, 0.05191911302972585, 0.051898321020416915, 0.05208897695410997, 0.05294131103437394, 0.052585733006708324, 0.05183518398553133, 0.05164628103375435, 0.05754600989166647, 0.05157466104719788, 0.05274107703007758, 0.05257321603130549, 0.05348884698469192, 0.05277076701167971, 0.054880861076526344, 0.05295655608642846, 0.05274054198525846, 0.05128402600530535, 0.05680395395029336, 0.0513569179456681, 0.05112328298855573, 0.0509703760035336, 0.05123263201676309, 0.05133143102284521, 0.05275435897056013, 0.052654596976935863, 0.051511794910766184, 0.05101102695334703, 0.05900959298014641, 0.051705469959415495, 0.051270366995595396, 0.051299965009093285, 0.05227570200804621, 0.05132996500469744, 0.05185047199483961, 0.05316168593708426, 0.05365363205783069, 0.053359249024651945, 0.05206910101696849, 0.1870371230179444, 0.055588218034245074, 0.055058489087969065, 0.056803713901899755, 0.05562730797100812, 0.05297379510011524, 0.054347440018318594, 0.052574411034584045, 0.05178079893812537, 0.05529139202553779, 0.05438580794725567, 0.05394640495069325, 0.05482713703531772, 0.05292271391954273, 0.05306365096475929, 0.05376300204079598, 0.053862778935581446, 0.05388035194482654, 0.05339451401960105, 0.053232577978633344, 0.05360228207428008, 0.05369901598896831, 0.05343984498176724, 0.05384680407587439, 0.05328937794547528, 0.05318303103558719, 0.05328142095822841, 0.05281269398983568, 0.05311065202113241, 0.053327158908359706, 0.0530405689496547, 0.05484480899758637, 0.05240062694065273, 0.053289729985408485, 0.05275595898274332, 0.10295938397757709, 0.05648581404238939, 0.056446575094014406, 0.05636444303672761, 0.05657672102097422, 0.052531496970914304, 0.053379026940092444, 0.053856237907893956, 0.05281749495770782, 0.053271214943379164, 0.12386319693177938, 0.05265633494127542, 0.052548751002177596, 0.05309315293561667, 0.05280439893249422, 0.05344834097195417, 0.053440792951732874, 0.05417659191880375, 0.05348545894958079, 0.05313155194744468, 0.053728191065602005, 0.05617806292138994, 0.05702922306954861, 0.056479127961210907, 0.0567393209785223, 0.05681533494498581, 0.056576926028355956, 0.05820804298855364, 0.0557328819995746, 0.05706162005662918, 0.06306322989985347, 0.05794219591189176, 0.05604478099849075, 0.056869245949201286, 0.05663620005361736, 0.05731904704589397, 0.0575954879168421, 0.058457609033212066, 0.057810200029052794, 0.06107982504181564, 0.21090887894388288, 0.057130843051709235, 0.05684946198016405, 0.056579177966341376, 0.0566252670250833, 0.05669897003099322, 0.05710105202160776, 0.05700889590661973, 0.0572482889983803, 0.06295418692752719, 0.05861304700374603, 0.05134591495152563, 0.051288170972839, 0.05134609097149223, 0.05124435503967106, 0.05152671900577843, 0.051594824995845556, 0.05127501499373466, 0.05126895196735859, 0.050945638096891344, 0.051065873936749995, 0.051619712030515075, 0.051156935980543494, 0.05127377202734351, 0.052412325982004404, 0.051410338026471436, 0.051453597960062325, 0.051960246986709535, 0.052221333025954664, 0.053150150924921036, 0.05268325505312532, 0.052264795056544244, 0.051924530998803675, 0.05183691706042737, 0.052131996024399996, 0.052093581994995475, 0.05219872703310102, 0.05239580397028476, 0.05220826808363199, 0.052302076015621424, 0.0548189909895882, 0.05167303804773837, 0.051780305919237435, 0.05237417109310627, 0.052071611979044974, 0.05298987601418048]
[0.0012740769995037806, 0.0012447241355072367, 0.0012465038638434965, 0.0012676169783596627, 0.0012418523864735935, 0.0012441719088449397, 0.0014348719083831054, 0.0012413934984413738, 0.0012515292037278414, 0.001461526249344884, 0.0013490590896584433, 0.0012316064993766222, 0.0012421158184720712, 0.0012486600687473335, 0.0012421028169972653, 0.0012425405915233898, 0.0012472938185303726, 0.0012504736818796532, 0.001247569728134708, 0.0012401413167191838, 0.0012539659536824647, 0.0012491617738057605, 0.0012419992735059086, 0.0012683986834335055, 0.0012450033391360193, 0.0012449699755631048, 0.0012400065236513249, 0.0012489068851044233, 0.0013035248636945405, 0.0012489093853880397, 0.001239474000282247, 0.001274380840847946, 0.0013843914546834474, 0.001263106112177907, 0.0012666885450016707, 0.0012495933412785896, 0.0012430731387046928, 0.0012496389787305486, 0.0012528822725554082, 0.0012492803639774634, 0.0012642783403862268, 0.001251378657550297, 0.0012454733633520928, 0.0012453502488576553, 0.0012441533855797554, 0.0012524531365753237, 0.0012518352040470663, 0.0012466273857915605, 0.0012462089758959007, 0.001252097387226637, 0.00125184454373084, 0.0012497574762991544, 0.0012588835908735002, 0.0012507350025275214, 0.0012537528395610439, 0.001254414523083886, 0.0012514991368251767, 0.0012500882968941535, 0.0012551291147246957, 0.001253794296644628, 0.0012535492053509436, 0.0012466417048761452, 0.001253820363093506, 0.0012547918648289685, 0.0012474804296454583, 0.001242980728751387, 0.0012501411150548267, 0.0012498659092340279, 0.0012479742713780565, 0.0012516858167311345, 0.0012568232486955822, 0.0012436437722168523, 0.0012455753855068576, 0.0012480217053300955, 0.0012591203849297017, 0.001245213021651249, 0.0012489817269273442, 0.001244501499141651, 0.0012561007487502966, 0.0012670455220028418, 0.0012426524110858074, 0.0012465688632801175, 0.0012557929545767945, 0.0012498920233073559, 0.001243720024252649, 0.0012438429323744706, 0.0012440613857258788, 0.0012468224317258732, 0.0012525488193866543, 0.0012556974305136298, 0.00124696379696781, 0.0012429518868554044, 0.0012473435913720591, 0.0012525553651027042, 0.0012429692962376232, 0.0012426119329492476, 0.0012507277503821322, 0.0012598510233643042, 0.0012510272261517291, 0.001252867270853709, 0.001252588657238944, 0.0012496399312195454, 0.0012487954544750128, 0.001248726023318754, 0.0012501830219248818, 0.0012521060919177464, 0.0012505188880657608, 0.0012505478199190375, 0.0012660417494110086, 0.00124504015812735, 0.0012519736139273102, 0.0012220539759064829, 0.0012172324404250397, 0.0012212694205646945, 0.0012035937438350777, 0.001213473882417866, 0.001213431883560017, 0.0012089451612514812, 0.0012124978834329996, 0.0012153965112385015, 0.001207275768243816, 0.0012270917217138894, 0.0012064570219927403, 0.0012028636519125727, 0.0024608533726571953, 0.0013253188605398634, 0.0013098958392389292, 0.001300436861509847, 0.0013023129512750825, 0.0013029827671342117, 0.0012487203023548042, 0.0012282292564334565, 0.0013367917448238924, 0.0012438444198693993, 0.001229619628988033, 0.001217293233589031, 0.0012413949088388404, 0.0012008081850877336, 0.0012155891163274646, 0.0012150305366620076, 0.001231220231369831, 0.0012355913478491265, 0.0012101911409043294, 0.0012067453258909112, 0.0012037682558171624, 0.0012035079998895526, 0.0012039213717460286, 0.0012149449064244712, 0.001205410280394866, 0.0011983711413259422, 0.0012076476989530546, 0.0012104419292882085, 0.001196286069814029, 0.001194091581436264, 0.0016248972333837734, 0.0012166280932941061, 0.0012095274192519313, 0.0012215136978125504, 0.001207713021485265, 0.001209088582220639, 0.0012192540710012233, 0.001209897211168048, 0.001212828581459647, 0.001201978394610071, 0.0011981213032159694, 0.001197935350044349, 0.001317710372034547, 0.0013219926500866233, 0.001328718696915826, 0.0013315519074324606, 0.0013376546964092657, 0.001325132420048291, 0.0013605553039544543, 0.0013431372326733761, 0.001242551210791219, 0.0012294808375584178, 0.0012076568362021515, 0.0012091988843844035, 0.0011973044196100428, 0.0012074212332494384, 0.0012069376981492306, 0.0012113715570723248, 0.0012311932798691613, 0.0012229240234118215, 0.0012054693950123566, 0.0012010763031105663, 0.001338279299806197, 0.0011994107220278576, 0.0012265366751180833, 0.0012226329309605929, 0.0012439266740626028, 0.001227227139806505, 0.0012762990948029381, 0.0012315478159634526, 0.001226524232215313, 0.0011926517675652406, 0.0013210221848905432, 0.0011943469289690256, 0.001188913557873389, 0.0011853575814775256, 0.0011914565585293743, 0.0011937542098336095, 0.0012268455574548868, 0.0012245255110915317, 0.0011979487188550275, 0.0011863029524034193, 0.0013723161158173583, 0.0012024527897538488, 0.001192334116176637, 0.0011930224420719367, 0.001215714000187121, 0.0011937201163883125, 0.0012058249301125491, 0.0012363182776066106, 0.00124775888506583, 0.0012409127680151615, 0.0012109093259760114, 0.004349700535301032, 0.0012927492566103505, 0.0012804299787899783, 0.0013210166023697617, 0.0012936583249071657, 0.001231948723258494, 0.001263893953914386, 0.0012226607217345126, 0.001204204626468032, 0.0012858463261752975, 0.0012647862313315272, 0.0012545675569928664, 0.001275049698495761, 0.001230760788826575, 0.0012340383945292858, 0.001250302373041767, 0.0012526227659437545, 0.0012530314405773614, 0.0012417328841767686, 0.0012379669297356592, 0.0012465646994018623, 0.0012488143253248445, 0.0012427870925992381, 0.0012522512575784742, 0.0012392878591970995, 0.0012368146752462137, 0.001239102812982056, 0.001228202185810132, 0.0012351314423519166, 0.0012401664862409234, 0.0012335016034803418, 0.0012754606743624738, 0.0012186192311779704, 0.0012392960461722904, 0.0012268827670405423, 0.0023944042785483044, 0.0013136235823811486, 0.0013127110486980094, 0.0013108010008541305, 0.0013157376981621912, 0.001221662720253821, 0.0012413727195370336, 0.0012524706490207897, 0.0012283138362257633, 0.0012388654637995155, 0.0028805394635297533, 0.00122456592886687, 0.0012220639767948278, 0.0012347244868748063, 0.0012280092774998657, 0.001242984673766376, 0.0012428091384123923, 0.0012599207422977618, 0.0012438478825483905, 0.0012356174871498763, 0.0012494928154791164, 0.0013064665795672079, 0.0013262610016174096, 0.0013134680921211839, 0.0013195190925237743, 0.0013212868591857164, 0.0013157424657757198, 0.001353675418338457, 0.001296113534873828, 0.0013270144199216088, 0.0014665867418570573, 0.0013474929281835292, 0.0013033669999649013, 0.0013225406034697974, 0.0013171209314794734, 0.0013330010940905573, 0.0013394299515544674, 0.001359479279842141, 0.0013444232564896, 0.0014204610474840846, 0.004904857649857742, 0.0013286242570164938, 0.0013220805111666058, 0.0013157948364265436, 0.0013168666750019372, 0.0013185806983951913, 0.001327931442362971, 0.0013257882768981332, 0.0013313555581018674, 0.001464050858779702, 0.001363094116366187, 0.001194091045384317, 0.0011927481621590464, 0.0011940951388719123, 0.0011917291869690946, 0.0011982957908320566, 0.0011998796510661756, 0.00119244220915662, 0.001192301208543223, 0.0011847822813230546, 0.0011875784636453488, 0.0012004584193143041, 0.0011896961855940348, 0.0011924133029614771, 0.0012188913019070791, 0.0011955892564295683, 0.0011965953013967983, 0.0012083778369002217, 0.0012144496052547595, 0.0012360500215097916, 0.0012251919779796587, 0.0012154603501521918, 0.001207547232530318, 0.0012055096990797062, 0.0012123720005674417, 0.0012114786510464064, 0.0012139238844907215, 0.0012185070690763898, 0.0012141457693867904, 0.0012163273492004983, 0.0012748602555718185, 0.0012016985592497296, 0.0012041931609124985, 0.0012180039789094481, 0.0012109677204429064, 0.0012323226980041973]
[784.8819187454712, 803.390865071071, 802.2438028523865, 788.8818287161413, 805.2486840562703, 803.7474507267865, 696.9263208496823, 805.5463487246757, 799.0225054448357, 684.2162434292514, 741.257375355724, 811.9476476505688, 805.0779042731311, 800.8584762410226, 805.0863312728496, 804.8026815558369, 801.735713865922, 799.6969584332611, 801.5584038698506, 806.3597160406831, 797.4698173130981, 800.5368247487662, 805.1534500315814, 788.3956464642797, 803.2106971648434, 803.2322221647923, 806.4473701762461, 800.7002058575314, 767.1506910621795, 800.6986028768589, 806.7938494654062, 784.6947850648957, 722.3390440738153, 791.6991219967679, 789.460048364676, 800.2603462793708, 804.4578946030642, 800.2311203639428, 798.1595892169314, 800.4608323596765, 790.9650652517769, 799.1186312523528, 802.907576689219, 802.9869515963785, 803.7594171188275, 798.4330677109205, 798.8271912845184, 802.16431260656, 802.433636205436, 798.6599207071055, 798.8212314443819, 800.1552452890708, 794.3546228179296, 799.5298748169446, 797.6053720046718, 797.184647975514, 799.04170172807, 799.9434939791868, 796.7307811350894, 797.5789989443837, 797.7349399061204, 802.1550988456228, 797.5624175800875, 796.9449181409083, 801.6157818878218, 804.5177023818633, 799.9096965594508, 800.0858272971406, 801.2985707596081, 798.9225304250632, 795.6568284664284, 804.0887771403011, 802.8418124151302, 801.2681155537315, 794.2052340418834, 803.0754438095439, 800.6522260819049, 803.5345884996627, 796.1144844431524, 789.2376261424939, 804.730261719943, 802.2019717135267, 796.3096116724136, 800.0691110531985, 804.0394787411255, 803.9600290134869, 803.8188561061437, 802.0388265037731, 798.3720750219366, 796.3701889482727, 801.9479013197164, 804.5363706956844, 801.7037221476522, 798.3679028176165, 804.5251021299774, 804.7564758424409, 799.5345107634113, 793.744642386051, 799.3431150783895, 798.1691462963956, 798.3466832633467, 800.2305104191754, 800.7716527286648, 800.8161769082766, 799.8828831160417, 798.6543683917258, 799.6680494340628, 799.6495488391172, 789.8633678275007, 803.1869441898871, 798.7388782604648, 818.2944613868058, 821.5357780399072, 818.8201416994596, 830.8451295315348, 824.0803650487179, 824.1088878150772, 827.1673786797869, 824.743707732219, 822.7767570115778, 828.3111665983877, 814.9350063280449, 828.8732891191356, 831.3494205348908, 406.3630979038032, 754.5354025918367, 763.4194796595555, 768.9723581343037, 767.8645897062678, 767.4698585610661, 800.8198458167341, 814.1802475083596, 748.0596763647272, 803.9590675697187, 813.2596263309425, 821.494749503889, 805.5454335118603, 832.772471422601, 822.6463914231134, 823.0245823674933, 812.2023781946956, 809.3290728692496, 826.3157498019183, 828.6752627458688, 830.7246807411141, 830.904323105265, 830.6190283421213, 823.0825897636425, 829.5930574546136, 834.466022682711, 828.0560637567805, 826.1445475439228, 835.9204585199733, 837.4567039466027, 615.4235353810938, 821.9438672441219, 826.7691861160785, 818.6563947590352, 828.0112760316055, 827.0692608504977, 820.1735994031359, 826.5164931115008, 824.5188275465058, 831.9617095317309, 834.6400296162193, 834.769589162703, 758.8921065074402, 756.4338575819428, 752.6047479584383, 751.0033926715113, 747.5770859881483, 754.6415625115849, 734.994010970006, 744.5255597669667, 804.7958034367293, 813.3514321263146, 828.0497986040535, 826.9938162480977, 835.2094785766312, 828.2113751708492, 828.5431812540468, 825.5105497249966, 812.2201577531919, 817.7122869907417, 829.5523753133107, 832.5865704037157, 747.2281758709225, 833.7427552000605, 815.3037901648773, 817.9069732845527, 803.9059060724613, 814.8450825147728, 783.5154033031739, 811.9863370612936, 815.312061298478, 838.467713037031, 756.989558114694, 837.2776583963018, 841.1040427436129, 843.6272865049879, 839.308821493508, 837.6933809007335, 815.0985215078889, 816.6428473250904, 834.7602733410638, 842.9549955801979, 728.6950786877519, 831.6334815978161, 838.6910903854872, 838.2071994079907, 822.5618853168437, 837.7173059842311, 829.3077834330911, 808.8532039952532, 801.4368897459235, 805.858417912404, 825.8256655129687, 229.90088441359615, 773.5452137269427, 780.9876499025835, 756.9927570979105, 773.0016347800035, 811.7220961559248, 791.2056204580423, 817.8883824626035, 830.423648954937, 777.6979096518191, 790.6474432025018, 797.087406274835, 784.2831547505555, 812.5055730394322, 810.3475584172907, 799.8065280538298, 798.3249444189826, 798.0645717391004, 805.3261798433967, 807.7760204899239, 802.2046512947372, 800.7595522576006, 804.6430526636233, 798.5617853830213, 806.9150299332977, 808.52856940829, 807.0355337127957, 814.1981927351741, 809.6304293701866, 806.3433507472907, 810.700202722466, 784.0304449212753, 820.6008689304505, 806.9096993318232, 815.073800744774, 417.6404164322187, 761.2530814857505, 761.7822680717385, 762.8923073360414, 760.0299067183297, 818.5565323563554, 805.5598324836292, 798.4219037642303, 814.1241843148957, 807.1901503598854, 347.15719491467087, 816.6158933764651, 818.2877647885123, 809.8972771902223, 814.3260953499672, 804.5151489840124, 804.6287793453424, 793.7007197581848, 803.956829472752, 809.311951635323, 800.3247298517289, 765.4233301025345, 753.9994004049537, 761.3431997309132, 757.8518610802007, 756.837921340019, 760.0271527380032, 738.7295258913921, 771.5373484602538, 753.5713139116252, 681.8553389714648, 742.1189225445786, 767.2436083059716, 756.1204528438789, 759.2317273985896, 750.1869311534601, 746.5862614461143, 735.5757567089344, 743.813375120483, 703.9967775048787, 203.87951524525968, 752.6582438330311, 756.3835874999764, 759.9969024926529, 759.3783174735809, 758.3912014009252, 753.0509242409099, 754.2682473702661, 751.1141512232196, 683.0363808764866, 733.6250578689727, 837.4570798980835, 838.3999504051682, 837.4542090044197, 839.116815241627, 834.5184950584141, 833.4169173645299, 838.6150643789028, 838.7142383440336, 844.0369304673371, 842.0496250247209, 833.0151081544291, 840.550732286902, 838.6353938826417, 820.4177012629416, 836.407649719383, 835.7044347681204, 827.5557275737854, 823.4182757959942, 809.028746893702, 816.1986186434226, 822.733542788777, 828.1249569878773, 829.5246407087445, 824.8293424229175, 825.4375750957369, 823.7748781255184, 820.6764042476874, 823.6243334316061, 822.1470977013779, 784.3996984214286, 832.1554455589442, 830.4315557167195, 821.0153803400215, 825.7858431059204, 811.4757616812102]
Elapsed: 0.055581115391491166~0.012557819902276128
Time per graph: 0.0012829894366932575~0.00029257019000813615
Speed: 793.3892813259064~66.3028827634732
Total Time: 0.0541
best val loss: 0.4017733633518219 test_score: 0.7907

Testing...
Test loss: 0.4405 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.17416391905862838, 0.1662289429223165, 0.1667760421987623, 0.16714738903101534, 0.16583566705230623, 0.16803856601472944, 0.17538854503072798, 0.1692471110727638, 0.16876224894076586, 0.17481354298070073, 0.19191436504479498, 0.1705856800545007, 0.1694756291108206, 0.166002290090546, 0.1670925960643217, 0.16571160696912557, 0.16629792505409569, 0.1675507149193436, 0.1657487970078364, 0.16606899700127542, 0.16728305292781442, 0.1667379600694403, 0.16676358506083488, 0.1668009030399844, 0.1654514839174226, 0.1657724060351029, 0.16651317290961742, 0.16509151994250715, 0.17723409889731556, 0.16721378185320646, 0.16572747996542603, 0.17144367576111108, 0.1733564439928159, 0.17107939103152603, 0.17462804506067187, 0.16787672485224903, 0.1677376281004399, 0.16726452705916017, 0.16574953694362193, 0.16632346890401095, 0.1674699210561812, 0.16696450510062277, 0.16717754502315074, 0.1675423220731318, 0.16773859516251832, 0.16666803299449384, 0.16610269714146852, 0.16827845806255937, 0.16769641893915832, 0.1685347140301019, 0.16687704587820917, 0.16800815903116018, 0.16763456887565553, 0.16716203407850116, 0.1682756330119446, 0.16731810790952295, 0.16872109204996377, 0.16844974900595844, 0.1687218361767009, 0.16789336293004453, 0.16913865495007485, 0.16827536409255117, 0.16743544209748507, 0.16799596999771893, 0.17006412101909518, 0.1688115200959146, 0.16888731205835938, 0.1692244311561808, 0.17105668399017304, 0.1696013188920915, 0.1703454969683662, 0.1701142778620124, 0.16979105595964938, 0.17068958503659815, 0.17052213998977095, 0.16970460605807602, 0.16944034304469824, 0.16964918817393482, 0.17001892905682325, 0.17096456291619688, 0.16916687309276313, 0.1689689529594034, 0.17092058213893324, 0.16915106098167598, 0.17013870098162442, 0.16848658095113933, 0.1697368489112705, 0.1699685329804197, 0.16952783009037375, 0.1695229740580544, 0.17024746409151703, 0.17004889505915344, 0.16984104691073298, 0.1705647560302168, 0.16965015907771885, 0.1697356681106612, 0.16989184799604118, 0.17197396187111735, 0.16942163521889597, 0.1690064910799265, 0.17018617212306708, 0.16995368199422956, 0.16904993099160492, 0.17055233183782548, 0.1699315841542557, 0.16885710204951465, 0.1691651149885729, 0.1702925229910761, 0.17049144499469548, 0.1691775229992345, 0.16882856702432036, 0.1750306359026581, 0.17255921312607825, 0.17176428611855954, 0.17081757495179772, 0.17208024498540908, 0.17174573394004256, 0.17277993401512504, 0.1713310849154368, 0.17186393111478537, 0.17194350401405245, 0.17770277988165617, 0.1717863620724529, 0.1699111128691584, 0.22163875412661582, 0.2228130791336298, 0.18285903602372855, 0.17936196795199066, 0.18224800401367247, 0.18373244302347302, 0.17685088806319982, 0.17419957113452256, 0.1755754449404776, 0.17290977691300213, 0.25604094099253416, 0.16928542591631413, 0.18571392097510397, 0.16931230493355542, 0.1675651960540563, 0.16772795491851866, 0.17185737704858184, 0.17222598800435662, 0.16961909004021436, 0.1672889970941469, 0.2759817660553381, 0.1658636329229921, 0.16445120400749147, 0.1667872698744759, 0.16628411691635847, 0.166761502972804, 0.1661591959418729, 0.16940442589111626, 0.16767863591667265, 0.1660915520042181, 0.24514639202971011, 0.16823213500902057, 0.16774128412362188, 0.16770209884271026, 0.1677225719904527, 0.16719437204301357, 0.16785966407041997, 0.16857014293782413, 0.1716232899343595, 0.16905148013029248, 0.16527451912406832, 0.16656598600093275, 0.2703460808843374, 0.1822080999845639, 0.18097230303101242, 0.18199651991017163, 0.18452706700190902, 0.1833086300175637, 0.18628479493781924, 0.18625526723917574, 0.1760986380977556, 0.1693458448862657, 0.2877460819436237, 0.1686421527992934, 0.16671528108417988, 0.1672414292115718, 0.16596834000665694, 0.16886188392527401, 0.16922547097783536, 0.1689848928945139, 0.1686996570788324, 0.1668176898965612, 0.3108784219948575, 0.16700326988939196, 0.168460848974064, 0.1711525860009715, 0.16979574703145772, 0.1722560141934082, 0.17334068496711552, 0.17323157796636224, 0.16971423290669918, 0.1658350459765643, 0.3043046708917245, 0.17868848389480263, 0.16425466805230826, 0.1627806529868394, 0.16298040107358247, 0.16363442514557391, 0.1627722439588979, 0.1722801560536027, 0.16786513885017484, 0.16531711211428046, 0.1710014439886436, 0.26774329389445484, 0.16455153306014836, 0.16450049995910376, 0.16542145085986704, 0.16559776198118925, 0.16759412095416337, 0.17001018906012177, 0.17441178183071315, 0.17277681594714522, 0.1697765908902511, 0.3050448150606826, 0.1793278530240059, 0.17712561890948564, 0.1796356060076505, 0.17915960890240967, 0.17320158798247576, 0.1726364529458806, 0.17405390087515116, 0.17011107504367828, 0.17279812297783792, 0.17058977019041777, 0.16672828688751906, 0.16813631693366915, 0.25508323905523866, 0.16518631798680872, 0.16584867087658495, 0.16628585301805288, 0.16668611601926386, 0.1662007230333984, 0.16619555500801653, 0.17021366790868342, 0.16660268884152174, 0.1651868070475757, 0.1656056238571182, 0.23942822392564267, 0.16582854301668704, 0.16507591307163239, 0.16467847803141922, 0.16383004293311387, 0.16488425899297, 0.16496455704327673, 0.16780877904966474, 0.16354835010133684, 0.16493139590602368, 0.16218621202278882, 0.2123517009895295, 0.2082157660042867, 0.1737576889572665, 0.17478691006544977, 0.17406184307765216, 0.167435371899046, 0.16459271288476884, 0.16709678899496794, 0.16616456909105182, 0.16449846397154033, 0.2489715740084648, 0.16442357713822275, 0.1644929489120841, 0.16356534301303327, 0.16255104483570904, 0.16440078907180578, 0.16753417800646275, 0.1693459120579064, 0.1691699109505862, 0.1664961609058082, 0.1654541400494054, 0.27749056403990835, 0.17449625208973885, 0.17373075208161026, 0.17569243104662746, 0.1737962190527469, 0.176249573007226, 0.18002750689629465, 0.1758298190543428, 0.1718089240603149, 0.1778373068664223, 0.27578965586144477, 0.17710444901604205, 0.17640531295910478, 0.17658521595876664, 0.17723120597656816, 0.1786615359596908, 0.17985359788872302, 0.1815194389782846, 0.19664416695013642, 0.33317015192005783, 0.17697874212171882, 0.17622748494613916, 0.1754537810338661, 0.1759285001317039, 0.17653435200918466, 0.17738975293468684, 0.17719218297861516, 0.17872882005758584, 0.18299262295477092, 0.18981973396148533, 0.1641766249667853, 0.1584095750004053, 0.15858428494539112, 0.15923714998643845, 0.15907498402521014, 0.15900628408417106, 0.15910519217140973, 0.1580222910270095, 0.15816143190022558, 0.15876261400990188, 0.15971586003433913, 0.1587886200286448, 0.15991174103692174, 0.16840161406435072, 0.16331366798840463, 0.15888922289013863, 0.16199947404675186, 0.16360828699544072, 0.1647767899557948, 0.16254104091785848, 0.16223663394339383, 0.16096838586963713, 0.16138665715698153, 0.16144293209072202, 0.16217720706481487, 0.16297616309020668, 0.16240813105832785, 0.16247942787595093, 0.16437374299857765, 0.17754166794475168, 0.16233269101940095, 0.16132157400716096, 0.1629849171731621, 0.16266169596929103, 0.16666113189421594]
Total Epoch List: [111, 115, 112]
Total Time List: [0.05564188398420811, 0.05262176599353552, 0.05405620206147432]
========================training times:2========================
========================k_idx:0========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a25cfaf0>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6935;  Loss pred: 0.6935; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6940;  Loss pred: 0.6940; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6929;  Loss pred: 0.6929; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6925;  Loss pred: 0.6925; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6931;  Loss pred: 0.6931; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6871;  Loss pred: 0.6871; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6842;  Loss pred: 0.6842; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6813;  Loss pred: 0.6813; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5116 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6798;  Loss pred: 0.6798; Loss self: 0.0000; time: 0.07s
Val loss: 0.6931 score: 0.6047 time: 0.05s
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6774;  Loss pred: 0.6774; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6726;  Loss pred: 0.6726; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6696;  Loss pred: 0.6696; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6676;  Loss pred: 0.6676; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6644;  Loss pred: 0.6644; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6576;  Loss pred: 0.6576; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6520;  Loss pred: 0.6520; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6477;  Loss pred: 0.6477; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6435;  Loss pred: 0.6435; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.4884 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.5000 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6935,   Val_Loss: 0.6929,   Val_Precision: 0.5116,   Val_Recall: 1.0000,   Val_accuracy: 0.6769,   Val_Score: 0.5116,   Val_Loss: 0.6929,   Test_Precision: 0.5000,   Test_Recall: 1.0000,   Test_accuracy: 0.6667,   Test_Score: 0.5000,   Test_loss: 0.6933


[0.05117114703170955, 0.05100728594698012, 0.05053778307046741, 0.050774551928043365, 0.05061662499792874, 0.05078648799099028, 0.05041044391691685, 0.050772582995705307, 0.050492285983636975, 0.0514059669803828, 0.05070261796936393, 0.05049758707173169, 0.05075423594098538, 0.05066299298778176, 0.05135265598073602, 0.050913013983517885, 0.05093683092854917, 0.050994510063901544, 0.05093730695080012, 0.050953872967511415, 0.051065757987089455]
[0.0011629806143570352, 0.0011592564987950027, 0.0011485859788742594, 0.0011539670892737129, 0.0011503778408620167, 0.0011542383634315972, 0.0011456919072026556, 0.0011539223408114842, 0.0011475519541735675, 0.0011683174313723364, 0.001152332226576453, 0.0011476724334484475, 0.0011535053622951223, 0.001151431658813222, 0.0011671058177440004, 0.001157113954170861, 0.0011576552483761175, 0.0011589661378159442, 0.001157666067063639, 0.0011580425674434412, 0.0011605854087974876]
[859.8595605592784, 862.6218624087568, 870.6357368040572, 866.5758402428816, 869.2796092548743, 866.3721737916937, 872.8350036456311, 866.60944556872, 871.4202405939607, 855.9317640458156, 867.805288211866, 871.3287614613768, 866.9227146116654, 868.4840236464385, 856.820336936531, 864.2191172230376, 863.8150273172727, 862.8379789287773, 863.8069547433906, 863.5261156311855, 861.6341308617051]
Elapsed: 0.05084507350832047~0.0002641585495968965
Time per graph: 0.0011555698524618287~6.0036033999294735e-06
Speed: 865.3972231661388~4.487638560827332
Total Time: 0.0514
best val loss: 0.6928992867469788 test_score: 0.5000

Testing...
Test loss: 0.6931 score: 0.5000 time: 0.05s
test Score 0.5000
Epoch Time List: [0.1647911979816854, 0.16073282796423882, 0.16090723604429513, 0.16036989504937083, 0.16099647292867303, 0.16066788288298994, 0.15984041197225451, 0.1605893480591476, 0.16047968703787774, 0.1599180728662759, 0.16127789998427033, 0.1618440969614312, 0.1611698690103367, 0.16109954996500164, 0.16101031203288585, 0.16110299306456, 0.16016995592508465, 0.1616735371062532, 0.16119990614242852, 0.16077687707729638, 0.16231202194467187]
Total Epoch List: [21]
Total Time List: [0.0513934480259195]
========================k_idx:1========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a25c4610>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6890;  Loss pred: 0.6890; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6925;  Loss pred: 0.6925; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 3/1000, LR 0.000030
Train loss: 0.6911;  Loss pred: 0.6911; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 4/1000, LR 0.000060
Train loss: 0.6893;  Loss pred: 0.6893; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6887;  Loss pred: 0.6887; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6870;  Loss pred: 0.6870; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 7/1000, LR 0.000150
Train loss: 0.6857;  Loss pred: 0.6857; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 8/1000, LR 0.000180
Train loss: 0.6811;  Loss pred: 0.6811; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6934 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6940 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 9/1000, LR 0.000210
Train loss: 0.6790;  Loss pred: 0.6790; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 10/1000, LR 0.000240
Train loss: 0.6780;  Loss pred: 0.6780; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6941 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 11/1000, LR 0.000270
Train loss: 0.6726;  Loss pred: 0.6726; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6935 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 12/1000, LR 0.000270
Train loss: 0.6682;  Loss pred: 0.6682; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6942 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 13/1000, LR 0.000270
Train loss: 0.6617;  Loss pred: 0.6617; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6936 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6943 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 14/1000, LR 0.000270
Train loss: 0.6592;  Loss pred: 0.6592; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6944 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 15/1000, LR 0.000270
Train loss: 0.6547;  Loss pred: 0.6547; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6937 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6945 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 16/1000, LR 0.000270
Train loss: 0.6520;  Loss pred: 0.6520; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6938 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6946 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 17/1000, LR 0.000270
Train loss: 0.6398;  Loss pred: 0.6398; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6939 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6948 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 18/1000, LR 0.000270
Train loss: 0.6336;  Loss pred: 0.6336; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6940 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6949 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 19/1000, LR 0.000270
Train loss: 0.6315;  Loss pred: 0.6315; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6941 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6951 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 20/1000, LR 0.000270
Train loss: 0.6251;  Loss pred: 0.6251; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6942 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6953 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 21/1000, LR 0.000270
Train loss: 0.6156;  Loss pred: 0.6156; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6943 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6954 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 000,   Train_Loss: 0.6890,   Val_Loss: 0.6934,   Val_Precision: 0.0000,   Val_Recall: 0.0000,   Val_accuracy: 0.0000,   Val_Score: 0.5000,   Val_Loss: 0.6934,   Test_Precision: 0.0000,   Test_Recall: 0.0000,   Test_accuracy: 0.0000,   Test_Score: 0.4884,   Test_loss: 0.6939


[0.05117114703170955, 0.05100728594698012, 0.05053778307046741, 0.050774551928043365, 0.05061662499792874, 0.05078648799099028, 0.05041044391691685, 0.050772582995705307, 0.050492285983636975, 0.0514059669803828, 0.05070261796936393, 0.05049758707173169, 0.05075423594098538, 0.05066299298778176, 0.05135265598073602, 0.050913013983517885, 0.05093683092854917, 0.050994510063901544, 0.05093730695080012, 0.050953872967511415, 0.051065757987089455, 0.051831852993927896, 0.051832168945111334, 0.05224371107760817, 0.05281137605197728, 0.05236614099703729, 0.05285306298173964, 0.05220677005127072, 0.05255464592482895, 0.052813366055488586, 0.05266587494406849, 0.052671821089461446, 0.05292598903179169, 0.05280704202596098, 0.05275611497927457, 0.053035911987535655, 0.05275688203983009, 0.053226787014864385, 0.05242182908114046, 0.05250273598358035, 0.05300009099300951, 0.053193735890090466]
[0.0011629806143570352, 0.0011592564987950027, 0.0011485859788742594, 0.0011539670892737129, 0.0011503778408620167, 0.0011542383634315972, 0.0011456919072026556, 0.0011539223408114842, 0.0011475519541735675, 0.0011683174313723364, 0.001152332226576453, 0.0011476724334484475, 0.0011535053622951223, 0.001151431658813222, 0.0011671058177440004, 0.001157113954170861, 0.0011576552483761175, 0.0011589661378159442, 0.001157666067063639, 0.0011580425674434412, 0.0011605854087974876, 0.0012053919300913465, 0.0012053992777932869, 0.001214970025060655, 0.0012281715360924947, 0.0012178172324892394, 0.0012291409995753406, 0.0012141109314249005, 0.0012222010680192777, 0.0012282178152439205, 0.0012247877893969417, 0.0012249260718479407, 0.0012308369542277137, 0.0012280707447897903, 0.0012268863948668505, 0.001233393302035713, 0.0012269042334844206, 0.0012378322561596368, 0.0012191123042125688, 0.001220993860083264, 0.001232560255651384, 0.001237063625350941]
[859.8595605592784, 862.6218624087568, 870.6357368040572, 866.5758402428816, 869.2796092548743, 866.3721737916937, 872.8350036456311, 866.60944556872, 871.4202405939607, 855.9317640458156, 867.805288211866, 871.3287614613768, 866.9227146116654, 868.4840236464385, 856.820336936531, 864.2191172230376, 863.8150273172727, 862.8379789287773, 863.8069547433906, 863.5261156311855, 861.6341308617051, 829.605686777925, 829.6006297852531, 823.065573119861, 814.2185115131092, 821.1412791030907, 813.576310891503, 823.6479666865231, 818.1959795049262, 814.1878318231386, 816.4679699267559, 816.3757984931989, 812.4552943955507, 814.2853367711896, 815.0713906225412, 810.7713884528983, 815.0595398631805, 807.8639048415904, 820.2689748471577, 819.0049374464556, 811.3193618039546, 808.3658588832172]
Elapsed: 0.051743439376531614~0.0009554570360370497
Time per graph: 0.0011898989407046674~3.514083694614337e-05
Speed: 841.1402669533795~24.813595549941454
Total Time: 0.0536
best val loss: 0.6933765411376953 test_score: 0.4884

Testing...
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6939 score: 0.4884 time: 0.05s
test Score 0.4884
Epoch Time List: [0.1647911979816854, 0.16073282796423882, 0.16090723604429513, 0.16036989504937083, 0.16099647292867303, 0.16066788288298994, 0.15984041197225451, 0.1605893480591476, 0.16047968703787774, 0.1599180728662759, 0.16127789998427033, 0.1618440969614312, 0.1611698690103367, 0.16109954996500164, 0.16101031203288585, 0.16110299306456, 0.16016995592508465, 0.1616735371062532, 0.16119990614242852, 0.16077687707729638, 0.16231202194467187, 0.16120251803658903, 0.15967755811288953, 0.16021521494258195, 0.1647674081614241, 0.1623883469728753, 0.16364081902429461, 0.1623837579973042, 0.1617552200332284, 0.16446033609099686, 0.16355250705964863, 0.16371880401857197, 0.1635595520492643, 0.1645534149138257, 0.16325932904146612, 0.16361964109819382, 0.1636988348327577, 0.16338657902088016, 0.16209136182442307, 0.16316042887046933, 0.16358276188839227, 0.16433814296033233]
Total Epoch List: [21, 21]
Total Time List: [0.0513934480259195, 0.05359590798616409]
========================k_idx:2========================
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
Extracting 1-hop subgraphs...
Done!
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Model: I2BGNNA
I2BGNN(
  (gcs): ModuleList(
    (0): GCNConv(14887, 64)
    (1): GCNConv(64, 64)
  )
  (bns): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (drops): ModuleList(
    (0-1): 2 x Dropout(p=0.2, inplace=False)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)
Extracting 1-hop subgraphs...
Done!
<torch_geometric.deprecation.DataLoader object at 0x7976a2790e20>
Training...
Epoch 1/1000, LR 0.000300
Train loss: 0.6930;  Loss pred: 0.6930; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 2/1000, LR 0.000000
Train loss: 0.6925;  Loss pred: 0.6925; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 3/1000, LR 0.000030
Train loss: 0.6905;  Loss pred: 0.6905; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 4/1000, LR 0.000060
Train loss: 0.6920;  Loss pred: 0.6920; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 5/1000, LR 0.000090
Train loss: 0.6889;  Loss pred: 0.6889; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 6/1000, LR 0.000120
Train loss: 0.6913;  Loss pred: 0.6913; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 7/1000, LR 0.000150
Train loss: 0.6902;  Loss pred: 0.6902; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 8/1000, LR 0.000180
Train loss: 0.6882;  Loss pred: 0.6882; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6932 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 9/1000, LR 0.000210
Train loss: 0.6838;  Loss pred: 0.6838; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 10/1000, LR 0.000240
Train loss: 0.6830;  Loss pred: 0.6830; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 11/1000, LR 0.000270
Train loss: 0.6819;  Loss pred: 0.6819; Loss self: 0.0000; time: 0.08s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 12/1000, LR 0.000270
Train loss: 0.6754;  Loss pred: 0.6754; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 13/1000, LR 0.000270
Train loss: 0.6748;  Loss pred: 0.6748; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 14/1000, LR 0.000270
Train loss: 0.6711;  Loss pred: 0.6711; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 15/1000, LR 0.000270
Train loss: 0.6679;  Loss pred: 0.6679; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6934 score: 0.4884 time: 0.05s
Epoch 16/1000, LR 0.000270
Train loss: 0.6666;  Loss pred: 0.6666; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6931 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 17/1000, LR 0.000270
Train loss: 0.6621;  Loss pred: 0.6621; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 18/1000, LR 0.000270
Train loss: 0.6544;  Loss pred: 0.6544; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6930 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6933 score: 0.4884 time: 0.05s
Epoch 19/1000, LR 0.000270
Train loss: 0.6528;  Loss pred: 0.6528; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6932 score: 0.4884 time: 0.05s
Epoch 20/1000, LR 0.000270
Train loss: 0.6462;  Loss pred: 0.6462; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6929 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6931 score: 0.4884 time: 0.05s
Epoch 21/1000, LR 0.000270
Train loss: 0.6424;  Loss pred: 0.6424; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6928 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6930 score: 0.4884 time: 0.05s
Epoch 22/1000, LR 0.000270
Train loss: 0.6367;  Loss pred: 0.6367; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6927 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6929 score: 0.4884 time: 0.05s
Epoch 23/1000, LR 0.000270
Train loss: 0.6301;  Loss pred: 0.6301; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6926 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6928 score: 0.4884 time: 0.05s
Epoch 24/1000, LR 0.000270
Train loss: 0.6226;  Loss pred: 0.6226; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6925 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6927 score: 0.4884 time: 0.05s
Epoch 25/1000, LR 0.000270
Train loss: 0.6150;  Loss pred: 0.6150; Loss self: 0.0000; time: 0.07s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Val loss: 0.6924 score: 0.5000 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6926 score: 0.4884 time: 0.05s
Epoch 26/1000, LR 0.000270
Train loss: 0.6090;  Loss pred: 0.6090; Loss self: 0.0000; time: 0.07s
Val loss: 0.6922 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6924 score: 0.4884 time: 0.05s
Epoch 27/1000, LR 0.000270
Train loss: 0.6033;  Loss pred: 0.6033; Loss self: 0.0000; time: 0.07s
Val loss: 0.6921 score: 0.5682 time: 0.05s
Test loss: 0.6922 score: 0.5581 time: 0.05s
Epoch 28/1000, LR 0.000270
Train loss: 0.5951;  Loss pred: 0.5951; Loss self: 0.0000; time: 0.07s
Val loss: 0.6919 score: 0.7045 time: 0.05s
Test loss: 0.6920 score: 0.6977 time: 0.05s
Epoch 29/1000, LR 0.000270
Train loss: 0.5844;  Loss pred: 0.5844; Loss self: 0.0000; time: 0.07s
Val loss: 0.6917 score: 0.7727 time: 0.05s
Test loss: 0.6918 score: 0.7674 time: 0.05s
Epoch 30/1000, LR 0.000270
Train loss: 0.5748;  Loss pred: 0.5748; Loss self: 0.0000; time: 0.07s
Val loss: 0.6915 score: 0.6818 time: 0.05s
Test loss: 0.6916 score: 0.6279 time: 0.05s
Epoch 31/1000, LR 0.000270
Train loss: 0.5671;  Loss pred: 0.5671; Loss self: 0.0000; time: 0.07s
Val loss: 0.6912 score: 0.6136 time: 0.05s
Test loss: 0.6913 score: 0.5581 time: 0.05s
Epoch 32/1000, LR 0.000270
Train loss: 0.5506;  Loss pred: 0.5506; Loss self: 0.0000; time: 0.07s
Val loss: 0.6910 score: 0.5455 time: 0.05s
Test loss: 0.6911 score: 0.5349 time: 0.05s
Epoch 33/1000, LR 0.000270
Train loss: 0.5451;  Loss pred: 0.5451; Loss self: 0.0000; time: 0.07s
Val loss: 0.6907 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6907 score: 0.5116 time: 0.05s
Epoch 34/1000, LR 0.000270
Train loss: 0.5351;  Loss pred: 0.5351; Loss self: 0.0000; time: 0.07s
Val loss: 0.6903 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6904 score: 0.5116 time: 0.05s
Epoch 35/1000, LR 0.000270
Train loss: 0.5221;  Loss pred: 0.5221; Loss self: 0.0000; time: 0.07s
Val loss: 0.6898 score: 0.5227 time: 0.05s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6900 score: 0.5116 time: 0.05s
Epoch 36/1000, LR 0.000270
Train loss: 0.5112;  Loss pred: 0.5112; Loss self: 0.0000; time: 0.08s
Val loss: 0.6893 score: 0.5227 time: 0.16s
/opt/conda/envs/SAMamba/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Test loss: 0.6895 score: 0.5116 time: 0.05s
Epoch 37/1000, LR 0.000270
Train loss: 0.4988;  Loss pred: 0.4988; Loss self: 0.0000; time: 0.07s
Val loss: 0.6887 score: 0.5455 time: 0.05s
Test loss: 0.6889 score: 0.5349 time: 0.05s
Epoch 38/1000, LR 0.000270
Train loss: 0.4857;  Loss pred: 0.4857; Loss self: 0.0000; time: 0.07s
Val loss: 0.6880 score: 0.5455 time: 0.05s
Test loss: 0.6882 score: 0.5349 time: 0.05s
Epoch 39/1000, LR 0.000269
Train loss: 0.4777;  Loss pred: 0.4777; Loss self: 0.0000; time: 0.07s
Val loss: 0.6870 score: 0.5682 time: 0.05s
Test loss: 0.6874 score: 0.5349 time: 0.05s
Epoch 40/1000, LR 0.000269
Train loss: 0.4710;  Loss pred: 0.4710; Loss self: 0.0000; time: 0.07s
Val loss: 0.6860 score: 0.5682 time: 0.05s
Test loss: 0.6865 score: 0.5349 time: 0.05s
Epoch 41/1000, LR 0.000269
Train loss: 0.4371;  Loss pred: 0.4371; Loss self: 0.0000; time: 0.07s
Val loss: 0.6848 score: 0.6136 time: 0.05s
Test loss: 0.6855 score: 0.5581 time: 0.05s
Epoch 42/1000, LR 0.000269
Train loss: 0.4314;  Loss pred: 0.4314; Loss self: 0.0000; time: 0.07s
Val loss: 0.6837 score: 0.6136 time: 0.05s
Test loss: 0.6844 score: 0.5581 time: 0.05s
Epoch 43/1000, LR 0.000269
Train loss: 0.4170;  Loss pred: 0.4170; Loss self: 0.0000; time: 0.07s
Val loss: 0.6822 score: 0.6364 time: 0.05s
Test loss: 0.6832 score: 0.5581 time: 0.05s
Epoch 44/1000, LR 0.000269
Train loss: 0.3996;  Loss pred: 0.3996; Loss self: 0.0000; time: 0.07s
Val loss: 0.6807 score: 0.6591 time: 0.05s
Test loss: 0.6818 score: 0.5581 time: 0.05s
Epoch 45/1000, LR 0.000269
Train loss: 0.3910;  Loss pred: 0.3910; Loss self: 0.0000; time: 0.07s
Val loss: 0.6789 score: 0.6591 time: 0.05s
Test loss: 0.6802 score: 0.6047 time: 0.05s
Epoch 46/1000, LR 0.000269
Train loss: 0.3834;  Loss pred: 0.3834; Loss self: 0.0000; time: 0.07s
Val loss: 0.6769 score: 0.6591 time: 0.05s
Test loss: 0.6785 score: 0.6512 time: 0.05s
Epoch 47/1000, LR 0.000269
Train loss: 0.3669;  Loss pred: 0.3669; Loss self: 0.0000; time: 0.12s
Val loss: 0.6746 score: 0.6591 time: 0.07s
Test loss: 0.6764 score: 0.6744 time: 0.06s
Epoch 48/1000, LR 0.000269
Train loss: 0.3485;  Loss pred: 0.3485; Loss self: 0.0000; time: 0.07s
Val loss: 0.6721 score: 0.7273 time: 0.05s
Test loss: 0.6743 score: 0.6744 time: 0.05s
Epoch 49/1000, LR 0.000269
Train loss: 0.3318;  Loss pred: 0.3318; Loss self: 0.0000; time: 0.07s
Val loss: 0.6694 score: 0.7500 time: 0.05s
Test loss: 0.6719 score: 0.6744 time: 0.05s
Epoch 50/1000, LR 0.000269
Train loss: 0.3215;  Loss pred: 0.3215; Loss self: 0.0000; time: 0.07s
Val loss: 0.6663 score: 0.7500 time: 0.05s
Test loss: 0.6692 score: 0.6977 time: 0.05s
Epoch 51/1000, LR 0.000269
Train loss: 0.3121;  Loss pred: 0.3121; Loss self: 0.0000; time: 0.07s
Val loss: 0.6629 score: 0.7500 time: 0.05s
Test loss: 0.6661 score: 0.6977 time: 0.05s
Epoch 52/1000, LR 0.000269
Train loss: 0.2968;  Loss pred: 0.2968; Loss self: 0.0000; time: 0.07s
Val loss: 0.6591 score: 0.7727 time: 0.05s
Test loss: 0.6627 score: 0.6977 time: 0.05s
Epoch 53/1000, LR 0.000269
Train loss: 0.2838;  Loss pred: 0.2838; Loss self: 0.0000; time: 0.07s
Val loss: 0.6552 score: 0.7727 time: 0.05s
Test loss: 0.6591 score: 0.7209 time: 0.05s
Epoch 54/1000, LR 0.000269
Train loss: 0.2643;  Loss pred: 0.2643; Loss self: 0.0000; time: 0.07s
Val loss: 0.6509 score: 0.7727 time: 0.05s
Test loss: 0.6551 score: 0.7209 time: 0.05s
Epoch 55/1000, LR 0.000269
Train loss: 0.2539;  Loss pred: 0.2539; Loss self: 0.0000; time: 0.07s
Val loss: 0.6463 score: 0.7727 time: 0.05s
Test loss: 0.6509 score: 0.7209 time: 0.05s
Epoch 56/1000, LR 0.000269
Train loss: 0.2410;  Loss pred: 0.2410; Loss self: 0.0000; time: 0.07s
Val loss: 0.6412 score: 0.7727 time: 0.05s
Test loss: 0.6464 score: 0.7209 time: 0.05s
Epoch 57/1000, LR 0.000269
Train loss: 0.2248;  Loss pred: 0.2248; Loss self: 0.0000; time: 0.07s
Val loss: 0.6360 score: 0.7727 time: 0.06s
Test loss: 0.6416 score: 0.7209 time: 0.13s
Epoch 58/1000, LR 0.000269
Train loss: 0.2063;  Loss pred: 0.2063; Loss self: 0.0000; time: 0.07s
Val loss: 0.6303 score: 0.7727 time: 0.05s
Test loss: 0.6363 score: 0.7209 time: 0.05s
Epoch 59/1000, LR 0.000268
Train loss: 0.2021;  Loss pred: 0.2021; Loss self: 0.0000; time: 0.07s
Val loss: 0.6241 score: 0.7727 time: 0.05s
Test loss: 0.6306 score: 0.7209 time: 0.05s
Epoch 60/1000, LR 0.000268
Train loss: 0.1875;  Loss pred: 0.1875; Loss self: 0.0000; time: 0.07s
Val loss: 0.6175 score: 0.7727 time: 0.05s
Test loss: 0.6245 score: 0.7209 time: 0.05s
Epoch 61/1000, LR 0.000268
Train loss: 0.1789;  Loss pred: 0.1789; Loss self: 0.0000; time: 0.07s
Val loss: 0.6105 score: 0.7727 time: 0.05s
Test loss: 0.6180 score: 0.7209 time: 0.05s
Epoch 62/1000, LR 0.000268
Train loss: 0.1703;  Loss pred: 0.1703; Loss self: 0.0000; time: 0.07s
Val loss: 0.6035 score: 0.7727 time: 0.05s
Test loss: 0.6114 score: 0.7209 time: 0.05s
Epoch 63/1000, LR 0.000268
Train loss: 0.1609;  Loss pred: 0.1609; Loss self: 0.0000; time: 0.07s
Val loss: 0.5956 score: 0.7727 time: 0.05s
Test loss: 0.6042 score: 0.7209 time: 0.05s
Epoch 64/1000, LR 0.000268
Train loss: 0.1478;  Loss pred: 0.1478; Loss self: 0.0000; time: 0.07s
Val loss: 0.5874 score: 0.7727 time: 0.05s
Test loss: 0.5967 score: 0.7209 time: 0.05s
Epoch 65/1000, LR 0.000268
Train loss: 0.1469;  Loss pred: 0.1469; Loss self: 0.0000; time: 0.07s
Val loss: 0.5788 score: 0.7727 time: 0.05s
Test loss: 0.5892 score: 0.7442 time: 0.05s
Epoch 66/1000, LR 0.000268
Train loss: 0.1284;  Loss pred: 0.1284; Loss self: 0.0000; time: 0.07s
Val loss: 0.5696 score: 0.7727 time: 0.05s
Test loss: 0.5808 score: 0.7442 time: 0.05s
Epoch 67/1000, LR 0.000268
Train loss: 0.1206;  Loss pred: 0.1206; Loss self: 0.0000; time: 0.06s
Val loss: 0.5599 score: 0.7727 time: 0.05s
Test loss: 0.5720 score: 0.7442 time: 0.05s
Epoch 68/1000, LR 0.000268
Train loss: 0.1106;  Loss pred: 0.1106; Loss self: 0.0000; time: 0.18s
Val loss: 0.5497 score: 0.7727 time: 0.05s
Test loss: 0.5627 score: 0.7442 time: 0.05s
Epoch 69/1000, LR 0.000268
Train loss: 0.1035;  Loss pred: 0.1035; Loss self: 0.0000; time: 0.07s
Val loss: 0.5394 score: 0.7727 time: 0.05s
Test loss: 0.5533 score: 0.7442 time: 0.05s
Epoch 70/1000, LR 0.000268
Train loss: 0.0974;  Loss pred: 0.0974; Loss self: 0.0000; time: 0.07s
Val loss: 0.5291 score: 0.7727 time: 0.05s
Test loss: 0.5439 score: 0.7442 time: 0.05s
Epoch 71/1000, LR 0.000268
Train loss: 0.0866;  Loss pred: 0.0866; Loss self: 0.0000; time: 0.07s
Val loss: 0.5184 score: 0.7727 time: 0.05s
Test loss: 0.5341 score: 0.7674 time: 0.05s
Epoch 72/1000, LR 0.000267
Train loss: 0.0824;  Loss pred: 0.0824; Loss self: 0.0000; time: 0.07s
Val loss: 0.5075 score: 0.7727 time: 0.05s
Test loss: 0.5240 score: 0.7674 time: 0.05s
Epoch 73/1000, LR 0.000267
Train loss: 0.0782;  Loss pred: 0.0782; Loss self: 0.0000; time: 0.07s
Val loss: 0.4966 score: 0.7727 time: 0.05s
Test loss: 0.5139 score: 0.7674 time: 0.05s
Epoch 74/1000, LR 0.000267
Train loss: 0.0677;  Loss pred: 0.0677; Loss self: 0.0000; time: 0.06s
Val loss: 0.4862 score: 0.7727 time: 0.05s
Test loss: 0.5042 score: 0.7907 time: 0.05s
Epoch 75/1000, LR 0.000267
Train loss: 0.0642;  Loss pred: 0.0642; Loss self: 0.0000; time: 0.07s
Val loss: 0.4756 score: 0.7955 time: 0.05s
Test loss: 0.4941 score: 0.7907 time: 0.05s
Epoch 76/1000, LR 0.000267
Train loss: 0.0593;  Loss pred: 0.0593; Loss self: 0.0000; time: 0.07s
Val loss: 0.4654 score: 0.7955 time: 0.05s
Test loss: 0.4843 score: 0.7907 time: 0.05s
Epoch 77/1000, LR 0.000267
Train loss: 0.0584;  Loss pred: 0.0584; Loss self: 0.0000; time: 0.07s
Val loss: 0.4557 score: 0.7955 time: 0.05s
Test loss: 0.4746 score: 0.7907 time: 0.05s
Epoch 78/1000, LR 0.000267
Train loss: 0.0495;  Loss pred: 0.0495; Loss self: 0.0000; time: 0.07s
Val loss: 0.4466 score: 0.7955 time: 0.20s
Test loss: 0.4654 score: 0.7907 time: 0.07s
Epoch 79/1000, LR 0.000267
Train loss: 0.0534;  Loss pred: 0.0534; Loss self: 0.0000; time: 0.09s
Val loss: 0.4385 score: 0.7955 time: 0.05s
Test loss: 0.4572 score: 0.7907 time: 0.05s
Epoch 80/1000, LR 0.000267
Train loss: 0.0427;  Loss pred: 0.0427; Loss self: 0.0000; time: 0.07s
Val loss: 0.4317 score: 0.7955 time: 0.05s
Test loss: 0.4501 score: 0.7907 time: 0.05s
Epoch 81/1000, LR 0.000267
Train loss: 0.0392;  Loss pred: 0.0392; Loss self: 0.0000; time: 0.07s
Val loss: 0.4256 score: 0.7955 time: 0.05s
Test loss: 0.4435 score: 0.7907 time: 0.05s
Epoch 82/1000, LR 0.000267
Train loss: 0.0372;  Loss pred: 0.0372; Loss self: 0.0000; time: 0.07s
Val loss: 0.4206 score: 0.7955 time: 0.05s
Test loss: 0.4379 score: 0.7907 time: 0.05s
Epoch 83/1000, LR 0.000266
Train loss: 0.0340;  Loss pred: 0.0340; Loss self: 0.0000; time: 0.07s
Val loss: 0.4160 score: 0.7955 time: 0.05s
Test loss: 0.4324 score: 0.7907 time: 0.05s
Epoch 84/1000, LR 0.000266
Train loss: 0.0308;  Loss pred: 0.0308; Loss self: 0.0000; time: 0.07s
Val loss: 0.4121 score: 0.7955 time: 0.05s
Test loss: 0.4273 score: 0.8140 time: 0.05s
Epoch 85/1000, LR 0.000266
Train loss: 0.0284;  Loss pred: 0.0284; Loss self: 0.0000; time: 0.07s
Val loss: 0.4091 score: 0.7955 time: 0.05s
Test loss: 0.4227 score: 0.8140 time: 0.05s
Epoch 86/1000, LR 0.000266
Train loss: 0.0259;  Loss pred: 0.0259; Loss self: 0.0000; time: 0.07s
Val loss: 0.4073 score: 0.7955 time: 0.05s
Test loss: 0.4194 score: 0.8140 time: 0.05s
Epoch 87/1000, LR 0.000266
Train loss: 0.0241;  Loss pred: 0.0241; Loss self: 0.0000; time: 0.07s
Val loss: 0.4059 score: 0.7955 time: 0.05s
Test loss: 0.4164 score: 0.8140 time: 0.05s
Epoch 88/1000, LR 0.000266
Train loss: 0.0238;  Loss pred: 0.0238; Loss self: 0.0000; time: 0.07s
Val loss: 0.4052 score: 0.7955 time: 0.05s
Test loss: 0.4137 score: 0.8140 time: 0.17s
Epoch 89/1000, LR 0.000266
Train loss: 0.0237;  Loss pred: 0.0237; Loss self: 0.0000; time: 0.07s
Val loss: 0.4053 score: 0.7955 time: 0.05s
Test loss: 0.4117 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 1 of 20
Epoch 90/1000, LR 0.000266
Train loss: 0.0231;  Loss pred: 0.0231; Loss self: 0.0000; time: 0.06s
Val loss: 0.4064 score: 0.7955 time: 0.05s
Test loss: 0.4108 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 2 of 20
Epoch 91/1000, LR 0.000266
Train loss: 0.0191;  Loss pred: 0.0191; Loss self: 0.0000; time: 0.07s
Val loss: 0.4086 score: 0.7955 time: 0.05s
Test loss: 0.4109 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 3 of 20
Epoch 92/1000, LR 0.000266
Train loss: 0.0173;  Loss pred: 0.0173; Loss self: 0.0000; time: 0.07s
Val loss: 0.4108 score: 0.7955 time: 0.05s
Test loss: 0.4103 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 4 of 20
Epoch 93/1000, LR 0.000265
Train loss: 0.0170;  Loss pred: 0.0170; Loss self: 0.0000; time: 0.07s
Val loss: 0.4141 score: 0.7955 time: 0.05s
Test loss: 0.4111 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 5 of 20
Epoch 94/1000, LR 0.000265
Train loss: 0.0156;  Loss pred: 0.0156; Loss self: 0.0000; time: 0.07s
Val loss: 0.4181 score: 0.7955 time: 0.05s
Test loss: 0.4126 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 6 of 20
Epoch 95/1000, LR 0.000265
Train loss: 0.0146;  Loss pred: 0.0146; Loss self: 0.0000; time: 0.07s
Val loss: 0.4227 score: 0.7955 time: 0.05s
Test loss: 0.4147 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 7 of 20
Epoch 96/1000, LR 0.000265
Train loss: 0.0142;  Loss pred: 0.0142; Loss self: 0.0000; time: 0.07s
Val loss: 0.4275 score: 0.7955 time: 0.05s
Test loss: 0.4170 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 8 of 20
Epoch 97/1000, LR 0.000265
Train loss: 0.0141;  Loss pred: 0.0141; Loss self: 0.0000; time: 0.07s
Val loss: 0.4329 score: 0.7955 time: 0.05s
Test loss: 0.4202 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 9 of 20
Epoch 98/1000, LR 0.000265
Train loss: 0.0115;  Loss pred: 0.0115; Loss self: 0.0000; time: 0.07s
Val loss: 0.4385 score: 0.7955 time: 0.05s
Test loss: 0.4230 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 10 of 20
Epoch 99/1000, LR 0.000265
Train loss: 0.0109;  Loss pred: 0.0109; Loss self: 0.0000; time: 0.07s
Val loss: 0.4445 score: 0.7955 time: 0.15s
Test loss: 0.4262 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 11 of 20
Epoch 100/1000, LR 0.000265
Train loss: 0.0103;  Loss pred: 0.0103; Loss self: 0.0000; time: 0.07s
Val loss: 0.4505 score: 0.7955 time: 0.05s
Test loss: 0.4293 score: 0.8140 time: 0.05s
     INFO: Early stopping counter 12 of 20
Epoch 101/1000, LR 0.000265
Train loss: 0.0098;  Loss pred: 0.0098; Loss self: 0.0000; time: 0.07s
Val loss: 0.4567 score: 0.7955 time: 0.05s
Test loss: 0.4323 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 13 of 20
Epoch 102/1000, LR 0.000264
Train loss: 0.0095;  Loss pred: 0.0095; Loss self: 0.0000; time: 0.07s
Val loss: 0.4635 score: 0.7955 time: 0.05s
Test loss: 0.4363 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 14 of 20
Epoch 103/1000, LR 0.000264
Train loss: 0.0097;  Loss pred: 0.0097; Loss self: 0.0000; time: 0.07s
Val loss: 0.4694 score: 0.7955 time: 0.05s
Test loss: 0.4396 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 15 of 20
Epoch 104/1000, LR 0.000264
Train loss: 0.0084;  Loss pred: 0.0084; Loss self: 0.0000; time: 0.07s
Val loss: 0.4754 score: 0.7955 time: 0.05s
Test loss: 0.4428 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 16 of 20
Epoch 105/1000, LR 0.000264
Train loss: 0.0085;  Loss pred: 0.0085; Loss self: 0.0000; time: 0.07s
Val loss: 0.4804 score: 0.7955 time: 0.05s
Test loss: 0.4452 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 17 of 20
Epoch 106/1000, LR 0.000264
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.07s
Val loss: 0.4857 score: 0.7955 time: 0.05s
Test loss: 0.4479 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 18 of 20
Epoch 107/1000, LR 0.000264
Train loss: 0.0080;  Loss pred: 0.0080; Loss self: 0.0000; time: 0.07s
Val loss: 0.4912 score: 0.7955 time: 0.05s
Test loss: 0.4505 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 19 of 20
Epoch 108/1000, LR 0.000264
Train loss: 0.0079;  Loss pred: 0.0079; Loss self: 0.0000; time: 0.07s
Val loss: 0.4971 score: 0.7955 time: 0.05s
Test loss: 0.4541 score: 0.8372 time: 0.05s
     INFO: Early stopping counter 20 of 20
     INFO: Early stopping

=====final results=====
Exp: 1,  Epoch: 087,   Train_Loss: 0.0238,   Val_Loss: 0.4052,   Val_Precision: 0.9333,   Val_Recall: 0.6364,   Val_accuracy: 0.7568,   Val_Score: 0.7955,   Val_Loss: 0.4052,   Test_Precision: 1.0000,   Test_Recall: 0.6190,   Test_accuracy: 0.7647,   Test_Score: 0.8140,   Test_loss: 0.4137


[0.05117114703170955, 0.05100728594698012, 0.05053778307046741, 0.050774551928043365, 0.05061662499792874, 0.05078648799099028, 0.05041044391691685, 0.050772582995705307, 0.050492285983636975, 0.0514059669803828, 0.05070261796936393, 0.05049758707173169, 0.05075423594098538, 0.05066299298778176, 0.05135265598073602, 0.050913013983517885, 0.05093683092854917, 0.050994510063901544, 0.05093730695080012, 0.050953872967511415, 0.051065757987089455, 0.051831852993927896, 0.051832168945111334, 0.05224371107760817, 0.05281137605197728, 0.05236614099703729, 0.05285306298173964, 0.05220677005127072, 0.05255464592482895, 0.052813366055488586, 0.05266587494406849, 0.052671821089461446, 0.05292598903179169, 0.05280704202596098, 0.05275611497927457, 0.053035911987535655, 0.05275688203983009, 0.053226787014864385, 0.05242182908114046, 0.05250273598358035, 0.05300009099300951, 0.053193735890090466, 0.053916533943265676, 0.053466391982510686, 0.053462789044715464, 0.05346440395805985, 0.05358131800312549, 0.05346363200806081, 0.05341960198711604, 0.053656380041502416, 0.053919265046715736, 0.05398705799598247, 0.05434361798688769, 0.05371444602496922, 0.05405532498843968, 0.05384330393280834, 0.05382030305918306, 0.05378766206558794, 0.05373361404053867, 0.05329057201743126, 0.053331964067183435, 0.053577913087792695, 0.05391327303368598, 0.05376420798711479, 0.0536971150431782, 0.05347238597460091, 0.05407295993063599, 0.05432304192800075, 0.05405527399852872, 0.053915036958642304, 0.05394854093901813, 0.05403515207581222, 0.05381889804266393, 0.05462380894459784, 0.05395496706478298, 0.05379726400133222, 0.05384487798437476, 0.0531702870503068, 0.05250312201678753, 0.05237758404109627, 0.05224739795085043, 0.05277929897420108, 0.052545149927027524, 0.05278460402041674, 0.05273181293159723, 0.051816293969750404, 0.051530287018977106, 0.0526393799809739, 0.06662760593462735, 0.05768884997814894, 0.05605880497023463, 0.051639409037306905, 0.05180140398442745, 0.05172726802993566, 0.05302905000280589, 0.052733647054992616, 0.052304149023257196, 0.05272604897618294, 0.13837701303418726, 0.05684621003456414, 0.057595612946897745, 0.051812903955578804, 0.051650129025802016, 0.05171575699932873, 0.05249348096549511, 0.05462394189089537, 0.05119938403367996, 0.051464776042848825, 0.051780818961560726, 0.053041781997308135, 0.05281736794859171, 0.051937823998741806, 0.05181089194957167, 0.05216512398328632, 0.05237602605484426, 0.05379372998140752, 0.052813054993748665, 0.05260246095713228, 0.052235427079722285, 0.07598310406319797, 0.05231231893412769, 0.05318972794339061, 0.05323338904418051, 0.05285141395870596, 0.053137599024921656, 0.05386748490855098, 0.05318867391906679, 0.05274024396203458, 0.05310635804198682, 0.17134266498032957, 0.05603828502353281, 0.05177231796551496, 0.05179638194385916, 0.052292534965090454, 0.05217934993561357, 0.05209750100038946, 0.0531434949953109, 0.05283944006077945, 0.05220960802398622, 0.05216660792939365, 0.05600516404956579, 0.056002452969551086, 0.05623012292198837, 0.0563836139626801, 0.05627741408534348, 0.05644355702679604, 0.05736164306290448, 0.05251670198049396, 0.052078044041991234, 0.052827178966253996]
[0.0011629806143570352, 0.0011592564987950027, 0.0011485859788742594, 0.0011539670892737129, 0.0011503778408620167, 0.0011542383634315972, 0.0011456919072026556, 0.0011539223408114842, 0.0011475519541735675, 0.0011683174313723364, 0.001152332226576453, 0.0011476724334484475, 0.0011535053622951223, 0.001151431658813222, 0.0011671058177440004, 0.001157113954170861, 0.0011576552483761175, 0.0011589661378159442, 0.001157666067063639, 0.0011580425674434412, 0.0011605854087974876, 0.0012053919300913465, 0.0012053992777932869, 0.001214970025060655, 0.0012281715360924947, 0.0012178172324892394, 0.0012291409995753406, 0.0012141109314249005, 0.0012222010680192777, 0.0012282178152439205, 0.0012247877893969417, 0.0012249260718479407, 0.0012308369542277137, 0.0012280707447897903, 0.0012268863948668505, 0.001233393302035713, 0.0012269042334844206, 0.0012378322561596368, 0.0012191123042125688, 0.001220993860083264, 0.001232560255651384, 0.001237063625350941, 0.0012538728824015273, 0.0012434044647095508, 0.0012433206754584993, 0.0012433582315827872, 0.0012460771628633835, 0.0012433402792572281, 0.0012423163252817684, 0.0012478227916628468, 0.0012539363964352496, 0.0012555129766507551, 0.0012638050694625045, 0.0012491731633713773, 0.0012571005811265043, 0.0012521698589025194, 0.0012516349548647224, 0.0012508758619904172, 0.001249618931175318, 0.0012393156283123548, 0.001240278234120545, 0.0012459979787858766, 0.0012537970472950228, 0.001250330418304995, 0.001248770117283214, 0.0012435438598744398, 0.001257510696061302, 0.0012633265564651337, 0.0012570993953146213, 0.001253838068805635, 0.0012546172311399565, 0.00125663144362354, 0.0012516022800619518, 0.0012703211382464614, 0.0012547666759251854, 0.0012510991628216796, 0.0012522064647529014, 0.001236518303495507, 0.00122100283759971, 0.0012180833497929366, 0.0012150557662988471, 0.0012274255575395602, 0.0012219802308611053, 0.001227548930707366, 0.0012263212309673774, 0.0012050300923197768, 0.0011983787678831884, 0.0012241716274645092, 0.0015494792077820315, 0.0013416011622825333, 0.001303693138842666, 0.0012009164892396954, 0.001204683813591336, 0.0012029597216264107, 0.0012332337209954858, 0.0012263638849998283, 0.0012163755586804, 0.0012261871854926264, 0.003218070070562494, 0.0013220048845247474, 0.00133943285923018, 0.0012049512547809024, 0.0012011657912977213, 0.0012026920232402032, 0.0012207786271045374, 0.0012703242300208225, 0.0011906833496204642, 0.0011968552568104379, 0.0012042050921293192, 0.001233529813890887, 0.0012283108825253885, 0.0012078563720637628, 0.0012049044639435272, 0.001213142418215961, 0.0012180471175545176, 0.0012510169763118029, 0.001228210581249969, 0.0012233130455147042, 0.0012147773739470298, 0.0017670489317022783, 0.0012165655566076206, 0.0012369704172881537, 0.0012379857917251282, 0.0012291026502024643, 0.0012357581168586432, 0.001252732207175604, 0.0012369459050945765, 0.0012265173014426648, 0.0012350315823717866, 0.003984713139077432, 0.0013032159307798327, 0.0012040073945468596, 0.001204567021950213, 0.0012161054643044292, 0.0012134732543165948, 0.0012115697907067317, 0.0012358952324490907, 0.0012288241874599873, 0.0012141769307903773, 0.00121317692859055, 0.0013024456755712974, 0.0013023826271988624, 0.0013076772772555435, 0.0013112468363413977, 0.001308777071752174, 0.00131264086108828, 0.0013339916991373134, 0.001221318650709162, 0.0012111173033021218, 0.001228539045726837]
[859.8595605592784, 862.6218624087568, 870.6357368040572, 866.5758402428816, 869.2796092548743, 866.3721737916937, 872.8350036456311, 866.60944556872, 871.4202405939607, 855.9317640458156, 867.805288211866, 871.3287614613768, 866.9227146116654, 868.4840236464385, 856.820336936531, 864.2191172230376, 863.8150273172727, 862.8379789287773, 863.8069547433906, 863.5261156311855, 861.6341308617051, 829.605686777925, 829.6006297852531, 823.065573119861, 814.2185115131092, 821.1412791030907, 813.576310891503, 823.6479666865231, 818.1959795049262, 814.1878318231386, 816.4679699267559, 816.3757984931989, 812.4552943955507, 814.2853367711896, 815.0713906225412, 810.7713884528983, 815.0595398631805, 807.8639048415904, 820.2689748471577, 819.0049374464556, 811.3193618039546, 808.3658588832172, 797.5290111424312, 804.2435332847159, 804.2977324665096, 804.2734383372411, 802.5185195610854, 804.2850510701707, 804.9479666728126, 801.3958445713284, 797.4886149272386, 796.4871877848931, 791.2612666012642, 800.5295257073191, 795.4812964161443, 798.6136967683146, 798.95499571445, 799.4398408238378, 800.2439584197552, 806.8969495379928, 806.2706999845715, 802.5695201965082, 797.5772491707714, 799.7885881682745, 800.7879001585732, 804.1533815308852, 795.2218642212259, 791.5609743834265, 795.482046787338, 797.5511550327765, 797.0558471378486, 795.7782729966278, 798.9758535359188, 787.2025190263228, 796.9609164689231, 799.2971538280303, 798.5903508311072, 808.7223595260219, 818.9989156502166, 820.9618825920174, 823.0074929367864, 814.7133598917015, 818.3438444788259, 814.6314782122432, 815.4470254185804, 829.8547948084201, 834.4607120888799, 816.8789225014052, 645.3781341354224, 745.3780066041757, 767.0516705240431, 832.697368185113, 830.0933313106083, 831.283028036876, 810.8763026628758, 815.4186634419196, 822.1145129591903, 815.5361692173004, 310.74525354421746, 756.426857196896, 746.5846407372264, 829.909090539792, 832.5245417783794, 831.4680572220598, 819.1493345290753, 787.2006030961155, 839.8538539392144, 835.5229208458777, 830.4233278334372, 810.6816622824294, 814.1261420268581, 827.9130061560084, 829.9413189383529, 824.3055266920707, 820.9863030649483, 799.3496642612789, 814.1926272791792, 817.4522487653632, 823.1961027976841, 565.9152851170085, 821.9861186835576, 808.4267707810905, 807.7637131897161, 813.6016953793686, 809.2198516502957, 798.2552011292091, 808.4427911368851, 815.3166684430553, 809.6958930228927, 250.95909419254377, 767.3325474172258, 830.5596830460997, 830.1738149704482, 822.297102802647, 824.0807915978182, 825.3754820155107, 809.1300732816705, 813.7860649268525, 823.6031954165385, 824.2820782635426, 767.7863413085275, 767.8235098626732, 764.7146718789259, 762.632917224167, 764.0720651235224, 761.8230009775281, 749.629852004848, 818.787135871009, 825.6838518230162, 813.9749432289087]
Elapsed: 0.05452351278935869~0.012107252148115803
Time per graph: 0.0012642263490700938~0.0002828580902909679
Speed: 806.0835813318985~71.1376059618872
Total Time: 0.0535
best val loss: 0.4051871597766876 test_score: 0.8140

Testing...
Test loss: 0.4941 score: 0.7907 time: 0.05s
test Score 0.7907
Epoch Time List: [0.1647911979816854, 0.16073282796423882, 0.16090723604429513, 0.16036989504937083, 0.16099647292867303, 0.16066788288298994, 0.15984041197225451, 0.1605893480591476, 0.16047968703787774, 0.1599180728662759, 0.16127789998427033, 0.1618440969614312, 0.1611698690103367, 0.16109954996500164, 0.16101031203288585, 0.16110299306456, 0.16016995592508465, 0.1616735371062532, 0.16119990614242852, 0.16077687707729638, 0.16231202194467187, 0.16120251803658903, 0.15967755811288953, 0.16021521494258195, 0.1647674081614241, 0.1623883469728753, 0.16364081902429461, 0.1623837579973042, 0.1617552200332284, 0.16446033609099686, 0.16355250705964863, 0.16371880401857197, 0.1635595520492643, 0.1645534149138257, 0.16325932904146612, 0.16361964109819382, 0.1636988348327577, 0.16338657902088016, 0.16209136182442307, 0.16316042887046933, 0.16358276188839227, 0.16433814296033233, 0.1672747409902513, 0.16472808388061821, 0.16706596803851426, 0.1658647310687229, 0.16470676905009896, 0.16526955692097545, 0.16520496702287346, 0.16552663908805698, 0.16688366595190018, 0.16647747403476387, 0.1755131249083206, 0.16587917204014957, 0.1645925510674715, 0.16597080288920552, 0.1665248820791021, 0.16673179692588747, 0.16587710194289684, 0.1656600551214069, 0.16550248605199158, 0.16699343489017338, 0.1662912709871307, 0.16600150091107935, 0.1661077570170164, 0.16643532493617386, 0.16845084889791906, 0.16767336102202535, 0.16689138894435018, 0.16818016895558685, 0.16906808596104383, 0.16659246699418873, 0.16876767785288393, 0.16909106203820556, 0.16663373808842152, 0.16502178297378123, 0.1659694310510531, 0.28354425786528736, 0.16316782287321985, 0.16353748191613704, 0.16227889608126134, 0.16307499282993376, 0.1640542319510132, 0.1663396619260311, 0.16656908206641674, 0.1618857050780207, 0.16001885710284114, 0.16061660193372518, 0.2512573200510815, 0.17587910895235837, 0.17589226982090622, 0.16601745504885912, 0.15865588001906872, 0.16002199694048613, 0.16035100899171084, 0.1681720910128206, 0.16257163393311203, 0.1613485749112442, 0.26540060597471893, 0.1808334490051493, 0.17009071493521333, 0.16672099102288485, 0.15945196500979364, 0.1603778979042545, 0.16069098003208637, 0.17416968406178057, 0.16143363004084677, 0.158655179082416, 0.15740342799108475, 0.2737070599105209, 0.16159654804505408, 0.1603232549969107, 0.15959883108735085, 0.16039377299603075, 0.1605555840069428, 0.1619107361184433, 0.1674216219689697, 0.16278406500350684, 0.16088451095856726, 0.3331526370020583, 0.18910471897106618, 0.16312540508806705, 0.16605502099264413, 0.1657631000271067, 0.16658726998139173, 0.16570280387531966, 0.16490215598605573, 0.16433935496024787, 0.16421740502119064, 0.28395526693202555, 0.178753198008053, 0.15760894108098, 0.16001006914302707, 0.1602826069574803, 0.16039133886806667, 0.1603606449207291, 0.1616351221455261, 0.1619049438741058, 0.16113841405604035, 0.16123213397804648, 0.26739943702705204, 0.1722838900750503, 0.17237890895921737, 0.17157596698962152, 0.1716404240578413, 0.1741045821690932, 0.1767589570954442, 0.16322198510169983, 0.16075041296426207, 0.16118690592702478]
Total Epoch List: [21, 21, 108]
Total Time List: [0.0513934480259195, 0.05359590798616409, 0.05348683393094689]
T-times Epoch Time: 0.17452699286282117 ~ 0.0036824825850071373
T-times Total Epoch: 91.66666666666667 ~ 29.46309681744392
T-times Total Time: 0.05493079632934597 ~ 0.002136540035323898
T-times Inference Elapsed: 0.05510532147810961 ~ 0.0004382238130277012
T-times Time Per Graph: 0.0012738275972227293 ~ 7.66629742361823e-06
T-times Speed: 798.8271478384304 ~ 5.339581916134603
T-times cross validation test micro f1 score:0.6971381223955203 ~ 0.10684392419931031
T-times cross validation test precision:0.7672435135670429 ~ 0.18935148075146552
T-times cross validation test recall:0.6717171717171717 ~ 0.0933667653568283
T-times cross validation test f1_score:0.6971381223955203 ~ 0.15560427690699083
